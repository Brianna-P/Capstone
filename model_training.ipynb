{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b25f859b-559e-4007-a500-1762ea9f2276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (4.49.0)\n",
      "Requirement already satisfied: datasets in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (3.5.0)\n",
      "Requirement already satisfied: accelerate in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (1.6.0)\n",
      "Requirement already satisfied: peft in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (0.15.1)\n",
      "Requirement already satisfied: bitsandbytes in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (0.45.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (19.0.1)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets) (2024.12.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from datasets) (3.11.14)\n",
      "Requirement already satisfied: psutil in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from accelerate) (2.7.0+cu118)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp->datasets) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp->datasets) (1.3.2)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp->datasets) (5.0.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp->datasets) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp->datasets) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp->datasets) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp->datasets) (0.3.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from aiohttp->datasets) (1.18.3)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from torch>=2.0.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from torch>=2.0.0->accelerate) (3.1.5)\n",
      "Requirement already satisfied: colorama in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from pandas->datasets) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from pandas->datasets) (2025.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.0 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu118\n",
      "Requirement already satisfied: torch in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (2.7.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (0.22.0+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (2.7.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from torch) (3.17.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from torch) (3.1.5)\n",
      "Requirement already satisfied: fsspec in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from torchvision) (1.26.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from torchvision) (10.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jason chen\\appdata\\roaming\\python\\python39\\site-packages (from jinja2->torch) (3.0.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers datasets accelerate peft bitsandbytes\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d1a4b90-4bfa-465b-af13-41a3e09c7460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "#\n",
    "# Use GPU if possible\n",
    "#\n",
    "torch.cuda.empty_cache()\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c02520b-47dc-45ad-9fb3-7f9fabd9badb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e23947616c3c44e1b95ebdab85d24579",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import login\n",
    "\n",
    "login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "32adb204-5ad1-4534-9554-467d20136161",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "#\n",
    "# Load Model from HuggingFace\n",
    "#\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")\n",
    "model = model.to(device)\n",
    "print(\"Model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4ab97c72-333a-4bcb-a1aa-6f539efbb301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data loaded successfully.\n",
      "                                           Esgish  \\\n",
      "0      [AbortifacientsDistrMaxRevRatio1Y] < '0.1'   \n",
      "1     [AbortifacientsDistrMaxRevRatio1Y] > '0.01'   \n",
      "2        [AbortifacientsDistrMaxRevRatio3Y] > '0'   \n",
      "3  [AbortifacientsInvolvement] ANY 'Distribution'   \n",
      "4    [AbortifacientsInvolvement] ANY 'Production'   \n",
      "\n",
      "                                             English  \n",
      "0  All companies or issuers where the maximum sha...  \n",
      "1  All companies or issuers where the maximum sha...  \n",
      "2  All companies that have a maximum share of rev...  \n",
      "3  All companies or issuers that are involved in ...  \n",
      "4  All companies or issuers that produce abortifa...  \n",
      "{'input': \"Convert Esgish to English: AND([FossilFuelOilPowerRevShareMin] > '0.1',[FossilFuelOilExtractRevShareMin] > '0.05',[FossilFuelGasExtractRevShareMin] > '0.05',[OilSandsProdMinRev] > '0.01',[HydraulicFracturingShareMin] > '0.01',[NuclearPowerRevShareMin] > '0.1',[NuclearPowerUraniumRevShareMin] > '0.1')\", 'output': 'The query is asking for all companies or issuers that have a minimum of 1% revenue from oil power, 5% revenue from oil extraction, 5% revenue from gas extraction, 1% revenue from oil sands production, 1% revenue from hydraulic fracturing, and 1% revenue from nuclear power, and at least 1% revenue from uranium mining.'}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4194385b7084145b2b8018dce0367ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/694 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a506f3132894a7c9117cd5393d0734b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/87 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ea4b78612664b3dbe820ddc1af81b4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/87 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [1193, 3027, 1122, 122, 1273, 12, 1566, 10, 3430, 599, 6306, 371, 32, 7, 7, 173, 371, 76, 15, 40, 667, 173, 23553, 1649, 208, 24501, 12858, 908, 2490, 3, 31, 16029, 31, 6, 6306, 371, 32, 7, 7, 173, 371, 76, 15, 40, 667, 173, 5420, 6471, 17, 1649, 208, 24501, 12858, 908, 2490, 3, 31, 25079, 31, 6, 6306, 371, 32, 7, 7, 173, 371, 76, 15, 40, 517, 9, 7, 5420, 6471, 17, 1649, 208, 24501, 12858, 908, 2490, 3, 31, 25079, 31, 6, 6306, 667, 173, 134, 232, 7, 3174, 26, 12858, 1649, 208, 908, 2490, 3, 31, 11739, 536, 31, 6, 6306, 566, 63, 3515, 83, 447, 371, 3738, 17, 7920, 24501, 12858, 908, 2490, 3, 31, 11739, 536, 31, 6, 6306, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [37, 11417, 19, 3558, 21, 66, 688, 42, 962, 52, 7, 24, 43, 3, 9, 2559, 13, 3, 4704, 3751, 45, 1043, 579, 6, 3, 2712, 3751, 45, 1043, 16629, 6, 3, 2712, 3751, 45, 1807, 16629, 6, 3, 4704, 3751, 45, 1043, 3, 7, 232, 7, 999, 6, 3, 4704, 3751, 45, 20320, 3, 9880, 17, 7920, 6, 11, 3, 4704, 3751, 45, 6414, 579, 6, 11, 44, 709, 3, 4704, 3751, 45, 3, 2414, 29, 2552, 5558, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset, Dataset\n",
    "#\n",
    "# \n",
    "# Format Data for English to Esgish translation and vice versa\n",
    "#\n",
    "#\n",
    "#\n",
    "\n",
    "# Path to Excel File\n",
    "train_excel_path = \"translated_queries_TEST2.xlsx\"\n",
    "train_df = pd.read_excel(train_excel_path)\n",
    "\n",
    "# Excel file should have two columns, \"Esgish\", and \"English\"\n",
    "expected_columns = [\"Esgish\", \"English\"]\n",
    "train_df.rename(columns=lambda x: x.strip(), inplace=True)\n",
    "\n",
    "for col in expected_columns:\n",
    "    assert col in train_df.columns, f\"Missing expected column: {col}\"\n",
    "print(\"Training data loaded successfully.\")\n",
    "print(train_df.head())\n",
    "\n",
    "train_data = []\n",
    "\n",
    "for _, row in train_df.iterrows():\n",
    "    # Format Data for English to Esgish\n",
    "    train_data.append({\n",
    "        \"input\": f\"Convert English to Esgish: {row['English']}\",\n",
    "        \"output\": row['Esgish']\n",
    "    })\n",
    "    # Format Data for Esgish to English\n",
    "    train_data.append({\n",
    "        \"input\": f\"Convert Esgish to English: {row['Esgish']}\",\n",
    "        \"output\": row[\"English\"]\n",
    "    })\n",
    "\n",
    "# Splits dataset into training data and other data for evaluation and test\n",
    "train_list = Dataset.from_list(train_data)\n",
    "split = train_list.train_test_split(test_size=0.2)\n",
    "train_dataset = split['train']\n",
    "temp_dataset = split['test']\n",
    "\n",
    "# Split temp into validation / test\n",
    "split_temp = temp_dataset.train_test_split(test_size=0.5, seed=42)\n",
    "eval_dataset = split_temp['train']\n",
    "test_dataset = split_temp['test']\n",
    "print(train_dataset[0])\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = tokenizer(examples[\"input\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "    labels = tokenizer(examples[\"output\"], max_length=128, truncation=True, padding=\"max_length\")    \n",
    "    model_inputs = {\n",
    "        \"input_ids\": inputs[\"input_ids\"],\n",
    "        \"attention_mask\": inputs[\"attention_mask\"],\n",
    "        \"labels\": labels[\"input_ids\"], \n",
    "    }\n",
    "    return model_inputs\n",
    "\n",
    "train_dataset = train_dataset.map(preprocess_function, batched=True, remove_columns=[\"input\", \"output\"])\n",
    "eval_dataset = eval_dataset.map(preprocess_function, batched=True, remove_columns=[\"input\", \"output\"])\n",
    "test_dataset = test_dataset.map(preprocess_function, batched=True, remove_columns=[\"input\", \"output\"])\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "996291bb-3007-4358-9515-5af3a9874a6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jason Chen\\AppData\\Roaming\\Python\\Python39\\site-packages\\transformers\\optimization.py:640: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='215' max='215' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [215/215 02:29, Epoch 4/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.592700</td>\n",
       "      <td>0.534204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.524200</td>\n",
       "      <td>0.505907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.481200</td>\n",
       "      <td>0.484658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.394000</td>\n",
       "      <td>0.462294</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "There were missing keys in the checkpoint model loaded: ['encoder.embed_tokens.weight', 'decoder.embed_tokens.weight'].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training done\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrainingArguments, Trainer, DataCollatorForSeq2Seq, T5Tokenizer, EarlyStoppingCallback\n",
    "from transformers import AdamW, get_scheduler\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./test\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=5e-5,\n",
    "    per_device_train_batch_size=4, #Can be increased if GPU has more VRAM, originally was 4\n",
    "    per_device_eval_batch_size=4, #Can be increased if GPU has more VRAM, originally was 4\n",
    "    gradient_accumulation_steps=4,\n",
    "    num_train_epochs=5,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_strategy=\"epoch\",\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    greater_is_better=False,\n",
    ")\n",
    "\n",
    "# Define the EarlyStoppingCallback\n",
    "early_stopping = EarlyStoppingCallback(\n",
    "    early_stopping_patience=3,\n",
    ")\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Define scheduler\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=\"linear\",  # can be \"linear\", \"cosine\", \"cosine_with_restarts\", \"polynomial\", \"constant\"\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,  # or a few hundred, depending on your dataset size\n",
    "    num_training_steps=len(train_dataset) * training_args.num_train_epochs // training_args.per_device_train_batch_size\n",
    ")\n",
    "\n",
    "# Initialize the trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    "    processing_class=tokenizer,\n",
    "    data_collator=DataCollatorForSeq2Seq(tokenizer, padding=True),\n",
    "    optimizers=(optimizer, lr_scheduler),\n",
    "    callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "print(\"Training started...\")\n",
    "\n",
    "trainer.train()\n",
    "print(\"training done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e905afd2-9c9e-4491-b38e-6350a5aef951",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./new_2\\\\tokenizer_config.json',\n",
       " './new_2\\\\special_tokens_map.json',\n",
       " './new_2\\\\spiece.model',\n",
       " './new_2\\\\added_tokens.json',\n",
       " './new_2\\\\tokenizer.json')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model after training, name can be changed\n",
    "# If you open a trained model and trained it again, has to be a different name than the trained model\n",
    "model.save_pretrained(\"./new_2\")\n",
    "tokenizer.save_pretrained(\"./new_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "4a656117-a5f2-4e64-92a4-e9fe286fc99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Loads saved model\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"./new_2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./new_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2788bdf7-8bc6-465c-aab5-2b1cae796ab9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  All companies that are involved in the production of fossil fuels and have a minimum percentage of revenue from fossil fuel business activities of 5% or more.\n",
      "Correct:  AND([FossilFuelInvolvement] ANY 'Production',[FossilFuelRevShareMin] >= '0.05')\n",
      "Model:  AND([FossilFuelInvolvement] ANY 'Production|RevShareMin] > '0.05') \n",
      "\n",
      "\n",
      "Query:  All companies or issuers where the Board Chair is an executive or insider.\n",
      "Correct:  [ChairmanClassification] == 'Executive/insider'\n",
      "Model:  AND([BoardPresident] IS 'Executive',[Insider] IS IN 'INNER') \n",
      "\n",
      "\n",
      "Query:  All companies with a GMO - Agriculture Production Maximum Percentage of Revenues greater than 10% in the latest financial year.\n",
      "Correct:  [GMOAgricultureProdMaxRev] > '0.1'\n",
      "Model:  AND([GMOAgricultureProdMaxRev] > '0.1') \n",
      "\n",
      "\n",
      "Query:  All companies or issuers that have a minimum percentage of recent-year revenues for their involvement in coal mining of at least 0% and a minimum percentage of recent-year revenues for their involvement in coal extraction of at least 0%.\n",
      "Correct:  AND([FossilFuelCoalExtractRevShareMin] >= '0',[CoalMiningRevShareMinThermal] >= '0')\n",
      "Model:  AND([CoalMiningRevShareMin] >= '0',[CaseExtractRatioMinRev] > '0%') \n",
      "\n",
      "\n",
      "Query:  All companies or issuers that have a Fund ESG Fund Rating Stars of 1-3, an ESG Rating Decile Rank of 7 or lower, or an ESG Rating Overall of D+, D, or D-\n",
      "Correct:  AND([FundESGRatingStars] IS :NC,OR([ESGRatingDecileRank] < '7',[oekomRating] IN 'D+|D|D-'))\n",
      "Model:  AND([FundESGRatingStars] == '1-3',[ScreenSEGRatingDimensionalRank]  '7',OR([OverallSEGRationD+,D-D] > 'D+') \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#\n",
    "# Translate random queries from English to Esgish2\n",
    "#\n",
    "\n",
    "excel = pd.read_excel(\"translated_queries_TEST2.xlsx\")\n",
    "sample = excel[[\"Esgish\", \"English\"]].dropna().sample(5).values\n",
    "\n",
    "for esg, eng in sample:\n",
    "    input_text = f\"Convert English to Esgish: {eng}\"\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    output_ids = model.generate(\n",
    "        **inputs,\n",
    "        max_length=1024,\n",
    "        num_beams=4,\n",
    "        early_stopping=True,\n",
    "        no_repeat_ngram_size=3\n",
    "    )\n",
    "    print(\"Query: \", eng)\n",
    "    print(\"Correct: \", esg)\n",
    "    print(\"Model: \", tokenizer.decode(output_ids[0], skip_special_tokens=True), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a4b13597-63a4-4881-9590-05be0e1b0a2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  [AFLCIOBoycottList] True\n",
      "Correct:  All companies or issuers listed on the AFL-CIO Boycott List.\n",
      "Model:  Please provide a list of all companies or issuers that have a BOYcott List of True. \n",
      "\n",
      "\n",
      "Query:  [CivFAAssaultWeaponsInvolvement] ANY 'Production|Distribution|Services'\n",
      "Correct:  All companies or issuers involved in the production, distribution, or provision of services related to assault weapons.\n",
      "Model:  All companies or issuers that are involved in the production, distribution, or provision of services related to assault weapons. \n",
      "\n",
      "\n",
      "Query:  [AdjustedEnterpriseValue] > '0'\n",
      "Correct:  All companies with an adjusted enterprise value greater than zero.\n",
      "Model:  Please provide a list of all companies or issuers that have an adjusted Enterprise Value greater than 0. \n",
      "\n",
      "\n",
      "Query:  [CCAMoneyLaunderingControversy] True\n",
      "Correct:  All companies or issuers that have been flagged for having a money laundering concern in their country.\n",
      "Model:  Please provide a list of all companies or issuers that are involved in the illegal smuggling of narcotics. \n",
      "\n",
      "\n",
      "Query:  [CivFARevShareInterval] IN '[1-5%)|[5-10%)|[10-15%)|[15-20%)|[20-25%)|[25-50%)|[50-100%]'\n",
      "Correct:  All companies or issuers that have a revenue share between 1% and 5% or between 5% and 10% or between 10% and 15% or between 15% and 20% or between 20% and 25% or between 25% and 50% or between 50% and 100% of their total revenue in the latest financial year from involvement in civilian firearms or ammunition.\n",
      "Model:  All companies or issuers that have a revenue share interval of 1-5%), 5-10%), 10-15%), 15-20%), 20-25%), 25-50%) or 50-100% of their revenue. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Translate random queries from Esgish2 to English\n",
    "#\n",
    "excel = pd.read_excel(\"translated_queries_TEST1.xlsx\")\n",
    "sample = excel[[\"Esgish\", \"English\"]].dropna().sample(5).values\n",
    "\n",
    "for esg, eng in sample:\n",
    "    input_text = \"Convert Esglish to English: \" + esg\n",
    "    inputs = tokenizer(input_text, return_tensors=\"pt\", padding=True, truncation=True)\n",
    "    output_ids = model.generate(\n",
    "        inputs[\"input_ids\"],\n",
    "        max_length=1024,\n",
    "        num_beams=4,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    print(\"Query: \", esg)\n",
    "    print(\"Correct: \", eng)\n",
    "    print(\"Model: \", tokenizer.decode(output_ids[0], skip_special_tokens=True), \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0df640-f6a5-4652-965e-17ccc2e2698f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
