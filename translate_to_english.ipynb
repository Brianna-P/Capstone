{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "11329b8f-ae0a-48d4-9da9-7c1c06875c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (2.2.3)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (3.1.5)\n",
      "Requirement already satisfied: transformers in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (4.49.0)\n",
      "Requirement already satisfied: torch in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (2.6.0)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas) (2.2.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from pandas) (2025.1)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from openpyxl) (2.0.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers) (0.29.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers) (2024.11.6)\n",
      "Requirement already satisfied: requests in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers) (0.5.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from torch) (76.0.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests->transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests->transformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: llama-cpp-python in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (0.3.8)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from llama-cpp-python) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.20.0 in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from llama-cpp-python) (2.2.3)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from llama-cpp-python) (5.6.3)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from llama-cpp-python) (3.1.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\solar\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.13_qbz5n2kfra8p0\\localcache\\local-packages\\python313\\site-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install pandas openpyxl transformers torch\n",
    "%pip install llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a607fdc-3c30-4006-af0d-60789c816fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from /Users/solar/OneDrive/Documents/Capstone/Capstone-Jupyter/mistral-7b-instruct-v0.1.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.1\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "print_info: file format = GGUF V2\n",
      "print_info: file type   = Q4_K - Medium\n",
      "print_info: file size   = 4.07 GiB (4.83 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 1\n",
      "load: control token:      2 '</s>' is not marked as EOG\n",
      "load: control token:      1 '<s>' is not marked as EOG\n",
      "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "load: special tokens cache size = 3\n",
      "load: token to piece cache size = 0.1637 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 32768\n",
      "print_info: n_embd           = 4096\n",
      "print_info: n_layer          = 32\n",
      "print_info: n_head           = 32\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 4\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 14336\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 10000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 32768\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: ssm_d_conv       = 0\n",
      "print_info: ssm_d_inner      = 0\n",
      "print_info: ssm_d_state      = 0\n",
      "print_info: ssm_dt_rank      = 0\n",
      "print_info: ssm_dt_b_c_rms   = 0\n",
      "print_info: model type       = 7B\n",
      "print_info: model params     = 7.24 B\n",
      "print_info: general.name     = mistralai_mistral-7b-instruct-v0.1\n",
      "print_info: vocab type       = SPM\n",
      "print_info: n_vocab          = 32000\n",
      "print_info: n_merges         = 0\n",
      "print_info: BOS token        = 1 '<s>'\n",
      "print_info: EOS token        = 2 '</s>'\n",
      "print_info: UNK token        = 0 '<unk>'\n",
      "print_info: LF token         = 13 '<0x0A>'\n",
      "print_info: EOG token        = 2 '</s>'\n",
      "print_info: max token length = 48\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device CPU\n",
      "load_tensors: layer   1 assigned to device CPU\n",
      "load_tensors: layer   2 assigned to device CPU\n",
      "load_tensors: layer   3 assigned to device CPU\n",
      "load_tensors: layer   4 assigned to device CPU\n",
      "load_tensors: layer   5 assigned to device CPU\n",
      "load_tensors: layer   6 assigned to device CPU\n",
      "load_tensors: layer   7 assigned to device CPU\n",
      "load_tensors: layer   8 assigned to device CPU\n",
      "load_tensors: layer   9 assigned to device CPU\n",
      "load_tensors: layer  10 assigned to device CPU\n",
      "load_tensors: layer  11 assigned to device CPU\n",
      "load_tensors: layer  12 assigned to device CPU\n",
      "load_tensors: layer  13 assigned to device CPU\n",
      "load_tensors: layer  14 assigned to device CPU\n",
      "load_tensors: layer  15 assigned to device CPU\n",
      "load_tensors: layer  16 assigned to device CPU\n",
      "load_tensors: layer  17 assigned to device CPU\n",
      "load_tensors: layer  18 assigned to device CPU\n",
      "load_tensors: layer  19 assigned to device CPU\n",
      "load_tensors: layer  20 assigned to device CPU\n",
      "load_tensors: layer  21 assigned to device CPU\n",
      "load_tensors: layer  22 assigned to device CPU\n",
      "load_tensors: layer  23 assigned to device CPU\n",
      "load_tensors: layer  24 assigned to device CPU\n",
      "load_tensors: layer  25 assigned to device CPU\n",
      "load_tensors: layer  26 assigned to device CPU\n",
      "load_tensors: layer  27 assigned to device CPU\n",
      "load_tensors: layer  28 assigned to device CPU\n",
      "load_tensors: layer  29 assigned to device CPU\n",
      "load_tensors: layer  30 assigned to device CPU\n",
      "load_tensors: layer  31 assigned to device CPU\n",
      "load_tensors: layer  32 assigned to device CPU\n",
      "load_tensors: tensor 'token_embd.weight' (q4_K) (and 290 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "load_tensors:   CPU_Mapped model buffer size =  4165.37 MiB\n",
      ".................................................................................................\n",
      "llama_init_from_model: n_seq_max     = 1\n",
      "llama_init_from_model: n_ctx         = 4096\n",
      "llama_init_from_model: n_ctx_per_seq = 4096\n",
      "llama_init_from_model: n_batch       = 512\n",
      "llama_init_from_model: n_ubatch      = 512\n",
      "llama_init_from_model: flash_attn    = 0\n",
      "llama_init_from_model: freq_base     = 10000.0\n",
      "llama_init_from_model: freq_scale    = 1\n",
      "llama_init_from_model: n_ctx_per_seq (4096) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
      "llama_kv_cache_init: kv_size = 4096, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1\n",
      "llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 28: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 29: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 30: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 31: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init:        CPU KV buffer size =   512.00 MiB\n",
      "llama_init_from_model: KV self size  =  512.00 MiB, K (f16):  256.00 MiB, V (f16):  256.00 MiB\n",
      "llama_init_from_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_init_from_model:        CPU compute buffer size =   296.01 MiB\n",
      "llama_init_from_model: graph nodes  = 1030\n",
      "llama_init_from_model: graph splits = 1\n",
      "CPU : SSE3 = 1 | SSSE3 = 1 | AVX = 1 | AVX2 = 1 | F16C = 1 | FMA = 1 | AVX512 = 1 | LLAMAFILE = 1 | OPENMP = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'general.name': 'mistralai_mistral-7b-instruct-v0.1', 'general.architecture': 'llama', 'llama.context_length': '32768', 'llama.rope.dimension_count': '128', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.feed_forward_length': '14336', 'llama.attention.head_count': '32', 'tokenizer.ggml.eos_token_id': '2', 'general.file_type': '15', 'llama.attention.head_count_kv': '8', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'llama.rope.freq_base': '10000.000000', 'tokenizer.ggml.model': 'llama', 'general.quantization_version': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.unknown_token_id': '0'}\n",
      "Using fallback chat format: llama-2\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "model_path = \"/Users/solar/OneDrive/Documents/Capstone/Capstone-Jupyter/mistral-7b-instruct-v0.1.Q4_K_M.gguf\"\n",
    "max_context = 4096\n",
    "llm = Llama(\n",
    "    model_path,\n",
    "    n_ctx=max_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4566bf9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest entry code: EUTaxManIntSerElcRevOverAlign\n",
      "Length: 1353\n",
      "Content: EU Taxon - Man, Instal, Serv of Elec Equip Overall Align. EU Taxon - Man, Instal, Serv of Elec Equip Overall Align: This factor identifies the overall alignment for Manufacture, installation, and servicing of high, medium and low voltage electrical equipment for electrical transmission and distribution that result in or enable a substantial contribution to climate change mitigation, covering the substantial contribution criteria, the do no significant harm criteria, and the minimum social safeguards. This is the aggregated result across all Taxonomy objectives. The possible values are: Aligned,Aligned (>90%),Aligned (>80%),Aligned (>70%),Aligned (>60%),Aligned (>50%),Aligned (>40%),Aligned (>30%),Aligned (>20%),Aligned (>10%),Aligned (>0%),Likely aligned (100%),Likely aligned (>90%),Likely aligned (>80%),Likely aligned (>70%),Likely aligned (>60%),Likely aligned (>50%),Likely aligned (>40%),Likely aligned (>30%),Likely aligned (>20%),Likely aligned (>10%),Likely aligned (>0%),Potentially aligned (100%),Potentially aligned (>90%),Potentially aligned (>80%),Potentially aligned (>70%),Potentially aligned (>60%),Potentially aligned (>50%),Potentially aligned (>40%),Potentially aligned (>30%),Potentially aligned (>20%),Potentially aligned (>10%),Potentially aligned (>0%),Likely not aligned,Not aligned, Not collected, and Not applicable.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "with open(\"metadata.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_metadata = json.load(f)\n",
    "\n",
    "# Create a lookup table\n",
    "metadata_lookup = {\n",
    "    entry[\"code\"]: f'{entry[\"name\"]}. {entry[\"description\"]}' \n",
    "    for entry in raw_metadata\n",
    "}\n",
    "\n",
    "def extract_codes(query):\n",
    "    return re.findall(r\"\\[([A-Za-z0-9_]+)\\]\", query)\n",
    "\n",
    "list_keywords = {\"IN\", \"ANY\", \"NONE\"}\n",
    "null_keywords = {\":NC\": \"Null type \\\"Not collected\\\"\", \":NA\": \"Null type \\\"Not applicable\\\"\", \":ND\": \"Null type \\\"Not disclosed\\\"\", \":NI\": \"Null type \\\"No information\\\"\", \":NM\": \"Null type \\\"Not meaningful\\\"\"}\n",
    "def extract_nulls_and_lists(query):\n",
    "    nulls = []\n",
    "    lists = []\n",
    "    contains_null = re.findall(r\"\\[([A-Za-z0-9_]+)\\]\\s+IS\\s+(:[A-Z]{2})\", query)\n",
    "    for code, null_keyword in contains_null:\n",
    "        nulls.append((code, null_keyword))\n",
    "    \n",
    "    contains_list = re.findall(r\"\\[([A-Za-z0-9_]+)\\]\\s+(IN|ANY|NONE)\\b\", query, re.IGNORECASE)\n",
    "    for code, list_keyword in contains_list:\n",
    "        lists.append((code, list_keyword.upper()))\n",
    "    \n",
    "    return nulls, lists\n",
    "\n",
    "# Find the entry with the longest name + description combo\n",
    "longest_entry = max(metadata_lookup.items(), key=lambda item: len(item[1]))\n",
    "\n",
    "# Print the result\n",
    "print(f'Longest entry code: {longest_entry[0]}')\n",
    "print(f'Length: {len(longest_entry[1])}')\n",
    "print(f'Content: {longest_entry[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efb3fc4c-e7b9-4bfb-9340-779aaba31116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_tokens(text, max_tokens=40):\n",
    "    #moved this to use in below function\n",
    "    tokens = llm.tokenize(text.encode(\"utf-8\"))\n",
    "    if len(tokens) <= max_tokens:\n",
    "        return text\n",
    "    truncated = llm.detokenize(tokens[:max_tokens]).decode(\"utf-8\", errors=\"ignore\")\n",
    "    return truncated + \"...\"\n",
    "\n",
    "def build_ordered_context(query, token_budget):\n",
    "    #builds context in-order: null type definitions, enumerations for list types, and metadata lookups\n",
    "    context_lines = []\n",
    "    seen = set()\n",
    "    used_tokens = 0\n",
    "\n",
    "    null_hits, list_hits = extract_nulls_and_lists(query)\n",
    "    codes_in_order = re.findall(r\"\\[([A-Za-z0-9_]+)\\]\", query)\n",
    "\n",
    "    #tokenizer = llm.tokenizer\n",
    "    for code in codes_in_order:\n",
    "        if code in seen:\n",
    "            continue\n",
    "        seen.add(code)\n",
    "\n",
    "        null_entry = next((kw for c, kw in null_hits if c == code), None)\n",
    "        if null_entry:\n",
    "            null_def = null_keywords.get(null_entry, f\"No definition for {null_entry}\")\n",
    "            line = f\"{code} = {null_entry} → {null_def}\"\n",
    "            tokens = len(llm.tokenize(line.encode(\"utf-8\")))\n",
    "            if used_tokens + tokens > token_budget:\n",
    "                break\n",
    "            context_lines.append(line)\n",
    "            used_tokens += tokens\n",
    "\n",
    "        base_meta = metadata_lookup.get(code, \"No metadata found.\")\n",
    "        metadata_line = f\"{code}: {max_tokens(base_meta, 100)}\" \n",
    "        tokens = len(llm.tokenize(metadata_line.encode(\"utf-8\")))\n",
    "        if used_tokens + tokens > token_budget:\n",
    "            break\n",
    "        context_lines.append(metadata_line)\n",
    "        used_tokens += tokens\n",
    "\n",
    "        if any(c == code for c, _ in list_hits):\n",
    "            enum_line = f\"{code} (enumeration): {max_tokens(base_meta, 100)}\"\n",
    "            tokens = len(llm.tokenize(enum_line.encode(\"utf-8\")))\n",
    "            if used_tokens + tokens > token_budget:\n",
    "                break\n",
    "            context_lines.append(enum_line)\n",
    "            used_tokens += tokens\n",
    "\n",
    "    return \"\\n\".join(context_lines)\n",
    "\n",
    "def max_afforded_tokens(codes):\n",
    "    return max(4096 // max(1, len(codes)), 100)\n",
    "\n",
    "\n",
    "def translate_query(query, max_total_tokens=2048, max_output_tokens=256):\n",
    "    codes = extract_codes(query)\n",
    "\n",
    "    m_tokens = max_afforded_tokens(codes)\n",
    "\n",
    "    # Initial prompt pieces\n",
    "    instruction = \"### Instruction:\\nRephrase the following ESGish query into a concise natural English sentence. Each query is asking for all companies or issuers that match some paramater. Use the following metadata definitions for clarity:\\n\\n\"\n",
    "    query_part = f\"\\n\\nQuery: {query}\\n\\n### Response:\"\n",
    "\n",
    "    # Tokenize instruction and query to calculate remaining token budget\n",
    "    #tokenizer = llm.tokenize  # Built-in tokenizer\n",
    "    instruction_tokens = len(llm.tokenize(instruction.encode(\"utf-8\")))\n",
    "    query_tokens = len(llm.tokenize(query_part.encode(\"utf-8\")))\n",
    "    token_budget = max_total_tokens - max_output_tokens - instruction_tokens - query_tokens\n",
    "\n",
    "    # Build full context blocks for each code\n",
    "    context = build_ordered_context(query, token_budget)\n",
    "    print(\"query: \", query)\n",
    "    print(context)\n",
    "\n",
    "    \"\"\"\n",
    "    # Now iteratively add context blocks until budget is exhausted\n",
    "    context = \"\"\n",
    "    used_tokens = 0\n",
    "    for block in context_blocks:\n",
    "        block_tokens = len(tokenizer(block.encode(\"utf-8\"))) + 1  # +1 for newline\n",
    "        if used_tokens + block_tokens <= token_budget:\n",
    "            context += block + \"\\n\"\n",
    "            used_tokens += block_tokens\n",
    "        else:\n",
    "            break  # stop once we're out of budget\n",
    "    \"\"\"\n",
    "    # Final prompt\n",
    "    prompt = instruction + context + query_part\n",
    "\n",
    "    # Call model\n",
    "    response = llm(prompt, max_tokens=max_output_tokens, temperature=0.1)\n",
    "    return response[\"choices\"][0][\"text\"].strip()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81772e84-bbeb-4000-a351-281347bf87a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query:  AND([ClawBackProvisionDisclosure] IS :ND,[CEOStockOwnershipGuideRatio] > '1')\n",
      "ClawBackProvisionDisclosure = :ND → Null type \"Not disclosed\"\n",
      "ClawBackProvisionDisclosure: Q155: Clawback Provision. Does the company have a clawback or malus provision? (Q155)\n",
      "CEOStockOwnershipGuideRatio: Q145: CEO Stock Ownership Guidelines (% of Salary). What salary multiple of the CEO is subject to stock ownership guidelines? (Q145)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    4566.29 ms /   191 tokens (   23.91 ms per token,    41.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4758.41 ms /    33 runs   (  144.19 ms per token,     6.94 tokens per second)\n",
      "llama_perf_context_print:       total time =    9330.64 ms /   224 tokens\n",
      "Llama.generate: 190 prefix-match hit, remaining 1 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query:  AND([ClawBackProvisionDisclosure] IS :ND,[CEOStockOwnershipGuideRatio] > '1')\n",
      "ClawBackProvisionDisclosure = :ND → Null type \"Not disclosed\"\n",
      "ClawBackProvisionDisclosure: Q155: Clawback Provision. Does the company have a clawback or malus provision? (Q155)\n",
      "CEOStockOwnershipGuideRatio: Q145: CEO Stock Ownership Guidelines (% of Salary). What salary multiple of the CEO is subject to stock ownership guidelines? (Q145)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =    4745.69 ms /    34 runs   (  139.58 ms per token,     7.16 tokens per second)\n",
      "llama_perf_context_print:       total time =    4750.83 ms /    35 tokens\n",
      "Llama.generate: 51 prefix-match hit, remaining 169 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query:  AND([ClimateEmissionsFiscalYear] == '2022',[ClimateParentEntityID] IS :NA)\n",
      "ClimateEmissionsFiscalYear: GHG Emissions - Fiscal Year. GHG Emissions - Fiscal Year: This factor provides the fiscal year associated with the corresponding GHG emissions values.\n",
      "ClimateParentEntityID = :NA → Null type \"Not applicable\"\n",
      "ClimateParentEntityID: Climate Parent Entity ID. Climate Parent Entity ID: This factor provides the identifier of the issuer‘s parent, from which the climate data is assigned. The climate data from the parent company is assigned to a subsidiary based on criteria such as industry classification, ownership structure, and business activities.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    3927.00 ms /   169 tokens (   23.24 ms per token,    43.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4290.62 ms /    30 runs   (  143.02 ms per token,     6.99 tokens per second)\n",
      "llama_perf_context_print:       total time =    8222.54 ms /   199 tokens\n",
      "Llama.generate: 50 prefix-match hit, remaining 1177 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query:  AND([FossilFuelCoalPowerRevShareMin] IS :NC,[CoalMiningServMinRev] IS :NC,[CivFADistMinRev] IS :NC,[MilitaryEqmtProdServMinRev] IS :NC,[APMinesTotalReds] IS :NC,[BiologicalWeaponsTotalReds] IS :NC,[ChemicalWeaponsTotalReds] IS :NC,[ClusterMunitionsTotalReds] IS :NC,[IncendiaryWeaponsTotalReds] IS :NC,[NBSOverallScore] IS :NC,[CCAAuthoritarianRegimeFreedom] IS :NC)\n",
      "FossilFuelCoalPowerRevShareMin = :NC → Null type \"Not collected\"\n",
      "FossilFuelCoalPowerRevShareMin: Fossil Fuel - Coal Power Minimum Revenue Share (%). Fossil Fuel - Coal Power Minimum Revenue Share (%): This factor provides the minimum percentage of recent-year revenues for the company's involvement in the generation of electric power sourced from coal.\n",
      "CoalMiningServMinRev = :NC → Null type \"Not collected\"\n",
      "CoalMiningServMinRev: Coal Mining - Services Minimum Percentage of Revenues (%). Coal Mining - Services Minimum Percentage of Revenues (%):  This factor provides the minimum percentage of revenues for the company's involvement in the provision of services for the extraction/mining of coal for the most recent fiscal year period.\n",
      "CivFADistMinRev = :NC → Null type \"Not collected\"\n",
      "CivFADistMinRev: Civilian Firearms - Distribution Revenue Share Min (%). Civilian Firearms - Distribution Revenue Share Min (%): This factor identifies the minimum share of revenue estimated or reported to be derived from involvement in the distribution of civilian firearms as a percentage of the issuers’ total revenue in the latest financial year.\n",
      "MilitaryEqmtProdServMinRev = :NC → Null type \"Not collected\"\n",
      "MilitaryEqmtProdServMinRev: Military Equipment and Services - Prod & Serv Rev Share Min (%). Military Equipment and Services - Prod & Serv Rev Share Min (%): This factor identifies the minimum share of revenue estimated or reported to be derived from involvement in the production of military equipment and/or the provision of related services as a percentage of the issuers’ total revenue in the latest financial year.\n",
      "APMinesTotalReds = :NC → Null type \"Not collected\"\n",
      "APMinesTotalReds: Anti-personnel Mines - Total Red Assessments. Anti-personnel Mines - Total Red Assessments: This factor provides the number of Red signals assigned to an issuer based on the issuer's involvement in any anti-personnel mines programme\n",
      "BiologicalWeaponsTotalReds = :NC → Null type \"Not collected\"\n",
      "BiologicalWeaponsTotalReds: Biological Weapons - Total Red Assessments. Biological Weapons - Total Red Assessments: This factor provides the number of Red signals assigned to an issuer based on the issuer's involvement in any biological weapons programme\n",
      "ChemicalWeaponsTotalReds = :NC → Null type \"Not collected\"\n",
      "ChemicalWeaponsTotalReds: Chemical Weapons - Total Red Assessments. Chemical Weapons - Total Red Assessments: This factor provides the number of Red signals assigned to an issuer based on the issuer's involvement in any chemical weapons programme\n",
      "ClusterMunitionsTotalReds = :NC → Null type \"Not collected\"\n",
      "ClusterMunitionsTotalReds: Cluster Munitions - Total Red Assessments. Cluster Munitions - Total Red Assessments: This factor provides the number of Red signals assigned to an issuer based on the issuer's involvement in any cluster munitions programme\n",
      "IncendiaryWeaponsTotalReds = :NC → Null type \"Not collected\"\n",
      "IncendiaryWeaponsTotalReds: Incendiary Weapons - Total Red Assessments. Incendiary Weapons - Total Red Assessments: This factor provides the number of Red signals assigned to an issuer based on the issuer's involvement in any incendiary weapons programme\n",
      "NBSOverallScore = :NC → Null type \"Not collected\"\n",
      "NBSOverallScore: NBR - Overall Score. NBR Overall Score: This factor assigns a 1-10 score to an issuer based on the issuer's link with any violations of international standards. Score 10 aligns with a Red flag; scores from 6 to 9 align with the Amber flag; scores from 2 to 5 reflect an \"active\" Green flag; and a score of 1 communicates a Green \"No allegation\" signal.\n",
      "CCAAuthoritarianRegimeFreedom = :NC → Null type \"Not collected\"\n",
      "CCAAuthoritarianRegimeFreedom: CCA - Authoritarian Regime / Freedom Status. CCA - Authoritarian Regime / Freedom Status: This factor identifies whether the country is considered a free, partly free or authoritarian society, per Freedom House. The options are \"Free\", \"Party free\", and \"Not free\".\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =   28418.20 ms /  1177 tokens (   24.14 ms per token,    41.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2177.99 ms /    15 runs   (  145.20 ms per token,     6.89 tokens per second)\n",
      "llama_perf_context_print:       total time =   30598.90 ms /  1192 tokens\n",
      "Llama.generate: 55 prefix-match hit, remaining 384 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query:  AND([FossilFuelInvolvement] ANY 'Exploration',[FundESGRatingStars] IS :NC)\n",
      "FossilFuelInvolvement: Fossil Fuel - Involvement Tie. Fossil Fuel - Involvement Tie: This factor identifies issuers engaged in the production, distribution, exploration or provision of services related to fossil fuels. The \"Production\" value identifies issuers engaged in the production of fossil fuels through extraction, processing, and electricity generation. \"Distribution\" includes issuers engaged in essential infrastructure specifically used for the transportation of foss...\n",
      "FossilFuelInvolvement (enumeration): Fossil Fuel - Involvement Tie. Fossil Fuel - Involvement Tie: This factor identifies issuers engaged in the production, distribution, exploration or provision of services related to fossil fuels. The \"Production\" value identifies issuers engaged in the production of fossil fuels through extraction, processing, and electricity generation. \"Distribution\" includes issuers engaged in essential infrastructure specifically used for the transportation of foss...\n",
      "FundESGRatingStars = :NC → Null type \"Not collected\"\n",
      "FundESGRatingStars: ISS ESG Fund Rating Stars. ISS ESG Fund Rating Stars: This factor provides the fund's overall star rating based on the fund's relative performance in comparison to peer funds in the same Lipper Global Classification class. The rating is derived from a weighted average ESG Performance Score which evaluates issuers across environmental, social, and governance performance metrics. The overall rating is graded on a scale from 1 (worst) to 5 (...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    8726.09 ms /   384 tokens (   22.72 ms per token,    44.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4912.85 ms /    35 runs   (  140.37 ms per token,     7.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   13644.47 ms /   419 tokens\n",
      "Llama.generate: 51 prefix-match hit, remaining 212 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query:  AND([FundESGRatingStars] IS :NC,OR([CountryOfIncorporation] == 'Malaysia',[StockExchange] == 'Malaysia Stock Exchange'))\n",
      "FundESGRatingStars = :NC → Null type \"Not collected\"\n",
      "FundESGRatingStars: ISS ESG Fund Rating Stars. ISS ESG Fund Rating Stars: This factor provides the fund's overall star rating based on the fund's relative performance in comparison to peer funds in the same Lipper Global Classification class. The rating is derived from a weighted average ESG Performance Score which evaluates issuers across environmental, social, and governance performance metrics. The overall rating is graded on a scale from 1 (worst) to 5 (...\n",
      "CountryOfIncorporation: Country Of Incorporation. Country issuer is incorporated in\n",
      "StockExchange: Stock Exchange. Stock exchange for primary security\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    4778.15 ms /   212 tokens (   22.54 ms per token,    44.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4577.14 ms /    33 runs   (  138.70 ms per token,     7.21 tokens per second)\n",
      "llama_perf_context_print:       total time =    9360.74 ms /   245 tokens\n",
      "Llama.generate: 198 prefix-match hit, remaining 154 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query:  AND([FundESGRatingStars] IS :NC,OR([CountryOfIncorporation] IN 'Brazil|Egypt|New Zealand|Singapore|Switzerland|United Kingdom',[CountryOfIncorporation] IN 'Australia|Canada|Switzerland|USA',[IssuerRegion] == 'Europe'))\n",
      "FundESGRatingStars = :NC → Null type \"Not collected\"\n",
      "FundESGRatingStars: ISS ESG Fund Rating Stars. ISS ESG Fund Rating Stars: This factor provides the fund's overall star rating based on the fund's relative performance in comparison to peer funds in the same Lipper Global Classification class. The rating is derived from a weighted average ESG Performance Score which evaluates issuers across environmental, social, and governance performance metrics. The overall rating is graded on a scale from 1 (worst) to 5 (...\n",
      "CountryOfIncorporation: Country Of Incorporation. Country issuer is incorporated in\n",
      "CountryOfIncorporation (enumeration): Country Of Incorporation. Country issuer is incorporated in\n",
      "IssuerRegion: IssuerRegion. Region: This factor provides the issuer's reference region as assigned to the following values: Africa, Asia, Europe, Latin America, Middle East, North America, Pacific.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    3481.65 ms /   154 tokens (   22.61 ms per token,    44.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9719.59 ms /    69 runs   (  140.86 ms per token,     7.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   13213.15 ms /   223 tokens\n",
      "Llama.generate: 177 prefix-match hit, remaining 1343 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query:  AND([FundESGRatingStars] IS :NC,OR([CRARating] IN 'Needs to Improve',[NBSIsLabourDiscriminationGender] True,[NBSIsLabourDiscriminationRacial] True,[APMinesOverallFlag] == 'RED',[NuclearWeaponsOverallFlag] == 'RED',[NuclearWeaponsNonNPTOverallFlag] == 'RED',[ChemicalWeaponsOverallFlag] == 'RED',[BiologicalWeaponsOverallFlag] == 'RED',[PornographyRevShareMax] > '0',[TobaccoRevShareMax] > '0',[AlcoholRevShareMax] > '0',[GamblingRevShareMax] > '0'))\n",
      "FundESGRatingStars = :NC → Null type \"Not collected\"\n",
      "FundESGRatingStars: ISS ESG Fund Rating Stars. ISS ESG Fund Rating Stars: This factor provides the fund's overall star rating based on the fund's relative performance in comparison to peer funds in the same Lipper Global Classification class. The rating is derived from a weighted average ESG Performance Score which evaluates issuers across environmental, social, and governance performance metrics. The overall rating is graded on a scale from 1 (worst) to 5 (...\n",
      "CRARating: Community Reinvestment Act - CRA Rating. Community Reinvestment Act - CRA Rating: This factor identifies issuers that have a \"Needs to Improve\" or \"Substantial Noncompliance\" rating under the U.S. Community Reinvestment Act\n",
      "CRARating (enumeration): Community Reinvestment Act - CRA Rating. Community Reinvestment Act - CRA Rating: This factor identifies issuers that have a \"Needs to Improve\" or \"Substantial Noncompliance\" rating under the U.S. Community Reinvestment Act\n",
      "NBSIsLabourDiscriminationGender: Norm-Based Research Assessment - Gender Discrimination. NBR Assessment - Gender Discrimination: This factor identifies companies involved in one or more workplace gender discrimination controversies where there is verification by an authoritative body but the issue remains unaddressed; where the issuer has entered contract(s) that would, when actualised, lead to a failure to respect established norms; where there are credible allegations; where the failure to respect established norms...\n",
      "NBSIsLabourDiscriminationRacial: Norm-Based Research Assessment - Racial Discrimination. NBR Assessment - Racial Discrimination: This factor identifies companies involved in one or more workplace racial discrimination controversies where there is verification by an authoritative body but the issue remains unaddressed; where the issuer has entered contract(s) that would, when actualised, lead to a failure to respect established norms; where there are credible allegations; where the failure to respect established...\n",
      "APMinesOverallFlag: Anti-personnel Mines - Overall Flag. Anti-personnel Mines - Overall Flag: This factor assigns an overall Red, Amber, or Green flag to an issuer based on the issuer's involvement in any anti-personnel mines programme. The Overall Flag is determined by the lowest individual assessment signal within the issue area. For example, if the issuer is assigned both a Red signal and an Amber signal for different assessments in this issue area, the...\n",
      "NuclearWeaponsOverallFlag: Nuclear Weapons Inside NPT - Overall Flag. Nuclear Weapons Inside NPT - Overall Flag: This factor assigns an overall Red, Amber, or Green flag to an issuer based on the issuer's involvement in any nuclear weapons programme inside of the Non-Proliferation Treaty (NPT). The Overall Flag is determined by the lowest individual assessment signal within the issue area. For example, if the issuer is assigned both a Red...\n",
      "NuclearWeaponsNonNPTOverallFlag: Nuclear Weapons Outside NPT - Overall Flag. Nuclear Weapons Outside NPT - Overall Flag: This factor assigns an overall Red, Amber, or Green flag to an issuer based on the issuer's involvement in any nuclear weapons programme outside of the Non-Proliferation Treaty (NPT). The Overall Flag is determined by the lowest individual assessment signal within the issue area. For example, if the issuer is assigned both a Red...\n",
      "ChemicalWeaponsOverallFlag: Chemical Weapons - Overall Flag. Chemical Weapons - Overall Flag: This factor assigns an overall Red, Amber, or Green flag to an issuer based on the issuer's involvement in any chemical weapons programme. The Overall Flag is determined by the lowest individual assessment signal within the issue area. For example, if the issuer is assigned both a Red signal and an Amber signal for different assessments in this issue area, the issuer's Overall...\n",
      "BiologicalWeaponsOverallFlag: Biological Weapons - Overall Flag. Biological Weapons - Overall Flag: This factor assigns an overall Red, Amber, or Green flag to an issuer based on the issuer's involvement in any biological weapons programme. The Overall Flag is determined by the lowest individual assessment signal within the issue area. For example, if the issuer is assigned both a Red signal and an Amber signal for different assessments in this issue area, the issuer's Overall...\n",
      "PornographyRevShareMax: Pornography - Revenue Share Max (%). Pornography - Revenue Share Max (%): This factor identifies the maximum share of revenue estimated or reported to be derived from pornography as a percentage of the issuers’ total revenue in the latest financial year.\n",
      "TobaccoRevShareMax: Tobacco - Revenue Share Max (%). Tobacco - Revenue Share Max (%): This factor identifies the maximum share of revenue estimated or reported to be derived from tobacco as a percentage of the issuers’ total revenue in the latest financial year.\n",
      "AlcoholRevShareMax: Alcohol - Revenue Share Max (%). Alcohol - Revenue Share Max (%)This factor identifies the maximum share of revenue estimated or reported to be derived from alcohol as a percentage of the issuers’ total revenue in the latest financial year.\n",
      "GamblingRevShareMax: Gambling - Revenue Share Max (%). Gambling - Revenue Share Max (%)This factor identifies the maximum share of revenue estimated or reported to be derived from gambling as a percentage of the issuers’ total revenue in the latest financial year.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =   32687.27 ms /  1343 tokens (   24.34 ms per token,    41.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =   17800.44 ms /   120 runs   (  148.34 ms per token,     6.74 tokens per second)\n",
      "llama_perf_context_print:       total time =   50512.95 ms /  1463 tokens\n",
      "Llama.generate: 50 prefix-match hit, remaining 251 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query:  OR(AND([PornographyNotAccessibeToMinors] IS :NA,[PornographyDistMinRev] IS :NA),AND([PornographyDistMinRev] <= '0.02',[PornographyNotAccessibeToMinors] False))\n",
      "PornographyNotAccessibeToMinors = :NA → Null type \"Not applicable\"\n",
      "PornographyNotAccessibeToMinors: Pornography - Not accessible to minors. Pornography - Not accessible to minors: This factor identifies pornographic materials which are specifically marked as not accessible to minors or are prohibited/restricted for those persons below 18 years of age.\n",
      "PornographyDistMinRev = :NA → Null type \"Not applicable\"\n",
      "PornographyDistMinRev: Pornography - Distribution Minimum Percentage of Revenues (%). Pornography - Distribution Minimum Percentage of Revenues (%): This factor identifies the minimum share of revenue estimated or reported to be derived from involvement in the distribution of pornography as a percentage of the issuers’ total revenue in the latest financial year.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    5753.05 ms /   251 tokens (   22.92 ms per token,    43.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =   13218.44 ms /    95 runs   (  139.14 ms per token,     7.19 tokens per second)\n",
      "llama_perf_context_print:       total time =   18989.85 ms /   346 tokens\n",
      "Llama.generate: 50 prefix-match hit, remaining 273 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query:  OR([TobaccoInvolvement] ANY 'Distribution|Services',[TobaccoInvolvement] IS :NC)\n",
      "TobaccoInvolvement = :NC → Null type \"Not collected\"\n",
      "TobaccoInvolvement: Tobacco - Involvement Tie. Tobacco - Involvement Tie: This factor identifies issuers engaged in the production, distribution, or provision of services related to tobacco. The \"Production\" value identifies issuers engaged in manufacturing and producing tobacco products, as well as companies that grow or process raw tobacco leaves, \"Distribution\" includes issuers engaged in the wholesale or retail distribution of tobacco products, and \"Services\"  identifies iss...\n",
      "TobaccoInvolvement (enumeration): Tobacco - Involvement Tie. Tobacco - Involvement Tie: This factor identifies issuers engaged in the production, distribution, or provision of services related to tobacco. The \"Production\" value identifies issuers engaged in manufacturing and producing tobacco products, as well as companies that grow or process raw tobacco leaves, \"Distribution\" includes issuers engaged in the wholesale or retail distribution of tobacco products, and \"Services\"  identifies iss...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    6292.50 ms /   273 tokens (   23.05 ms per token,    43.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5129.16 ms /    37 runs   (  138.63 ms per token,     7.21 tokens per second)\n",
      "llama_perf_context_print:       total time =   11427.90 ms /   310 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 1 to translated_queries_TEST.xlsx\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from functools import partial\n",
    "import time\n",
    "\n",
    "#Reads and stores the Esgish queries\n",
    "df = pd.read_excel(\"NullType_10Queries.xlsx\")\n",
    "queries = df[\"Esgish\"].tolist()\n",
    "\n",
    "#Ensures no overload and efficiency\n",
    "batch_size = 100 \n",
    "output_file = \"translated_queries_TEST.xlsx\"\n",
    "\n",
    "#Looks at each query in each batch, calls the translate_query function, and stores it\n",
    "for i in range(0, len(queries), batch_size):\n",
    "    batch = queries[i:i + batch_size]\n",
    "    translated_batch = []\n",
    "    \n",
    "    for query in batch:\n",
    "        translated = translate_query(query)\n",
    "        translated_batch.append(translated)\n",
    "    \n",
    "    df_batch = pd.DataFrame({\n",
    "        \"Esgish\": batch,\n",
    "        \"English\": translated_batch\n",
    "    })\n",
    "\n",
    "    #Makes a new file if needed, or adds onto the current file during each batch in case the program crashes at some point\n",
    "    if i == 0:\n",
    "        df_batch.to_excel(output_file, index=False)  \n",
    "    else:\n",
    "        with pd.ExcelWriter(output_file, mode=\"a\", engine=\"openpyxl\", if_sheet_exists=\"overlay\") as writer:\n",
    "            df_batch.to_excel(writer, index=False, header=False, startrow=i + 1)\n",
    "    \n",
    "    print(f\"Saved batch {i // batch_size + 1} to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4814e3a0-0ddd-467e-8074-18a33f13a0c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 6 prefix-match hit, remaining 206 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    4678.38 ms /   206 tokens (   22.71 ms per token,    44.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9648.40 ms /    70 runs   (  137.83 ms per token,     7.26 tokens per second)\n",
      "llama_perf_context_print:       total time =   14339.53 ms /   276 tokens\n",
      "Llama.generate: 191 prefix-match hit, remaining 20 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 6\n",
      "\n",
      "The text is understandable but has some complexity and awkwardness. The use of technical terms such as \"abortifacients\" and \"maximum share of revenue\" may make it more challenging for some readers to fully comprehend. However, the overall structure and grammar of the text are clear.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     500.06 ms /    20 tokens (   25.00 ms per token,    39.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8782.47 ms /    64 runs   (  137.23 ms per token,     7.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    9293.47 ms /    84 tokens\n",
      "Llama.generate: 166 prefix-match hit, remaining 44 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is understandable, but it requires some knowledge of financial terminology and the context of the topic. The sentence structure is complex, and there are some minor errors in the phrasing. However, overall, the text is clear and easy to understand with some effort.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1008.98 ms /    44 tokens (   22.93 ms per token,    43.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    7579.05 ms /    55 runs   (  137.80 ms per token,     7.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    8597.58 ms /    99 tokens\n",
      "Llama.generate: 166 prefix-match hit, remaining 21 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 6\n",
      "\n",
      "The text is somewhat understandable, but it requires some knowledge of specific terms and concepts related to the topic of abortion and pharmaceuticals. It may also be more clear with some additional context or clarification on the specific terms used.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     491.99 ms /    21 tokens (   23.43 ms per token,    42.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =     956.87 ms /     7 runs   (  136.70 ms per token,     7.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    1450.18 ms /    28 tokens\n",
      "Llama.generate: 171 prefix-match hit, remaining 11 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     263.97 ms /    11 tokens (   24.00 ms per token,    41.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9346.55 ms /    68 runs   (  137.45 ms per token,     7.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    9622.05 ms /    79 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 28 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 4\n",
      "\n",
      "The text is somewhat understandable, but it contains awkward phrasing and lacks clarity. It could be improved by rephrasing to make it more clear what is being asked for. For example: \"Please provide a list of companies or issuers that produce abortifacients.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     637.27 ms /    28 tokens (   22.76 ms per token,    43.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5716.44 ms /    41 runs   (  139.43 ms per token,     7.17 tokens per second)\n",
      "llama_perf_context_print:       total time =    6360.38 ms /    69 tokens\n",
      "Llama.generate: 175 prefix-match hit, remaining 25 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would rate this text as 8. While there may be some minor errors or awkwardness in the phrasing, the overall meaning and intent of the text are clear and easy to understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     587.49 ms /    25 tokens (   23.50 ms per token,    42.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =   15351.97 ms /   104 runs   (  147.62 ms per token,     6.77 tokens per second)\n",
      "llama_perf_context_print:       total time =   15961.71 ms /   129 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 21 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rating for this text is 7. While it is grammatically correct and mostly understandable, there are some minor errors and awkwardness in the phrasing. For example, \"abortifacients\" may not be a commonly used term, and \"involved in the production, distribution, or provision of services related to\" could be simplified to \"provide services related to\". Overall, the text is mostly comprehensible, but could benefit from some revisions for clarity and flow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     494.80 ms /    21 tokens (   23.56 ms per token,    42.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =   14929.65 ms /   107 runs   (  139.53 ms per token,     7.17 tokens per second)\n",
      "llama_perf_context_print:       total time =   15446.62 ms /   128 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 27 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 6\n",
      "\n",
      "The text is generally understandable, but it could be improved by providing more context or clarifying some terms. For example, \"abortifacients\" may not be familiar to everyone, and it could be helpful to provide a brief explanation or definition. Additionally, it might be clearer to specify whether the companies or issuers being referred to are those that provide services related to abortifacients, or if the text is referring to all companies or issuers in general.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     624.83 ms /    27 tokens (   23.14 ms per token,    43.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6117.34 ms /    44 runs   (  139.03 ms per token,     7.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    6749.56 ms /    71 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 18 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but there are some minor errors and awkwardness. The sentence could be improved by rephrasing it to be more clear and concise.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     438.94 ms /    18 tokens (   24.39 ms per token,    41.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =   16777.26 ms /   121 runs   (  138.66 ms per token,     7.21 tokens per second)\n",
      "llama_perf_context_print:       total time =   17241.71 ms /   139 tokens\n",
      "Llama.generate: 171 prefix-match hit, remaining 42 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but there are a few issues that make it less clear. First, the phrase \"data factors related to abortion\" is somewhat unclear. It's not immediately clear what these factors are, and how they relate to abortion. Second, the phrase \"have involvement\" is also somewhat unclear. It's not clear what this means, and how it relates to the data factors related to abortion. Overall, the text is mostly understandable, but there are a few areas where it could be improved for clarity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     952.80 ms /    42 tokens (   22.69 ms per token,    44.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6904.73 ms /    50 runs   (  138.09 ms per token,     7.24 tokens per second)\n",
      "llama_perf_context_print:       total time =    7866.24 ms /    92 tokens\n",
      "Llama.generate: 166 prefix-match hit, remaining 13 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly clear and easy to understand, but there are a few minor errors and awkwardnesses. The sentence could be rephrased to make it more concise and easier to follow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     309.74 ms /    13 tokens (   23.83 ms per token,    41.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8292.61 ms /    60 runs   (  138.21 ms per token,     7.24 tokens per second)\n",
      "llama_perf_context_print:       total time =    8613.06 ms /    73 tokens\n",
      "Llama.generate: 166 prefix-match hit, remaining 31 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7. The text is mostly understandable, but it could be clearer. It might be helpful to specify what \"ESG data\" refers to, and to use more precise language (e.g., \"all companies with more than 2 board meetings per year\").\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     703.82 ms /    31 tokens (   22.70 ms per token,    44.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10082.69 ms /    73 runs   (  138.12 ms per token,     7.24 tokens per second)\n",
      "llama_perf_context_print:       total time =   10799.96 ms /   104 tokens\n",
      "Llama.generate: 166 prefix-match hit, remaining 14 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is clear and concise, but it may require some knowledge of corporate governance and ESG issues to fully understand. The use of technical terms such as \"low vote support\" and \"management proposal\" may make it slightly more complex, but overall the text is easily understandable with a moderate level of effort.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     330.21 ms /    14 tokens (   23.59 ms per token,    42.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4004.35 ms /    29 runs   (  138.08 ms per token,     7.24 tokens per second)\n",
      "llama_perf_context_print:       total time =    4339.32 ms /    43 tokens\n",
      "Llama.generate: 166 prefix-match hit, remaining 21 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8. The text is mostly understandable, but it could be improved by providing more context or clarifying some terms.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     488.89 ms /    21 tokens (   23.28 ms per token,    42.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =   15490.43 ms /   112 runs   (  138.31 ms per token,     7.23 tokens per second)\n",
      "llama_perf_context_print:       total time =   16002.60 ms /   133 tokens\n",
      "Llama.generate: 166 prefix-match hit, remaining 14 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8\n",
      "\n",
      "The text is mostly understandable, but it could be improved by providing more context or clarifying some terms. For example, it's not clear what the AFL-CIO Boycott List is or what criteria are used to determine which companies or issuers are listed. Additionally, the use of abbreviations like \"AFL-CIO\" may be unfamiliar to some readers. Overall, the text is clear and concise, but could benefit from some additional explanation or clarification.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     339.93 ms /    14 tokens (   24.28 ms per token,    41.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8447.81 ms /    61 runs   (  138.49 ms per token,     7.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    8798.53 ms /    75 tokens\n",
      "Llama.generate: 166 prefix-match hit, remaining 36 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8. The text is mostly clear and easy to understand, but it could be improved by adding more context or specificity. For example, it's not clear what is meant by \"ESG data\" or what criteria are being used to determine a company's age.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     823.15 ms /    36 tokens (   22.87 ms per token,    43.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4833.14 ms /    35 runs   (  138.09 ms per token,     7.24 tokens per second)\n",
      "llama_perf_context_print:       total time =    5662.14 ms /    71 tokens\n",
      "Llama.generate: 166 prefix-match hit, remaining 25 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8.\n",
      "\n",
      "The text is clear and easy to understand, but it may require some knowledge of financial terminology and regulations related to alcohol distribution.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     575.49 ms /    25 tokens (   23.02 ms per token,    43.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8160.79 ms /    59 runs   (  138.32 ms per token,     7.23 tokens per second)\n",
      "llama_perf_context_print:       total time =    8746.83 ms /    84 tokens\n",
      "Llama.generate: 179 prefix-match hit, remaining 13 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would rate this text as 7. While it is grammatically correct and conveys a clear message, it may be somewhat difficult to understand for those unfamiliar with financial terminology or the acronym \"ESG\" (Environmental, Social, and Governance).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     309.89 ms /    13 tokens (   23.84 ms per token,    41.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4562.01 ms /    33 runs   (  138.24 ms per token,     7.23 tokens per second)\n",
      "llama_perf_context_print:       total time =    4877.25 ms /    46 tokens\n",
      "Llama.generate: 175 prefix-match hit, remaining 13 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7. The text is mostly understandable, but it may require some effort to comprehend the specific criteria for the companies being selected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     310.56 ms /    13 tokens (   23.89 ms per token,    41.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4169.49 ms /    30 runs   (  138.98 ms per token,     7.20 tokens per second)\n",
      "llama_perf_context_print:       total time =    4484.82 ms /    43 tokens\n",
      "Llama.generate: 168 prefix-match hit, remaining 23 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7. The text is mostly understandable, but it could be improved by providing more context or clarifying some terms.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     530.56 ms /    23 tokens (   23.07 ms per token,    43.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4699.51 ms /    34 runs   (  138.22 ms per token,     7.23 tokens per second)\n",
      "llama_perf_context_print:       total time =    5235.64 ms /    57 tokens\n",
      "Llama.generate: 166 prefix-match hit, remaining 24 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8. The text is clear and easy to understand, but it may require some knowledge of financial terminology and concepts related to alcohol distribution.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     553.73 ms /    24 tokens (   23.07 ms per token,    43.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9695.28 ms /    70 runs   (  138.50 ms per token,     7.22 tokens per second)\n",
      "llama_perf_context_print:       total time =   10261.67 ms /    94 tokens\n",
      "Llama.generate: 173 prefix-match hit, remaining 27 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is understandable, but it may require some effort to comprehend. The language used is somewhat complex, and the sentence structure is a bit awkward. Additionally, there may be some minor errors or ambiguities in the text. However, overall, the text is relatively clear and easy to understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     640.78 ms /    27 tokens (   23.73 ms per token,    42.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8425.76 ms /    61 runs   (  138.13 ms per token,     7.24 tokens per second)\n",
      "llama_perf_context_print:       total time =    9077.35 ms /    88 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 18 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 5\n",
      "\n",
      "The text is understandable with effort, but it is somewhat awkward and complex. The sentence structure is a bit convoluted, and some of the language used may be unfamiliar to some readers. However, overall, the meaning of the text is clear.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     428.13 ms /    18 tokens (   23.79 ms per token,    42.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =   20953.67 ms /   151 runs   (  138.77 ms per token,     7.21 tokens per second)\n",
      "llama_perf_context_print:       total time =   21417.65 ms /   169 tokens\n",
      "Llama.generate: 175 prefix-match hit, remaining 21 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 6\n",
      "\n",
      "The text is mostly clear and easy to understand, but it could be improved by being more concise and specific. For example, instead of saying \"All companies or issuers,\" it would be better to specify the type of entity being referred to, such as \"Alcoholic beverage distributors\" or \"Licensed alcohol retailers.\" Additionally, the text could be revised to be more precise about what is meant by \"involved in the distribution of alcoholic beverages,\" as this could potentially include activities such as manufacturing, transportation, or wholesale distribution. Overall, while the text is generally understandable, there is room for improvement in terms of clarity and specificity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     510.81 ms /    21 tokens (   24.32 ms per token,    41.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6767.17 ms /    49 runs   (  138.11 ms per token,     7.24 tokens per second)\n",
      "llama_perf_context_print:       total time =    7286.64 ms /    70 tokens\n",
      "Llama.generate: 176 prefix-match hit, remaining 35 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rating for this text is 6. While the sentence is grammatically correct and relatively clear, it may still be somewhat difficult to understand for those who are not familiar with the specific terminology related to alcoholic beverages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     802.90 ms /    35 tokens (   22.94 ms per token,    43.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5959.92 ms /    43 runs   (  138.60 ms per token,     7.21 tokens per second)\n",
      "llama_perf_context_print:       total time =    6770.05 ms /    78 tokens\n",
      "Llama.generate: 176 prefix-match hit, remaining 20 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but there are a few minor errors and awkwardnesses. The sentence could be improved by using more precise language and avoiding unnecessary words.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     472.23 ms /    20 tokens (   23.61 ms per token,    42.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =   16354.86 ms /   118 runs   (  138.60 ms per token,     7.21 tokens per second)\n",
      "llama_perf_context_print:       total time =   16852.42 ms /   138 tokens\n",
      "Llama.generate: 176 prefix-match hit, remaining 15 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly comprehensible, but it could be improved by providing more context or clarifying some terms. For example, it might be helpful to define what is meant by \"ESG data\" or provide more information about the purpose of the list. Additionally, some of the language used in the text, such as \"involved in the production, distribution, or provision of services related to alcoholic beverages,\" could be more concise or easier to understand. Overall, however, the text is relatively clear and easy to understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     352.89 ms /    15 tokens (   23.53 ms per token,    42.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =   14590.33 ms /   104 runs   (  140.29 ms per token,     7.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14965.14 ms /   119 tokens\n",
      "Llama.generate: 171 prefix-match hit, remaining 15 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but there are a few minor issues. Firstly, the phrase \"involved in the production or services related to alcoholic beverages\" could be rephrased for clarity. Secondly, the use of \"or issuers\" could be confusing, as it is not clear whether the text is referring to companies or organizations. Overall, the text is comprehensible, but could benefit from some revisions for clarity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     354.45 ms /    15 tokens (   23.63 ms per token,    42.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =   16646.47 ms /   118 runs   (  141.07 ms per token,     7.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   17026.76 ms /   133 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 27 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8\n",
      "\n",
      "The text is generally understandable, but there are a few minor issues that could make it clearer. The phrase \"or issuers\" could be rephrased to \"such as issuers\" for clarity. Additionally, the phrase \"that provide services related to alcoholic beverages\" could be rephrased to \"that offer products or services related to alcoholic beverages\" for greater precision. Overall, the text is clear and easy to understand, but these small changes could make it even clearer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     648.92 ms /    27 tokens (   24.03 ms per token,    41.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =   20844.80 ms /   145 runs   (  143.76 ms per token,     6.96 tokens per second)\n",
      "llama_perf_context_print:       total time =   21529.22 ms /   172 tokens\n",
      "Llama.generate: 178 prefix-match hit, remaining 14 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but there are a few minor issues that make it slightly less clear. First, the phrase \"alcohol revenue share interval\" may be unfamiliar to some readers, and it's not immediately clear what it means. Second, the phrase \"in the latest financial year\" could be more precise, as it's not clear which financial year is being referred to. Finally, the use of \"or issuers\" could be more consistent, as it's not clear whether the text is referring to companies or issuers (or both). Overall, the text is mostly clear, but these minor issues make it slightly less comprehensible.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     342.21 ms /    14 tokens (   24.44 ms per token,    40.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =     866.79 ms /     6 runs   (  144.46 ms per token,     6.92 tokens per second)\n",
      "llama_perf_context_print:       total time =    1210.36 ms /    20 tokens\n",
      "Llama.generate: 172 prefix-match hit, remaining 33 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     813.33 ms /    33 tokens (   24.65 ms per token,    40.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =   18942.98 ms /   135 runs   (  140.32 ms per token,     7.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   19787.90 ms /   168 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 72 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is generally understandable, but there are a few minor issues that make it less clear. First, the phrase \"Alcohol - Revenue Share Interval\" is not commonly used and may be confusing to some readers. Second, the use of the word \"issuers\" instead of \"companies\" may be confusing for some readers who are not familiar with financial terminology. Finally, the use of the phrase \"in the latest financial year\" may be confusing for some readers who are not familiar with financial reporting practices. Overall, however, the text is clear and easy to understand with a bit of effort.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1688.66 ms /    72 tokens (   23.45 ms per token,    42.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10613.10 ms /    76 runs   (  139.65 ms per token,     7.16 tokens per second)\n",
      "llama_perf_context_print:       total time =   12316.84 ms /   148 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 63 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 6\n",
      "\n",
      "The text is understandable, but it requires some effort to comprehend. The language used is somewhat complex, and the sentence structure is not very clear. Additionally, the use of abbreviations and technical terms may make it more difficult for some readers to understand. However, overall, the text is still relatively easy to understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1469.03 ms /    63 tokens (   23.32 ms per token,    42.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =     829.87 ms /     6 runs   (  138.31 ms per token,     7.23 tokens per second)\n",
      "llama_perf_context_print:       total time =    2300.26 ms /    69 tokens\n",
      "Llama.generate: 183 prefix-match hit, remaining 41 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     962.11 ms /    41 tokens (   23.47 ms per token,    42.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9027.89 ms /    64 runs   (  141.06 ms per token,     7.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   10001.71 ms /   105 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 48 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: All companies or issuers with an Alcohol - Revenue Share Interval between 15% and 20%, 20% and 25%, 25% and 50%, or 50% and 100%.\n",
      "Rating: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1111.85 ms /    48 tokens (   23.16 ms per token,    43.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9596.48 ms /    68 runs   (  141.12 ms per token,     7.09 tokens per second)\n",
      "llama_perf_context_print:       total time =   10721.23 ms /   116 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 46 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 6\n",
      "\n",
      "The text is mostly understandable, but there are some minor errors and awkwardness. The phrase \"Alcohol - Revenue Share Interval\" could be rephrased for clarity, and the use of percentages could be more consistent. Overall, the text is comprehensible with some effort.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1071.63 ms /    46 tokens (   23.30 ms per token,    42.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =   11275.81 ms /    81 runs   (  139.21 ms per token,     7.18 tokens per second)\n",
      "llama_perf_context_print:       total time =   12363.29 ms /   127 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 26 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 6\n",
      "\n",
      "The text is mostly understandable, but there are a few awkward phrases and minor errors. The phrase \"Alcohol - Revenue Share Interval\" could be rephrased for clarity, and the use of \"or\" in the second condition could be replaced with \"and\" for better flow. Overall, the text is comprehensible with some effort.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     630.94 ms /    26 tokens (   24.27 ms per token,    41.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =   16301.01 ms /   117 runs   (  139.32 ms per token,     7.18 tokens per second)\n",
      "llama_perf_context_print:       total time =   16958.30 ms /   143 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 26 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 6\n",
      "\n",
      "The text is mostly understandable, but there are a few issues that make it less than perfect. First, the phrase \"Alcohol - Revenue Share Interval\" is not commonly used and may be confusing to some readers. Second, the use of percentages without context or explanation can make the text harder to understand. Finally, the use of \"or issuers\" instead of \"companies\" may be confusing to some readers. Overall, the text is mostly understandable, but could benefit from some clarification and context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     610.68 ms /    26 tokens (   23.49 ms per token,    42.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =     841.78 ms /     6 runs   (  140.30 ms per token,     7.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    1453.75 ms /    32 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 15 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     357.67 ms /    15 tokens (   23.84 ms per token,    41.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =   11151.13 ms /    80 runs   (  139.39 ms per token,     7.17 tokens per second)\n",
      "llama_perf_context_print:       total time =   11524.09 ms /    95 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 20 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 5\n",
      "\n",
      "The text is somewhat understandable, but it contains some awkwardness and complexity. The phrase \"alcohol revenue share interval\" may be unfamiliar to some readers, and the use of \"or issuers\" instead of \"companies\" may also cause confusion. Overall, the text could benefit from some rephrasing to improve clarity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     545.64 ms /    20 tokens (   27.28 ms per token,    36.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5289.66 ms /    38 runs   (  139.20 ms per token,     7.18 tokens per second)\n",
      "llama_perf_context_print:       total time =    5842.15 ms /    58 tokens\n",
      "Llama.generate: 166 prefix-match hit, remaining 24 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7. The text is mostly understandable, but it may be slightly confusing for some people due to the use of technical jargon and abbreviations.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     609.96 ms /    24 tokens (   25.42 ms per token,    39.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10851.20 ms /    76 runs   (  142.78 ms per token,     7.00 tokens per second)\n",
      "llama_perf_context_print:       total time =   11476.21 ms /   100 tokens\n",
      "Llama.generate: 168 prefix-match hit, remaining 20 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7. The text is mostly understandable, but there are a few minor issues. The phrase \"Alcohol Revenue Share Max\" may be unfamiliar to some readers, and the use of percent symbols and the phrase \"in the latest financial year\" could be clearer. Overall, however, the text is relatively clear and easy to understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     484.39 ms /    20 tokens (   24.22 ms per token,    41.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6541.06 ms /    46 runs   (  142.20 ms per token,     7.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    7033.71 ms /    66 tokens\n",
      "Llama.generate: 166 prefix-match hit, remaining 24 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8. The text is mostly understandable, but it may be slightly confusing for those unfamiliar with financial terminology or the concept of ESG (Environmental, Social, and Governance) data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     577.99 ms /    24 tokens (   24.08 ms per token,    41.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =   16493.69 ms /   116 runs   (  142.19 ms per token,     7.03 tokens per second)\n",
      "llama_perf_context_print:       total time =   17097.78 ms /   140 tokens\n",
      "Llama.generate: 166 prefix-match hit, remaining 23 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but it could be improved by providing more context or clarifying some terms. For example, it's not clear what \"Alcohol Revenue Share Max\" means, and it's not clear what the purpose of the list is. Additionally, the use of abbreviations like \"or\" and \"higher\" can make the text more difficult to understand for some readers. Overall, the text is mostly comprehensible, but it could be improved with some additional context and clarity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     551.71 ms /    23 tokens (   23.99 ms per token,    41.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =   23330.80 ms /   166 runs   (  140.55 ms per token,     7.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   23925.15 ms /   189 tokens\n",
      "Llama.generate: 166 prefix-match hit, remaining 29 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8\n",
      "\n",
      "The text is mostly clear and easy to understand, but there are a few minor issues that could make it slightly more comprehensible. Firstly, the phrase \"alcohol revenue share\" might not be immediately clear to everyone, as it is a specific term used in the financial industry. It could be helpful to provide a brief explanation of what this term means, or use a more common phrase. Secondly, the use of the word \"at least\" could be confusing, as it is not clear whether the companies must meet this requirement or if it is optional. It might be better to use \"with a revenue share of at least 30%\" to make this clear. Overall, the text is mostly understandable, and these small changes would make it even clearer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     703.71 ms /    29 tokens (   24.27 ms per token,    41.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9439.77 ms /    67 runs   (  140.89 ms per token,     7.10 tokens per second)\n",
      "llama_perf_context_print:       total time =   10156.00 ms /    96 tokens\n",
      "Llama.generate: 176 prefix-match hit, remaining 16 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8\n",
      "\n",
      "The text is clear and concise, but it may require some knowledge of financial terminology and regulations related to alcohol. Additionally, the phrase \"or issuers\" may add some complexity to the text. Overall, the text is easily understandable with a bit of context and effort.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     388.26 ms /    16 tokens (   24.27 ms per token,    41.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =   14112.21 ms /   101 runs   (  139.72 ms per token,     7.16 tokens per second)\n",
      "llama_perf_context_print:       total time =   14522.32 ms /   117 tokens\n",
      "Llama.generate: 180 prefix-match hit, remaining 13 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but it could be improved by providing more context or clarifying certain terms. For example, \"alcohol revenue share\" may not be immediately clear to all readers, and it's not specified what \"issuers\" refer to. Additionally, the use of percentages and specific financial year could be more precise. Overall, the text is clear and concise, but could benefit from some additional explanations or definitions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     349.40 ms /    13 tokens (   26.88 ms per token,    37.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3091.57 ms /    22 runs   (  140.53 ms per token,     7.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    3444.87 ms /    35 tokens\n",
      "Llama.generate: 171 prefix-match hit, remaining 22 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is understandable with effort. I would rate it a 6 out of 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     527.72 ms /    22 tokens (   23.99 ms per token,    41.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =   17572.62 ms /   125 runs   (  140.58 ms per token,     7.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   18128.59 ms /   147 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 28 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8\n",
      "\n",
      "The text is mostly clear and easy to understand, but there are a few minor issues. First, the phrase \"or issuers\" could be rephrased to \"companies or issuers\" for clarity. Second, the phrase \"minimum alcohol revenue share\" could be rephrased to \"alcohol revenue share\" for clarity. Finally, the phrase \"in the latest financial year\" could be rephrased to \"in the most recent financial year\" for clarity. Overall, the text is understandable with some minor revisions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     663.48 ms /    28 tokens (   23.70 ms per token,    42.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =   15959.78 ms /   114 runs   (  140.00 ms per token,     7.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16648.14 ms /   142 tokens\n",
      "Llama.generate: 172 prefix-match hit, remaining 23 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but it could be improved by providing more context or clarifying some terms. For example, it might be helpful to define what \"ESG data\" means or provide more information about the Paris Agreement and the United Nations Framework Convention on Climate Change. Additionally, the use of technical jargon such as \"ratified\" and \"issuers\" may make the text more difficult to understand for some readers. Overall, however, the text is relatively clear and easy to follow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     546.47 ms /    23 tokens (   23.76 ms per token,    42.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9426.18 ms /    67 runs   (  140.69 ms per token,     7.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    9985.22 ms /    90 tokens\n",
      "Llama.generate: 172 prefix-match hit, remaining 49 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 6\n",
      "\n",
      "The text is understandable, but it has some awkwardness and complexity due to the use of technical terms and jargon. The sentence structure is also somewhat convoluted, making it harder to follow. However, overall, the meaning of the text is clear and easy to understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1132.19 ms /    49 tokens (   23.11 ms per token,    43.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8392.30 ms /    60 runs   (  139.87 ms per token,     7.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    9535.69 ms /   109 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 30 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is understandable, but it requires some effort to comprehend. The language used is more complex than in everyday communication, and some of the terms may not be familiar to everyone. However, the overall structure and meaning of the text are clear.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     694.90 ms /    30 tokens (   23.16 ms per token,    43.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =   11575.83 ms /    82 runs   (  141.17 ms per token,     7.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   12286.79 ms /   112 tokens\n",
      "Llama.generate: 177 prefix-match hit, remaining 247 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8\n",
      "\n",
      "The text is mostly understandable, but there are a few minor issues. Firstly, it is not clear what \"Corruption Perception Index\" refers to without further context. Secondly, the use of \"or\" instead of \"and\" in the scoring range could be confusing. Overall, the text is clear and easy to understand once the context is provided.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    5633.42 ms /   247 tokens (   22.81 ms per token,    43.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =   36323.61 ms /   255 runs   (  142.45 ms per token,     7.02 tokens per second)\n",
      "llama_perf_context_print:       total time =   42034.88 ms /   502 tokens\n",
      "Llama.generate: 177 prefix-match hit, remaining 13 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n",
      "\n",
      "### Response:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     318.66 ms /    13 tokens (   24.51 ms per token,    40.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6982.49 ms /    50 runs   (  139.65 ms per token,     7.16 tokens per second)\n",
      "llama_perf_context_print:       total time =    7310.26 ms /    63 tokens\n",
      "Llama.generate: 179 prefix-match hit, remaining 11 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8. The text is mostly understandable, but there is a minor error in the phrasing. It should be \"All companies or issuers with a Corruption Perception Index score of less than 30.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     279.80 ms /    11 tokens (   25.44 ms per token,    39.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6884.03 ms /    49 runs   (  140.49 ms per token,     7.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    7172.45 ms /    60 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 15 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8\n",
      "\n",
      "The text is clear and easy to understand. However, it may be slightly more comprehensible if it includes more context or explanation of what the Corruption Perception Index is and why it is relevant.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     364.93 ms /    15 tokens (   24.33 ms per token,    41.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8531.63 ms /    61 runs   (  139.86 ms per token,     7.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    8908.24 ms /    76 tokens\n",
      "Llama.generate: 172 prefix-match hit, remaining 21 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7. The text is mostly understandable, but it could be improved by providing more context or clarifying some terms. For example, it might be helpful to specify which country's death penalty is being referred to, or to define what is meant by \"issuers.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     506.78 ms /    21 tokens (   24.13 ms per token,    41.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =   22728.51 ms /   162 runs   (  140.30 ms per token,     7.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   23277.04 ms /   183 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 24 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but there are a few minor issues. Firstly, the phrase \"Death penalty not fully abolished\" could be more clearly stated as \"companies or issuers that have a Death Penalty Status of 'Death penalty not fully abolished'\" to make it clear that the text is referring to companies or issuers. Secondly, the phrase \"All companies or issuers\" could be more clearly stated as \"All companies or issuers that meet the criteria\" to make it clear that the text is referring to a specific group of companies or issuers. Overall, the text is mostly understandable, but there are a few minor issues that could be clarified for better comprehension.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     581.53 ms /    24 tokens (   24.23 ms per token,    41.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =   14900.03 ms /   105 runs   (  141.91 ms per token,     7.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   15504.04 ms /   129 tokens\n",
      "Llama.generate: 176 prefix-match hit, remaining 14 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly comprehensible, but there are a few minor issues that make it slightly less clear. The phrase \"euthanasia is either illegal, not punishable by law, or legal\" could be rephrased to be more concise and clear. Additionally, the use of \"issuers\" instead of \"companies\" may be confusing for some readers. Overall, the text is understandable with some effort, and the meaning is clear.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     337.61 ms /    14 tokens (   24.11 ms per token,    41.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4070.24 ms /    29 runs   (  140.35 ms per token,     7.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4412.63 ms /    43 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 26 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: All companies or issuers where euthanasia is not punishable by law or legal. → Rating: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     610.61 ms /    26 tokens (   23.48 ms per token,    42.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =   11394.16 ms /    81 runs   (  140.67 ms per token,     7.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   12020.63 ms /   107 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 21 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8\n",
      "\n",
      "The text is mostly understandable, but there are a few minor issues. Firstly, it is not clear what \"Climate Change Performance Index\" refers to without additional context. Secondly, the phrase \"or issuers\" could be rephrased for clarity. Overall, the text is clear and easy to understand with a little bit of effort.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     509.00 ms /    21 tokens (   24.24 ms per token,    41.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4212.97 ms /    30 runs   (  140.43 ms per token,     7.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4727.10 ms /    51 tokens\n",
      "Llama.generate: 172 prefix-match hit, remaining 27 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: All companies or issuers that have been flagged for having a money laundering concern in their country. → Rating: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     636.07 ms /    27 tokens (   23.56 ms per token,    42.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4637.30 ms /    33 runs   (  140.52 ms per token,     7.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5279.11 ms /    60 tokens\n",
      "Llama.generate: 193 prefix-match hit, remaining 80 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8. The text is mostly understandable, but it may require some knowledge of energy terminology and specifics of nuclear power usage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1828.54 ms /    80 tokens (   22.86 ms per token,    43.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =   12088.15 ms /    86 runs   (  140.56 ms per token,     7.11 tokens per second)\n",
      "llama_perf_context_print:       total time =   13933.82 ms /   166 tokens\n",
      "Llama.generate: 172 prefix-match hit, remaining 31 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 6\n",
      "\n",
      "The text is somewhat understandable, but it is quite complex and contains several technical terms related to energy and nuclear power. The sentence structure is also quite convoluted, making it difficult to follow. However, the overall meaning of the text is clear, and it provides specific criteria for companies or issuers that meet certain conditions related to nuclear power usage and moratoriums.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     740.75 ms /    31 tokens (   23.90 ms per token,    41.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5060.11 ms /    36 runs   (  140.56 ms per token,     7.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5806.81 ms /    67 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 21 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8\n",
      "\n",
      "The text is mostly clear and easy to understand, but it contains some technical jargon related to nuclear power plants and the assessment year.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     506.65 ms /    21 tokens (   24.13 ms per token,    41.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =   15377.29 ms /   110 runs   (  139.79 ms per token,     7.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   15907.69 ms /   131 tokens\n",
      "Llama.generate: 172 prefix-match hit, remaining 21 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 6\n",
      "\n",
      "The text is mostly understandable, but there are a few minor issues that make it less clear. The abbreviation \"CCANuclearPowerTPES\" may not be immediately clear to everyone, and it's not entirely clear what the value of 5 represents. Additionally, the use of \"or\" instead of \"and\" in the first clause may make the sentence a bit more confusing. Overall, however, the text is still relatively easy to understand with a bit of effort.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     506.39 ms /    21 tokens (   24.11 ms per token,    41.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8824.14 ms /    63 runs   (  140.07 ms per token,     7.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    9342.51 ms /    84 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 28 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is clear and concise, but it may require some knowledge of energy industry terminology to fully understand. The sentence structure is also somewhat complex, with multiple clauses and modifiers. However, overall the meaning is clear and the text is relatively easy to understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     656.32 ms /    28 tokens (   23.44 ms per token,    42.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =   11192.72 ms /    80 runs   (  139.91 ms per token,     7.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   11865.25 ms /   108 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 24 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8\n",
      "\n",
      "The text is mostly understandable, but it may require some knowledge of the Nuclear Weapons Treaty on Non-Proliferation and its signatories. The sentence structure is also somewhat complex, with multiple clauses and modifiers. However, the overall meaning is clear, and the use of technical terms is appropriate for the context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     572.70 ms /    24 tokens (   23.86 ms per token,    41.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =   13710.97 ms /    98 runs   (  139.91 ms per token,     7.15 tokens per second)\n",
      "llama_perf_context_print:       total time =   14304.29 ms /   122 tokens\n",
      "Llama.generate: 185 prefix-match hit, remaining 9 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7.\n",
      "\n",
      "The text is mostly understandable, but it could be improved by providing more context or clarifying some terms. For example, it's not clear what \"ESG data\" refers to, and the phrase \"All companies or issuers\" could be more specific. Additionally, the use of abbreviations like \"CEO\" and \"Median Employee Pay Ratio\" may make the text less accessible to some readers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     253.59 ms /     9 tokens (   28.18 ms per token,    35.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =   17352.46 ms /   117 runs   (  148.31 ms per token,     6.74 tokens per second)\n",
      "llama_perf_context_print:       total time =   17632.64 ms /   126 tokens\n",
      "Llama.generate: 173 prefix-match hit, remaining 17 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but it could be improved by providing more context or clarifying some terms. For example, it's not clear what \"ESG data\" refers to, and it's not clear what the \"Median Employee Pay Ratio\" is. Additionally, the use of \"or issuers\" could be confusing, as it's not clear what an \"issuer\" is in this context. Overall, the text is mostly understandable, but it could benefit from some additional clarification.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     439.44 ms /    17 tokens (   25.85 ms per token,    38.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4235.34 ms /    29 runs   (  146.05 ms per token,     6.85 tokens per second)\n",
      "llama_perf_context_print:       total time =    4679.64 ms /    46 tokens\n",
      "Llama.generate: 166 prefix-match hit, remaining 29 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7. The text is mostly understandable, but it could be improved by adding more context or clarifying certain terms.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     794.97 ms /    29 tokens (   27.41 ms per token,    36.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2279.16 ms /    16 runs   (  142.45 ms per token,     7.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    3076.91 ms /    45 tokens\n",
      "Llama.generate: 171 prefix-match hit, remaining 15 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is understandable with some effort. The rating is 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     362.09 ms /    15 tokens (   24.14 ms per token,    41.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =   16255.87 ms /   116 runs   (  140.14 ms per token,     7.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   16641.59 ms /   131 tokens\n",
      "Llama.generate: 177 prefix-match hit, remaining 7 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but it could be improved by providing more context or clarifying some terms. For example, it's not clear what \"special grant percentage\" refers to, and it might be helpful to specify which companies are being referred to (e.g., publicly traded companies, private companies, etc.). Additionally, the phrase \"greater than 50%\" could be rephrased to be more precise (e.g., \"with a special grant percentage of more than 50%\").\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     198.49 ms /     7 tokens (   28.36 ms per token,    35.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =     851.94 ms /     6 runs   (  141.99 ms per token,     7.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    1051.69 ms /    13 tokens\n",
      "Llama.generate: 166 prefix-match hit, remaining 19 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     510.19 ms /    19 tokens (   26.85 ms per token,    37.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =   18294.14 ms /   131 runs   (  139.65 ms per token,     7.16 tokens per second)\n",
      "llama_perf_context_print:       total time =   18833.17 ms /   150 tokens\n",
      "Llama.generate: 166 prefix-match hit, remaining 24 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8.\n",
      "\n",
      "The text is mostly understandable, but there are a few minor issues that make it slightly less clear. First, the abbreviation \"NEO\" is not immediately clear, so readers may need to look it up or understand its context. Second, the phrase \"average NEO pay ratio\" may be confusing to some readers who are not familiar with the concept or terminology. Finally, the use of \"greater than\" instead of \"more than\" may be slightly less common or less clear to some readers. Overall, however, the text is relatively clear and easy to understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     587.73 ms /    24 tokens (   24.49 ms per token,    40.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4754.41 ms /    34 runs   (  139.84 ms per token,     7.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    5347.65 ms /    58 tokens\n",
      "Llama.generate: 166 prefix-match hit, remaining 25 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8. The text is clear and easy to understand, but it may require some knowledge of financial terminology and regulations related to executive compensation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     590.29 ms /    25 tokens (   23.61 ms per token,    42.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8946.71 ms /    64 runs   (  139.79 ms per token,     7.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    9548.38 ms /    89 tokens\n",
      "Llama.generate: 166 prefix-match hit, remaining 30 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 6\n",
      "\n",
      "The text is understandable, but it requires some effort to comprehend. The language used is more formal and technical, and there are some unfamiliar terms such as \"CEO\" and \"NEO.\" Additionally, the sentence structure is complex and could be improved for clarity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     700.57 ms /    30 tokens (   23.35 ms per token,    42.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9756.81 ms /    68 runs   (  143.48 ms per token,     6.97 tokens per second)\n",
      "llama_perf_context_print:       total time =   10470.22 ms /    98 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 27 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 6\n",
      "\n",
      "The text is mostly understandable, but it contains some technical jargon and abbreviations that may not be familiar to everyone. The sentence structure is also somewhat complex, making it slightly more difficult to follow. However, overall, the text is clear and conveys a specific message.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     660.04 ms /    27 tokens (   24.45 ms per token,    40.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8344.21 ms /    59 runs   (  141.43 ms per token,     7.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    9014.90 ms /    86 tokens\n",
      "Llama.generate: 172 prefix-match hit, remaining 14 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is understandable, but it may require some effort to comprehend fully. The sentence structure is complex, and some words may be unfamiliar to some readers. However, the meaning of the text is clear, and the grammar is correct.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     341.67 ms /    14 tokens (   24.41 ms per token,    40.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =   12755.12 ms /    90 runs   (  141.72 ms per token,     7.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   13115.08 ms /   104 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 23 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but it could be improved by providing more context or clarifying certain terms. For example, it may not be clear what \"executive\" or \"insider\" means in this context, and it's unclear what \"ESG data\" refers to. Additionally, it's not clear what the purpose of the list is or how it will be used.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     546.56 ms /    23 tokens (   23.76 ms per token,    42.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =   14826.94 ms /   105 runs   (  141.21 ms per token,     7.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   15395.89 ms /   128 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 22 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8\n",
      "\n",
      "The text is mostly clear and easy to understand, but it could be improved by providing more context or clarifying some terms. For example, it's not clear what \"Red flag\" means in this context, and it's not clear what \"chemical weapons\" refers to. Additionally, it's not clear what \"issuers\" means in this context. Overall, the text is understandable with some effort, but it could be improved with more clarity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     552.59 ms /    22 tokens (   25.12 ms per token,    39.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10748.68 ms /    76 runs   (  141.43 ms per token,     7.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   11315.60 ms /    98 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 29 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize, but I cannot rate the given text as it does not meet the criteria for comprehensibility. The text is grammatically correct and does not contain any errors, but it is not clear what the \"green flag\" represents or what the \"overall flag\" refers to. Without additional context, it is difficult to determine the meaning of the text.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     678.44 ms /    29 tokens (   23.39 ms per token,    42.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4539.54 ms /    32 runs   (  141.86 ms per token,     7.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    5223.38 ms /    61 tokens\n",
      "Llama.generate: 177 prefix-match hit, remaining 16 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Show me all companies or issuers that have an overall Red or Amber flag for Chemical Weapons. → Rating: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     413.06 ms /    16 tokens (   25.82 ms per token,    38.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =   12584.73 ms /    88 runs   (  143.01 ms per token,     6.99 tokens per second)\n",
      "llama_perf_context_print:       total time =   13015.31 ms /   104 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 21 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8\n",
      "\n",
      "The text is mostly understandable, but there are a few minor issues. Firstly, the use of \"or issuers\" is a bit awkward and could be rephrased to \"companies or issuers\". Secondly, the use of \"flag\" instead of \"rating\" might be confusing for some people. Overall, the text is clear and easy to understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     511.59 ms /    21 tokens (   24.36 ms per token,    41.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    7939.74 ms /    56 runs   (  141.78 ms per token,     7.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    8461.30 ms /    77 tokens\n",
      "Llama.generate: 166 prefix-match hit, remaining 24 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8. The text is mostly understandable, but it could be improved by adding more context or clarifying some terms. For example, it might be helpful to define what \"ESG\" stands for or provide more information about the purpose of the list.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     597.59 ms /    24 tokens (   24.90 ms per token,    40.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8182.16 ms /    58 runs   (  141.07 ms per token,     7.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    8790.34 ms /    82 tokens\n",
      "Llama.generate: 176 prefix-match hit, remaining 16 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: All companies or issuers that are involved in the production of ammunition for civilian firearms. → Rating: 7. The text is generally understandable, but it may be less clear to some people due to the use of technical terms and jargon.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     387.10 ms /    16 tokens (   24.19 ms per token,    41.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10494.21 ms /    74 runs   (  141.81 ms per token,     7.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   10895.40 ms /    90 tokens\n",
      "Llama.generate: 179 prefix-match hit, remaining 8 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 6\n",
      "\n",
      "The text is generally understandable, but it contains some technical jargon and specific terms that may not be familiar to everyone. Additionally, the sentence structure is somewhat complex, making it slightly more difficult to follow. However, with some effort and context, most people should be able to understand the main idea of the text.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     218.08 ms /     8 tokens (   27.26 ms per token,    36.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =   12269.95 ms /    86 runs   (  142.67 ms per token,     7.01 tokens per second)\n",
      "llama_perf_context_print:       total time =   12505.90 ms /    94 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 21 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 6\n",
      "\n",
      "The text is mostly understandable, but it contains some jargon and technical terms that may require some context or explanation. The phrase \"assault weapons\" may not be familiar to everyone, and the use of the word \"involved\" could be ambiguous. Overall, the text is clear and concise, but there may be some minor confusion or misunderstandings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     507.43 ms /    21 tokens (   24.16 ms per token,    41.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =     848.33 ms /     6 runs   (  141.39 ms per token,     7.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    1357.38 ms /    27 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 31 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     722.74 ms /    31 tokens (   23.31 ms per token,    42.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9460.12 ms /    67 runs   (  141.20 ms per token,     7.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   10195.21 ms /    98 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 31 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 6\n",
      "\n",
      "The text is somewhat understandable, but it requires some knowledge of financial terms and specific industry jargon. The sentence structure is also somewhat complex, making it more challenging to comprehend. However, the meaning of the text is clear, and with some effort, it can be understood.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     722.98 ms /    31 tokens (   23.32 ms per token,    42.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =     857.51 ms /     6 runs   (  142.92 ms per token,     7.00 tokens per second)\n",
      "llama_perf_context_print:       total time =    1581.73 ms /    37 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 14 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     384.41 ms /    14 tokens (   27.46 ms per token,    36.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6640.95 ms /    47 runs   (  141.30 ms per token,     7.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    7033.56 ms /    61 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 16 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 5.\n",
      "\n",
      "The text is understandable with effort, but it is somewhat awkward and complex. The use of the term \"civilian firearms\" may also be unfamiliar to some readers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     385.75 ms /    16 tokens (   24.11 ms per token,    41.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =   14020.51 ms /    99 runs   (  141.62 ms per token,     7.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   14426.99 ms /   115 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 16 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly clear and easy to understand, but there are a few minor issues. Firstly, the phrase \"involved in the production\" could be rephrased to \"manufacture\" or \"produce\" for clarity. Secondly, the term \"civilian firearms\" could be defined or explained for those who may not be familiar with it. Overall, the text is understandable with a little effort.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     390.02 ms /    16 tokens (   24.38 ms per token,    41.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9313.75 ms /    66 runs   (  141.12 ms per token,     7.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    9716.21 ms /    82 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 24 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but it contains some technical jargon and specific terminology that may not be familiar to everyone. The sentence structure is also somewhat complex, with multiple clauses and modifiers. However, overall the meaning is clear and the text is coherent.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     573.94 ms /    24 tokens (   23.91 ms per token,    41.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5383.70 ms /    38 runs   (  141.68 ms per token,     7.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    5964.11 ms /    62 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 27 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but it contains some technical jargon and specific terms related to firearms that may not be familiar to everyone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     636.20 ms /    27 tokens (   23.56 ms per token,    42.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =     848.72 ms /     6 runs   (  141.45 ms per token,     7.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    1486.15 ms /    33 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 28 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     654.82 ms /    28 tokens (   23.39 ms per token,    42.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    7646.22 ms /    54 runs   (  141.60 ms per token,     7.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    8310.94 ms /    82 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 37 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8\n",
      "\n",
      "The text is clear and easy to understand, but it may be slightly more complex than some other examples due to the use of technical terms related to firearms. However, the sentence structure is straightforward, and the meaning is clear.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     865.62 ms /    37 tokens (   23.40 ms per token,    42.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =   15439.38 ms /   109 runs   (  141.65 ms per token,     7.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   16328.37 ms /   146 tokens\n",
      "Llama.generate: 183 prefix-match hit, remaining 20 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 6\n",
      "\n",
      "The text is mostly understandable, but it contains some technical jargon and specific terminology that may not be immediately clear to everyone. The phrase \"Civilian Firearms - Production & Services Revenue Share Max\" may require some context or explanation to fully understand. Additionally, the use of \"or issuers\" may add some complexity to the sentence. Overall, the text is relatively clear, but there may be some minor confusion for those unfamiliar with the specific terms and phrases used.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     493.91 ms /    20 tokens (   24.70 ms per token,    40.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =     853.84 ms /     6 runs   (  142.31 ms per token,     7.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    1349.16 ms /    26 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 104 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    2440.26 ms /   104 tokens (   23.46 ms per token,    42.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    7496.22 ms /    53 runs   (  141.44 ms per token,     7.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    9945.97 ms /   157 tokens\n",
      "Llama.generate: 173 prefix-match hit, remaining 26 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 5\n",
      "\n",
      "The text is somewhat understandable, but it contains some complex sentence structures and technical terms related to the topic of firearms and ammunition. It may require some effort to fully comprehend the meaning of the text.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     679.59 ms /    26 tokens (   26.14 ms per token,    38.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =     852.63 ms /     6 runs   (  142.11 ms per token,     7.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    1533.41 ms /    32 tokens\n",
      "Llama.generate: 171 prefix-match hit, remaining 38 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     892.15 ms /    38 tokens (   23.48 ms per token,    42.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8782.12 ms /    62 runs   (  141.65 ms per token,     7.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    9685.96 ms /   100 tokens\n",
      "Llama.generate: 174 prefix-match hit, remaining 47 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but it could be improved by providing more context or clarifying some terms. For example, it's not clear what \"ESG\" stands for, and some of the sub-industries listed may not be familiar to everyone.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1087.31 ms /    47 tokens (   23.13 ms per token,    43.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10892.59 ms /    77 runs   (  141.46 ms per token,     7.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   11994.97 ms /   124 tokens\n",
      "Llama.generate: 177 prefix-match hit, remaining 42 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but there are some minor errors and awkwardness. The sentence could be improved by removing unnecessary words and phrases, such as \"All companies or issuers that operate in the\" and \"sub-industries.\" Additionally, the sentence could be rephrased to be more concise and clear.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     993.87 ms /    42 tokens (   23.66 ms per token,    42.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    7086.41 ms /    50 runs   (  141.73 ms per token,     7.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    8089.11 ms /    92 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 169 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 6\n",
      "\n",
      "The text is mostly understandable, but there are a few awkward phrases and minor errors. The sentence could be improved by breaking it up into smaller, more concise phrases, and using more common language.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    3845.68 ms /   169 tokens (   22.76 ms per token,    43.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5668.18 ms /    40 runs   (  141.70 ms per token,     7.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    9520.83 ms /   209 tokens\n",
      "Llama.generate: 175 prefix-match hit, remaining 248 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would rate this text as 8. While there may be some minor errors or awkwardness in the phrasing, the overall comprehensibility is good and the text is easy to understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    5786.18 ms /   248 tokens (   23.33 ms per token,    42.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =   36660.10 ms /   255 runs   (  143.77 ms per token,     6.96 tokens per second)\n",
      "llama_perf_context_print:       total time =   42529.61 ms /   503 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 25 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Please provide a list of companies or issuers that belong to the following sub-industries: Oil & Gas Exploration & Production, Hotels, Resorts & Cruise Lines, Automobile Manufacturers, Diversified REITs, Aluminum, Electronic Equipment & Instruments, Industrial REITs, Homebuilding, Airlines, Airport Services, Tires & Rubber, Construction Machinery & Heavy Trucks, Industrial Conglomerates, Construction Materials, Hotel & Resort REITs, Building Products, Electronic Manufacturing Services, Industrial Gases, Marine, Gold, Copper, Diversified Metals & Mining, Computer Hardware, Multi-Utilities, Electronic Components, Real Estate Services, Real Estate Operating Companies, Fertilizers & Agricultural Chemicals, Real Estate Management & Development, Coal & Consumable Fuels, Networking Equipment, Semiconductors, Marine Ports & Services, Semiconductor Equipment, Steel, Metal & Glass Containers, Oil & Gas Refining & Marketing, Diversified Chemicals, Oil & Gas Storage & Transportation, Highways & Railtracks, Air Freight & Logistics, Residential RE\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     607.57 ms /    25 tokens (   24.30 ms per token,    41.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10178.42 ms /    72 runs   (  141.37 ms per token,     7.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   10799.53 ms /    97 tokens\n",
      "Llama.generate: 171 prefix-match hit, remaining 47 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but there are a few minor issues. The phrase \"sub-industry\" might be unfamiliar to some people, and the word \"issuers\" could be confusing if not properly defined. Overall, the text is clear and easy to understand with a little bit of context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1085.40 ms /    47 tokens (   23.09 ms per token,    43.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =   16306.69 ms /   115 runs   (  141.80 ms per token,     7.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   17418.11 ms /   162 tokens\n",
      "Llama.generate: 174 prefix-match hit, remaining 48 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly clear and easy to understand, but there are a few minor issues. First, the sub-industries listed are not separated by commas, which can make it harder to quickly identify them. Second, the phrase \"or issuers\" could be clarified to make it clear that the list includes both companies and issuers. Finally, the text could benefit from some additional context or explanation to help readers understand the purpose of the list. Overall, however, the text is understandable with some effort.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1125.04 ms /    48 tokens (   23.44 ms per token,    42.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =   19966.57 ms /   141 runs   (  141.61 ms per token,     7.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   21126.40 ms /   189 tokens\n",
      "Llama.generate: 171 prefix-match hit, remaining 32 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but there are some minor errors and awkwardness. The sentence could be improved by using more precise language and avoiding some unnecessary words. For example, instead of saying \"All companies or issuers,\" it would be better to specify the type of entities being referred to, such as \"All publicly traded companies in the Renewable Electricity sub-industry.\" Additionally, the sentence could be rephrased to make it clearer what is being requested, such as \"Please provide a list of companies or issuers that operate in the Renewable Electricity sub-industry and have complete ESG data.\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     741.01 ms /    32 tokens (   23.16 ms per token,    43.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =   14467.10 ms /   102 runs   (  141.83 ms per token,     7.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   15229.91 ms /   134 tokens\n",
      "Llama.generate: 177 prefix-match hit, remaining 23 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is generally understandable, but there are a few minor issues that make it less than perfectly clear. The use of abbreviations such as \"Thrifts & Mortgage Finance\" and \"Diversified Banks\" may be unfamiliar to some readers, and the phrase \"or issuers\" could be clarified. Additionally, the sentence structure could be improved for clarity. Overall, however, the text is relatively easy to understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     557.07 ms /    23 tokens (   24.22 ms per token,    41.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =   16822.76 ms /   118 runs   (  142.57 ms per token,     7.01 tokens per second)\n",
      "llama_perf_context_print:       total time =   17405.65 ms /   141 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 47 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8\n",
      "\n",
      "The text is mostly understandable, but there are a few minor issues that make it less clear. The main issue is that the GICS Sub Industry ID '50101020' may not be well-known or familiar to everyone, which could make it less clear what the sub-industry is. Additionally, the use of the term 'issuers' instead of 'companies' may be less common or less clear to some people. Overall, however, the text is mostly clear and easy to understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1108.64 ms /    47 tokens (   23.59 ms per token,    42.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8355.29 ms /    59 runs   (  141.62 ms per token,     7.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    9474.79 ms /   106 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 44 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rating for this text is 7. While it is grammatically correct and coherent, it may be somewhat difficult to understand for those unfamiliar with the specific terminology and context related to genetically modified plants and animals, as well as the criteria mentioned in the text.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1076.37 ms /    44 tokens (   24.46 ms per token,    40.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =   21836.45 ms /   152 runs   (  143.66 ms per token,     6.96 tokens per second)\n",
      "llama_perf_context_print:       total time =   22951.05 ms /   196 tokens\n",
      "Llama.generate: 166 prefix-match hit, remaining 33 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but there are a few issues that make it less than perfect. Firstly, the abbreviation \"GMO\" is not immediately clear, and it may take some effort to understand what it stands for. Secondly, the phrase \"Agriculture Production Maximum Percentage of Revenues (%)\" is quite long and complex, and it may be difficult to remember or understand all of the words. Finally, the use of percentages and numbers may make the text seem a bit technical or jargon-heavy. Overall, however, the text is still quite comprehensible, and most people should be able to understand what it is asking for.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     835.83 ms /    33 tokens (   25.33 ms per token,    39.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    7816.42 ms /    55 runs   (  142.12 ms per token,     7.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    8662.58 ms /    88 tokens\n",
      "Llama.generate: 186 prefix-match hit, remaining 14 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 6\n",
      "\n",
      "The text is understandable, but it has some awkwardness and complexity. The sentence structure is a bit confusing, and some of the terms may not be familiar to everyone. However, overall, the meaning of the text is clear.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     344.81 ms /    14 tokens (   24.63 ms per token,    40.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =   14089.88 ms /    98 runs   (  143.77 ms per token,     6.96 tokens per second)\n",
      "llama_perf_context_print:       total time =   14455.38 ms /   112 tokens\n",
      "Llama.generate: 166 prefix-match hit, remaining 33 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 5\n",
      "\n",
      "The text is somewhat understandable, but it contains some awkwardness and complexity. The sentence structure is a bit confusing, and some of the terms used may not be familiar to everyone. Additionally, there are a few minor errors in the text, such as the use of \"Maximum\" instead of \"Maximum Percentage.\" Overall, while the text is not completely incomprehensible, it may require some effort to fully understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     786.15 ms /    33 tokens (   23.82 ms per token,    41.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4668.14 ms /    33 runs   (  141.46 ms per token,     7.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    5460.01 ms /    66 tokens\n",
      "Llama.generate: 166 prefix-match hit, remaining 38 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7. The text is mostly understandable, but there are a few awkward phrases and unfamiliar terms that may require some clarification.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     890.25 ms /    38 tokens (   23.43 ms per token,    42.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =   15718.89 ms /   111 runs   (  141.61 ms per token,     7.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   16633.30 ms /   149 tokens\n",
      "Llama.generate: 166 prefix-match hit, remaining 40 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but it could be improved by using more common and concise language. The phrase \"Agriculture Production Maximum Percentage of Revenues (%)\" could be simplified to \"maximum percentage of revenue from agriculture production.\" Additionally, the use of abbreviations like \"GMO\" and \"ESG\" may be confusing for some readers. Overall, the text is comprehensible with effort, but could benefit from some revisions for clarity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     932.78 ms /    40 tokens (   23.32 ms per token,    42.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =   16018.49 ms /   113 runs   (  141.76 ms per token,     7.05 tokens per second)\n",
      "llama_perf_context_print:       total time =   16976.16 ms /   153 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 122 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but there are a few minor issues that make it less than perfect. The abbreviation \"GMO\" is not immediately clear, and it's not clear what \"Agriculture Production\" refers to. Additionally, the phrase \"Minimum Percentage of Revenues\" could be more clearly phrased as \"Minimum percentage of revenue from agriculture production.\" Overall, the text is mostly understandable, but it could benefit from some clarification on certain terms.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    2818.43 ms /   122 tokens (   23.10 ms per token,    43.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10484.18 ms /    74 runs   (  141.68 ms per token,     7.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   13317.61 ms /   196 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 35 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but it contains some complex and technical terms related to genetic engineering and GMOs. It may require some effort to fully comprehend the meaning of the text, especially for those who are not familiar with these concepts. However, the overall structure and grammar of the text are relatively clear.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     825.78 ms /    35 tokens (   23.59 ms per token,    42.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =   11903.76 ms /    84 runs   (  141.71 ms per token,     7.06 tokens per second)\n",
      "llama_perf_context_print:       total time =   12746.46 ms /   119 tokens\n",
      "Llama.generate: 175 prefix-match hit, remaining 29 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but there are a few minor errors and awkwardness. The phrase \"Other Production Minimum Percentage of Revenues (%)\" could be rephrased for clarity, and the use of abbreviations like \"GMO\" might confuse some readers. Overall, however, the text is clear and easy to understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     683.58 ms /    29 tokens (   23.57 ms per token,    42.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6912.85 ms /    49 runs   (  141.08 ms per token,     7.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    7605.19 ms /    78 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 33 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 6\n",
      "\n",
      "The text is understandable, but it requires some effort to comprehend. The language used is somewhat complex, and there are a few minor errors. However, the overall meaning of the text is clear.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     784.88 ms /    33 tokens (   23.78 ms per token,    42.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =   12454.33 ms /    88 runs   (  141.53 ms per token,     7.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   13257.01 ms /   121 tokens\n",
      "Llama.generate: 174 prefix-match hit, remaining 26 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8. The text is mostly understandable, but there are a few minor errors. The word \"issuers\" should be \"companies\" to make it more clear. Additionally, the phrase \"whose fossil fuel revenue share is greater than 30%\" could be rephrased to \"that have a fossil fuel revenue share greater than 30%\" for clarity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     616.72 ms /    26 tokens (   23.72 ms per token,    42.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5360.32 ms /    38 runs   (  141.06 ms per token,     7.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    5983.65 ms /    64 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 40 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8\n",
      "\n",
      "The text is clear and easy to understand, but it may require some knowledge of the specific terms used in the context of carbon performance and risk ratings.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     934.65 ms /    40 tokens (   23.37 ms per token,    42.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5241.70 ms /    37 runs   (  141.67 ms per token,     7.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    6183.09 ms /    77 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 26 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8\n",
      "\n",
      "The text is clear and easy to understand, but it may require some knowledge of the specific industry group and the Carbon Risk Rating system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     619.83 ms /    26 tokens (   23.84 ms per token,    41.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =   13161.78 ms /    93 runs   (  141.52 ms per token,     7.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   13800.80 ms /   119 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 39 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but there are a few minor issues. The phrase \"Climate Laggard\" may not be familiar to everyone, and it's not clear what \"issuers\" refers to in this context. Additionally, the use of \"or\" instead of \"and\" in the sentence structure can make it slightly less clear. Overall, however, the text is relatively easy to understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     915.14 ms /    39 tokens (   23.47 ms per token,    42.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =     870.88 ms /     6 runs   (  145.15 ms per token,     6.89 tokens per second)\n",
      "llama_perf_context_print:       total time =    1787.31 ms /    45 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 71 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1668.03 ms /    71 tokens (   23.49 ms per token,    42.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9336.71 ms /    66 runs   (  141.47 ms per token,     7.07 tokens per second)\n",
      "llama_perf_context_print:       total time =   11016.97 ms /   137 tokens\n",
      "Llama.generate: 173 prefix-match hit, remaining 250 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8\n",
      "\n",
      "The text is clear and concise, but it may require some effort to understand the specific terms related to climate change and fossil fuels. Additionally, the text may be slightly more complex than a typical instruction due to the use of technical terms and specific criteria for evaluating companies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    5747.03 ms /   250 tokens (   22.99 ms per token,    43.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =   13342.44 ms /    93 runs   (  143.47 ms per token,     6.97 tokens per second)\n",
      "llama_perf_context_print:       total time =   19108.70 ms /   343 tokens\n",
      "Llama.generate: 172 prefix-match hit, remaining 70 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is understandable, but it requires some effort to read and comprehend due to its length and complexity. The text contains a list of industries and criteria for companies to be considered \"Climate Leaders\" or \"Climate Outperformers,\" as well as their commitment to science-based targets for greenhouse gas emissions reduction. While the text is not perfect, it is generally clear and easy to understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1642.98 ms /    70 tokens (   23.47 ms per token,    42.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =   15684.73 ms /   111 runs   (  141.30 ms per token,     7.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   17351.83 ms /   181 tokens\n",
      "Llama.generate: 172 prefix-match hit, remaining 239 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would rate this text as 7. While it is clear what the criteria are for the companies or issuers being sought, there are some complex terms and phrases used that may require some effort to understand, such as \"Carbon Risk Rating\", \"Prime status\", \"SDG Solutions Score\", and \"Overall QualityScore\". Additionally, the use of \"or\" and \"and\" in the criteria may make it slightly more difficult to follow. However, overall, the text is clear and understandable with some effort.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    5498.39 ms /   239 tokens (   23.01 ms per token,    43.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =   14943.25 ms /   105 runs   (  142.32 ms per token,     7.03 tokens per second)\n",
      "llama_perf_context_print:       total time =   20464.24 ms /   344 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 62 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 6\n",
      "\n",
      "The text is quite long and complex, with multiple clauses and conditions. While it is technically understandable, it requires a lot of effort to parse and understand all the different criteria being listed. Additionally, some of the terms and acronyms used (such as ESG, CPI, and FSI) may not be immediately familiar to everyone. Overall, while the text is not completely incomprehensible, it is quite challenging to fully understand and rate.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1432.51 ms /    62 tokens (   23.11 ms per token,    43.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9382.14 ms /    62 runs   (  151.32 ms per token,     6.61 tokens per second)\n",
      "llama_perf_context_print:       total time =   10827.20 ms /   124 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 54 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but there are a few complexities and minor errors. The sentence structure is a bit awkward, and some of the terms may not be familiar to everyone. However, overall, the text is clear and easy to understand with some effort.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1224.75 ms /    54 tokens (   22.68 ms per token,    44.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8042.03 ms /    58 runs   (  138.66 ms per token,     7.21 tokens per second)\n",
      "llama_perf_context_print:       total time =    9277.27 ms /   112 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 44 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 6\n",
      "\n",
      "The text is generally understandable, but it contains some complex sentence structures and technical terms related to nuclear power. It may require some effort to fully comprehend the meaning, especially for those who are not familiar with the specific terminology and context.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     997.37 ms /    44 tokens (   22.67 ms per token,    44.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =   12917.51 ms /    93 runs   (  138.90 ms per token,     7.20 tokens per second)\n",
      "llama_perf_context_print:       total time =   13933.80 ms /   137 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 96 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8\n",
      "\n",
      "The text is mostly understandable, but there are a few minor issues that make it less than perfect. The use of abbreviations like \"(:NC)\" and \"ISS ESG Fund Rating Stars\" may be unfamiliar to some readers, and the phrase \"discrimination concern ratio\" might be a bit confusing. However, overall the text is clear and easy to understand with a little bit of effort.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    2149.19 ms /    96 tokens (   22.39 ms per token,    44.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =   12303.18 ms /    89 runs   (  138.24 ms per token,     7.23 tokens per second)\n",
      "llama_perf_context_print:       total time =   14469.89 ms /   185 tokens\n",
      "Llama.generate: 172 prefix-match hit, remaining 82 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is quite long and complex, but it is understandable with some effort. The language used is formal and technical, and there are some specific terms and acronyms that may require some knowledge or research to fully understand. However, the overall structure and logic of the text are clear, and the criteria for identifying companies or issuers are specified in a clear and concise manner.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1846.58 ms /    82 tokens (   22.52 ms per token,    44.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9107.72 ms /    66 runs   (  138.00 ms per token,     7.25 tokens per second)\n",
      "llama_perf_context_print:       total time =   10966.25 ms /   148 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 63 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but it contains some complex terms and phrases that may require some effort to understand. The sentence structure is also somewhat convoluted, making it a bit difficult to follow. Overall, however, the text is clear and easy to understand with some effort.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1420.00 ms /    63 tokens (   22.54 ms per token,    44.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =   13233.82 ms /    96 runs   (  137.85 ms per token,     7.25 tokens per second)\n",
      "llama_perf_context_print:       total time =   14673.09 ms /   159 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 259 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but there are some minor errors and awkwardness. The use of the Climate Change Performance Index score ranges is clear, but the phrasing of \"All sovereign issuers\" could be more concise. Additionally, it might be helpful to clarify what \"score\" refers to in the context of the Climate Change Performance Index. Overall, the text is comprehensible with some effort.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    5806.82 ms /   259 tokens (   22.42 ms per token,    44.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6536.32 ms /    47 runs   (  139.07 ms per token,     7.19 tokens per second)\n",
      "llama_perf_context_print:       total time =   12351.39 ms /   306 tokens\n",
      "Llama.generate: 182 prefix-match hit, remaining 241 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is quite complex and contains multiple criteria for evaluating companies or issuers. However, it is still understandable with some effort. I would rate it a 7 out of 10 for comprehensibility.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    5397.84 ms /   241 tokens (   22.40 ms per token,    44.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5405.89 ms /    39 runs   (  138.61 ms per token,     7.21 tokens per second)\n",
      "llama_perf_context_print:       total time =   10810.39 ms /   280 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 77 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is quite complex and contains multiple criteria for the query. However, it is still understandable with some effort. I would rate it a 6 out of 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1753.72 ms /    77 tokens (   22.78 ms per token,    43.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9923.05 ms /    72 runs   (  137.82 ms per token,     7.26 tokens per second)\n",
      "llama_perf_context_print:       total time =   11690.03 ms /   149 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 66 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is clear and easy to understand, but it is quite long and complex. It contains several clauses and conditions that need to be met in order for a company or issuer to be included in the list. However, the language used is generally understandable, and the meaning of the text is clear.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1493.72 ms /    66 tokens (   22.63 ms per token,    44.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =   11536.14 ms /    84 runs   (  137.33 ms per token,     7.28 tokens per second)\n",
      "llama_perf_context_print:       total time =   13046.32 ms /   150 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 57 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but there are a few complexities and minor errors. The acronyms PTA, MSOP, and TSR may not be immediately familiar to everyone, and the phrase \"Pay for Performance Concern of High or Medium\" could be more clearly phrased. However, overall the text is clear and easy to follow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1306.76 ms /    57 tokens (   22.93 ms per token,    43.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5612.79 ms /    41 runs   (  136.90 ms per token,     7.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    6926.63 ms /    98 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 62 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is understandable with effort. The language used is clear and concise, but there may be some minor errors or awkwardness in the phrasing. The rating would be around 6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1396.66 ms /    62 tokens (   22.53 ms per token,    44.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4930.74 ms /    36 runs   (  136.97 ms per token,     7.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    6333.49 ms /    98 tokens\n",
      "Llama.generate: 166 prefix-match hit, remaining 105 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8\n",
      "\n",
      "The text is clear and easy to understand, but it contains some complex sentence structures and technical terms related to compensation and corporate governance.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    2364.97 ms /   105 tokens (   22.52 ms per token,    44.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9466.83 ms /    69 runs   (  137.20 ms per token,     7.29 tokens per second)\n",
      "llama_perf_context_print:       total time =   11844.40 ms /   174 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 99 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8\n",
      "\n",
      "The text is clear and concise, but it may require some effort to understand the specific criteria for evaluating companies or issuers. Additionally, some of the terms used in the criteria may be unfamiliar to some readers. However, overall, the text is understandable and easy to follow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    2235.70 ms /    99 tokens (   22.58 ms per token,    44.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =   11128.56 ms /    81 runs   (  137.39 ms per token,     7.28 tokens per second)\n",
      "llama_perf_context_print:       total time =   13379.65 ms /   180 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 24 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but it contains some complex and technical terms related to corporate governance and executive compensation. The sentence structure is also somewhat convoluted, making it harder to follow. However, the overall meaning of the text is clear, and it provides specific criteria for identifying companies or issuers that may have governance or compensation issues.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     559.81 ms /    24 tokens (   23.33 ms per token,    42.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6730.43 ms /    49 runs   (  137.36 ms per token,     7.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    7298.50 ms /    73 tokens\n",
      "Llama.generate: 165 prefix-match hit, remaining 38 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would rate this text as 7. While it is grammatically correct and conveys a clear message, it may be somewhat difficult to understand for those unfamiliar with financial terminology or the concept of CEO pay ratios.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     902.72 ms /    38 tokens (   23.76 ms per token,    42.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =   11427.23 ms /    82 runs   (  139.36 ms per token,     7.18 tokens per second)\n",
      "llama_perf_context_print:       total time =   12345.56 ms /   120 tokens\n",
      "Llama.generate: 166 prefix-match hit, remaining 41 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is understandable, but it contains some technical jargon and complex sentence structures. The use of terms like \"related party transactions\" and \"material\" may require some additional context or explanation for those unfamiliar with corporate governance or accounting standards. However, the overall structure and grammar of the sentence are clear, and the meaning is conveyed effectively.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     935.29 ms /    41 tokens (   22.81 ms per token,    43.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =   12402.94 ms /    90 runs   (  137.81 ms per token,     7.26 tokens per second)\n",
      "llama_perf_context_print:       total time =   13355.64 ms /   131 tokens\n",
      "Llama.generate: 166 prefix-match hit, remaining 68 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but there are some complex terms and phrases that may require some effort to understand. \"Excise tax gross-ups\" and \"change-in-control payments\" may be unfamiliar to some readers, and the phrase \"basis that includes both salary and target bonus\" could be confusing. Overall, however, the text is relatively clear and easy to follow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1531.21 ms /    68 tokens (   22.52 ms per token,    44.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9080.78 ms /    66 runs   (  137.59 ms per token,     7.27 tokens per second)\n",
      "llama_perf_context_print:       total time =   10624.16 ms /   134 tokens\n",
      "Llama.generate: 166 prefix-match hit, remaining 36 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but it contains some complex and technical terms related to corporate governance and executive compensation. The sentence structure is also somewhat convoluted. However, the overall meaning is clear, and the text is not overly difficult to comprehend with some effort.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     846.82 ms /    36 tokens (   23.52 ms per token,    42.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    7533.72 ms /    55 runs   (  136.98 ms per token,     7.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    8390.28 ms /    91 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 56 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is clear and concise, but it may require some knowledge of corporate governance and compensation practices to fully understand. The use of specific language and percentages may also make it slightly more complex than a casual reader might find.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1289.20 ms /    56 tokens (   23.02 ms per token,    43.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9396.54 ms /    68 runs   (  138.18 ms per token,     7.24 tokens per second)\n",
      "llama_perf_context_print:       total time =   10698.19 ms /   124 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 42 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but it contains some complex and technical terms related to corporate governance and executive compensation. The sentence structure is also somewhat convoluted, making it slightly more difficult to follow. However, with some effort and context, the meaning of the text can be grasped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     955.21 ms /    42 tokens (   22.74 ms per token,    43.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =   17981.38 ms /   131 runs   (  137.26 ms per token,     7.29 tokens per second)\n",
      "llama_perf_context_print:       total time =   18965.46 ms /   173 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 46 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but it could be improved by using more concise language and removing some unnecessary words. For example, \"All companies or issuers\" could be simplified to \"All companies,\" and \"where the chairman is an executive and is a member of the Compensation, Corporate Governance, Nominating, and Audit committees\" could be shortened to \"where the chairman is an executive and serves on those committees.\" Overall, the text is clear and easy to understand, but could benefit from some minor revisions for clarity and concision.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1062.35 ms /    46 tokens (   23.09 ms per token,    43.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6848.55 ms /    50 runs   (  136.97 ms per token,     7.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    7919.35 ms /    96 tokens\n",
      "Llama.generate: 172 prefix-match hit, remaining 19 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly clear and easy to understand, but there are a few minor errors and awkwardnesses. The sentence could be improved by removing some unnecessary words and rephrasing it for clarity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     459.21 ms /    19 tokens (   24.17 ms per token,    41.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10981.63 ms /    80 runs   (  137.27 ms per token,     7.28 tokens per second)\n",
      "llama_perf_context_print:       total time =   11456.03 ms /    99 tokens\n",
      "Llama.generate: 171 prefix-match hit, remaining 20 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8\n",
      "\n",
      "The text is mostly clear and easy to understand, but it could be improved by adding some context or clarification for certain terms. For example, it may be helpful to define what \"clawback provision\" means or provide more information on what \"independent Board Chair\" entails. Overall, however, the text is understandable with minimal effort.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     476.06 ms /    20 tokens (   23.80 ms per token,    42.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =   13339.16 ms /    97 runs   (  137.52 ms per token,     7.27 tokens per second)\n",
      "llama_perf_context_print:       total time =   13834.72 ms /   117 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 68 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 6\n",
      "\n",
      "The text is mostly understandable, but there are a few issues that make it less than perfectly clear. First, the phrase \"Red flag for chemical weapons\" may be unfamiliar to some readers, and it's not immediately clear what this means. Second, the phrase \"private funds or public funds\" could be more clearly defined. Overall, the text is comprehensible with some effort, but it could benefit from a bit more clarity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1548.00 ms /    68 tokens (   22.76 ms per token,    43.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10238.25 ms /    74 runs   (  138.35 ms per token,     7.23 tokens per second)\n",
      "llama_perf_context_print:       total time =   11800.10 ms /   142 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 31 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: 7\n",
      "\n",
      "The text is clear and easy to understand, but it contains a lot of technical jargon related to weapons and their classification. It is also quite long and repetitive, which could make it more difficult to comprehend for some readers. Overall, however, the text is understandable with some effort and knowledge of the subject matter.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     730.33 ms /    31 tokens (   23.56 ms per token,    42.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9607.09 ms /    70 runs   (  137.24 ms per token,     7.29 tokens per second)\n",
      "llama_perf_context_print:       total time =   10350.33 ms /   101 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 29 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is understandable with effort. The language is clear and concise, but there may be some minor confusion about the specific criteria for being considered a Canadian company with a quarterly market cap of over $100 million and an ESG Performance Score of over 1. Overall, I would rate this text as a 6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     684.17 ms /    29 tokens (   23.59 ms per token,    42.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4101.11 ms /    30 runs   (  136.70 ms per token,     7.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    4790.28 ms /    59 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 92 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8. The text is clear and easy to understand, but it may require some knowledge of the chemicals industry and financial terms.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    2075.33 ms /    92 tokens (   22.56 ms per token,    44.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8693.41 ms /    63 runs   (  137.99 ms per token,     7.25 tokens per second)\n",
      "llama_perf_context_print:       total time =   10779.78 ms /   155 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 52 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8\n",
      "\n",
      "The text is clear and easy to understand, but it contains some technical terms related to firearms and ammunition that may not be familiar to everyone. However, the overall structure and meaning of the text are clear, and it is easy to follow the instructions provided.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1180.47 ms /    52 tokens (   22.70 ms per token,    44.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2331.29 ms /    17 runs   (  137.13 ms per token,     7.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    3514.68 ms /    69 tokens\n",
      "Llama.generate: 169 prefix-match hit, remaining 69 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is understandable with effort. I would rate it a 6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1600.93 ms /    69 tokens (   23.20 ms per token,    43.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10041.36 ms /    73 runs   (  137.55 ms per token,     7.27 tokens per second)\n",
      "llama_perf_context_print:       total time =   11655.78 ms /   142 tokens\n",
      "Llama.generate: 189 prefix-match hit, remaining 44 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would rate this text as 8. While there may be some minor errors or awkwardness in the phrasing, the overall message is clear and easy to understand. The text provides specific criteria for identifying companies or issuers involved in the production, distribution, or provision of certain firearm-related products, making it relatively straightforward to comprehend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1004.52 ms /    44 tokens (   22.83 ms per token,    43.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10730.01 ms /    78 runs   (  137.56 ms per token,     7.27 tokens per second)\n",
      "llama_perf_context_print:       total time =   11749.04 ms /   122 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 249 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would rate this text as 7. While it is clear what the request is, there are some complexities and awkwardness in the phrasing. The use of technical terms such as \"assault weapons\" and \"ESG data\" may make it more challenging for some readers to fully understand the text. However, overall, the text is relatively easy to comprehend.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    5586.48 ms /   249 tokens (   22.44 ms per token,    44.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3461.24 ms /    25 runs   (  138.45 ms per token,     7.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    9051.96 ms /   274 tokens\n",
      "Llama.generate: 178 prefix-match hit, remaining 245 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is quite clear and easy to understand. I would rate it as 9 out of 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    5474.52 ms /   245 tokens (   22.34 ms per token,    44.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6384.17 ms /    46 runs   (  138.79 ms per token,     7.21 tokens per second)\n",
      "llama_perf_context_print:       total time =   11866.92 ms /   291 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 40 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is quite complex and contains many technical terms and specific criteria. It would require a significant amount of knowledge and understanding of the specific industries and regulations mentioned to fully comprehend. I would rate it a 5.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     918.71 ms /    40 tokens (   22.97 ms per token,    43.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10432.34 ms /    76 runs   (  137.27 ms per token,     7.29 tokens per second)\n",
      "llama_perf_context_print:       total time =   11365.52 ms /   116 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 50 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly clear and easy to understand, but it contains some technical jargon related to firearms and revenue share that may not be familiar to everyone. Additionally, the phrase \"Civilian Firearms - Distribution Revenue Share Max\" may be confusing to some readers. Overall, the text is understandable with some effort.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1164.54 ms /    50 tokens (   23.29 ms per token,    42.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    7280.12 ms /    53 runs   (  137.36 ms per token,     7.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    8453.91 ms /   103 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 253 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Please provide a list of companies or issuers that have a Civilian Firearms - Distribution Revenue Share Max (%) greater than 10% and are involved in the distribution of semi-automatic firearms. → Rating: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    5640.97 ms /   253 tokens (   22.30 ms per token,    44.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =   12104.82 ms /    87 runs   (  139.14 ms per token,     7.19 tokens per second)\n",
      "llama_perf_context_print:       total time =   17762.77 ms /   340 tokens\n",
      "Llama.generate: 170 prefix-match hit, remaining 253 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but it contains some technical jargon related to weapons and their classification. The criteria for evaluating companies are clearly stated, but the language used to describe them may be unfamiliar to some readers. Overall, the text is comprehensible with some effort, but it could benefit from simplifying some of the technical terms and providing more context for the criteria.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    5660.84 ms /   253 tokens (   22.37 ms per token,    44.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10444.57 ms /    75 runs   (  139.26 ms per token,     7.18 tokens per second)\n",
      "llama_perf_context_print:       total time =   16119.73 ms /   328 tokens\n",
      "Llama.generate: 203 prefix-match hit, remaining 219 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would rate this text as 8. While it is not perfectly clear and natural, it is understandable with some effort. The text contains specific criteria for evaluating companies or issuers, and each criterion is clearly stated. However, the text may be difficult to understand for someone who is not familiar with the terminology used in the criteria.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    4898.41 ms /   219 tokens (   22.37 ms per token,    44.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8612.25 ms /    62 runs   (  138.91 ms per token,     7.20 tokens per second)\n",
      "llama_perf_context_print:       total time =   13522.04 ms /   281 tokens\n",
      "Llama.generate: 204 prefix-match hit, remaining 163 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would rate this text as 7. While the criteria for each item are clear, the overall structure and organization of the text could be improved for clarity. Additionally, some of the terms used (such as \"NBS\" and \"NPT\") may not be immediately familiar to all readers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    3642.70 ms /   163 tokens (   22.35 ms per token,    44.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =   13022.36 ms /    94 runs   (  138.54 ms per token,     7.22 tokens per second)\n",
      "llama_perf_context_print:       total time =   16683.58 ms /   257 tokens\n",
      "Llama.generate: 194 prefix-match hit, remaining 229 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would rate this text as 7. While it is clear what the criteria are for the list of companies or issuers, some of the language used is more technical and specific to the topic of weapons and their classification. Additionally, some of the criteria may be less well-known or understood by the general public. However, overall the text is clear and concise, and anyone with a basic understanding of the topic should be able to understand it.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    5138.59 ms /   229 tokens (   22.44 ms per token,    44.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =   35549.55 ms /   255 runs   (  139.41 ms per token,     7.17 tokens per second)\n",
      "llama_perf_context_print:       total time =   40766.99 ms /   484 tokens\n",
      "Llama.generate: 422 prefix-match hit, remaining 1 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide a list of companies or issuers that meet the following criteria:\n",
      "\n",
      "1. Civilian Firearms - Distribution Revenue Share Min (%): The minimum share of revenue estimated or reported to be derived from involvement in the distribution of civilian firearms as a percentage of the issuer's total revenue in the latest financial year is less than or equal to 15%.\n",
      "2. Anti-personnel Mines - Overall Flag: The issuer's involvement in any anti-personnel mines programme is assessed as Green.\n",
      "3. Biological Weapons - Overall Flag: The issuer's involvement in any biological weapons programme is assessed as Green.\n",
      "4. Chemical Weapons - Overall Flag: The issuer's involvement in any chemical weapons programme is assessed as Green.\n",
      "5. Cluster Munitions - Overall Flag: The issuer's involvement in any cluster munitions programme is assessed as Green.\n",
      "6. Depleted Uranium - Overall Flag: The issuer's involvement in any depleted uranium programme is assessed as Green.\n",
      "7. Incendiary Weapons - Overall Flag: The issuer's involvement in any inc\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =       0.00 ms /     1 tokens (    0.00 ms per token,      inf tokens per second)\n",
      "llama_perf_context_print:        eval time =   13908.56 ms /   100 runs   (  139.09 ms per token,     7.19 tokens per second)\n",
      "llama_perf_context_print:       total time =   13928.37 ms /   101 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 67 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I apologize, but I cannot rate the text as it is incomplete. The text appears to be a list of criteria for evaluating companies or issuers in terms of their involvement in various weapons programs. However, the text is missing the name of the organization or entity that is providing the criteria, as well as any additional information or context that might be necessary to understand the criteria fully. Without this information, it is difficult to accurately rate the text's comprehensibility.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1523.53 ms /    67 tokens (   22.74 ms per token,    43.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8512.34 ms /    62 runs   (  137.30 ms per token,     7.28 tokens per second)\n",
      "llama_perf_context_print:       total time =   10047.04 ms /   129 tokens\n",
      "Llama.generate: 171 prefix-match hit, remaining 61 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 5\n",
      "\n",
      "The text is somewhat understandable, but it contains some complex and technical terms related to the firearms and military industries. Additionally, the sentence structure is somewhat awkward, making it more difficult to follow. However, with some effort and context, the text can be understood.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1373.12 ms /    61 tokens (   22.51 ms per token,    44.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8530.18 ms /    62 runs   (  137.58 ms per token,     7.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    9914.51 ms /   123 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 35 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but it contains some complex and technical terms related to the firearms industry and financial analysis. The sentence structure is also somewhat complex, making it slightly more difficult to follow. However, overall, the text is comprehensible with effort.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     808.01 ms /    35 tokens (   23.09 ms per token,    43.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9199.01 ms /    67 runs   (  137.30 ms per token,     7.28 tokens per second)\n",
      "llama_perf_context_print:       total time =   10019.35 ms /   102 tokens\n",
      "Llama.generate: 168 prefix-match hit, remaining 40 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is understandable, but it has some awkwardness and complexity. The use of phrases like \"involvement in the latest financial year\" and \"maximum revenue share\" may make it slightly more difficult to understand. However, overall, the text is clear and easy to follow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     911.89 ms /    40 tokens (   22.80 ms per token,    43.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8953.25 ms /    65 runs   (  137.74 ms per token,     7.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    9876.86 ms /   105 tokens\n",
      "Llama.generate: 189 prefix-match hit, remaining 19 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8. The text is mostly understandable, but it may require some effort to understand the specific requirements for the list of companies or issuers. Additionally, the use of technical terms such as \"civilian firearms\" and \"ESG data\" may make the text slightly more complex.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     458.59 ms /    19 tokens (   24.14 ms per token,    41.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6030.50 ms /    44 runs   (  137.06 ms per token,     7.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    6496.81 ms /    63 tokens\n",
      "Llama.generate: 168 prefix-match hit, remaining 29 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8\n",
      "\n",
      "The text is mostly understandable, but there are a few minor errors and awkwardnesses. The sentence could be rephrased to be more clear and concise.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     670.21 ms /    29 tokens (   23.11 ms per token,    43.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4281.60 ms /    31 runs   (  138.12 ms per token,     7.24 tokens per second)\n",
      "llama_perf_context_print:       total time =    4956.88 ms /    60 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 75 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7. The text is mostly understandable, but it may require some effort to understand the specific requirements for the list of companies.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1698.04 ms /    75 tokens (   22.64 ms per token,    44.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =   12695.37 ms /    92 runs   (  137.99 ms per token,     7.25 tokens per second)\n",
      "llama_perf_context_print:       total time =   14411.75 ms /   167 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 21 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but there are some complexities and minor errors. The sentence could be improved by breaking it up into smaller sentences or using simpler language. Additionally, the use of technical terms such as \"issuers\" and \"ESG data\" may make the text less accessible to some readers. Overall, the text is comprehensible, but could benefit from some revisions for clarity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     519.89 ms /    21 tokens (   24.76 ms per token,    40.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3436.67 ms /    25 runs   (  137.47 ms per token,     7.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    3960.67 ms /    46 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 42 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Show me all publicly-held companies involved in the production of civilian firearms. → Rating: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     954.67 ms /    42 tokens (   22.73 ms per token,    43.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =   11138.08 ms /    81 runs   (  137.51 ms per token,     7.27 tokens per second)\n",
      "llama_perf_context_print:       total time =   12108.26 ms /   123 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 103 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but there are a few minor errors and awkwardnesses. The sentence could be improved by clarifying what is meant by \"involved in the production of civilian firearms\" and what is meant by \"revenue share interval.\" Additionally, it might be helpful to provide more context for why this information is being requested.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    2352.03 ms /   103 tokens (   22.84 ms per token,    43.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8390.81 ms /    61 runs   (  137.55 ms per token,     7.27 tokens per second)\n",
      "llama_perf_context_print:       total time =   10753.93 ms /   164 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 95 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rating for this text is 6. While it is grammatically correct and contains coherent sentences, the language used is somewhat complex and may require some effort to fully understand. The text also includes specific technical terms related to the firearms industry, which may not be familiar to all readers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    2154.45 ms /    95 tokens (   22.68 ms per token,    44.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    7984.10 ms /    58 runs   (  137.66 ms per token,     7.26 tokens per second)\n",
      "llama_perf_context_print:       total time =   10148.79 ms /   153 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 62 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 6\n",
      "\n",
      "The text is clear and easy to understand, but it is quite long and complex. The sentence structure is also somewhat awkward, with multiple clauses and conditions separated by \"or\". However, the meaning is clear, and the instructions are specific.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1420.67 ms /    62 tokens (   22.91 ms per token,    43.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9204.12 ms /    67 runs   (  137.37 ms per token,     7.28 tokens per second)\n",
      "llama_perf_context_print:       total time =   10637.21 ms /   129 tokens\n",
      "Llama.generate: 169 prefix-match hit, remaining 99 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 6\n",
      "\n",
      "The text is mostly understandable, but there are a few awkward phrases and complex sentence structures. The use of technical jargon related to firearms and ammunition may also make it more difficult for some readers to fully comprehend. However, overall the text is clear and concise.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    2216.04 ms /    99 tokens (   22.38 ms per token,    44.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5791.69 ms /    42 runs   (  137.90 ms per token,     7.25 tokens per second)\n",
      "llama_perf_context_print:       total time =    8014.96 ms /   141 tokens\n",
      "Llama.generate: 192 prefix-match hit, remaining 79 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is quite complex and contains technical terms related to the firearms industry. However, it is still understandable with some effort. I would rate it a 7 out of 10.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1789.92 ms /    79 tokens (   22.66 ms per token,    44.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =   12090.16 ms /    88 runs   (  137.39 ms per token,     7.28 tokens per second)\n",
      "llama_perf_context_print:       total time =   13897.34 ms /   167 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 60 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 5\n",
      "\n",
      "The text is understandable with effort, but it contains some awkwardness and complexity due to the use of technical terms and specific requirements. The sentence structure is also somewhat convoluted, making it harder to follow. However, the meaning is clear, and the text provides specific criteria for identifying companies or issuers involved in the production, distribution, or provision of services related to civilian firearms.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1354.13 ms /    60 tokens (   22.57 ms per token,    44.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =   21040.65 ms /   153 runs   (  137.52 ms per token,     7.27 tokens per second)\n",
      "llama_perf_context_print:       total time =   22430.97 ms /   213 tokens\n",
      "Llama.generate: 196 prefix-match hit, remaining 65 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly clear and easy to understand, but there are a few minor issues that could make it more comprehensible. First, the phrase \"involved in the production, distribution, or provision of services related to civilian firearms\" could be rephrased to be more precise. Second, the phrase \"revenue share interval\" could be clarified to mean \"revenue share range.\" Finally, the phrase \"latest financial year\" could be rephrased to be more specific, such as \"the fiscal year ending December 31, 2021.\" Overall, the text is mostly understandable with a little effort, but could benefit from some minor revisions for clarity.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1500.86 ms /    65 tokens (   23.09 ms per token,    43.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6603.74 ms /    48 runs   (  137.58 ms per token,     7.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    8112.70 ms /   113 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 62 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 6\n",
      "\n",
      "The text is somewhat understandable, but it contains some complex sentence structures and technical terms related to the firearms industry. It may require some effort to fully comprehend the meaning of the text.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1396.99 ms /    62 tokens (   22.53 ms per token,    44.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10592.28 ms /    77 runs   (  137.56 ms per token,     7.27 tokens per second)\n",
      "llama_perf_context_print:       total time =   12003.82 ms /   139 tokens\n",
      "Llama.generate: 196 prefix-match hit, remaining 31 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but there are a few awkward phrases and complex sentences that make it slightly more difficult to follow. The use of technical terms related to firearms and ammunition may also make it more challenging for some readers to fully comprehend the text. Overall, however, the text is relatively clear and easy to understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     740.77 ms /    31 tokens (   23.90 ms per token,    41.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4942.26 ms /    36 runs   (  137.28 ms per token,     7.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    5689.02 ms /    67 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 35 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7. The text is mostly understandable, but it contains some complex terms and phrases related to the topic of civilian firearms and ammunition.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     811.44 ms /    35 tokens (   23.18 ms per token,    43.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6047.37 ms /    44 runs   (  137.44 ms per token,     7.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    6866.37 ms /    79 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 52 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but there are some minor errors and awkwardness. The sentence could be improved by rephrasing it to be more concise and clear.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1181.51 ms /    52 tokens (   22.72 ms per token,    44.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3577.26 ms /    26 runs   (  137.59 ms per token,     7.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    4763.20 ms /    78 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 149 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is understandable with effort, but it contains some awkwardness and complexity. I would rate it a 6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    3328.12 ms /   149 tokens (   22.34 ms per token,    44.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5386.35 ms /    39 runs   (  138.11 ms per token,     7.24 tokens per second)\n",
      "llama_perf_context_print:       total time =    8721.15 ms /   188 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 41 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I would rate this text as 8. While there may be some minor errors or awkwardness in the phrasing, the criteria for the query are clearly stated and easy to understand.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     938.09 ms /    41 tokens (   22.88 ms per token,    43.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8368.80 ms /    61 runs   (  137.19 ms per token,     7.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    9317.75 ms /   102 tokens\n",
      "Llama.generate: 185 prefix-match hit, remaining 25 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but it contains some technical jargon and specific terms that may not be familiar to everyone. The sentence structure is also somewhat complex. However, with some effort and context, the meaning of the text can be grasped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     590.40 ms /    25 tokens (   23.62 ms per token,    42.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6693.84 ms /    48 runs   (  139.45 ms per token,     7.17 tokens per second)\n",
      "llama_perf_context_print:       total time =    7292.51 ms /    73 tokens\n",
      "Llama.generate: 173 prefix-match hit, remaining 85 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 6\n",
      "\n",
      "The text is mostly understandable, but it contains some technical jargon and specific terms related to firearms production. It may require some effort to fully comprehend the meaning of the text.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1956.27 ms /    85 tokens (   23.01 ms per token,    43.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10744.67 ms /    78 runs   (  137.75 ms per token,     7.26 tokens per second)\n",
      "llama_perf_context_print:       total time =   12716.10 ms /   163 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 61 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 6\n",
      "\n",
      "The text is somewhat understandable, but it contains complex and technical terms related to the firearms industry, which may make it challenging for some readers to fully comprehend. Additionally, the text is quite long and repetitive, which can make it difficult to follow. However, the grammar and syntax are correct, and the meaning is clear.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1401.22 ms /    61 tokens (   22.97 ms per token,    43.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8926.77 ms /    65 runs   (  137.33 ms per token,     7.28 tokens per second)\n",
      "llama_perf_context_print:       total time =   10339.43 ms /   126 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 84 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Show me all companies or issuers that have a revenue share of between 10% and 15% from their involvement in civilian firearms or ammunition, or have any involvement in the production, distribution, or provision of services related to civilian firearms. → Rating: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1885.38 ms /    84 tokens (   22.45 ms per token,    44.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9779.20 ms /    71 runs   (  137.74 ms per token,     7.26 tokens per second)\n",
      "llama_perf_context_print:       total time =   11677.83 ms /   155 tokens\n",
      "Llama.generate: 178 prefix-match hit, remaining 70 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 8\n",
      "\n",
      "The text is clear and easy to understand, but it is quite long and complex. It contains technical terms related to finance and sustainability, which may require some knowledge or effort to understand fully. However, the overall structure and meaning of the text are clear, and it is easy to follow the main idea.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1576.68 ms /    70 tokens (   22.52 ms per token,    44.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9359.42 ms /    68 runs   (  137.64 ms per token,     7.27 tokens per second)\n",
      "llama_perf_context_print:       total time =   10948.51 ms /   138 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 51 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rating: 7\n",
      "\n",
      "The text is mostly understandable, but it contains some complex and technical terms related to the query's criteria. The use of percentages and specific industry categories may require some effort to fully comprehend. However, the overall structure and grammar of the text is clear and easy to follow.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1174.55 ms /    51 tokens (   23.03 ms per token,    43.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2488.85 ms /    18 runs   (  138.27 ms per token,     7.23 tokens per second)\n",
      "llama_perf_context_print:       total time =    3666.48 ms /    69 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 26 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The text is understandable with some effort. I would rate it a 6.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    4566.49 ms\n",
      "llama_perf_context_print: prompt eval time =     607.33 ms /    26 tokens (   23.36 ms per token,    42.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9747.21 ms /    71 runs   (  137.28 ms per token,     7.28 tokens per second)\n",
      "llama_perf_context_print:       total time =   10367.31 ms /    97 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The rating for this text is 7. While there are no major errors, the text is somewhat complex and may require some effort to understand. The sentence structure is a bit awkward, and some words may be unfamiliar to those not familiar with the specific industry or terminology. However, overall, the text is relatively clear and easy to understand.\n",
      "Comprehensibility ratings added and saved to 'translated_queries_with_ratings.xlsx'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "output_file = \"translated_queries_TEST5.xlsx\"\n",
    "\n",
    "# Extract the English column\n",
    "df = pd.read_excel(output_file)\n",
    "english_queries = df[\"English\"].tolist()\n",
    "\n",
    "# Function to request a comprehensibility rating from the model\n",
    "def rate_comprehensibility(text, max_tokens=256):\n",
    "    # Adjust the prompt to ask the model for a rating from 1 to 10\n",
    "    prompt = f\"\"\"### Instruction:\n",
    "Please rate the following text's comprehensibility from 1 to 10, where:\n",
    "- 1 = Completely incomprehensible, nonsensical, or full of errors.\n",
    "- 5 = Understandable with effort; some awkwardness, complexity, or minor errors.\n",
    "- 10 = Perfectly clear, natural, and easy to understand.\n",
    "\n",
    "Here are some examples:\n",
    "Text: \"asjdk asjd aksd\" → Rating: 1\n",
    "Text: \"Provide list companies ESG data incomplete understandable\" → Rating: 4\n",
    "Text: \"Please provide a list of companies with complete ESG data.\" → Rating: 9\n",
    "\n",
    "Now, rate this text:\n",
    "Text: {text}\n",
    "\n",
    "### Response:\"\"\"\n",
    "    # Call model (adjust temperature and other params as needed)\n",
    "    response = llm(prompt, max_tokens=max_tokens, temperature=0.2)\n",
    "    rating = response[\"choices\"][0][\"text\"].strip()\n",
    "    print(rating)\n",
    "    # Ensure the response is a valid number between 1 and 10\n",
    "    try:\n",
    "        rating = int(rating)\n",
    "        if 1 <= rating <= 10:\n",
    "            return rating\n",
    "    except ValueError:\n",
    "        pass\n",
    "    return None  # Return None if no valid rating is obtained\n",
    "\n",
    "# List to store ratings\n",
    "ratings = []\n",
    "\n",
    "# Iterate through each English translation and get a rating\n",
    "for query in english_queries:\n",
    "    rating = rate_comprehensibility(query)\n",
    "    ratings.append(rating)\n",
    "\n",
    "# Add the ratings as a new column to the dataframe\n",
    "df[\"Comprehensibility Rating\"] = ratings\n",
    "\n",
    "# Save the updated dataframe with ratings to a new Excel file\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(\"Comprehensibility ratings added and saved to 'translated_queries_with_ratings.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f42872-6939-4c34-b74f-f177f8eb3d49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
