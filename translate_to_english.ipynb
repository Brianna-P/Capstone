{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11329b8f-ae0a-48d4-9da9-7c1c06875c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas openpyxl transformers torch\n",
    "%pip install llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a607fdc-3c30-4006-af0d-60789c816fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "model_path = \"ENTER_YOUR_PATH_HERE/mistral-7b-instruct-v0.1.Q4_K_M.gguf\"\n",
    "max_context = 4096\n",
    "llm = Llama(\n",
    "    model_path,\n",
    "    n_ctx=max_context\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4566bf9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "with open(\"metadata.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    raw_metadata = json.load(f)\n",
    "\n",
    "# Create a lookup table\n",
    "metadata_lookup = {\n",
    "    entry[\"code\"]: f'{entry[\"name\"]}. {entry[\"description\"]}' \n",
    "    for entry in raw_metadata\n",
    "}\n",
    "\n",
    "def extract_codes(query):\n",
    "    return re.findall(r\"\\[([A-Za-z0-9_]+)\\]\", query)\n",
    "\n",
    "list_keywords = {\"IN\", \"ANY\", \"NONE\"}\n",
    "null_keywords = {\":NC\": \"Null type \\\"Not collected\\\"\", \":NA\": \"Null type \\\"Not applicable\\\"\", \":ND\": \"Null type \\\"Not disclosed\\\"\", \":NI\": \"Null type \\\"No information\\\"\", \":NM\": \"Null type \\\"Not meaningful\\\"\"}\n",
    "def extract_nulls_and_lists(query):\n",
    "    nulls = []\n",
    "    lists = []\n",
    "    contains_null = re.findall(r\"\\[([A-Za-z0-9_]+)\\]\\s+IS\\s+(:[A-Z]{2})\", query)\n",
    "    for code, null_keyword in contains_null:\n",
    "        nulls.append((code, null_keyword))\n",
    "    \n",
    "    contains_list = re.findall(r\"\\[([A-Za-z0-9_]+)\\]\\s+(IN|ANY|NONE)\\b\", query, re.IGNORECASE)\n",
    "    for code, list_keyword in contains_list:\n",
    "        lists.append((code, list_keyword.upper()))\n",
    "    \n",
    "    return nulls, lists\n",
    "\n",
    "# Find the entry with the longest name + description combo\n",
    "longest_entry = max(metadata_lookup.items(), key=lambda item: len(item[1]))\n",
    "\n",
    "# Print the result\n",
    "print(f'Longest entry code: {longest_entry[0]}')\n",
    "print(f'Length: {len(longest_entry[1])}')\n",
    "print(f'Content: {longest_entry[1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efb3fc4c-e7b9-4bfb-9340-779aaba31116",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_tokens(text, max_tokens=40):\n",
    "    #moved this to use in below function\n",
    "    tokens = llm.tokenize(text.encode(\"utf-8\"))\n",
    "    if len(tokens) <= max_tokens:\n",
    "        return text\n",
    "    truncated = llm.detokenize(tokens[:max_tokens]).decode(\"utf-8\", errors=\"ignore\")\n",
    "    return truncated + \"...\"\n",
    "\n",
    "def build_ordered_context(query, token_budget):\n",
    "    #builds context in-order: null type definitions, enumerations for list types, and metadata lookups\n",
    "    context_lines = []\n",
    "    seen = set()\n",
    "    used_tokens = 0\n",
    "\n",
    "    null_hits, list_hits = extract_nulls_and_lists(query)\n",
    "    codes_in_order = re.findall(r\"\\[([A-Za-z0-9_]+)\\]\", query)\n",
    "\n",
    "    #tokenizer = llm.tokenizer\n",
    "    for code in codes_in_order:\n",
    "        if code in seen:\n",
    "            continue\n",
    "        seen.add(code)\n",
    "\n",
    "        null_entry = next((kw for c, kw in null_hits if c == code), None)\n",
    "        if null_entry:\n",
    "            null_def = null_keywords.get(null_entry, f\"No definition for {null_entry}\")\n",
    "            line = f\"{code} = {null_entry} → {null_def}\"\n",
    "            tokens = len(llm.tokenize(line.encode(\"utf-8\")))\n",
    "            if used_tokens + tokens > token_budget:\n",
    "                break\n",
    "            context_lines.append(line)\n",
    "            used_tokens += tokens\n",
    "\n",
    "        base_meta = metadata_lookup.get(code, \"No metadata found.\")\n",
    "        metadata_line = f\"{code}: {max_tokens(base_meta, 100)}\" \n",
    "        tokens = len(llm.tokenize(metadata_line.encode(\"utf-8\")))\n",
    "        if used_tokens + tokens > token_budget:\n",
    "            break\n",
    "        context_lines.append(metadata_line)\n",
    "        used_tokens += tokens\n",
    "\n",
    "        if any(c == code for c, _ in list_hits):\n",
    "            enum_line = f\"{code} (enumeration): {max_tokens(base_meta, 100)}\"\n",
    "            tokens = len(llm.tokenize(enum_line.encode(\"utf-8\")))\n",
    "            if used_tokens + tokens > token_budget:\n",
    "                break\n",
    "            context_lines.append(enum_line)\n",
    "            used_tokens += tokens\n",
    "\n",
    "    return \"\\n\".join(context_lines)\n",
    "\n",
    "def max_afforded_tokens(codes):\n",
    "    return max(4096 // max(1, len(codes)), 100)\n",
    "\n",
    "\n",
    "def translate_query(query, max_total_tokens=2048, max_output_tokens=256):\n",
    "    codes = extract_codes(query)\n",
    "\n",
    "    m_tokens = max_afforded_tokens(codes)\n",
    "\n",
    "    # Initial prompt pieces\n",
    "    instruction = \"### Instruction:\\nRephrase the following ESGish query into a concise natural English sentence. Each query is asking for all companies or issuers that match some paramater. Use the following metadata definitions for clarity:\\n\\n\"\n",
    "    query_part = f\"\\n\\nQuery: {query}\\n\\n### Response:\"\n",
    "\n",
    "    # Tokenize instruction and query to calculate remaining token budget\n",
    "    #tokenizer = llm.tokenize  # Built-in tokenizer\n",
    "    instruction_tokens = len(llm.tokenize(instruction.encode(\"utf-8\")))\n",
    "    query_tokens = len(llm.tokenize(query_part.encode(\"utf-8\")))\n",
    "    token_budget = max_total_tokens - max_output_tokens - instruction_tokens - query_tokens\n",
    "\n",
    "    # Build full context blocks for each code\n",
    "    context = build_ordered_context(query, token_budget)\n",
    "    print(\"query: \", query)\n",
    "    print(context)\n",
    "\n",
    "    \"\"\"\n",
    "    # Now iteratively add context blocks until budget is exhausted\n",
    "    context = \"\"\n",
    "    used_tokens = 0\n",
    "    for block in context_blocks:\n",
    "        block_tokens = len(tokenizer(block.encode(\"utf-8\"))) + 1  # +1 for newline\n",
    "        if used_tokens + block_tokens <= token_budget:\n",
    "            context += block + \"\\n\"\n",
    "            used_tokens += block_tokens\n",
    "        else:\n",
    "            break  # stop once we're out of budget\n",
    "    \"\"\"\n",
    "    # Final prompt\n",
    "    prompt = instruction + context + query_part\n",
    "\n",
    "    # Call model\n",
    "    response = llm(prompt, max_tokens=max_output_tokens, temperature=0.1)\n",
    "    return response[\"choices\"][0][\"text\"].strip()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81772e84-bbeb-4000-a351-281347bf87a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from functools import partial\n",
    "import time\n",
    "\n",
    "# Reads and stores the Esgish queries\n",
    "df = pd.read_excel(\"Esgish2.xlsx\") ## Input File\n",
    "queries = df[\"Esgish\"].tolist()\n",
    "\n",
    "#Ensures no overload and efficiency\n",
    "batch_size = 100 \n",
    "output_file = \"Translated_Esgish2.xlsx\" ## Output File\n",
    "\n",
    "#Looks at each query in each batch, calls the translate_query function, and stores it\n",
    "for i in range(0, len(queries), batch_size):\n",
    "    batch = queries[i:i + batch_size]\n",
    "    translated_batch = []\n",
    "    \n",
    "    for query in batch:\n",
    "        translated = translate_query(query)\n",
    "        translated_batch.append(translated)\n",
    "    \n",
    "    df_batch = pd.DataFrame({\n",
    "        \"Esgish\": batch,\n",
    "        \"English\": translated_batch\n",
    "    })\n",
    "\n",
    "    #Makes a new file if needed, or adds onto the current file during each batch in case the program crashes at some point\n",
    "    if i == 0:\n",
    "        df_batch.to_excel(output_file, index=False)  \n",
    "    else:\n",
    "        with pd.ExcelWriter(output_file, mode=\"a\", engine=\"openpyxl\", if_sheet_exists=\"overlay\") as writer:\n",
    "            df_batch.to_excel(writer, index=False, header=False, startrow=i + 1)\n",
    "    \n",
    "    print(f\"Saved batch {i // batch_size + 1} to {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4814e3a0-0ddd-467e-8074-18a33f13a0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "input_file = \"Translated_Esgish2.xlsx\"\n",
    "output_file = \"Translated_Esgish2.xlsx\"\n",
    "\n",
    "# Extract the English column\n",
    "df = pd.read_excel(input_file)\n",
    "english_queries = df[\"English\"].tolist()\n",
    "\n",
    "# Function to request a comprehensibility rating from the model\n",
    "def rate_comprehensibility(text, max_tokens=256):\n",
    "    # Adjust the prompt to ask the model for a rating from 1 to 10\n",
    "    prompt = f\"\"\"### Instruction:\n",
    "Please rate the following text's comprehensibility from 1 to 10, where:\n",
    "- 1 = Completely incomprehensible, nonsensical, or full of errors.\n",
    "- 5 = Understandable with effort; some awkwardness, complexity, or minor errors.\n",
    "- 10 = Perfectly clear, natural, and easy to understand.\n",
    "\n",
    "Here are some examples:\n",
    "Text: \"asjdk asjd aksd\" → Rating: 1\n",
    "Text: \"Provide list companies ESG data incomplete understandable\" → Rating: 4\n",
    "Text: \"Please provide a list of companies with complete ESG data.\" → Rating: 9\n",
    "\n",
    "Now, rate this text:\n",
    "Text: {text}\n",
    "\n",
    "### Response:\"\"\"\n",
    "    # Call model (adjust temperature and other params as needed)\n",
    "    response = llm(prompt, max_tokens=max_tokens, temperature=0.2)\n",
    "    rating = response[\"choices\"][0][\"text\"].strip()\n",
    "    print(rating)\n",
    "    # Ensure the response is a valid number between 1 and 10\n",
    "    try:\n",
    "        rating = int(rating)\n",
    "        if 1 <= rating <= 10:\n",
    "            return rating\n",
    "    except ValueError:\n",
    "        pass\n",
    "    return None  # Return None if no valid rating is obtained\n",
    "\n",
    "# List to store ratings\n",
    "ratings = []\n",
    "\n",
    "# Iterate through each English translation and get a rating\n",
    "for query in english_queries:\n",
    "    rating = rate_comprehensibility(query)\n",
    "    ratings.append(rating)\n",
    "\n",
    "# Add the ratings as a new column to the dataframe\n",
    "df[\"Comprehensibility Rating\"] = ratings\n",
    "\n",
    "# Save the updated dataframe with ratings to a new Excel file\n",
    "df.to_excel(output_file, index=False)\n",
    "\n",
    "print(\"Comprehensibility ratings added and saved to 'Translated_Esgish2.xlsx'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f42872-6939-4c34-b74f-f177f8eb3d49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
