{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11329b8f-ae0a-48d4-9da9-7c1c06875c10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (2.1.4)\n",
      "Requirement already satisfied: openpyxl in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (3.0.10)\n",
      "Requirement already satisfied: transformers in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (4.44.2)\n",
      "Requirement already satisfied: torch in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (2.6.0)\n",
      "Requirement already satisfied: numpy<2,>=1.23.2 in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: et_xmlfile in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: filelock in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from transformers) (0.24.7)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from transformers) (23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from transformers) (2023.10.3)\n",
      "Requirement already satisfied: requests in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: llama-cpp-python in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (0.3.7)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from llama-cpp-python) (4.12.2)\n",
      "Requirement already satisfied: numpy>=1.20.0 in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from llama-cpp-python) (1.26.4)\n",
      "Requirement already satisfied: diskcache>=5.6.1 in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from llama-cpp-python) (5.6.3)\n",
      "Requirement already satisfied: jinja2>=2.11.3 in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from llama-cpp-python) (3.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/briannapatten/opt/anaconda3/lib/python3.11/site-packages (from jinja2>=2.11.3->llama-cpp-python) (2.1.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas openpyxl transformers torch\n",
    "!pip install llama-cpp-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a607fdc-3c30-4006-af0d-60789c816fda",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_load_from_file_impl: using device Metal (Apple M2 Pro) - 10922 MiB free\n",
      "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from /Users/briannapatten/Desktop/mistral-7b-instruct-v0.1.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.1\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "print_info: file format = GGUF V2\n",
      "print_info: file type   = Q4_K - Medium\n",
      "print_info: file size   = 4.07 GiB (4.83 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 1\n",
      "load: control token:      2 '</s>' is not marked as EOG\n",
      "load: control token:      1 '<s>' is not marked as EOG\n",
      "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "load: special tokens cache size = 3\n",
      "load: token to piece cache size = 0.1637 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 32768\n",
      "print_info: n_embd           = 4096\n",
      "print_info: n_layer          = 32\n",
      "print_info: n_head           = 32\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 4\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: n_ff             = 14336\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 10000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 32768\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: ssm_d_conv       = 0\n",
      "print_info: ssm_d_inner      = 0\n",
      "print_info: ssm_d_state      = 0\n",
      "print_info: ssm_dt_rank      = 0\n",
      "print_info: ssm_dt_b_c_rms   = 0\n",
      "print_info: model type       = 7B\n",
      "print_info: model params     = 7.24 B\n",
      "print_info: general.name     = mistralai_mistral-7b-instruct-v0.1\n",
      "print_info: vocab type       = SPM\n",
      "print_info: n_vocab          = 32000\n",
      "print_info: n_merges         = 0\n",
      "print_info: BOS token        = 1 '<s>'\n",
      "print_info: EOS token        = 2 '</s>'\n",
      "print_info: UNK token        = 0 '<unk>'\n",
      "print_info: LF token         = 13 '<0x0A>'\n",
      "print_info: EOG token        = 2 '</s>'\n",
      "print_info: max token length = 48\n",
      "load_tensors: layer   0 assigned to device CPU\n",
      "load_tensors: layer   1 assigned to device CPU\n",
      "load_tensors: layer   2 assigned to device CPU\n",
      "load_tensors: layer   3 assigned to device CPU\n",
      "load_tensors: layer   4 assigned to device CPU\n",
      "load_tensors: layer   5 assigned to device CPU\n",
      "load_tensors: layer   6 assigned to device CPU\n",
      "load_tensors: layer   7 assigned to device CPU\n",
      "load_tensors: layer   8 assigned to device CPU\n",
      "load_tensors: layer   9 assigned to device CPU\n",
      "load_tensors: layer  10 assigned to device CPU\n",
      "load_tensors: layer  11 assigned to device CPU\n",
      "load_tensors: layer  12 assigned to device CPU\n",
      "load_tensors: layer  13 assigned to device CPU\n",
      "load_tensors: layer  14 assigned to device CPU\n",
      "load_tensors: layer  15 assigned to device CPU\n",
      "load_tensors: layer  16 assigned to device CPU\n",
      "load_tensors: layer  17 assigned to device CPU\n",
      "load_tensors: layer  18 assigned to device CPU\n",
      "load_tensors: layer  19 assigned to device CPU\n",
      "load_tensors: layer  20 assigned to device CPU\n",
      "load_tensors: layer  21 assigned to device CPU\n",
      "load_tensors: layer  22 assigned to device CPU\n",
      "load_tensors: layer  23 assigned to device CPU\n",
      "load_tensors: layer  24 assigned to device CPU\n",
      "load_tensors: layer  25 assigned to device CPU\n",
      "load_tensors: layer  26 assigned to device CPU\n",
      "load_tensors: layer  27 assigned to device CPU\n",
      "load_tensors: layer  28 assigned to device CPU\n",
      "load_tensors: layer  29 assigned to device CPU\n",
      "load_tensors: layer  30 assigned to device CPU\n",
      "load_tensors: layer  31 assigned to device CPU\n",
      "load_tensors: layer  32 assigned to device CPU\n",
      "load_tensors: tensor 'token_embd.weight' (q4_K) (and 290 others) cannot be used with preferred buffer type CPU_AARCH64, using CPU instead\n",
      "load_tensors: offloading 0 repeating layers to GPU\n",
      "load_tensors: offloaded 0/33 layers to GPU\n",
      "load_tensors:   CPU_Mapped model buffer size =  4165.37 MiB\n",
      "llama_init_from_model: n_seq_max     = 1\n",
      "llama_init_from_model: n_ctx         = 512\n",
      "llama_init_from_model: n_ctx_per_seq = 512\n",
      "llama_init_from_model: n_batch       = 512\n",
      "llama_init_from_model: n_ubatch      = 512\n",
      "llama_init_from_model: flash_attn    = 0\n",
      "llama_init_from_model: freq_base     = 10000.0\n",
      "llama_init_from_model: freq_scale    = 1\n",
      "llama_init_from_model: n_ctx_per_seq (512) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M2 Pro\n",
      "ggml_metal_init: picking default device: Apple M2 Pro\n",
      "ggml_metal_init: using embedded metal library\n",
      "ggml_metal_init: GPU name:   Apple M2 Pro\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple8  (1008)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal3  (5001)\n",
      "ggml_metal_init: simdgroup reduction   = true\n",
      "ggml_metal_init: simdgroup matrix mul. = true\n",
      "ggml_metal_init: has residency sets    = false\n",
      "ggml_metal_init: has bfloat            = true\n",
      "ggml_metal_init: use bfloat            = false\n",
      "ggml_metal_init: hasUnifiedMemory      = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 11453.25 MB\n",
      "ggml_metal_init: loaded kernel_add                                    0x103e0ec20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row                                0x103fc1240 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub                                    0x103fc1590 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub_row                                0x103fc18e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul                                    0x103fc1c30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_row                                0x28171c080 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div                                    0x106cf60e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div_row                                0x103fc1f80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f32                             0x103fc2420 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f16                             0x137c5d0a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i32                             0x103fc27c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i16                             0x103fc29f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale                                  0x28171c2b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale_4                                0x28171c850 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_clamp                                  0x103e776b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_tanh                                   0x28171cd00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_relu                                   0x1119d7e80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sigmoid                                0x103fc2e30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu                                   0x28171d430 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_4                                 0x103fc3410 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick                             0x137c5d6a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick_4                           0x103fc39f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu                                   0x1119d8e10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu_4                                 0x137c5dd70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_elu                                    0x137c5e220 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16                           0x1119d6260 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16_4                         0x137c5e450 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32                           0x137c5e680 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32_4                         0x103fc3c20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf                          0x103fc3f70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf_8                        0x103fc42c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f32                           0x103fc4610 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f16                           0x103fc4960 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_0                          0x103fc4cb0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_1                          0x1119d7310 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_0                          0x1119d7540 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_1                          0x1119d7770 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q8_0                          0x137c5eac0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q2_K                          0x137c5ecf0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q3_K                          0x103e77b70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_K                          0x137c5ef20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_K                          0x137c5f150 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q6_K                          0x1119d79a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xxs                       0x137c5f380 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xs                        0x1119dc1d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_xxs                       0x1119dc520 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_s                         0x137c5f5b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_s                         0x1119dcb80 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_s                         0x103fc5000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_m                         0x28171d870 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_nl                        0x28171daa0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_xs                        0x1119dced0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_i32                           0x103fc5350 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rms_norm                               0x1119dd560 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_group_norm                             0x1119dd8b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_norm                                   0x103fc56a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_conv_f32                           0x1119ddee0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_scan_f32                           0x28171dcd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f32_f32                         0x1119de230 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32                         0x137c5f7e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_1row                    0x137c5fa10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_l4                      0x1119de460 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f16                         0x137c5fc40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_0_f32                        0x137c60080 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_1_f32                        0x1119de930 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_0_f32                        0x1119dec80 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_1_f32                        0x137c604c0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q8_0_f32                        0x1119defd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_2                0x1119df200 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_3                0x1119df550 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_4                0x137c60810 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_5                0x1119df8a0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_2               0x137c60ce0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_3               0x1119dfbf0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_4               0x137c61030 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_5               0x137c61380 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_2               0x1119dff40 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_3               0x137c615b0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_4               0x1119e03b0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_5               0x1119e0700 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_2               0x1119e0a50 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_3               0x1119e0c80 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_4               0x1119e1490 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_5               0x137c61900 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_2               0x1119e17e0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_3               0x1119e1b30 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_4               0x1119e1e80 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_5               0x137c61c50 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_2               0x1119e21d0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_3               0x137c61fa0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_4               0x1119e2520 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_5               0x1119e2870 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_2               0x137c622f0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_3               0x137c62640 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_4               0x1119e2aa0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_5               0x137c62990 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_2               0x1119e2f70 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_3               0x1119e31a0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_4               0x1119e33d0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_5               0x137c62ce0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_2               0x1119e3720 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_3               0x137c63030 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_4               0x1119e3a70 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_5               0x137c63380 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_2             0x1119e3dc0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_3             0x1119e3ff0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_4             0x137c636d0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_5             0x1119e44c0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q2_K_f32                        0x1119e4960 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q3_K_f32                        0x137c63a20 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_K_f32                        0x1119e4da0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_K_f32                        0x28171df00 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q6_K_f32                        0x28171e130 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xxs_f32                     0x1119e4fd0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xs_f32                      0x1119e5410 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_xxs_f32                     0x17fb9c4f0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_s_f32                       0x137c63ed0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_s_f32                       0x1119e5850 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_s_f32                       0x1119e5e40 | th_max =  448 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_m_f32                       0x137c64310 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_nl_f32                      0x28171e360 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_xs_f32                      0x1119e6280 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f32_f32                      0x137c64540 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f16_f32                      0x1119e66c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_0_f32                     0x28171e590 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_1_f32                     0x1119e6b00 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_0_f32                     0x1119e6ea0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_1_f32                     0x103e75cc0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q8_0_f32                     0x1119e72e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q2_K_f32                     0x1119e7680 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q3_K_f32                     0x137c64980 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_K_f32                     0x28171e7c0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_K_f32                     0x137c64d20 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q6_K_f32                     0x1119e7ac0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xxs_f32                  0x1119e7f00 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xs_f32                   0x137c65160 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_xxs_f32                  0x1119e8340 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_s_f32                    0x28171e9f0 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_s_f32                    0x28171ec20 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_s_f32                    0x28171ee50 | th_max =  448 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_m_f32                    0x137c65500 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_nl_f32                   0x137c658a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_xs_f32                   0x28171f080 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f32_f32                         0x1119e8780 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f16_f32                         0x137c65c40 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_0_f32                        0x28171f2b0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_1_f32                        0x137c66080 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_0_f32                        0x1119e8bc0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_1_f32                        0x137c66420 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q8_0_f32                        0x1119e8f60 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q2_K_f32                        0x137c667c0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q3_K_f32                        0x17fb9c070 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_K_f32                        0x137c669f0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_K_f32                        0x137c66fa0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q6_K_f32                        0x17fb9dd10 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_xxs_f32                     0x103e75ef0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_xs_f32                      0x137c673e0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq3_xxs_f32                     0x137c67820 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq3_s_f32                       0x1119e93a0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_s_f32                       0x1119e97e0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq1_s_f32                       0x1119e9b80 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq1_m_f32                       0x103e76120 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq4_nl_f32                      0x103fc5a40 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq4_xs_f32                      0x1119e9fc0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_f32_f32                      0x103e78390 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_f16_f32                      0x17fb9df40 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_0_f32                     0x137c67c60 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_1_f32                     0x103e785c0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_0_f32                     0x103e787f0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_1_f32                     0x17fb9cbf0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q8_0_f32                     0x1119ea400 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q2_K_f32                     0x103fc5de0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q3_K_f32                     0x17fb9ce20 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_K_f32                     0x103fc6180 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_K_f32                     0x17fb9d050 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q6_K_f32                     0x103fc6520 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_xxs_f32                  0x17fb9d280 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_xs_f32                   0x103fc6750 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq3_xxs_f32                  0x1119ea840 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq3_s_f32                    0x103fc6d00 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_s_f32                    0x103fc7140 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq1_s_f32                    0x103fc74e0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq1_m_f32                    0x137c680a0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq4_nl_f32                   0x103fc7920 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq4_xs_f32                   0x1119eac80 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_norm_f32                          0x17fb9e810 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_norm_f16                          0x103fc7c70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f32                          0x1119eafd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f16                          0x1119eb320 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f16                             0x17fb9ea40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f32                             0x137c683f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f16                         0x137c68740 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f32                         0x1119eb670 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_conv_transpose_1d_f32_f32              0x137c68970 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_conv_transpose_1d_f16_f32              0x103fc7fc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_upscale_f32                            0x1119ebad0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pad_f32                                0x1119ebf10 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pad_reflect_1d_f32                     0x1119ec350 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_timestep_embedding_f32                 0x103fc8410 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_arange_f32                             0x28171f4e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_asc                    0x1119ec790 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_desc                   0x28171f710 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_leaky_relu_f32                         0x28171fc60 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h64                 0x137c68e40 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h80                 0x137c69190 | th_max =  640 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h96                 0x1119ecae0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h112                0x1119ecd10 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h128                0x17fb9ec70 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h256                0x1119ed060 | th_max =  512 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h64                0x137c694e0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h80                0x1119ed530 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h96                0x137c69830 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h112               0x137c69b80 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h128               0x1119ed880 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h256               0x1119edbd0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h64                0x137c69ed0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h80                0x28171fe90 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h96                0x137c6a220 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h112               0x137c6a570 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h128               0x1119ee3b0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h256               0x17fb9eea0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h64                0x137c6a7a0 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h80                0x137c6ac70 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h96                0x1119ee5e0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h112               0x2817200c0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h128               0x2817203b0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h256               0x1119ee930 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h64                0x1119eec80 | th_max =  576 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h80                0x2817205e0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h96                0x137c6afc0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h112               0x281720810 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h128               0x1119eefd0 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h256               0x1119ef320 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h64                0x137c6b310 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h80                0x281720a40 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h96                0x1119ef550 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h112               0x1119efa20 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h128               0x1119efd70 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h256               0x137c6b660 | th_max =  896 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h128            0x137c6b9b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h128           0x137c6bd00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h128           0x1119f00c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h128           0x281720c70 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h128           0x1119f0410 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h128           0x1119f0640 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h256            0x281720ea0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h256           0x1119f0b10 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h256           0x137c6c050 | th_max =  768 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h256           0x17fb9f0d0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h256           0x2817210d0 | th_max =  704 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h256           0x137c6c3a0 | th_max =  832 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_f32                                0x281721300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_i32                                0x1119f1060 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f32                            0x1119f1290 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f16                            0x137c6c6f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f32                            0x137c6cb50 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f16                            0x281721540 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q8_0                           0x1119f16d0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_0                           0x1119f1a70 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_1                           0x281721770 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_0                           0x17fb9f300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_1                           0x2817219a0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_iq4_nl                         0x281721bd0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_concat                                 0x1119f1dc0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqr                                    0x1119f23c0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqrt                                   0x137c6d210 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sin                                    0x137c6d7e0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cos                                    0x281722080 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sum_rows                               0x1119f2710 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argmax                                 0x2817222b0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_avg_f32                        0x137c6db30 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_max_f32                        0x137c6de80 | th_max = 1024 | th_width =   32\n",
      "llama_kv_cache_init: kv_size = 512, offload = 1, type_k = 'f16', type_v = 'f16', n_layer = 32, can_shift = 1\n",
      "llama_kv_cache_init: layer 0: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 1: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 2: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 3: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 4: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 5: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 6: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 7: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 8: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 9: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 10: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 11: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 12: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 13: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 14: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 15: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 16: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 17: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 18: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 19: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 20: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 21: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 22: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 23: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 24: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 25: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 26: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 27: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 28: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 29: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 30: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init: layer 31: n_embd_k_gqa = 1024, n_embd_v_gqa = 1024\n",
      "llama_kv_cache_init:        CPU KV buffer size =    64.00 MiB\n",
      "llama_init_from_model: KV self size  =   64.00 MiB, K (f16):   32.00 MiB, V (f16):   32.00 MiB\n",
      "llama_init_from_model:        CPU  output buffer size =     0.12 MiB\n",
      "llama_init_from_model:        CPU compute buffer size =    81.01 MiB\n",
      "llama_init_from_model: graph nodes  = 1030\n",
      "llama_init_from_model: graph splits = 514 (with bs=512), 1 (with bs=1)\n",
      "Metal : EMBED_LIBRARY = 1 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | MATMUL_INT8 = 1 | DOTPROD = 1 | MATMUL_INT8 = 1 | ACCELERATE = 1 | AARCH64_REPACK = 1 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '8', 'llama.context_length': '32768', 'llama.attention.head_count': '32', 'llama.rope.freq_base': '10000.000000', 'llama.rope.dimension_count': '128', 'general.file_type': '15', 'llama.feed_forward_length': '14336', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.name': 'mistralai_mistral-7b-instruct-v0.1'}\n",
      "Using fallback chat format: llama-2\n"
     ]
    }
   ],
   "source": [
    "from llama_cpp import Llama\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "model_path = \"/Users/briannapatten/Desktop/mistral-7b-instruct-v0.1.Q4_K_M.gguf\"\n",
    "llm = Llama(model_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "efb3fc4c-e7b9-4bfb-9340-779aaba31116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def translate_query(query):\n",
    "    #prompt = f\"### Instruction:\\nRephrase the following ESGish query into a natural English sentence that begins with 'Return all occurrences of'.\\n\\n{query}\\n\\n### Response:\"\n",
    "    #Changes up prompts each time to ensure variety in English conversions\n",
    "    PROMPTS = [\n",
    "        f\"### Instruction:\\nRephrase the following ESGish query into a natural English sentence that begins with 'Return all occurrences of'.\\n\\n{query}\\n\\n### Response:\",\n",
    "        f\"### Instruction:\\nRephrase the following ESGish query into a natural English sentence that begins with 'Find where'.\\n\\n{query}\\n\\n### Response:\",\n",
    "        f\"### Instruction:\\nRephrase the following ESGish query into a natural English sentence that begins with 'Return issuers that'.\\n\\n{query}\\n\\n### Response:\",\n",
    "        f\"### Instruction:\\nRephrase the following ESGish query into a natural English sentence.\\n\\n{query}\\n\\n### Response:\",\n",
    "        f\"### Instruction:\\nRephrase the following ESGish query into a natural English sentence that begins with 'Return'.\\n\\n{query}\\n\\n### Response:\"\n",
    "    ]\n",
    "    #Error handling \n",
    "    try:\n",
    "        #Chooses a random prompt from the array, queries a response from Mistral, returns response\n",
    "        prompt = random.choice(PROMPTS).format(query=query)\n",
    "        response = llm(prompt, max_tokens=575, temperature=0.1)\n",
    "        return response[\"choices\"][0][\"text\"].strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error translating query: '{query}'\\nError: {str(e)}\")\n",
    "        return \"[TRANSLATION_FAILED]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81772e84-bbeb-4000-a351-281347bf87a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 25 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1870.76 ms /    69 tokens (   27.11 ms per token,    36.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3010.59 ms /    62 runs   (   48.56 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    4890.39 ms /   131 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     551.78 ms /    13 tokens (   42.44 ms per token,    23.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1303.88 ms /    27 runs   (   48.29 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1859.27 ms /    40 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     322.45 ms /     9 tokens (   35.83 ms per token,    27.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =     913.30 ms /    19 runs   (   48.07 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1238.49 ms /    28 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     675.44 ms /    22 tokens (   30.70 ms per token,    32.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =     897.64 ms /    18 runs   (   49.87 ms per token,    20.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    1575.55 ms /    40 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     828.76 ms /    26 tokens (   31.88 ms per token,    31.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1124.07 ms /    23 runs   (   48.87 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    1956.17 ms /    49 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     599.12 ms /    21 tokens (   28.53 ms per token,    35.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =     776.07 ms /    16 runs   (   48.50 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    1377.60 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     845.47 ms /    28 tokens (   30.20 ms per token,    33.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =     726.38 ms /    15 runs   (   48.43 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    1574.11 ms /    43 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     615.59 ms /    21 tokens (   29.31 ms per token,    34.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =     773.99 ms /    16 runs   (   48.37 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    1391.80 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1471.45 ms /    32 tokens (   45.98 ms per token,    21.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1347.57 ms /    28 runs   (   48.13 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    2823.00 ms /    60 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     873.29 ms /    26 tokens (   33.59 ms per token,    29.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =     819.56 ms /    17 runs   (   48.21 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1695.37 ms /    43 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     663.50 ms /    23 tokens (   28.85 ms per token,    34.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =     829.38 ms /    17 runs   (   48.79 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    1495.23 ms /    40 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     591.74 ms /    20 tokens (   29.59 ms per token,    33.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =     681.06 ms /    14 runs   (   48.65 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    1274.98 ms /    34 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     853.99 ms /    28 tokens (   30.50 ms per token,    32.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1398.11 ms /    29 runs   (   48.21 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    2256.24 ms /    57 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     667.73 ms /    23 tokens (   29.03 ms per token,    34.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =     721.01 ms /    15 runs   (   48.07 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1390.82 ms /    38 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     839.69 ms /    30 tokens (   27.99 ms per token,    35.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1111.13 ms /    23 runs   (   48.31 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1954.11 ms /    53 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     720.60 ms /    24 tokens (   30.02 ms per token,    33.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1013.76 ms /    21 runs   (   48.27 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1737.33 ms /    45 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     837.18 ms /    29 tokens (   28.87 ms per token,    34.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1171.33 ms /    24 runs   (   48.81 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    2011.82 ms /    53 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     916.76 ms /    29 tokens (   31.61 ms per token,    31.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1113.67 ms /    23 runs   (   48.42 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    2033.72 ms /    52 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     728.64 ms /    24 tokens (   30.36 ms per token,    32.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1060.86 ms /    22 runs   (   48.22 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1792.55 ms /    46 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     834.76 ms /    28 tokens (   29.81 ms per token,    33.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1261.75 ms /    26 runs   (   48.53 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    2100.10 ms /    54 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     799.26 ms /    24 tokens (   33.30 ms per token,    30.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =     731.75 ms /    15 runs   (   48.78 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    1533.12 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1608.44 ms /    32 tokens (   50.26 ms per token,    19.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1183.09 ms /    24 runs   (   49.30 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    2795.17 ms /    56 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     798.01 ms /    27 tokens (   29.56 ms per token,    33.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1265.54 ms /    26 runs   (   48.67 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    2067.26 ms /    53 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1642.09 ms /    35 tokens (   46.92 ms per token,    21.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =     728.62 ms /    15 runs   (   48.57 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    2373.01 ms /    50 tokens\n",
      "Llama.generate: 47 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     376.79 ms /    12 tokens (   31.40 ms per token,    31.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =     536.26 ms /    11 runs   (   48.75 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =     914.82 ms /    23 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1741.05 ms /    40 tokens (   43.53 ms per token,    22.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =     871.24 ms /    18 runs   (   48.40 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    2615.12 ms /    58 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1010.96 ms /    30 tokens (   33.70 ms per token,    29.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1424.25 ms /    29 runs   (   49.11 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    2439.29 ms /    59 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     444.38 ms /    13 tokens (   34.18 ms per token,    29.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1426.79 ms /    29 runs   (   49.20 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    1875.28 ms /    42 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     941.57 ms /    30 tokens (   31.39 ms per token,    31.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =     879.43 ms /    18 runs   (   48.86 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    1823.64 ms /    48 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1641.93 ms /    39 tokens (   42.10 ms per token,    23.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1700.18 ms /    34 runs   (   50.01 ms per token,    20.00 tokens per second)\n",
      "llama_perf_context_print:       total time =    3347.31 ms /    73 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     498.21 ms /    15 tokens (   33.21 ms per token,    30.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1236.45 ms /    25 runs   (   49.46 ms per token,    20.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    1738.34 ms /    40 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1724.91 ms /    45 tokens (   38.33 ms per token,    26.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1390.39 ms /    28 runs   (   49.66 ms per token,    20.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    3119.47 ms /    73 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1673.86 ms /    37 tokens (   45.24 ms per token,    22.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1337.68 ms /    27 runs   (   49.54 ms per token,    20.18 tokens per second)\n",
      "llama_perf_context_print:       total time =    3015.51 ms /    64 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     379.53 ms /    10 tokens (   37.95 ms per token,    26.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =     731.88 ms /    15 runs   (   48.79 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    1113.71 ms /    25 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     891.92 ms /    29 tokens (   30.76 ms per token,    32.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =     689.48 ms /    14 runs   (   49.25 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    1583.55 ms /    43 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1673.05 ms /    45 tokens (   37.18 ms per token,    26.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1287.14 ms /    26 runs   (   49.51 ms per token,    20.20 tokens per second)\n",
      "llama_perf_context_print:       total time =    2964.06 ms /    71 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     308.24 ms /     9 tokens (   34.25 ms per token,    29.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =     786.47 ms /    16 runs   (   49.15 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    1097.12 ms /    25 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     734.32 ms /    23 tokens (   31.93 ms per token,    31.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =     885.78 ms /    18 runs   (   49.21 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    1622.73 ms /    41 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     782.25 ms /    25 tokens (   31.29 ms per token,    31.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =     691.34 ms /    14 runs   (   49.38 ms per token,    20.25 tokens per second)\n",
      "llama_perf_context_print:       total time =    1475.81 ms /    39 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     495.37 ms /    11 tokens (   45.03 ms per token,    22.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1040.94 ms /    21 runs   (   49.57 ms per token,    20.17 tokens per second)\n",
      "llama_perf_context_print:       total time =    1539.35 ms /    32 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1631.66 ms /    36 tokens (   45.32 ms per token,    22.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =     803.92 ms /    16 runs   (   50.25 ms per token,    19.90 tokens per second)\n",
      "llama_perf_context_print:       total time =    2438.16 ms /    52 tokens\n",
      "Llama.generate: 44 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     607.18 ms /    19 tokens (   31.96 ms per token,    31.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =     552.29 ms /    11 runs   (   50.21 ms per token,    19.92 tokens per second)\n",
      "llama_perf_context_print:       total time =    1161.21 ms /    30 tokens\n",
      "Llama.generate: 30 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     548.15 ms /    17 tokens (   32.24 ms per token,    31.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =     833.34 ms /    17 runs   (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    1383.99 ms /    34 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     644.32 ms /    21 tokens (   30.68 ms per token,    32.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =     791.95 ms /    16 runs   (   49.50 ms per token,    20.20 tokens per second)\n",
      "llama_perf_context_print:       total time =    1438.68 ms /    37 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     757.79 ms /    25 tokens (   30.31 ms per token,    32.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1328.70 ms /    27 runs   (   49.21 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    2090.32 ms /    52 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     838.72 ms /    27 tokens (   31.06 ms per token,    32.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1104.67 ms /    22 runs   (   50.21 ms per token,    19.92 tokens per second)\n",
      "llama_perf_context_print:       total time =    1946.66 ms /    49 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     904.89 ms /    25 tokens (   36.20 ms per token,    27.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1140.63 ms /    23 runs   (   49.59 ms per token,    20.16 tokens per second)\n",
      "llama_perf_context_print:       total time =    2048.87 ms /    48 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     614.03 ms /    20 tokens (   30.70 ms per token,    32.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =     783.24 ms /    16 runs   (   48.95 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    1399.66 ms /    36 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     774.99 ms /    25 tokens (   31.00 ms per token,    32.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =     984.71 ms /    20 runs   (   49.24 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    1762.67 ms /    45 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     922.94 ms /    30 tokens (   30.76 ms per token,    32.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1288.38 ms /    26 runs   (   49.55 ms per token,    20.18 tokens per second)\n",
      "llama_perf_context_print:       total time =    2214.97 ms /    56 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     539.35 ms /    17 tokens (   31.73 ms per token,    31.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1298.34 ms /    26 runs   (   49.94 ms per token,    20.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    1841.36 ms /    43 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     854.25 ms /    26 tokens (   32.86 ms per token,    30.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =     949.07 ms /    19 runs   (   49.95 ms per token,    20.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    1806.10 ms /    45 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     743.75 ms /    24 tokens (   30.99 ms per token,    32.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =     890.23 ms /    18 runs   (   49.46 ms per token,    20.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    1636.77 ms /    42 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     655.06 ms /    21 tokens (   31.19 ms per token,    32.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =     804.21 ms /    16 runs   (   50.26 ms per token,    19.90 tokens per second)\n",
      "llama_perf_context_print:       total time =    1461.59 ms /    37 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1627.67 ms /    34 tokens (   47.87 ms per token,    20.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1030.94 ms /    21 runs   (   49.09 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    2661.86 ms /    55 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     766.99 ms /    24 tokens (   31.96 ms per token,    31.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =     730.61 ms /    15 runs   (   48.71 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    1499.82 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     879.59 ms /    26 tokens (   33.83 ms per token,    29.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =     895.89 ms /    18 runs   (   49.77 ms per token,    20.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    1778.20 ms /    44 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1665.61 ms /    34 tokens (   48.99 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =     931.20 ms /    19 runs   (   49.01 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    2599.74 ms /    53 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     881.88 ms /    28 tokens (   31.50 ms per token,    31.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1120.29 ms /    23 runs   (   48.71 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    2005.63 ms /    51 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1022.50 ms /    26 tokens (   39.33 ms per token,    25.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =     922.91 ms /    19 runs   (   48.57 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    1948.25 ms /    45 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     441.09 ms /    11 tokens (   40.10 ms per token,    24.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =     634.85 ms /    13 runs   (   48.83 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    1077.92 ms /    24 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     972.43 ms /    30 tokens (   32.41 ms per token,    30.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1223.54 ms /    25 runs   (   48.94 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    2199.49 ms /    55 tokens\n",
      "Llama.generate: 30 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     655.75 ms /    19 tokens (   34.51 ms per token,    28.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =     823.03 ms /    17 runs   (   48.41 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    1481.28 ms /    36 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     843.63 ms /    26 tokens (   32.45 ms per token,    30.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1026.34 ms /    21 runs   (   48.87 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    1873.11 ms /    47 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     747.00 ms /    24 tokens (   31.13 ms per token,    32.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =     783.11 ms /    16 runs   (   48.94 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    1532.45 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     951.30 ms /    31 tokens (   30.69 ms per token,    32.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1070.03 ms /    22 runs   (   48.64 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    2024.45 ms /    53 tokens\n",
      "Llama.generate: 32 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     604.20 ms /    19 tokens (   31.80 ms per token,    31.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1072.40 ms /    22 runs   (   48.75 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    1679.78 ms /    41 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     888.95 ms /    21 tokens (   42.33 ms per token,    23.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =     677.02 ms /    14 runs   (   48.36 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1568.10 ms /    35 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     832.60 ms /    27 tokens (   30.84 ms per token,    32.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =     734.27 ms /    15 runs   (   48.95 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    1569.14 ms /    42 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     833.85 ms /    25 tokens (   33.35 ms per token,    29.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =     882.74 ms /    18 runs   (   49.04 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    1719.17 ms /    43 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     683.81 ms /    22 tokens (   31.08 ms per token,    32.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =     776.59 ms /    16 runs   (   48.54 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    1462.78 ms /    38 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     712.67 ms /    23 tokens (   30.99 ms per token,    32.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =     730.11 ms /    15 runs   (   48.67 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1445.05 ms /    38 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     671.73 ms /    21 tokens (   31.99 ms per token,    31.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =     681.60 ms /    14 runs   (   48.69 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1355.44 ms /    35 tokens\n",
      "Llama.generate: 28 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     597.55 ms /    19 tokens (   31.45 ms per token,    31.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =     874.85 ms /    18 runs   (   48.60 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    1475.03 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     875.92 ms /    29 tokens (   30.20 ms per token,    33.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =     831.81 ms /    17 runs   (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    1710.30 ms /    46 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1545.89 ms /    32 tokens (   48.31 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1669.45 ms /    34 runs   (   49.10 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    3220.26 ms /    66 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     587.26 ms /    20 tokens (   29.36 ms per token,    34.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =     583.13 ms /    12 runs   (   48.59 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    1172.21 ms /    32 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1627.52 ms /    34 tokens (   47.87 ms per token,    20.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1424.04 ms /    29 runs   (   49.10 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    3055.76 ms /    63 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     631.40 ms /    20 tokens (   31.57 ms per token,    31.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =     867.70 ms /    18 runs   (   48.21 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1501.71 ms /    38 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     610.08 ms /    19 tokens (   32.11 ms per token,    31.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =     628.19 ms /    13 runs   (   48.32 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1240.17 ms /    32 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     680.33 ms /    22 tokens (   30.92 ms per token,    32.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =     871.88 ms /    18 runs   (   48.44 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    1554.89 ms /    40 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     258.08 ms /     7 tokens (   36.87 ms per token,    27.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =     920.29 ms /    19 runs   (   48.44 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    1181.18 ms /    26 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     582.90 ms /    18 tokens (   32.38 ms per token,    30.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =     675.88 ms /    14 runs   (   48.28 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1260.88 ms /    32 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     578.86 ms /    17 tokens (   34.05 ms per token,    29.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =     529.90 ms /    11 runs   (   48.17 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1110.43 ms /    28 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     766.57 ms /    25 tokens (   30.66 ms per token,    32.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1012.90 ms /    21 runs   (   48.23 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1782.45 ms /    46 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     655.31 ms /    20 tokens (   32.77 ms per token,    30.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =     866.35 ms /    18 runs   (   48.13 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1524.19 ms /    38 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     859.48 ms /    29 tokens (   29.64 ms per token,    33.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =     965.55 ms /    20 runs   (   48.28 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1827.95 ms /    49 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     612.86 ms /    20 tokens (   30.64 ms per token,    32.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =     981.72 ms /    20 runs   (   49.09 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    1597.45 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     645.38 ms /    20 tokens (   32.27 ms per token,    30.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =     914.28 ms /    19 runs   (   48.12 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1562.37 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     906.72 ms /    27 tokens (   33.58 ms per token,    29.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =     867.20 ms /    18 runs   (   48.18 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1776.39 ms /    45 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     634.66 ms /    20 tokens (   31.73 ms per token,    31.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =     918.51 ms /    19 runs   (   48.34 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1555.84 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     630.58 ms /    20 tokens (   31.53 ms per token,    31.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =     686.35 ms /    14 runs   (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    1319.05 ms /    34 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     888.35 ms /    29 tokens (   30.63 ms per token,    32.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =     727.28 ms /    15 runs   (   48.49 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    1617.89 ms /    44 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     823.46 ms /    28 tokens (   29.41 ms per token,    34.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =     776.13 ms /    16 runs   (   48.51 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    1602.06 ms /    44 tokens\n",
      "Llama.generate: 45 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     326.31 ms /     7 tokens (   46.62 ms per token,    21.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =     780.22 ms /    16 runs   (   48.76 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    1108.83 ms /    23 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     389.53 ms /    12 tokens (   32.46 ms per token,    30.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1307.49 ms /    27 runs   (   48.43 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    1700.88 ms /    39 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     737.49 ms /    24 tokens (   30.73 ms per token,    32.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =     581.58 ms /    12 runs   (   48.47 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    1320.81 ms /    36 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     357.48 ms /    10 tokens (   35.75 ms per token,    27.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =     729.02 ms /    15 runs   (   48.60 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    1088.68 ms /    25 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1495.71 ms /    32 tokens (   46.74 ms per token,    21.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1016.38 ms /    21 runs   (   48.40 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    2515.12 ms /    53 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     659.57 ms /    20 tokens (   32.98 ms per token,    30.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =     682.45 ms /    14 runs   (   48.75 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    1344.07 ms /    34 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 1 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     654.94 ms /    22 tokens (   29.77 ms per token,    33.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =     642.73 ms /    13 runs   (   49.44 ms per token,    20.23 tokens per second)\n",
      "llama_perf_context_print:       total time =    1300.69 ms /    35 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     623.56 ms /    20 tokens (   31.18 ms per token,    32.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =     341.18 ms /     7 runs   (   48.74 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =     966.07 ms /    27 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     733.91 ms /    25 tokens (   29.36 ms per token,    34.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =     631.94 ms /    13 runs   (   48.61 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    1367.83 ms /    38 tokens\n",
      "Llama.generate: 29 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     490.14 ms /    15 tokens (   32.68 ms per token,    30.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =     504.97 ms /    10 runs   (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_perf_context_print:       total time =     996.73 ms /    25 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     743.05 ms /    22 tokens (   33.78 ms per token,    29.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =     578.58 ms /    12 runs   (   48.21 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1323.39 ms /    34 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1073.43 ms /    27 tokens (   39.76 ms per token,    25.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =     774.44 ms /    16 runs   (   48.40 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    1850.14 ms /    43 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     270.69 ms /     6 tokens (   45.11 ms per token,    22.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =     722.73 ms /    15 runs   (   48.18 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =     995.59 ms /    21 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     635.28 ms /    19 tokens (   33.44 ms per token,    29.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =     493.10 ms /    10 runs   (   49.31 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    1130.04 ms /    29 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     563.62 ms /    18 tokens (   31.31 ms per token,    31.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =     593.67 ms /    12 runs   (   49.47 ms per token,    20.21 tokens per second)\n",
      "llama_perf_context_print:       total time =    1159.22 ms /    30 tokens\n",
      "Llama.generate: 26 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     403.95 ms /    11 tokens (   36.72 ms per token,    27.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =     530.57 ms /    11 runs   (   48.23 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =     936.25 ms /    22 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     873.61 ms /    29 tokens (   30.12 ms per token,    33.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =     826.11 ms /    17 runs   (   48.59 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    1702.13 ms /    46 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     819.41 ms /    27 tokens (   30.35 ms per token,    32.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1274.91 ms /    26 runs   (   49.03 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    2098.06 ms /    53 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     766.33 ms /    26 tokens (   29.47 ms per token,    33.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1115.50 ms /    23 runs   (   48.50 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    1885.09 ms /    49 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1696.17 ms /    45 tokens (   37.69 ms per token,    26.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1017.46 ms /    21 runs   (   48.45 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    2716.80 ms /    66 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     892.29 ms /    29 tokens (   30.77 ms per token,    32.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1210.95 ms /    25 runs   (   48.44 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    2106.71 ms /    54 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1625.09 ms /    33 tokens (   49.25 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1071.62 ms /    22 runs   (   48.71 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    2699.98 ms /    55 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1721.48 ms /    46 tokens (   37.42 ms per token,    26.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1024.12 ms /    21 runs   (   48.77 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    2748.79 ms /    67 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     637.58 ms /    21 tokens (   30.36 ms per token,    32.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =     856.61 ms /    15 runs   (   57.11 ms per token,    17.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    1496.76 ms /    36 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     661.53 ms /    22 tokens (   30.07 ms per token,    33.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1032.09 ms /    21 runs   (   49.15 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    1696.83 ms /    43 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     433.31 ms /     9 tokens (   48.15 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1046.65 ms /    21 runs   (   49.84 ms per token,    20.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    1483.12 ms /    30 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     563.05 ms /    18 tokens (   31.28 ms per token,    31.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =     578.17 ms /    12 runs   (   48.18 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1143.08 ms /    30 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     280.43 ms /     7 tokens (   40.06 ms per token,    24.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =     585.38 ms /    12 runs   (   48.78 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =     867.68 ms /    19 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     535.13 ms /    16 tokens (   33.45 ms per token,    29.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =     483.60 ms /    10 runs   (   48.36 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1020.34 ms /    26 tokens\n",
      "Llama.generate: 27 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     308.90 ms /     9 tokens (   34.32 ms per token,    29.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =     583.23 ms /    12 runs   (   48.60 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =     894.01 ms /    21 tokens\n",
      "Llama.generate: 29 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     260.16 ms /     8 tokens (   32.52 ms per token,    30.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =     634.59 ms /    13 runs   (   48.81 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =     896.77 ms /    21 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     746.82 ms /    23 tokens (   32.47 ms per token,    30.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =     581.04 ms /    12 runs   (   48.42 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    1329.61 ms /    35 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     530.14 ms /    18 tokens (   29.45 ms per token,    33.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =     788.25 ms /    16 runs   (   49.27 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    1320.78 ms /    34 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     530.36 ms /    16 tokens (   33.15 ms per token,    30.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =     536.42 ms /    11 runs   (   48.77 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    1068.44 ms /    27 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     969.03 ms /    25 tokens (   38.76 ms per token,    25.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =     749.00 ms /    15 runs   (   49.93 ms per token,    20.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    1720.39 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     770.48 ms /    17 tokens (   45.32 ms per token,    22.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1176.02 ms /    24 runs   (   49.00 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    1949.82 ms /    41 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1027.45 ms /    28 tokens (   36.69 ms per token,    27.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =     844.03 ms /    17 runs   (   49.65 ms per token,    20.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    1874.09 ms /    45 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     871.26 ms /    23 tokens (   37.88 ms per token,    26.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =     940.34 ms /    19 runs   (   49.49 ms per token,    20.21 tokens per second)\n",
      "llama_perf_context_print:       total time =    1814.45 ms /    42 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1074.02 ms /    31 tokens (   34.65 ms per token,    28.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1282.10 ms /    26 runs   (   49.31 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    2359.89 ms /    57 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1075.29 ms /    30 tokens (   35.84 ms per token,    27.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1148.85 ms /    23 runs   (   49.95 ms per token,    20.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    2227.56 ms /    53 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     857.42 ms /    28 tokens (   30.62 ms per token,    32.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =     638.94 ms /    13 runs   (   49.15 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    1498.38 ms /    41 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1634.12 ms /    31 tokens (   52.71 ms per token,    18.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1123.03 ms /    22 runs   (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    2760.60 ms /    53 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1860.86 ms /    35 tokens (   53.17 ms per token,    18.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =     893.68 ms /    18 runs   (   49.65 ms per token,    20.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    2757.45 ms /    53 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1737.05 ms /    33 tokens (   52.64 ms per token,    19.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1225.07 ms /    25 runs   (   49.00 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    2966.01 ms /    58 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1623.68 ms /    34 tokens (   47.76 ms per token,    20.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1022.61 ms /    21 runs   (   48.70 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    2649.46 ms /    55 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1793.26 ms /    33 tokens (   54.34 ms per token,    18.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1602.74 ms /    33 runs   (   48.57 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    3400.83 ms /    66 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1714.49 ms /    34 tokens (   50.43 ms per token,    19.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1284.71 ms /    26 runs   (   49.41 ms per token,    20.24 tokens per second)\n",
      "llama_perf_context_print:       total time =    3003.20 ms /    60 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     951.39 ms /    30 tokens (   31.71 ms per token,    31.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1465.35 ms /    30 runs   (   48.85 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    2420.98 ms /    60 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 82 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1881.32 ms /    82 tokens (   22.94 ms per token,    43.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3913.82 ms /    79 runs   (   49.54 ms per token,    20.18 tokens per second)\n",
      "llama_perf_context_print:       total time =    5807.43 ms /   161 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1797.00 ms /    65 tokens (   27.65 ms per token,    36.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2644.65 ms /    54 runs   (   48.98 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    4449.59 ms /   119 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1614.86 ms /    53 tokens (   30.47 ms per token,    32.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3092.54 ms /    63 runs   (   49.09 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    4716.86 ms /   116 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     636.58 ms /    21 tokens (   30.31 ms per token,    32.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =     839.64 ms /    17 runs   (   49.39 ms per token,    20.25 tokens per second)\n",
      "llama_perf_context_print:       total time =    1478.67 ms /    38 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     900.13 ms /    24 tokens (   37.51 ms per token,    26.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =     746.67 ms /    15 runs   (   49.78 ms per token,    20.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    1649.18 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1475.33 ms /    32 tokens (   46.10 ms per token,    21.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1122.44 ms /    23 runs   (   48.80 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    2601.09 ms /    55 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1038.05 ms /    27 tokens (   38.45 ms per token,    26.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =     797.88 ms /    15 runs   (   53.19 ms per token,    18.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1838.37 ms /    42 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1807.06 ms /    36 tokens (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =     834.37 ms /    17 runs   (   49.08 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    2644.10 ms /    53 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     752.31 ms /    24 tokens (   31.35 ms per token,    31.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =     585.42 ms /    12 runs   (   48.79 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    1339.67 ms /    36 tokens\n",
      "Llama.generate: 31 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     989.50 ms /    19 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =     889.23 ms /    16 runs   (   55.58 ms per token,    17.99 tokens per second)\n",
      "llama_perf_context_print:       total time =    1881.16 ms /    35 tokens\n",
      "Llama.generate: 32 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     726.54 ms /    14 tokens (   51.90 ms per token,    19.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =     735.15 ms /    15 runs   (   49.01 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    1464.02 ms /    29 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     772.58 ms /    24 tokens (   32.19 ms per token,    31.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =     834.29 ms /    17 runs   (   49.08 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    1609.45 ms /    41 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     697.56 ms /    20 tokens (   34.88 ms per token,    28.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =     689.60 ms /    14 runs   (   49.26 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    1389.21 ms /    34 tokens\n",
      "Llama.generate: 27 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     687.06 ms /    18 tokens (   38.17 ms per token,    26.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =     843.07 ms /    17 runs   (   49.59 ms per token,    20.16 tokens per second)\n",
      "llama_perf_context_print:       total time =    1532.75 ms /    35 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1655.56 ms /    33 tokens (   50.17 ms per token,    19.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1281.34 ms /    26 runs   (   49.28 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    2940.89 ms /    59 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     744.87 ms /    25 tokens (   29.79 ms per token,    33.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =     829.20 ms /    17 runs   (   48.78 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    1576.59 ms /    42 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1669.51 ms /    44 tokens (   37.94 ms per token,    26.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2988.69 ms /    39 runs   (   76.63 ms per token,    13.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    4664.29 ms /    83 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     793.49 ms /    23 tokens (   34.50 ms per token,    28.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =     729.48 ms /    15 runs   (   48.63 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    1525.13 ms /    38 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1599.61 ms /    36 tokens (   44.43 ms per token,    22.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1409.11 ms /    29 runs   (   48.59 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    3013.03 ms /    65 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1043.09 ms /    31 tokens (   33.65 ms per token,    29.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1322.80 ms /    27 runs   (   48.99 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    2369.82 ms /    58 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     651.24 ms /    21 tokens (   31.01 ms per token,    32.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =     821.68 ms /    17 runs   (   48.33 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1475.36 ms /    38 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     744.25 ms /    25 tokens (   29.77 ms per token,    33.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1281.73 ms /    26 runs   (   49.30 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    2029.66 ms /    51 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 144 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2264.94 ms /   144 tokens (   15.73 ms per token,    63.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3131.00 ms /    63 runs   (   49.70 ms per token,    20.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    5405.76 ms /   207 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 195 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2676.57 ms /   195 tokens (   13.73 ms per token,    72.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1692.34 ms /    34 runs   (   49.77 ms per token,    20.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    4374.34 ms /   229 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 125 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2128.46 ms /   125 tokens (   17.03 ms per token,    58.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2310.09 ms /    47 runs   (   49.15 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    4445.71 ms /   172 tokens\n",
      "Llama.generate: 127 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     477.43 ms /    14 tokens (   34.10 ms per token,    29.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2911.62 ms /    59 runs   (   49.35 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    3397.74 ms /    73 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 135 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2181.27 ms /   135 tokens (   16.16 ms per token,    61.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1319.36 ms /    27 runs   (   48.87 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    3504.98 ms /   162 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 146 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2273.38 ms /   146 tokens (   15.57 ms per token,    64.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3052.33 ms /    62 runs   (   49.23 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    5335.31 ms /   208 tokens\n",
      "Llama.generate: 136 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1651.64 ms /    47 tokens (   35.14 ms per token,    28.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3429.71 ms /    70 runs   (   49.00 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    5092.16 ms /   117 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 100 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2046.56 ms /   100 tokens (   20.47 ms per token,    48.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2012.11 ms /    41 runs   (   49.08 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    4064.71 ms /   141 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 132 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2289.16 ms /   132 tokens (   17.34 ms per token,    57.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2201.64 ms /    45 runs   (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    4497.60 ms /   177 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 102 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1981.83 ms /   102 tokens (   19.43 ms per token,    51.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2212.96 ms /    44 runs   (   50.29 ms per token,    19.88 tokens per second)\n",
      "llama_perf_context_print:       total time =    4201.30 ms /   146 tokens\n",
      "Llama.generate: 120 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1633.79 ms /    48 tokens (   34.04 ms per token,    29.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    7254.24 ms /   147 runs   (   49.35 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    8913.42 ms /   195 tokens\n",
      "Llama.generate: 100 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1668.19 ms /    52 tokens (   32.08 ms per token,    31.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6454.41 ms /   131 runs   (   49.27 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    8145.16 ms /   183 tokens\n",
      "Llama.generate: 88 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1628.05 ms /    47 tokens (   34.64 ms per token,    28.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2079.74 ms /    42 runs   (   49.52 ms per token,    20.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    3714.32 ms /    89 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1614.19 ms /    43 tokens (   37.54 ms per token,    26.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1111.33 ms /    23 runs   (   48.32 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    2728.94 ms /    66 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2040.79 ms /    66 tokens (   30.92 ms per token,    32.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1951.88 ms /    40 runs   (   48.80 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    3998.57 ms /   106 tokens\n",
      "Llama.generate: 80 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1671.05 ms /    37 tokens (   45.16 ms per token,    22.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2465.76 ms /    50 runs   (   49.32 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    4144.36 ms /    87 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     853.01 ms /    28 tokens (   30.46 ms per token,    32.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1453.74 ms /    30 runs   (   48.46 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    2311.00 ms /    58 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1691.31 ms /    50 tokens (   33.83 ms per token,    29.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1402.75 ms /    28 runs   (   50.10 ms per token,    19.96 tokens per second)\n",
      "llama_perf_context_print:       total time =    3098.45 ms /    78 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 116 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2010.09 ms /   116 tokens (   17.33 ms per token,    57.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2488.44 ms /    50 runs   (   49.77 ms per token,    20.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    4506.02 ms /   166 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 159 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2273.97 ms /   159 tokens (   14.30 ms per token,    69.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3539.03 ms /    72 runs   (   49.15 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    5824.34 ms /   231 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 129 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2173.39 ms /   129 tokens (   16.85 ms per token,    59.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2751.25 ms /    56 runs   (   49.13 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    4933.30 ms /   185 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     816.84 ms /    28 tokens (   29.17 ms per token,    34.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =     776.55 ms /    16 runs   (   48.53 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    1595.76 ms /    44 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1740.37 ms /    44 tokens (   39.55 ms per token,    25.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1471.54 ms /    30 runs   (   49.05 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    3216.69 ms /    74 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     879.41 ms /    30 tokens (   29.31 ms per token,    34.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =     874.95 ms /    18 runs   (   48.61 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    1756.96 ms /    48 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1669.58 ms /    45 tokens (   37.10 ms per token,    26.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1125.93 ms /    23 runs   (   48.95 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    2798.91 ms /    68 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     812.18 ms /    28 tokens (   29.01 ms per token,    34.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1124.68 ms /    23 runs   (   48.90 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    1940.24 ms /    51 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1638.82 ms /    47 tokens (   34.87 ms per token,    28.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1179.86 ms /    24 runs   (   49.16 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    2822.33 ms /    71 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     566.69 ms /    15 tokens (   37.78 ms per token,    26.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1125.03 ms /    23 runs   (   48.91 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    1695.08 ms /    38 tokens\n",
      "Llama.generate: 45 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2452.28 ms /    38 tokens (   64.53 ms per token,    15.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1427.12 ms /    29 runs   (   49.21 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    3883.72 ms /    67 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 157 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2329.86 ms /   157 tokens (   14.84 ms per token,    67.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3441.22 ms /    70 runs   (   49.16 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    5782.10 ms /   227 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 176 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2733.90 ms /   176 tokens (   15.53 ms per token,    64.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1716.24 ms /    35 runs   (   49.04 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    4455.42 ms /   211 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     847.46 ms /    28 tokens (   30.27 ms per token,    33.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =     775.99 ms /    16 runs   (   48.50 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    1625.87 ms /    44 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     893.06 ms /    31 tokens (   28.81 ms per token,    34.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1456.99 ms /    30 runs   (   48.57 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    2354.15 ms /    61 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1830.21 ms /    38 tokens (   48.16 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =     965.59 ms /    20 runs   (   48.28 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    2798.85 ms /    58 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     378.45 ms /    10 tokens (   37.84 ms per token,    26.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =     851.22 ms /    17 runs   (   50.07 ms per token,    19.97 tokens per second)\n",
      "llama_perf_context_print:       total time =    1232.29 ms /    27 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1777.81 ms /    62 tokens (   28.67 ms per token,    34.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1578.96 ms /    32 runs   (   49.34 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    3361.81 ms /    94 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 2 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 54 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1022.25 ms /    28 tokens (   36.51 ms per token,    27.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1769.04 ms /    34 runs   (   52.03 ms per token,    19.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    2796.90 ms /    62 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1707.86 ms /    42 tokens (   40.66 ms per token,    24.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =     970.32 ms /    20 runs   (   48.52 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    2681.30 ms /    62 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     830.15 ms /    27 tokens (   30.75 ms per token,    32.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =     966.97 ms /    20 runs   (   48.35 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1800.09 ms /    47 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     806.75 ms /    28 tokens (   28.81 ms per token,    34.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =     433.75 ms /     9 runs   (   48.19 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    1241.87 ms /    37 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     985.16 ms /    29 tokens (   33.97 ms per token,    29.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1015.05 ms /    21 runs   (   48.34 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    2003.09 ms /    50 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     323.28 ms /    10 tokens (   32.33 ms per token,    30.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1012.52 ms /    21 runs   (   48.22 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1338.72 ms /    31 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     890.88 ms /    23 tokens (   38.73 ms per token,    25.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =     818.92 ms /    17 runs   (   48.17 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1712.23 ms /    40 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     235.60 ms /     7 tokens (   33.66 ms per token,    29.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =     824.12 ms /    17 runs   (   48.48 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    1062.23 ms /    24 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     641.40 ms /    21 tokens (   30.54 ms per token,    32.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =     772.28 ms /    16 runs   (   48.27 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1416.10 ms /    37 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     271.44 ms /     8 tokens (   33.93 ms per token,    29.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =     935.47 ms /    19 runs   (   49.23 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    1209.58 ms /    27 tokens\n",
      "Llama.generate: 30 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     684.49 ms /    18 tokens (   38.03 ms per token,    26.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =     874.98 ms /    18 runs   (   48.61 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    1561.88 ms /    36 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     543.28 ms /    12 tokens (   45.27 ms per token,    22.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =     833.88 ms /    17 runs   (   49.05 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    1379.49 ms /    29 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     522.13 ms /    16 tokens (   32.63 ms per token,    30.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =     488.32 ms /    10 runs   (   48.83 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    1011.96 ms /    26 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     616.21 ms /    20 tokens (   30.81 ms per token,    32.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =     837.74 ms /    17 runs   (   49.28 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    1456.48 ms /    37 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     762.01 ms /    24 tokens (   31.75 ms per token,    31.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =     792.58 ms /    16 runs   (   49.54 ms per token,    20.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    1557.04 ms /    40 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     959.31 ms /    25 tokens (   38.37 ms per token,    26.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1041.60 ms /    21 runs   (   49.60 ms per token,    20.16 tokens per second)\n",
      "llama_perf_context_print:       total time =    2003.87 ms /    46 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     312.64 ms /     8 tokens (   39.08 ms per token,    25.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =     762.04 ms /    15 runs   (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1076.97 ms /    23 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     800.37 ms /    20 tokens (   40.02 ms per token,    24.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =     733.86 ms /    15 runs   (   48.92 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    1536.43 ms /    35 tokens\n",
      "Llama.generate: 31 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     302.70 ms /     9 tokens (   33.63 ms per token,    29.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =     953.24 ms /    19 runs   (   50.17 ms per token,    19.93 tokens per second)\n",
      "llama_perf_context_print:       total time =    1258.83 ms /    28 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1412.21 ms /    30 tokens (   47.07 ms per token,    21.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =     997.14 ms /    20 runs   (   49.86 ms per token,    20.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    2412.25 ms /    50 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     630.82 ms /    21 tokens (   30.04 ms per token,    33.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =     981.06 ms /    20 runs   (   49.05 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    1614.73 ms /    41 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     745.31 ms /    22 tokens (   33.88 ms per token,    29.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =     607.68 ms /    12 runs   (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    1354.93 ms /    34 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     685.11 ms /    21 tokens (   32.62 ms per token,    30.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =     750.76 ms /    14 runs   (   53.63 ms per token,    18.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    1437.96 ms /    35 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     755.21 ms /     7 tokens (  107.89 ms per token,     9.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =     746.60 ms /    14 runs   (   53.33 ms per token,    18.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    1504.02 ms /    21 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     868.26 ms /    21 tokens (   41.35 ms per token,    24.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =     786.05 ms /    16 runs   (   49.13 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    1656.77 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     624.63 ms /    16 tokens (   39.04 ms per token,    25.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =     498.04 ms /    10 runs   (   49.80 ms per token,    20.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    1124.33 ms /    26 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     901.24 ms /    25 tokens (   36.05 ms per token,    27.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =     757.71 ms /    15 runs   (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1661.17 ms /    40 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     656.35 ms /    16 tokens (   41.02 ms per token,    24.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =     593.57 ms /    12 runs   (   49.46 ms per token,    20.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    1251.84 ms /    28 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     672.68 ms /    20 tokens (   33.63 ms per token,    29.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =     787.31 ms /    15 runs   (   52.49 ms per token,    19.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    1462.31 ms /    35 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     598.34 ms /    16 tokens (   37.40 ms per token,    26.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =     492.44 ms /    10 runs   (   49.24 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    1092.35 ms /    26 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     809.51 ms /    21 tokens (   38.55 ms per token,    25.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =     692.52 ms /    14 runs   (   49.47 ms per token,    20.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    1504.25 ms /    35 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     625.50 ms /    18 tokens (   34.75 ms per token,    28.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =     591.16 ms /    12 runs   (   49.26 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    1218.66 ms /    30 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     551.96 ms /    17 tokens (   32.47 ms per token,    30.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =     686.98 ms /    14 runs   (   49.07 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    1241.03 ms /    31 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     689.92 ms /    20 tokens (   34.50 ms per token,    28.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =     808.00 ms /    16 runs   (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1500.45 ms /    36 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     757.82 ms /    21 tokens (   36.09 ms per token,    27.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1013.11 ms /    20 runs   (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1773.95 ms /    41 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     589.58 ms /    16 tokens (   36.85 ms per token,    27.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =     508.59 ms /    10 runs   (   50.86 ms per token,    19.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    1099.85 ms /    26 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     407.48 ms /    12 tokens (   33.96 ms per token,    29.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =     891.00 ms /    17 runs   (   52.41 ms per token,    19.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    1301.05 ms /    29 tokens\n",
      "Llama.generate: 30 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     301.82 ms /     8 tokens (   37.73 ms per token,    26.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =     916.08 ms /    18 runs   (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    1220.64 ms /    26 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     874.55 ms /    26 tokens (   33.64 ms per token,    29.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =     544.03 ms /    11 runs   (   49.46 ms per token,    20.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    1420.46 ms /    37 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     467.16 ms /     9 tokens (   51.91 ms per token,    19.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =     453.40 ms /     9 runs   (   50.38 ms per token,    19.85 tokens per second)\n",
      "llama_perf_context_print:       total time =     922.04 ms /    18 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     702.96 ms /    23 tokens (   30.56 ms per token,    32.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =     690.30 ms /    14 runs   (   49.31 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    1395.44 ms /    37 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     370.01 ms /     8 tokens (   46.25 ms per token,    21.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =     858.97 ms /    17 runs   (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    1231.52 ms /    25 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     281.59 ms /     8 tokens (   35.20 ms per token,    28.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =     607.83 ms /    12 runs   (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_perf_context_print:       total time =     891.44 ms /    20 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     836.46 ms /    22 tokens (   38.02 ms per token,    26.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =     940.70 ms /    19 runs   (   49.51 ms per token,    20.20 tokens per second)\n",
      "llama_perf_context_print:       total time =    1779.93 ms /    41 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     684.46 ms /    22 tokens (   31.11 ms per token,    32.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =     791.92 ms /    16 runs   (   49.49 ms per token,    20.20 tokens per second)\n",
      "llama_perf_context_print:       total time =    1478.75 ms /    38 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     685.69 ms /    18 tokens (   38.09 ms per token,    26.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =     784.26 ms /    16 runs   (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    1472.31 ms /    34 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     604.17 ms /    18 tokens (   33.57 ms per token,    29.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =     827.64 ms /    17 runs   (   48.69 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1434.25 ms /    35 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1005.53 ms /    26 tokens (   38.67 ms per token,    25.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =     982.22 ms /    20 runs   (   49.11 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    1990.68 ms /    46 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     311.04 ms /     9 tokens (   34.56 ms per token,    28.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =     853.32 ms /    17 runs   (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_perf_context_print:       total time =    1166.91 ms /    26 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     690.10 ms /    22 tokens (   31.37 ms per token,    31.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =     930.38 ms /    19 runs   (   48.97 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    1623.15 ms /    41 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     244.51 ms /     7 tokens (   34.93 ms per token,    28.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =     936.58 ms /    19 runs   (   49.29 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    1183.78 ms /    26 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     291.86 ms /     8 tokens (   36.48 ms per token,    27.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =     977.45 ms /    20 runs   (   48.87 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    1272.25 ms /    28 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     808.13 ms /    22 tokens (   36.73 ms per token,    27.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =     443.89 ms /     9 runs   (   49.32 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    1253.59 ms /    31 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     605.02 ms /    20 tokens (   30.25 ms per token,    33.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =     688.06 ms /    14 runs   (   49.15 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    1295.36 ms /    34 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     637.92 ms /    21 tokens (   30.38 ms per token,    32.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =     743.68 ms /    15 runs   (   49.58 ms per token,    20.17 tokens per second)\n",
      "llama_perf_context_print:       total time =    1383.83 ms /    36 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     689.99 ms /    23 tokens (   30.00 ms per token,    33.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =     539.93 ms /    11 runs   (   49.08 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    1231.72 ms /    34 tokens\n",
      "Llama.generate: 33 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     757.76 ms /    22 tokens (   34.44 ms per token,    29.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1261.02 ms /    26 runs   (   48.50 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    2022.52 ms /    48 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     635.71 ms /    18 tokens (   35.32 ms per token,    28.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =     875.35 ms /    18 runs   (   48.63 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    1513.68 ms /    36 tokens\n",
      "Llama.generate: 32 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     300.03 ms /     9 tokens (   33.34 ms per token,    30.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =     881.80 ms /    18 runs   (   48.99 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    1184.50 ms /    27 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     851.87 ms /    27 tokens (   31.55 ms per token,    31.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =     737.75 ms /    15 runs   (   49.18 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    1591.91 ms /    42 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1676.16 ms /    35 tokens (   47.89 ms per token,    20.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1402.06 ms /    29 runs   (   48.35 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    3082.46 ms /    64 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     840.61 ms /    29 tokens (   28.99 ms per token,    34.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1026.63 ms /    21 runs   (   48.89 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    1870.51 ms /    50 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     827.16 ms /    28 tokens (   29.54 ms per token,    33.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =     974.58 ms /    20 runs   (   48.73 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    1804.61 ms /    48 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     700.05 ms /    24 tokens (   29.17 ms per token,    34.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =     679.58 ms /    14 runs   (   48.54 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    1381.77 ms /    38 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     948.98 ms /    31 tokens (   30.61 ms per token,    32.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =     975.30 ms /    20 runs   (   48.77 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    1927.13 ms /    51 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     833.70 ms /    29 tokens (   28.75 ms per token,    34.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =     968.13 ms /    20 runs   (   48.41 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    1804.72 ms /    49 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     390.27 ms /    12 tokens (   32.52 ms per token,    30.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =     870.19 ms /    18 runs   (   48.34 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1262.95 ms /    30 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     646.39 ms /    21 tokens (   30.78 ms per token,    32.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =     723.53 ms /    15 runs   (   48.24 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1372.07 ms /    36 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1531.58 ms /    32 tokens (   47.86 ms per token,    20.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =     675.62 ms /    14 runs   (   48.26 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    2209.51 ms /    46 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     771.22 ms /    26 tokens (   29.66 ms per token,    33.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =     732.20 ms /    15 runs   (   48.81 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    1505.60 ms /    41 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     982.42 ms /    31 tokens (   31.69 ms per token,    31.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =     774.07 ms /    16 runs   (   48.38 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    1758.87 ms /    47 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1532.42 ms /    32 tokens (   47.89 ms per token,    20.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2131.96 ms /    44 runs   (   48.45 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    3670.77 ms /    76 tokens\n",
      "Llama.generate: 46 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     267.86 ms /     8 tokens (   33.48 ms per token,    29.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1357.01 ms /    28 runs   (   48.46 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    1628.80 ms /    36 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     937.87 ms /    30 tokens (   31.26 ms per token,    31.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =     726.88 ms /    15 runs   (   48.46 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    1666.99 ms /    45 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     865.78 ms /    29 tokens (   29.85 ms per token,    33.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1214.93 ms /    25 runs   (   48.60 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    2084.24 ms /    54 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     608.45 ms /    21 tokens (   28.97 ms per token,    34.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =     728.06 ms /    15 runs   (   48.54 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    1338.84 ms /    36 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     917.34 ms /    30 tokens (   30.58 ms per token,    32.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =     627.02 ms /    13 runs   (   48.23 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1546.39 ms /    43 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1704.47 ms /    38 tokens (   44.85 ms per token,    22.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1256.08 ms /    26 runs   (   48.31 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    2964.26 ms /    64 tokens\n",
      "Llama.generate: 47 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     538.58 ms /    17 tokens (   31.68 ms per token,    31.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1941.60 ms /    40 runs   (   48.54 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    2485.95 ms /    57 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     527.61 ms /    16 tokens (   32.98 ms per token,    30.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1418.59 ms /    29 runs   (   48.92 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    1950.26 ms /    45 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1662.41 ms /    48 tokens (   34.63 ms per token,    28.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1477.80 ms /    30 runs   (   49.26 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    3144.68 ms /    78 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     887.13 ms /    31 tokens (   28.62 ms per token,    34.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1319.55 ms /    27 runs   (   48.87 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    2210.37 ms /    58 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     786.47 ms /    27 tokens (   29.13 ms per token,    34.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =     770.95 ms /    16 runs   (   48.18 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    1559.66 ms /    43 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     383.07 ms /    12 tokens (   31.92 ms per token,    31.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =     876.27 ms /    18 runs   (   48.68 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1262.02 ms /    30 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     826.75 ms /    28 tokens (   29.53 ms per token,    33.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1211.89 ms /    25 runs   (   48.48 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    2042.19 ms /    53 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     726.14 ms /    24 tokens (   30.26 ms per token,    33.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =     386.65 ms /     8 runs   (   48.33 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1114.23 ms /    32 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     332.93 ms /    10 tokens (   33.29 ms per token,    30.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =     533.79 ms /    11 runs   (   48.53 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =     868.36 ms /    21 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1681.74 ms /    40 tokens (   42.04 ms per token,    23.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1904.38 ms /    39 runs   (   48.83 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    3591.74 ms /    79 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     951.10 ms /    31 tokens (   30.68 ms per token,    32.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =     822.30 ms /    17 runs   (   48.37 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    1775.95 ms /    48 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1753.70 ms /    60 tokens (   29.23 ms per token,    34.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2943.16 ms /    60 runs   (   49.05 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    4705.70 ms /   120 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     662.56 ms /    22 tokens (   30.12 ms per token,    33.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =     730.83 ms /    15 runs   (   48.72 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    1395.70 ms /    37 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1642.15 ms /    41 tokens (   40.05 ms per token,    24.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1847.62 ms /    38 runs   (   48.62 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    3495.43 ms /    79 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 91 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1948.35 ms /    91 tokens (   21.41 ms per token,    46.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2512.00 ms /    51 runs   (   49.25 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    4468.07 ms /   142 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     630.49 ms /    21 tokens (   30.02 ms per token,    33.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =     531.90 ms /    11 runs   (   48.35 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1164.05 ms /    32 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     644.52 ms /    22 tokens (   29.30 ms per token,    34.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =     828.83 ms /    17 runs   (   48.75 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    1475.84 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1477.27 ms /    32 tokens (   46.16 ms per token,    21.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1184.69 ms /    24 runs   (   49.36 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    2665.50 ms /    56 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     870.30 ms /    30 tokens (   29.01 ms per token,    34.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1115.14 ms /    23 runs   (   48.48 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    1988.94 ms /    53 tokens\n",
      "Llama.generate: 33 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     678.37 ms /    21 tokens (   32.30 ms per token,    30.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1039.66 ms /    21 runs   (   49.51 ms per token,    20.20 tokens per second)\n",
      "llama_perf_context_print:       total time =    1721.05 ms /    42 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     774.73 ms /    25 tokens (   30.99 ms per token,    32.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =     722.45 ms /    15 runs   (   48.16 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1499.30 ms /    40 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     846.41 ms /    29 tokens (   29.19 ms per token,    34.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =     870.58 ms /    18 runs   (   48.37 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1719.49 ms /    47 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 3 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     865.19 ms /    30 tokens (   28.84 ms per token,    34.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1310.32 ms /    27 runs   (   48.53 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    2180.32 ms /    57 tokens\n",
      "Llama.generate: 31 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     779.58 ms /    19 tokens (   41.03 ms per token,    24.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =     820.10 ms /    17 runs   (   48.24 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1602.17 ms /    36 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     748.37 ms /    27 tokens (   27.72 ms per token,    36.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =     903.44 ms /    18 runs   (   50.19 ms per token,    19.92 tokens per second)\n",
      "llama_perf_context_print:       total time =    1654.52 ms /    45 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     770.95 ms /    25 tokens (   30.84 ms per token,    32.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =     999.21 ms /    20 runs   (   49.96 ms per token,    20.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    1773.15 ms /    45 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     749.72 ms /    24 tokens (   31.24 ms per token,    32.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =     626.57 ms /    13 runs   (   48.20 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    1378.33 ms /    37 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     842.45 ms /    27 tokens (   31.20 ms per token,    32.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1063.61 ms /    22 runs   (   48.35 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1909.15 ms /    49 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     302.99 ms /     9 tokens (   33.67 ms per token,    29.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1194.59 ms /    24 runs   (   49.77 ms per token,    20.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    1500.97 ms /    33 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     893.03 ms /    27 tokens (   33.08 ms per token,    30.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =     923.85 ms /    19 runs   (   48.62 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    1819.75 ms /    46 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     769.92 ms /    23 tokens (   33.47 ms per token,    29.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =     675.74 ms /    14 runs   (   48.27 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1447.71 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     663.48 ms /    23 tokens (   28.85 ms per token,    34.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =     580.18 ms /    12 runs   (   48.35 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1245.49 ms /    35 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1144.05 ms /    29 tokens (   39.45 ms per token,    25.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =     673.25 ms /    14 runs   (   48.09 ms per token,    20.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    1819.41 ms /    43 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     777.14 ms /    26 tokens (   29.89 ms per token,    33.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =     817.97 ms /    17 runs   (   48.12 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1597.58 ms /    43 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     259.46 ms /     8 tokens (   32.43 ms per token,    30.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =     962.67 ms /    20 runs   (   48.13 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1224.96 ms /    28 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     795.86 ms /    27 tokens (   29.48 ms per token,    33.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =     789.65 ms /    16 runs   (   49.35 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    1587.81 ms /    43 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1705.83 ms /    34 tokens (   50.17 ms per token,    19.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =     821.48 ms /    17 runs   (   48.32 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    2530.17 ms /    51 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     815.63 ms /    28 tokens (   29.13 ms per token,    34.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1028.48 ms /    21 runs   (   48.98 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    1847.22 ms /    49 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     955.95 ms /    31 tokens (   30.84 ms per token,    32.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =     775.62 ms /    16 runs   (   48.48 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    1733.97 ms /    47 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1552.90 ms /    32 tokens (   48.53 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1171.08 ms /    24 runs   (   48.80 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    2727.67 ms /    56 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     710.79 ms /    23 tokens (   30.90 ms per token,    32.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =     975.52 ms /    20 runs   (   48.78 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    1689.26 ms /    43 tokens\n",
      "Llama.generate: 26 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     377.68 ms /    11 tokens (   34.33 ms per token,    29.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =     532.48 ms /    11 runs   (   48.41 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =     911.87 ms /    22 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     856.23 ms /    26 tokens (   32.93 ms per token,    30.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =     969.14 ms /    20 runs   (   48.46 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    1828.20 ms /    46 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     798.92 ms /    26 tokens (   30.73 ms per token,    32.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1123.07 ms /    23 runs   (   48.83 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    1925.22 ms /    49 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     775.86 ms /    24 tokens (   32.33 ms per token,    30.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =     783.41 ms /    16 runs   (   48.96 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    1561.70 ms /    40 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     891.43 ms /    30 tokens (   29.71 ms per token,    33.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1027.87 ms /    21 runs   (   48.95 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    1922.24 ms /    51 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     246.97 ms /     7 tokens (   35.28 ms per token,    28.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =     585.02 ms /    12 runs   (   48.75 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =     833.81 ms /    19 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1512.42 ms /    32 tokens (   47.26 ms per token,    21.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1561.58 ms /    32 runs   (   48.80 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    3078.52 ms /    64 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     715.92 ms /    24 tokens (   29.83 ms per token,    33.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1339.61 ms /    27 runs   (   49.62 ms per token,    20.16 tokens per second)\n",
      "llama_perf_context_print:       total time =    2059.39 ms /    51 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     846.61 ms /    28 tokens (   30.24 ms per token,    33.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =     887.98 ms /    18 runs   (   49.33 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    1737.24 ms /    46 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1779.42 ms /    67 tokens (   26.56 ms per token,    37.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3313.23 ms /    67 runs   (   49.45 ms per token,    20.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    5102.83 ms /   134 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1799.40 ms /    67 tokens (   26.86 ms per token,    37.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2871.40 ms /    58 runs   (   49.51 ms per token,    20.20 tokens per second)\n",
      "llama_perf_context_print:       total time =    4679.33 ms /   125 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1874.94 ms /    65 tokens (   28.85 ms per token,    34.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2640.33 ms /    54 runs   (   48.89 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    4523.32 ms /   119 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1930.05 ms /    69 tokens (   27.97 ms per token,    35.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2884.40 ms /    59 runs   (   48.89 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    4823.10 ms /   128 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     749.12 ms /    23 tokens (   32.57 ms per token,    30.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1087.56 ms /    22 runs   (   49.43 ms per token,    20.23 tokens per second)\n",
      "llama_perf_context_print:       total time =    1839.96 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1589.10 ms /    34 tokens (   46.74 ms per token,    21.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1465.51 ms /    30 runs   (   48.85 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    3059.11 ms /    64 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     945.42 ms /    27 tokens (   35.02 ms per token,    28.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1097.75 ms /    22 runs   (   49.90 ms per token,    20.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    2046.31 ms /    49 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     769.91 ms /    25 tokens (   30.80 ms per token,    32.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1145.17 ms /    23 runs   (   49.79 ms per token,    20.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    1918.55 ms /    48 tokens\n",
      "Llama.generate: 33 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     633.59 ms /    18 tokens (   35.20 ms per token,    28.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =     489.71 ms /    10 runs   (   48.97 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    1124.95 ms /    28 tokens\n",
      "Llama.generate: 45 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     557.10 ms /    11 tokens (   50.65 ms per token,    19.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =     833.45 ms /    17 runs   (   49.03 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    1393.07 ms /    28 tokens\n",
      "Llama.generate: 30 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     612.57 ms /    17 tokens (   36.03 ms per token,    27.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =     882.33 ms /    18 runs   (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    1497.62 ms /    35 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     896.13 ms /    30 tokens (   29.87 ms per token,    33.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =     882.87 ms /    18 runs   (   49.05 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    1781.61 ms /    48 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1482.00 ms /    32 tokens (   46.31 ms per token,    21.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =     876.05 ms /    18 runs   (   48.67 ms per token,    20.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    2360.74 ms /    50 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1665.37 ms /    40 tokens (   41.63 ms per token,    24.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1610.38 ms /    33 runs   (   48.80 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    3280.61 ms /    73 tokens\n",
      "Llama.generate: 45 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     291.73 ms /     9 tokens (   32.41 ms per token,    30.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1310.06 ms /    27 runs   (   48.52 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    1605.54 ms /    36 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1656.03 ms /    45 tokens (   36.80 ms per token,    27.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1796.02 ms /    37 runs   (   48.54 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    3457.53 ms /    82 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     832.64 ms /    28 tokens (   29.74 ms per token,    33.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1072.48 ms /    22 runs   (   48.75 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    1908.32 ms /    50 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     784.53 ms /    25 tokens (   31.38 ms per token,    31.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1321.77 ms /    27 runs   (   48.95 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    2110.20 ms /    52 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1613.50 ms /    44 tokens (   36.67 ms per token,    27.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1555.30 ms /    32 runs   (   48.60 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    3173.45 ms /    76 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     648.91 ms /    19 tokens (   34.15 ms per token,    29.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =     627.25 ms /    13 runs   (   48.25 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1278.22 ms /    32 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     794.48 ms /    28 tokens (   28.37 ms per token,    35.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =     868.57 ms /    18 runs   (   48.25 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1665.76 ms /    46 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     862.19 ms /    29 tokens (   29.73 ms per token,    33.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1066.47 ms /    22 runs   (   48.48 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    1931.94 ms /    51 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1067.40 ms /    28 tokens (   38.12 ms per token,    26.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1166.43 ms /    24 runs   (   48.60 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    2237.38 ms /    52 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     829.29 ms /    29 tokens (   28.60 ms per token,    34.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1111.83 ms /    23 runs   (   48.34 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1944.40 ms /    52 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1587.85 ms /    35 tokens (   45.37 ms per token,    22.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1210.77 ms /    25 runs   (   48.43 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    2802.31 ms /    60 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     876.82 ms /    29 tokens (   30.24 ms per token,    33.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1217.11 ms /    25 runs   (   48.68 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    2097.40 ms /    54 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1599.29 ms /    39 tokens (   41.01 ms per token,    24.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1481.27 ms /    30 runs   (   49.38 ms per token,    20.25 tokens per second)\n",
      "llama_perf_context_print:       total time =    3085.04 ms /    69 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1702.84 ms /    48 tokens (   35.48 ms per token,    28.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2180.74 ms /    45 runs   (   48.46 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    3889.96 ms /    93 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     908.98 ms /    29 tokens (   31.34 ms per token,    31.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1215.22 ms /    25 runs   (   48.61 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    2127.67 ms /    54 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1584.75 ms /    33 tokens (   48.02 ms per token,    20.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1494.19 ms /    31 runs   (   48.20 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    3083.60 ms /    64 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     612.86 ms /    17 tokens (   36.05 ms per token,    27.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =     771.29 ms /    16 runs   (   48.21 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1386.52 ms /    33 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1604.57 ms /    36 tokens (   44.57 ms per token,    22.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2082.97 ms /    43 runs   (   48.44 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    3693.85 ms /    79 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     873.01 ms /    28 tokens (   31.18 ms per token,    32.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =     965.10 ms /    20 runs   (   48.25 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1841.04 ms /    48 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     767.98 ms /    26 tokens (   29.54 ms per token,    33.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =     672.55 ms /    14 runs   (   48.04 ms per token,    20.82 tokens per second)\n",
      "llama_perf_context_print:       total time =    1442.54 ms /    40 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     499.69 ms /    16 tokens (   31.23 ms per token,    32.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =     723.44 ms /    15 runs   (   48.23 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1225.51 ms /    31 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1670.98 ms /    35 tokens (   47.74 ms per token,    20.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1350.70 ms /    28 runs   (   48.24 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    3026.08 ms /    63 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1454.28 ms /    32 tokens (   45.45 ms per token,    22.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1011.66 ms /    21 runs   (   48.17 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    2469.21 ms /    53 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     707.94 ms /    24 tokens (   29.50 ms per token,    33.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =     734.99 ms /    15 runs   (   49.00 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    1445.27 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     783.60 ms /    27 tokens (   29.02 ms per token,    34.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1011.50 ms /    21 runs   (   48.17 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1798.08 ms /    48 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     410.58 ms /    12 tokens (   34.22 ms per token,    29.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =     770.24 ms /    16 runs   (   48.14 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    1183.03 ms /    28 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     780.48 ms /    27 tokens (   28.91 ms per token,    34.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =     926.14 ms /    19 runs   (   48.74 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    1709.38 ms /    46 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     666.07 ms /    21 tokens (   31.72 ms per token,    31.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =     818.41 ms /    17 runs   (   48.14 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    1486.88 ms /    38 tokens\n",
      "Llama.generate: 31 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     790.17 ms /    27 tokens (   29.27 ms per token,    34.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1253.35 ms /    26 runs   (   48.21 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    2047.18 ms /    53 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     842.04 ms /    29 tokens (   29.04 ms per token,    34.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1131.94 ms /    23 runs   (   49.21 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    1977.19 ms /    52 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     807.57 ms /    27 tokens (   29.91 ms per token,    33.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =     966.30 ms /    20 runs   (   48.32 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1776.76 ms /    47 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     835.47 ms /    28 tokens (   29.84 ms per token,    33.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =     819.26 ms /    17 runs   (   48.19 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    1657.12 ms /    45 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     931.87 ms /    31 tokens (   30.06 ms per token,    33.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1222.71 ms /    25 runs   (   48.91 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    2158.11 ms /    56 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1608.49 ms /    33 tokens (   48.74 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1594.72 ms /    33 runs   (   48.32 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    3208.00 ms /    66 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1641.77 ms /    37 tokens (   44.37 ms per token,    22.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1501.81 ms /    31 runs   (   48.45 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    3148.18 ms /    68 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1610.03 ms /    37 tokens (   43.51 ms per token,    22.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1554.08 ms /    32 runs   (   48.56 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    3168.65 ms /    69 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     902.31 ms /    29 tokens (   31.11 ms per token,    32.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =     818.16 ms /    17 runs   (   48.13 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1723.00 ms /    46 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1595.19 ms /    34 tokens (   46.92 ms per token,    21.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1355.42 ms /    28 runs   (   48.41 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    2954.73 ms /    62 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1676.13 ms /    54 tokens (   31.04 ms per token,    32.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2854.95 ms /    59 runs   (   48.39 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    4539.69 ms /   113 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1704.22 ms /    33 tokens (   51.64 ms per token,    19.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =     868.11 ms /    18 runs   (   48.23 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    2575.03 ms /    51 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1619.21 ms /    45 tokens (   35.98 ms per token,    27.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2177.63 ms /    45 runs   (   48.39 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    3803.42 ms /    90 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     964.72 ms /    26 tokens (   37.10 ms per token,    26.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =     912.22 ms /    19 runs   (   48.01 ms per token,    20.83 tokens per second)\n",
      "llama_perf_context_print:       total time =    1879.64 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1635.59 ms /    36 tokens (   45.43 ms per token,    22.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =     926.89 ms /    19 runs   (   48.78 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    2565.29 ms /    55 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1528.90 ms /    32 tokens (   47.78 ms per token,    20.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1397.13 ms /    29 runs   (   48.18 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    2930.33 ms /    61 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     736.40 ms /    24 tokens (   30.68 ms per token,    32.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =     720.66 ms /    15 runs   (   48.04 ms per token,    20.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    1459.19 ms /    39 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     663.30 ms /    22 tokens (   30.15 ms per token,    33.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =     770.38 ms /    16 runs   (   48.15 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    1436.11 ms /    38 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     796.19 ms /    25 tokens (   31.85 ms per token,    31.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =     867.69 ms /    18 runs   (   48.21 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1666.41 ms /    43 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     337.65 ms /     8 tokens (   42.21 ms per token,    23.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =     773.33 ms /    16 runs   (   48.33 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1113.15 ms /    24 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     891.68 ms /    22 tokens (   40.53 ms per token,    24.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =     585.47 ms /    12 runs   (   48.79 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    1479.05 ms /    34 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     686.32 ms /    23 tokens (   29.84 ms per token,    33.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =     770.56 ms /    16 runs   (   48.16 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1459.23 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     970.46 ms /    31 tokens (   31.31 ms per token,    31.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1014.35 ms /    21 runs   (   48.30 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1987.85 ms /    52 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     908.34 ms /    29 tokens (   31.32 ms per token,    31.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =     771.25 ms /    16 runs   (   48.20 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    1682.00 ms /    45 tokens\n",
      "Llama.generate: 32 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     290.11 ms /     8 tokens (   36.26 ms per token,    27.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1110.42 ms /    23 runs   (   48.28 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1403.78 ms /    31 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     917.07 ms /    28 tokens (   32.75 ms per token,    30.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =     724.14 ms /    15 runs   (   48.28 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1643.48 ms /    43 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     755.62 ms /    24 tokens (   31.48 ms per token,    31.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =     776.74 ms /    16 runs   (   48.55 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    1534.57 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     659.14 ms /    18 tokens (   36.62 ms per token,    27.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =     630.24 ms /    13 runs   (   48.48 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    1291.26 ms /    31 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1641.10 ms /    45 tokens (   36.47 ms per token,    27.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1402.23 ms /    29 runs   (   48.35 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    3047.85 ms /    74 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     598.45 ms /    19 tokens (   31.50 ms per token,    31.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =     878.47 ms /    18 runs   (   48.80 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    1479.47 ms /    37 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 4 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     897.36 ms /    30 tokens (   29.91 ms per token,    33.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1159.29 ms /    24 runs   (   48.30 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    2061.19 ms /    54 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     878.91 ms /    28 tokens (   31.39 ms per token,    31.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1075.71 ms /    22 runs   (   48.90 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    1957.63 ms /    50 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     522.38 ms /    18 tokens (   29.02 ms per token,    34.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1010.66 ms /    21 runs   (   48.13 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1536.02 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1566.20 ms /    33 tokens (   47.46 ms per token,    21.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1209.17 ms /    25 runs   (   48.37 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    2779.11 ms /    58 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     762.08 ms /    27 tokens (   28.23 ms per token,    35.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1541.63 ms /    32 runs   (   48.18 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    2308.20 ms /    59 tokens\n",
      "Llama.generate: 29 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     408.70 ms /    13 tokens (   31.44 ms per token,    31.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1057.37 ms /    22 runs   (   48.06 ms per token,    20.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    1469.04 ms /    35 tokens\n",
      "Llama.generate: 28 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     342.23 ms /    11 tokens (   31.11 ms per token,    32.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =     629.67 ms /    13 runs   (   48.44 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =     973.76 ms /    24 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     954.59 ms /    30 tokens (   31.82 ms per token,    31.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =     964.19 ms /    20 runs   (   48.21 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1921.58 ms /    50 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     917.30 ms /    30 tokens (   30.58 ms per token,    32.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1253.14 ms /    26 runs   (   48.20 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    2174.06 ms /    56 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     699.21 ms /    24 tokens (   29.13 ms per token,    34.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =     771.96 ms /    16 runs   (   48.25 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1473.52 ms /    40 tokens\n",
      "Llama.generate: 29 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     456.00 ms /    15 tokens (   30.40 ms per token,    32.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1206.33 ms /    25 runs   (   48.25 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1665.72 ms /    40 tokens\n",
      "Llama.generate: 29 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     416.55 ms /    13 tokens (   32.04 ms per token,    31.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =     866.68 ms /    18 runs   (   48.15 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    1285.80 ms /    31 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     896.87 ms /    31 tokens (   28.93 ms per token,    34.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1162.59 ms /    24 runs   (   48.44 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    2062.76 ms /    55 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     861.18 ms /    29 tokens (   29.70 ms per token,    33.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1112.09 ms /    23 runs   (   48.35 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1976.51 ms /    52 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     836.12 ms /    28 tokens (   29.86 ms per token,    33.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1017.03 ms /    21 runs   (   48.43 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    1856.04 ms /    49 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     896.59 ms /    30 tokens (   29.89 ms per token,    33.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1180.02 ms /    24 runs   (   49.17 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    2080.03 ms /    54 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1454.29 ms /    32 tokens (   45.45 ms per token,    22.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =     964.90 ms /    20 runs   (   48.24 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    2422.01 ms /    52 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     767.12 ms /    26 tokens (   29.50 ms per token,    33.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1164.03 ms /    24 runs   (   48.50 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    1934.63 ms /    50 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     837.62 ms /    27 tokens (   31.02 ms per token,    32.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1021.42 ms /    21 runs   (   48.64 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    1862.06 ms /    48 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     863.59 ms /    29 tokens (   29.78 ms per token,    33.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =     925.49 ms /    19 runs   (   48.71 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    1791.97 ms /    48 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     774.83 ms /    26 tokens (   29.80 ms per token,    33.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1124.51 ms /    23 runs   (   48.89 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    1902.77 ms /    49 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     941.95 ms /    25 tokens (   37.68 ms per token,    26.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1368.59 ms /    28 runs   (   48.88 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    2314.49 ms /    53 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     884.03 ms /    27 tokens (   32.74 ms per token,    30.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1034.01 ms /    21 runs   (   49.24 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    1921.08 ms /    48 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     597.79 ms /    19 tokens (   31.46 ms per token,    31.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1092.14 ms /    22 runs   (   49.64 ms per token,    20.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    1693.15 ms /    41 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     849.67 ms /    28 tokens (   30.35 ms per token,    32.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1227.47 ms /    25 runs   (   49.10 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    2080.78 ms /    53 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     917.94 ms /    25 tokens (   36.72 ms per token,    27.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1080.29 ms /    22 runs   (   49.10 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    2001.37 ms /    47 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1057.19 ms /    29 tokens (   36.45 ms per token,    27.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =     884.09 ms /    18 runs   (   49.12 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    1943.82 ms /    47 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     934.80 ms /    25 tokens (   37.39 ms per token,    26.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =     933.85 ms /    19 runs   (   49.15 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    1871.38 ms /    44 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1040.85 ms /    28 tokens (   37.17 ms per token,    26.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1275.96 ms /    26 runs   (   49.08 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    2320.69 ms /    54 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     741.55 ms /    22 tokens (   33.71 ms per token,    29.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =     924.07 ms /    19 runs   (   48.64 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    1668.25 ms /    41 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1591.84 ms /    32 tokens (   49.75 ms per token,    20.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1315.88 ms /    27 runs   (   48.74 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    2911.70 ms /    59 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     860.48 ms /    27 tokens (   31.87 ms per token,    31.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1073.18 ms /    22 runs   (   48.78 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    1936.87 ms /    49 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1505.17 ms /    32 tokens (   47.04 ms per token,    21.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1765.17 ms /    36 runs   (   49.03 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    3275.70 ms /    68 tokens\n",
      "Llama.generate: 46 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     410.29 ms /     9 tokens (   45.59 ms per token,    21.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1371.03 ms /    28 runs   (   48.97 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    1785.32 ms /    37 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     910.89 ms /    30 tokens (   30.36 ms per token,    32.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1214.02 ms /    25 runs   (   48.56 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    2128.41 ms /    55 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1667.98 ms /    35 tokens (   47.66 ms per token,    20.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1706.74 ms /    35 runs   (   48.76 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    3380.05 ms /    70 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     831.98 ms /    28 tokens (   29.71 ms per token,    33.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1421.47 ms /    29 runs   (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    2257.55 ms /    57 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1530.53 ms /    32 tokens (   47.83 ms per token,    20.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1305.67 ms /    27 runs   (   48.36 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    2840.11 ms /    59 tokens\n",
      "Llama.generate: 45 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     356.06 ms /    11 tokens (   32.37 ms per token,    30.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1462.77 ms /    30 runs   (   48.76 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    1823.14 ms /    41 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     867.54 ms /    27 tokens (   32.13 ms per token,    31.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =     966.51 ms /    20 runs   (   48.33 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1836.91 ms /    47 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     904.11 ms /    23 tokens (   39.31 ms per token,    25.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1254.66 ms /    26 runs   (   48.26 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    2162.56 ms /    49 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1661.00 ms /    34 tokens (   48.85 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1307.48 ms /    27 runs   (   48.43 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    2972.42 ms /    61 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     715.63 ms /    20 tokens (   35.78 ms per token,    27.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =     773.20 ms /    16 runs   (   48.33 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1491.38 ms /    36 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     656.91 ms /    20 tokens (   32.85 ms per token,    30.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =     681.59 ms /    14 runs   (   48.68 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1340.56 ms /    34 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     923.08 ms /    29 tokens (   31.83 ms per token,    31.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =     773.27 ms /    16 runs   (   48.33 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1698.77 ms /    45 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     723.33 ms /    23 tokens (   31.45 ms per token,    31.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =     784.43 ms /    16 runs   (   49.03 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    1510.16 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     608.73 ms /    21 tokens (   28.99 ms per token,    34.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =     830.10 ms /    17 runs   (   48.83 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    1441.40 ms /    38 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1097.39 ms /    30 tokens (   36.58 ms per token,    27.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1035.88 ms /    21 runs   (   49.33 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    2136.37 ms /    51 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     761.97 ms /    25 tokens (   30.48 ms per token,    32.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =     879.84 ms /    18 runs   (   48.88 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    1644.32 ms /    43 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     272.24 ms /     8 tokens (   34.03 ms per token,    29.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1062.70 ms /    22 runs   (   48.30 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1337.99 ms /    30 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     908.07 ms /    26 tokens (   34.93 ms per token,    28.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =     923.45 ms /    19 runs   (   48.60 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    1834.21 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     805.48 ms /    23 tokens (   35.02 ms per token,    28.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1027.29 ms /    21 runs   (   48.92 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    1835.81 ms /    44 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1480.76 ms /    32 tokens (   46.27 ms per token,    21.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1126.05 ms /    23 runs   (   48.96 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    2610.20 ms /    55 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     594.19 ms /    20 tokens (   29.71 ms per token,    33.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =     977.33 ms /    20 runs   (   48.87 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    1574.44 ms /    40 tokens\n",
      "Llama.generate: 30 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     528.30 ms /    13 tokens (   40.64 ms per token,    24.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1166.98 ms /    24 runs   (   48.62 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    1698.63 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1605.03 ms /    36 tokens (   44.58 ms per token,    22.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1254.61 ms /    26 runs   (   48.25 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    2863.60 ms /    62 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     682.60 ms /    23 tokens (   29.68 ms per token,    33.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =     674.23 ms /    14 runs   (   48.16 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1358.76 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1080.78 ms /    27 tokens (   40.03 ms per token,    24.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2198.80 ms /    45 runs   (   48.86 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    3285.92 ms /    72 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1474.64 ms /    32 tokens (   46.08 ms per token,    21.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1169.57 ms /    24 runs   (   48.73 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    2648.03 ms /    56 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     772.25 ms /    26 tokens (   29.70 ms per token,    33.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1025.39 ms /    21 runs   (   48.83 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    1800.69 ms /    47 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     670.26 ms /    23 tokens (   29.14 ms per token,    34.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1071.10 ms /    22 runs   (   48.69 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1744.55 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1673.40 ms /    40 tokens (   41.84 ms per token,    23.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1103.89 ms /    22 runs   (   50.18 ms per token,    19.93 tokens per second)\n",
      "llama_perf_context_print:       total time =    2780.89 ms /    62 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1840.76 ms /    34 tokens (   54.14 ms per token,    18.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1559.08 ms /    32 runs   (   48.72 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    3404.69 ms /    66 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1089.56 ms /    25 tokens (   43.58 ms per token,    22.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1067.09 ms /    22 runs   (   48.50 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    2159.77 ms /    47 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     415.93 ms /     9 tokens (   46.21 ms per token,    21.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1262.44 ms /    26 runs   (   48.56 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    1682.02 ms /    35 tokens\n",
      "Llama.generate: 28 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     583.54 ms /    14 tokens (   41.68 ms per token,    23.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =     825.70 ms /    17 runs   (   48.57 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    1411.73 ms /    31 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1053.21 ms /    27 tokens (   39.01 ms per token,    25.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =     630.14 ms /    13 runs   (   48.47 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    1685.37 ms /    40 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1051.40 ms /    27 tokens (   38.94 ms per token,    25.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1164.73 ms /    24 runs   (   48.53 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    2219.42 ms /    51 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     643.07 ms /    16 tokens (   40.19 ms per token,    24.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1306.71 ms /    27 runs   (   48.40 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    1953.47 ms /    43 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     901.63 ms /    23 tokens (   39.20 ms per token,    25.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =     820.70 ms /    17 runs   (   48.28 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1724.86 ms /    40 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     904.07 ms /    20 tokens (   45.20 ms per token,    22.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =     674.27 ms /    14 runs   (   48.16 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1580.35 ms /    34 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     412.49 ms /     7 tokens (   58.93 ms per token,    16.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =     692.85 ms /    13 runs   (   53.30 ms per token,    18.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1107.37 ms /    20 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1137.85 ms /    24 tokens (   47.41 ms per token,    21.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1015.56 ms /    21 runs   (   48.36 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    2156.20 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     839.94 ms /    21 tokens (   40.00 ms per token,    25.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =     968.22 ms /    20 runs   (   48.41 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    1811.03 ms /    41 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     982.42 ms /    26 tokens (   37.79 ms per token,    26.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =     917.14 ms /    19 runs   (   48.27 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1902.29 ms /    45 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     996.04 ms /    24 tokens (   41.50 ms per token,    24.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =     929.53 ms /    19 runs   (   48.92 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    1928.28 ms /    43 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     782.14 ms /    21 tokens (   37.24 ms per token,    26.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =     866.18 ms /    18 runs   (   48.12 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1650.98 ms /    39 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     478.75 ms /    11 tokens (   43.52 ms per token,    22.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =     842.41 ms /    17 runs   (   49.55 ms per token,    20.18 tokens per second)\n",
      "llama_perf_context_print:       total time =    1323.60 ms /    28 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     692.62 ms /    19 tokens (   36.45 ms per token,    27.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =     593.63 ms /    12 runs   (   49.47 ms per token,    20.21 tokens per second)\n",
      "llama_perf_context_print:       total time =    1287.94 ms /    31 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1069.14 ms /    25 tokens (   42.77 ms per token,    23.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =     730.33 ms /    15 runs   (   48.69 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1801.71 ms /    40 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     974.06 ms /    27 tokens (   36.08 ms per token,    27.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1129.40 ms /    23 runs   (   49.10 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    2106.77 ms /    50 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     861.89 ms /    23 tokens (   37.47 ms per token,    26.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =     927.49 ms /    18 runs   (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    1792.05 ms /    41 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     893.38 ms /    24 tokens (   37.22 ms per token,    26.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1090.50 ms /    22 runs   (   49.57 ms per token,    20.17 tokens per second)\n",
      "llama_perf_context_print:       total time =    1987.14 ms /    46 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     950.78 ms /    23 tokens (   41.34 ms per token,    24.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =     923.28 ms /    19 runs   (   48.59 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    1876.94 ms /    42 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     801.06 ms /    19 tokens (   42.16 ms per token,    23.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =     685.94 ms /    14 runs   (   49.00 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    1489.06 ms /    33 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     995.16 ms /    29 tokens (   34.32 ms per token,    29.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1065.67 ms /    22 runs   (   48.44 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    2063.97 ms /    51 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     962.04 ms /    25 tokens (   38.48 ms per token,    25.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1030.33 ms /    21 runs   (   49.06 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    1995.34 ms /    46 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1135.48 ms /    28 tokens (   40.55 ms per token,    24.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =     792.62 ms /    16 runs   (   49.54 ms per token,    20.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    1930.56 ms /    44 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     969.49 ms /    29 tokens (   33.43 ms per token,    29.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1038.59 ms /    21 runs   (   49.46 ms per token,    20.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    2011.11 ms /    50 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     545.56 ms /    12 tokens (   45.46 ms per token,    22.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1116.76 ms /    23 runs   (   48.55 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    1665.61 ms /    35 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     806.45 ms /    19 tokens (   42.44 ms per token,    23.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =     821.21 ms /    17 runs   (   48.31 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1630.16 ms /    36 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     717.90 ms /    19 tokens (   37.78 ms per token,    26.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =     775.13 ms /    16 runs   (   48.45 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    1495.27 ms /    35 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     999.74 ms /    28 tokens (   35.70 ms per token,    28.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =     964.36 ms /    20 runs   (   48.22 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1966.97 ms /    48 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     906.82 ms /    23 tokens (   39.43 ms per token,    25.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1059.21 ms /    22 runs   (   48.15 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    1969.08 ms /    45 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     886.28 ms /    24 tokens (   36.93 ms per token,    27.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1156.70 ms /    24 runs   (   48.20 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    2046.21 ms /    48 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     813.62 ms /    24 tokens (   33.90 ms per token,    29.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =     678.35 ms /    14 runs   (   48.45 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    1494.07 ms /    38 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     897.03 ms /    26 tokens (   34.50 ms per token,    28.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1114.70 ms /    23 runs   (   48.47 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    2014.80 ms /    49 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     493.78 ms /     9 tokens (   54.86 ms per token,    18.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =     799.33 ms /    16 runs   (   49.96 ms per token,    20.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    1295.48 ms /    25 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     831.98 ms /    27 tokens (   30.81 ms per token,    32.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1164.53 ms /    24 runs   (   48.52 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    1999.99 ms /    51 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     380.62 ms /    11 tokens (   34.60 ms per token,    28.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1015.63 ms /    21 runs   (   48.36 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1399.22 ms /    32 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 5 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     809.84 ms /    25 tokens (   32.39 ms per token,    30.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =     823.14 ms /    17 runs   (   48.42 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    1636.19 ms /    42 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     263.18 ms /     8 tokens (   32.90 ms per token,    30.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =     876.92 ms /    18 runs   (   48.72 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    1142.87 ms /    26 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     866.62 ms /    31 tokens (   27.96 ms per token,    35.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =     827.47 ms /    17 runs   (   48.67 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1696.61 ms /    48 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     788.69 ms /    27 tokens (   29.21 ms per token,    34.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1115.46 ms /    23 runs   (   48.50 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    1907.38 ms /    50 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     947.23 ms /    25 tokens (   37.89 ms per token,    26.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1010.13 ms /    21 runs   (   48.10 ms per token,    20.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    1960.22 ms /    46 tokens\n",
      "Llama.generate: 33 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     373.74 ms /     8 tokens (   46.72 ms per token,    21.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =     818.78 ms /    17 runs   (   48.16 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1194.83 ms /    25 tokens\n",
      "Llama.generate: 26 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     786.19 ms /    18 tokens (   43.68 ms per token,    22.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =     925.23 ms /    19 runs   (   48.70 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1714.08 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1846.62 ms /    35 tokens (   52.76 ms per token,    18.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =     772.86 ms /    16 runs   (   48.30 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    2622.20 ms /    51 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     873.49 ms /    28 tokens (   31.20 ms per token,    32.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =     982.95 ms /    20 runs   (   49.15 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    1859.37 ms /    48 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     908.81 ms /    27 tokens (   33.66 ms per token,    29.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =     488.06 ms /    10 runs   (   48.81 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    1398.43 ms /    37 tokens\n",
      "Llama.generate: 27 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     573.98 ms /    13 tokens (   44.15 ms per token,    22.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =     578.37 ms /    12 runs   (   48.20 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    1154.15 ms /    25 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2153.47 ms /    47 tokens (   45.82 ms per token,    21.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2087.16 ms /    43 runs   (   48.54 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    4246.81 ms /    90 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     714.19 ms /    22 tokens (   32.46 ms per token,    30.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =     772.85 ms /    16 runs   (   48.30 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1489.34 ms /    38 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1013.04 ms /    31 tokens (   32.68 ms per token,    30.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1112.27 ms /    23 runs   (   48.36 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    2128.58 ms /    54 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     686.77 ms /    21 tokens (   32.70 ms per token,    30.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =     528.36 ms /    11 runs   (   48.03 ms per token,    20.82 tokens per second)\n",
      "llama_perf_context_print:       total time =    1216.82 ms /    32 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     409.85 ms /    12 tokens (   34.15 ms per token,    29.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =     529.07 ms /    11 runs   (   48.10 ms per token,    20.79 tokens per second)\n",
      "llama_perf_context_print:       total time =     940.61 ms /    23 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     805.37 ms /    25 tokens (   32.21 ms per token,    31.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1268.43 ms /    26 runs   (   48.79 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    2077.56 ms /    51 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     359.30 ms /     7 tokens (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =     977.59 ms /    20 runs   (   48.88 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    1339.85 ms /    27 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     390.72 ms /    10 tokens (   39.07 ms per token,    25.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1216.95 ms /    25 runs   (   48.68 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1611.07 ms /    35 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     783.85 ms /    24 tokens (   32.66 ms per token,    30.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1012.65 ms /    21 runs   (   48.22 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1799.48 ms /    45 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     850.75 ms /    28 tokens (   30.38 ms per token,    32.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =     923.14 ms /    19 runs   (   48.59 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    1776.60 ms /    47 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     667.17 ms /    23 tokens (   29.01 ms per token,    34.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =     876.87 ms /    18 runs   (   48.72 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    1546.62 ms /    41 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     755.12 ms /    26 tokens (   29.04 ms per token,    34.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1162.20 ms /    24 runs   (   48.43 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    1920.67 ms /    50 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     312.58 ms /     9 tokens (   34.73 ms per token,    28.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1232.31 ms /    25 runs   (   49.29 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    1548.41 ms /    34 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     795.97 ms /    23 tokens (   34.61 ms per token,    28.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1367.80 ms /    28 runs   (   48.85 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    2167.89 ms /    51 tokens\n",
      "Llama.generate: 46 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     291.47 ms /     9 tokens (   32.39 ms per token,    30.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1167.85 ms /    24 runs   (   48.66 ms per token,    20.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    1462.87 ms /    33 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     847.82 ms /    29 tokens (   29.24 ms per token,    34.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =     886.93 ms /    18 runs   (   49.27 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    1737.33 ms /    47 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1763.96 ms /    33 tokens (   53.45 ms per token,    18.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1086.50 ms /    22 runs   (   49.39 ms per token,    20.25 tokens per second)\n",
      "llama_perf_context_print:       total time =    2854.14 ms /    55 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     973.43 ms /    27 tokens (   36.05 ms per token,    27.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =     969.98 ms /    20 runs   (   48.50 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    1946.40 ms /    47 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1502.73 ms /    32 tokens (   46.96 ms per token,    21.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1464.41 ms /    30 runs   (   48.81 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    2971.56 ms /    62 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     877.14 ms /    25 tokens (   35.09 ms per token,    28.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1031.01 ms /    21 runs   (   49.10 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    1911.15 ms /    46 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1645.91 ms /    33 tokens (   49.88 ms per token,    20.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1460.02 ms /    30 runs   (   48.67 ms per token,    20.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    3110.34 ms /    63 tokens\n",
      "Llama.generate: 46 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     398.28 ms /    12 tokens (   33.19 ms per token,    30.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1485.74 ms /    30 runs   (   49.52 ms per token,    20.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    1888.38 ms /    42 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     887.62 ms /    27 tokens (   32.87 ms per token,    30.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =     827.03 ms /    17 runs   (   48.65 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    1717.19 ms /    44 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     282.99 ms /     8 tokens (   35.37 ms per token,    28.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =     826.91 ms /    17 runs   (   48.64 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    1112.38 ms /    25 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     904.25 ms /    30 tokens (   30.14 ms per token,    33.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1073.92 ms /    22 runs   (   48.81 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    1981.36 ms /    52 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     302.07 ms /     9 tokens (   33.56 ms per token,    29.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =     837.28 ms /    17 runs   (   49.25 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    1141.86 ms /    26 tokens\n",
      "Llama.generate: 33 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     534.11 ms /    14 tokens (   38.15 ms per token,    26.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =     787.28 ms /    16 runs   (   49.21 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    1323.88 ms /    30 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     749.82 ms /    20 tokens (   37.49 ms per token,    26.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =     687.00 ms /    14 runs   (   49.07 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    1438.94 ms /    34 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1015.73 ms /    31 tokens (   32.77 ms per token,    30.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =     685.00 ms /    14 runs   (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    1702.82 ms /    45 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     345.42 ms /     9 tokens (   38.38 ms per token,    26.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =     690.71 ms /    14 runs   (   49.34 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    1038.27 ms /    23 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     705.87 ms /    22 tokens (   32.09 ms per token,    31.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =     537.89 ms /    11 runs   (   48.90 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    1245.51 ms /    33 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     382.59 ms /    10 tokens (   38.26 ms per token,    26.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =     686.49 ms /    14 runs   (   49.03 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    1071.25 ms /    24 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1605.98 ms /    35 tokens (   45.89 ms per token,    21.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1134.85 ms /    23 runs   (   49.34 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    2744.50 ms /    58 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     744.15 ms /    21 tokens (   35.44 ms per token,    28.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =     389.44 ms /     8 runs   (   48.68 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1134.92 ms /    29 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1073.97 ms /    30 tokens (   35.80 ms per token,    27.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1281.76 ms /    26 runs   (   49.30 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    2359.46 ms /    56 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     848.59 ms /    28 tokens (   30.31 ms per token,    33.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1223.32 ms /    25 runs   (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    2075.50 ms /    53 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     775.37 ms /    26 tokens (   29.82 ms per token,    33.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =     838.59 ms /    17 runs   (   49.33 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    1616.43 ms /    43 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     791.88 ms /    23 tokens (   34.43 ms per token,    29.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =     537.96 ms /    11 runs   (   48.91 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    1331.68 ms /    34 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     876.59 ms /    29 tokens (   30.23 ms per token,    33.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1374.03 ms /    28 runs   (   49.07 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    2254.69 ms /    57 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     959.16 ms /    26 tokens (   36.89 ms per token,    27.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =     989.90 ms /    20 runs   (   49.50 ms per token,    20.20 tokens per second)\n",
      "llama_perf_context_print:       total time =    1952.06 ms /    46 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     879.80 ms /    25 tokens (   35.19 ms per token,    28.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =     595.18 ms /    12 runs   (   49.60 ms per token,    20.16 tokens per second)\n",
      "llama_perf_context_print:       total time =    1476.75 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1649.21 ms /    50 tokens (   32.98 ms per token,    30.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1821.13 ms /    37 runs   (   49.22 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    3476.08 ms /    87 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     534.03 ms /    17 tokens (   31.41 ms per token,    31.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =     928.59 ms /    19 runs   (   48.87 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    1465.38 ms /    36 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     873.69 ms /    29 tokens (   30.13 ms per token,    33.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =     929.01 ms /    19 runs   (   48.90 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    1805.64 ms /    48 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1674.19 ms /    35 tokens (   47.83 ms per token,    20.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =     873.70 ms /    18 runs   (   48.54 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    2550.72 ms /    53 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     791.92 ms /    27 tokens (   29.33 ms per token,    34.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =     822.31 ms /    17 runs   (   48.37 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    1616.77 ms /    44 tokens\n",
      "Llama.generate: 45 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     247.99 ms /     7 tokens (   35.43 ms per token,    28.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =     918.90 ms /    19 runs   (   48.36 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1169.59 ms /    26 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     881.88 ms /    26 tokens (   33.92 ms per token,    29.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =     872.58 ms /    18 runs   (   48.48 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    1756.97 ms /    44 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     930.57 ms /    30 tokens (   31.02 ms per token,    32.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =     723.61 ms /    15 runs   (   48.24 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1656.33 ms /    45 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1614.34 ms /    33 tokens (   48.92 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1424.86 ms /    29 runs   (   49.13 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    3043.21 ms /    62 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     776.16 ms /    26 tokens (   29.85 ms per token,    33.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =     822.88 ms /    17 runs   (   48.40 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    1601.65 ms /    43 tokens\n",
      "Llama.generate: 44 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     254.73 ms /     7 tokens (   36.39 ms per token,    27.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =     824.38 ms /    17 runs   (   48.49 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    1081.64 ms /    24 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     927.51 ms /    30 tokens (   30.92 ms per token,    32.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1322.41 ms /    27 runs   (   48.98 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    2253.81 ms /    57 tokens\n",
      "Llama.generate: 47 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     307.45 ms /     7 tokens (   43.92 ms per token,    22.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1295.33 ms /    26 runs   (   49.82 ms per token,    20.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    1606.37 ms /    33 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     840.97 ms /    26 tokens (   32.34 ms per token,    30.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =     727.73 ms /    15 runs   (   48.52 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    1570.91 ms /    41 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     926.26 ms /    30 tokens (   30.88 ms per token,    32.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1226.01 ms /    25 runs   (   49.04 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    2155.77 ms /    55 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     738.92 ms /    24 tokens (   30.79 ms per token,    32.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =     834.16 ms /    17 runs   (   49.07 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    1575.58 ms /    41 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     843.96 ms /    28 tokens (   30.14 ms per token,    33.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =     922.86 ms /    19 runs   (   48.57 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    1769.59 ms /    47 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     840.94 ms /    29 tokens (   29.00 ms per token,    34.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =     943.76 ms /    19 runs   (   49.67 ms per token,    20.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    1787.51 ms /    48 tokens\n",
      "Llama.generate: 45 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     250.69 ms /     7 tokens (   35.81 ms per token,    27.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1063.68 ms /    22 runs   (   48.35 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1317.62 ms /    29 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1464.58 ms /    32 tokens (   45.77 ms per token,    21.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =     918.78 ms /    19 runs   (   48.36 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    2386.10 ms /    51 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     752.53 ms /    26 tokens (   28.94 ms per token,    34.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =     787.72 ms /    16 runs   (   49.23 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    1542.62 ms /    42 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1631.25 ms /    34 tokens (   47.98 ms per token,    20.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1016.14 ms /    21 runs   (   48.39 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    2650.62 ms /    55 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     909.83 ms /    31 tokens (   29.35 ms per token,    34.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1301.94 ms /    27 runs   (   48.22 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    2215.69 ms /    58 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1662.90 ms /    33 tokens (   50.39 ms per token,    19.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1411.50 ms /    29 runs   (   48.67 ms per token,    20.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    3078.75 ms /    62 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     900.24 ms /    28 tokens (   32.15 ms per token,    31.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1023.62 ms /    21 runs   (   48.74 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    1926.85 ms /    49 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1511.36 ms /    32 tokens (   47.23 ms per token,    21.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1357.79 ms /    28 runs   (   48.49 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    2873.26 ms /    60 tokens\n",
      "Llama.generate: 50 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     235.22 ms /     7 tokens (   33.60 ms per token,    29.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1424.37 ms /    29 runs   (   49.12 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    1663.67 ms /    36 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     764.86 ms /    27 tokens (   28.33 ms per token,    35.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1074.10 ms /    22 runs   (   48.82 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    1842.08 ms /    49 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     761.51 ms /    26 tokens (   29.29 ms per token,    34.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =     724.40 ms /    15 runs   (   48.29 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1488.12 ms /    41 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     926.63 ms /    30 tokens (   30.89 ms per token,    32.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1026.23 ms /    21 runs   (   48.87 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    1955.74 ms /    51 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     760.38 ms /    26 tokens (   29.25 ms per token,    34.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =     924.33 ms /    19 runs   (   48.65 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    1687.45 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     728.84 ms /    24 tokens (   30.37 ms per token,    32.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =     778.67 ms /    16 runs   (   48.67 ms per token,    20.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    1509.76 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1605.24 ms /    35 tokens (   45.86 ms per token,    21.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1256.83 ms /    26 runs   (   48.34 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    2866.05 ms /    61 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     899.89 ms /    29 tokens (   31.03 ms per token,    32.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =     876.25 ms /    18 runs   (   48.68 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1778.86 ms /    47 tokens\n",
      "Llama.generate: 46 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     251.33 ms /     7 tokens (   35.90 ms per token,    27.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =     923.57 ms /    19 runs   (   48.61 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    1177.57 ms /    26 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     759.67 ms /    26 tokens (   29.22 ms per token,    34.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =     734.85 ms /    15 runs   (   48.99 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    1496.82 ms /    41 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     876.60 ms /    27 tokens (   32.47 ms per token,    30.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =     933.49 ms /    18 runs   (   51.86 ms per token,    19.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    1812.77 ms /    45 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     898.36 ms /    31 tokens (   28.98 ms per token,    34.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1415.60 ms /    29 runs   (   48.81 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    2318.15 ms /    60 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     767.98 ms /    26 tokens (   29.54 ms per token,    33.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1064.31 ms /    22 runs   (   48.38 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    1835.39 ms /    48 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     637.88 ms /    18 tokens (   35.44 ms per token,    28.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =     646.06 ms /    13 runs   (   49.70 ms per token,    20.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    1285.96 ms /    31 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     916.65 ms /    24 tokens (   38.19 ms per token,    26.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =     867.70 ms /    17 runs   (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    1786.95 ms /    41 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     968.26 ms /    28 tokens (   34.58 ms per token,    28.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =     744.06 ms /    15 runs   (   49.60 ms per token,    20.16 tokens per second)\n",
      "llama_perf_context_print:       total time =    1714.68 ms /    43 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     919.97 ms /    28 tokens (   32.86 ms per token,    30.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1012.78 ms /    20 runs   (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    1935.83 ms /    48 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     855.51 ms /    26 tokens (   32.90 ms per token,    30.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1128.01 ms /    23 runs   (   49.04 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    1986.84 ms /    49 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     618.06 ms /    19 tokens (   32.53 ms per token,    30.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =     786.28 ms /    16 runs   (   49.14 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    1406.71 ms /    35 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1803.48 ms /    41 tokens (   43.99 ms per token,    22.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =     914.19 ms /    18 runs   (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    2720.50 ms /    59 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     534.62 ms /    16 tokens (   33.41 ms per token,    29.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =     836.36 ms /    17 runs   (   49.20 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    1373.61 ms /    33 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     686.32 ms /    21 tokens (   32.68 ms per token,    30.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =     690.34 ms /    14 runs   (   49.31 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    1378.84 ms /    35 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 6 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 30 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     626.04 ms /    16 tokens (   39.13 ms per token,    25.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =     688.23 ms /    14 runs   (   49.16 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    1317.54 ms /    30 tokens\n",
      "Llama.generate: 30 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     720.81 ms /    16 tokens (   45.05 ms per token,    22.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1120.42 ms /    22 runs   (   50.93 ms per token,    19.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    1844.65 ms /    38 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2269.40 ms /    23 tokens (   98.67 ms per token,    10.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1325.54 ms /    23 runs   (   57.63 ms per token,    17.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    3598.84 ms /    46 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1940.94 ms /    22 tokens (   88.22 ms per token,    11.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =     816.12 ms /    16 runs   (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    2759.66 ms /    38 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     762.93 ms /    19 tokens (   40.15 ms per token,    24.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =     684.14 ms /    13 runs   (   52.63 ms per token,    19.00 tokens per second)\n",
      "llama_perf_context_print:       total time =    1449.12 ms /    32 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1111.37 ms /    28 tokens (   39.69 ms per token,    25.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1917.46 ms /    37 runs   (   51.82 ms per token,    19.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    3034.52 ms /    65 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1045.29 ms /    28 tokens (   37.33 ms per token,    26.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1925.59 ms /    39 runs   (   49.37 ms per token,    20.25 tokens per second)\n",
      "llama_perf_context_print:       total time =    2976.41 ms /    67 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2086.50 ms /    34 tokens (   61.37 ms per token,    16.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1489.59 ms /    30 runs   (   49.65 ms per token,    20.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    3580.71 ms /    64 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     979.38 ms /    27 tokens (   36.27 ms per token,    27.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =     841.27 ms /    17 runs   (   49.49 ms per token,    20.21 tokens per second)\n",
      "llama_perf_context_print:       total time =    1823.20 ms /    44 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     912.44 ms /    22 tokens (   41.47 ms per token,    24.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =     741.62 ms /    15 runs   (   49.44 ms per token,    20.23 tokens per second)\n",
      "llama_perf_context_print:       total time =    1656.25 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     950.98 ms /    27 tokens (   35.22 ms per token,    28.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1095.08 ms /    22 runs   (   49.78 ms per token,    20.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    2049.26 ms /    49 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     988.77 ms /    29 tokens (   34.10 ms per token,    29.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =     835.12 ms /    17 runs   (   49.12 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    1826.48 ms /    46 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     873.36 ms /    21 tokens (   41.59 ms per token,    24.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =     752.44 ms /    15 runs   (   50.16 ms per token,    19.94 tokens per second)\n",
      "llama_perf_context_print:       total time =    1628.03 ms /    36 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1876.11 ms /    34 tokens (   55.18 ms per token,    18.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1332.35 ms /    27 runs   (   49.35 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    3212.85 ms /    61 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1660.72 ms /    32 tokens (   51.90 ms per token,    19.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1678.01 ms /    34 runs   (   49.35 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    3344.03 ms /    66 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1076.07 ms /    27 tokens (   39.85 ms per token,    25.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1565.49 ms /    31 runs   (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    2646.06 ms /    58 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2034.20 ms /    35 tokens (   58.12 ms per token,    17.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1385.17 ms /    27 runs   (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    3423.75 ms /    62 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     779.73 ms /    20 tokens (   38.99 ms per token,    25.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =     440.50 ms /     9 runs   (   48.94 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    1221.73 ms /    29 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     774.16 ms /    19 tokens (   40.75 ms per token,    24.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =     446.46 ms /     9 runs   (   49.61 ms per token,    20.16 tokens per second)\n",
      "llama_perf_context_print:       total time =    1222.20 ms /    28 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     908.56 ms /    26 tokens (   34.94 ms per token,    28.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =     695.29 ms /    14 runs   (   49.66 ms per token,    20.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    1606.09 ms /    40 tokens\n",
      "Llama.generate: 33 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     557.55 ms /    12 tokens (   46.46 ms per token,    21.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =     559.65 ms /    11 runs   (   50.88 ms per token,    19.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    1119.01 ms /    23 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 233 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    3436.67 ms /   233 tokens (   14.75 ms per token,    67.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9611.21 ms /   187 runs   (   51.40 ms per token,    19.46 tokens per second)\n",
      "llama_perf_context_print:       total time =   13085.15 ms /   420 tokens\n",
      "Llama.generate: 45 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     659.25 ms /    15 tokens (   43.95 ms per token,    22.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =     916.28 ms /    18 runs   (   50.90 ms per token,    19.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    1578.41 ms /    33 tokens\n",
      "Llama.generate: 45 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     366.20 ms /     8 tokens (   45.77 ms per token,    21.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1268.92 ms /    25 runs   (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1638.88 ms /    33 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1734.81 ms /    34 tokens (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1176.59 ms /    23 runs   (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    2915.02 ms /    57 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     428.62 ms /     8 tokens (   53.58 ms per token,    18.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =     601.58 ms /    12 runs   (   50.13 ms per token,    19.95 tokens per second)\n",
      "llama_perf_context_print:       total time =    1032.26 ms /    20 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     443.21 ms /    10 tokens (   44.32 ms per token,    22.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =     735.43 ms /    14 runs   (   52.53 ms per token,    19.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    1180.78 ms /    24 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     944.38 ms /    26 tokens (   36.32 ms per token,    27.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =     749.59 ms /    15 runs   (   49.97 ms per token,    20.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    1696.40 ms /    41 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     746.38 ms /    17 tokens (   43.90 ms per token,    22.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =     403.33 ms /     8 runs   (   50.42 ms per token,    19.83 tokens per second)\n",
      "llama_perf_context_print:       total time =    1151.13 ms /    25 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     968.27 ms /    26 tokens (   37.24 ms per token,    26.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =     354.75 ms /     7 runs   (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1324.28 ms /    33 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     366.39 ms /     8 tokens (   45.80 ms per token,    21.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =     361.16 ms /     7 runs   (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_perf_context_print:       total time =     728.81 ms /    15 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1010.42 ms /    26 tokens (   38.86 ms per token,    25.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1276.43 ms /    25 runs   (   51.06 ms per token,    19.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    2290.80 ms /    51 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     419.32 ms /     8 tokens (   52.41 ms per token,    19.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =     892.60 ms /    17 runs   (   52.51 ms per token,    19.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    1314.60 ms /    25 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     928.90 ms /    25 tokens (   37.16 ms per token,    26.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =     497.48 ms /    10 runs   (   49.75 ms per token,    20.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    1428.08 ms /    35 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     921.99 ms /    22 tokens (   41.91 ms per token,    23.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =     509.81 ms /    10 runs   (   50.98 ms per token,    19.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    1433.50 ms /    32 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1079.98 ms /    26 tokens (   41.54 ms per token,    24.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =     514.06 ms /    10 runs   (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    1595.74 ms /    36 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1010.01 ms /    27 tokens (   37.41 ms per token,    26.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1186.32 ms /    23 runs   (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    2199.62 ms /    50 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     830.68 ms /    21 tokens (   39.56 ms per token,    25.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =     497.87 ms /    10 runs   (   49.79 ms per token,    20.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    1330.33 ms /    31 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1807.98 ms /    38 tokens (   47.58 ms per token,    21.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1310.10 ms /    26 runs   (   50.39 ms per token,    19.85 tokens per second)\n",
      "llama_perf_context_print:       total time =    3122.12 ms /    64 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2031.00 ms /    66 tokens (   30.77 ms per token,    32.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3292.08 ms /    65 runs   (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    5333.53 ms /   131 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     901.40 ms /    24 tokens (   37.56 ms per token,    26.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =     557.70 ms /    11 runs   (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1460.95 ms /    35 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1957.23 ms /    42 tokens (   46.60 ms per token,    21.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1239.11 ms /    25 runs   (   49.56 ms per token,    20.18 tokens per second)\n",
      "llama_perf_context_print:       total time =    3200.12 ms /    67 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 116 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2267.19 ms /   116 tokens (   19.54 ms per token,    51.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3460.42 ms /    69 runs   (   50.15 ms per token,    19.94 tokens per second)\n",
      "llama_perf_context_print:       total time =    5738.56 ms /   185 tokens\n",
      "Llama.generate: 32 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     665.65 ms /    16 tokens (   41.60 ms per token,    24.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =     544.37 ms /    11 runs   (   49.49 ms per token,    20.21 tokens per second)\n",
      "llama_perf_context_print:       total time =    1211.81 ms /    27 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     869.44 ms /    22 tokens (   39.52 ms per token,    25.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1304.31 ms /    26 runs   (   50.17 ms per token,    19.93 tokens per second)\n",
      "llama_perf_context_print:       total time =    2177.62 ms /    48 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     961.26 ms /    25 tokens (   38.45 ms per token,    26.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =     703.48 ms /    14 runs   (   50.25 ms per token,    19.90 tokens per second)\n",
      "llama_perf_context_print:       total time =    1666.94 ms /    39 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     795.98 ms /    22 tokens (   36.18 ms per token,    27.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1101.78 ms /    22 runs   (   50.08 ms per token,    19.97 tokens per second)\n",
      "llama_perf_context_print:       total time =    1901.10 ms /    44 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     928.77 ms /    25 tokens (   37.15 ms per token,    26.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =     556.92 ms /    11 runs   (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    1487.51 ms /    36 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     974.42 ms /    26 tokens (   37.48 ms per token,    26.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1127.82 ms /    23 runs   (   49.04 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    2105.76 ms /    49 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     361.99 ms /     9 tokens (   40.22 ms per token,    24.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =     742.27 ms /    15 runs   (   49.48 ms per token,    20.21 tokens per second)\n",
      "llama_perf_context_print:       total time =    1106.59 ms /    24 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     797.51 ms /    21 tokens (   37.98 ms per token,    26.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =     783.67 ms /    16 runs   (   48.98 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    1583.59 ms /    37 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1090.91 ms /    26 tokens (   41.96 ms per token,    23.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1146.71 ms /    23 runs   (   49.86 ms per token,    20.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    2240.99 ms /    49 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     759.16 ms /    21 tokens (   36.15 ms per token,    27.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =     447.47 ms /     9 runs   (   49.72 ms per token,    20.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    1208.12 ms /    30 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1508.32 ms /    32 tokens (   47.14 ms per token,    21.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1173.99 ms /    24 runs   (   48.92 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    2685.98 ms /    56 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     806.24 ms /    25 tokens (   32.25 ms per token,    31.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =     590.34 ms /    12 runs   (   49.19 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    1398.49 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     658.97 ms /    21 tokens (   31.38 ms per token,    31.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =     396.85 ms /     8 runs   (   49.61 ms per token,    20.16 tokens per second)\n",
      "llama_perf_context_print:       total time =    1057.14 ms /    29 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     897.23 ms /    26 tokens (   34.51 ms per token,    28.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =     630.32 ms /    13 runs   (   48.49 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    1529.56 ms /    39 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     892.91 ms /    26 tokens (   34.34 ms per token,    29.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1145.16 ms /    23 runs   (   49.79 ms per token,    20.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    2041.43 ms /    49 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     880.63 ms /    25 tokens (   35.23 ms per token,    28.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =     535.61 ms /    11 runs   (   48.69 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1418.01 ms /    36 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     280.87 ms /     7 tokens (   40.12 ms per token,    24.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =     636.78 ms /    13 runs   (   48.98 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =     919.59 ms /    20 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     729.09 ms /    22 tokens (   33.14 ms per token,    30.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =     547.00 ms /    11 runs   (   49.73 ms per token,    20.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    1277.95 ms /    33 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 139 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2320.18 ms /   139 tokens (   16.69 ms per token,    59.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5978.02 ms /   120 runs   (   49.82 ms per token,    20.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    8318.84 ms /   259 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1001.97 ms /    29 tokens (   34.55 ms per token,    28.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1185.55 ms /    24 runs   (   49.40 ms per token,    20.24 tokens per second)\n",
      "llama_perf_context_print:       total time =    2191.07 ms /    53 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 129 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2324.25 ms /   129 tokens (   18.02 ms per token,    55.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3976.83 ms /    80 runs   (   49.71 ms per token,    20.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6314.16 ms /   209 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     789.13 ms /    24 tokens (   32.88 ms per token,    30.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1032.78 ms /    21 runs   (   49.18 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    1825.01 ms /    45 tokens\n",
      "Llama.generate: 33 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1748.44 ms /    59 tokens (   29.63 ms per token,    33.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =     746.40 ms /    15 runs   (   49.76 ms per token,    20.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    2497.36 ms /    74 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1750.38 ms /    64 tokens (   27.35 ms per token,    36.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1866.48 ms /    38 runs   (   49.12 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    3622.51 ms /   102 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     920.56 ms /    30 tokens (   30.69 ms per token,    32.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =     825.05 ms /    17 runs   (   48.53 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    1748.14 ms /    47 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 108 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2247.40 ms /   108 tokens (   20.81 ms per token,    48.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3596.32 ms /    72 runs   (   49.95 ms per token,    20.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    5854.92 ms /   180 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1710.96 ms /    45 tokens (   38.02 ms per token,    26.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1970.12 ms /    40 runs   (   49.25 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    3687.24 ms /    85 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     994.86 ms /    26 tokens (   38.26 ms per token,    26.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =     936.79 ms /    19 runs   (   49.30 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    1934.49 ms /    45 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1686.41 ms /    48 tokens (   35.13 ms per token,    28.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1563.93 ms /    32 runs   (   48.87 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    3255.19 ms /    80 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1726.15 ms /    33 tokens (   52.31 ms per token,    19.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1078.75 ms /    22 runs   (   49.03 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    2808.13 ms /    55 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1677.04 ms /    35 tokens (   47.92 ms per token,    20.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1336.76 ms /    27 runs   (   49.51 ms per token,    20.20 tokens per second)\n",
      "llama_perf_context_print:       total time =    3017.96 ms /    62 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1760.36 ms /    41 tokens (   42.94 ms per token,    23.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1173.48 ms /    24 runs   (   48.90 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    2937.44 ms /    65 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     828.82 ms /    23 tokens (   36.04 ms per token,    27.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =     530.38 ms /    11 runs   (   48.22 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1360.96 ms /    34 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     889.41 ms /    27 tokens (   32.94 ms per token,    30.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1197.99 ms /    24 runs   (   49.92 ms per token,    20.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    2090.91 ms /    51 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     784.70 ms /    25 tokens (   31.39 ms per token,    31.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =     546.45 ms /    11 runs   (   49.68 ms per token,    20.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    1332.80 ms /    36 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 154 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2369.97 ms /   154 tokens (   15.39 ms per token,    64.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4961.45 ms /   100 runs   (   49.61 ms per token,    20.16 tokens per second)\n",
      "llama_perf_context_print:       total time =    7348.01 ms /   254 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     931.19 ms /    30 tokens (   31.04 ms per token,    32.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1387.03 ms /    28 runs   (   49.54 ms per token,    20.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    2322.33 ms /    58 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1678.86 ms /    35 tokens (   47.97 ms per token,    20.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1620.49 ms /    33 runs   (   49.11 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    3304.42 ms /    68 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     941.00 ms /    21 tokens (   44.81 ms per token,    22.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =     769.35 ms /    15 runs   (   51.29 ms per token,    19.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    1712.78 ms /    36 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     310.27 ms /     6 tokens (   51.71 ms per token,    19.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1005.50 ms /    20 runs   (   50.27 ms per token,    19.89 tokens per second)\n",
      "llama_perf_context_print:       total time =    1318.85 ms /    26 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     866.49 ms /    26 tokens (   33.33 ms per token,    30.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =     839.01 ms /    17 runs   (   49.35 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    1708.13 ms /    43 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     877.78 ms /    27 tokens (   32.51 ms per token,    30.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1285.14 ms /    25 runs   (   51.41 ms per token,    19.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    2166.62 ms /    52 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     749.56 ms /    21 tokens (   35.69 ms per token,    28.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =     887.97 ms /    18 runs   (   49.33 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    1640.24 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1069.13 ms /    29 tokens (   36.87 ms per token,    27.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =     784.54 ms /    16 runs   (   49.03 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    1856.09 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     915.07 ms /    26 tokens (   35.20 ms per token,    28.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1232.30 ms /    25 runs   (   49.29 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    2151.10 ms /    51 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     484.09 ms /    12 tokens (   40.34 ms per token,    24.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1335.12 ms /    27 runs   (   49.45 ms per token,    20.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    1823.13 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1795.08 ms /    61 tokens (   29.43 ms per token,    33.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3397.47 ms /    68 runs   (   49.96 ms per token,    20.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    5203.02 ms /   129 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1640.60 ms /    32 tokens (   51.27 ms per token,    19.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =     635.71 ms /    13 runs   (   48.90 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    2278.47 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1055.58 ms /    27 tokens (   39.10 ms per token,    25.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1040.25 ms /    21 runs   (   49.54 ms per token,    20.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    2099.02 ms /    48 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     839.89 ms /    25 tokens (   33.60 ms per token,    29.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1189.23 ms /    24 runs   (   49.55 ms per token,    20.18 tokens per second)\n",
      "llama_perf_context_print:       total time =    2032.63 ms /    49 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1752.04 ms /    35 tokens (   50.06 ms per token,    19.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1827.11 ms /    37 runs   (   49.38 ms per token,    20.25 tokens per second)\n",
      "llama_perf_context_print:       total time =    3584.55 ms /    72 tokens\n",
      "Llama.generate: 53 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     931.01 ms /    28 tokens (   33.25 ms per token,    30.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2883.60 ms /    58 runs   (   49.72 ms per token,    20.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    3823.37 ms /    86 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     502.17 ms /    11 tokens (   45.65 ms per token,    21.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1172.46 ms /    24 runs   (   48.85 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    1678.22 ms /    35 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     805.76 ms /    21 tokens (   38.37 ms per token,    26.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =     897.30 ms /    18 runs   (   49.85 ms per token,    20.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    1705.73 ms /    39 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     880.97 ms /    25 tokens (   35.24 ms per token,    28.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =     869.91 ms /    17 runs   (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1753.40 ms /    42 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     801.50 ms /    22 tokens (   36.43 ms per token,    27.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1123.69 ms /    23 runs   (   48.86 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    1928.53 ms /    45 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     782.61 ms /    24 tokens (   32.61 ms per token,    30.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =     974.44 ms /    20 runs   (   48.72 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    1760.01 ms /    44 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 7 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1097.20 ms /    30 tokens (   36.57 ms per token,    27.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1284.95 ms /    26 runs   (   49.42 ms per token,    20.23 tokens per second)\n",
      "llama_perf_context_print:       total time =    2387.07 ms /    56 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     950.62 ms /    30 tokens (   31.69 ms per token,    31.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1288.83 ms /    26 runs   (   49.57 ms per token,    20.17 tokens per second)\n",
      "llama_perf_context_print:       total time =    2243.31 ms /    56 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1662.98 ms /    35 tokens (   47.51 ms per token,    21.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1583.16 ms /    32 runs   (   49.47 ms per token,    20.21 tokens per second)\n",
      "llama_perf_context_print:       total time =    3251.05 ms /    67 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1696.29 ms /    33 tokens (   51.40 ms per token,    19.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2106.77 ms /    43 runs   (   48.99 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    3809.61 ms /    76 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     921.89 ms /    25 tokens (   36.88 ms per token,    27.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =     737.32 ms /    15 runs   (   49.15 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    1661.50 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     782.20 ms /    23 tokens (   34.01 ms per token,    29.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =     743.09 ms /    15 runs   (   49.54 ms per token,    20.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    1527.54 ms /    38 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1912.45 ms /    32 tokens (   59.76 ms per token,    16.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1203.10 ms /    24 runs   (   50.13 ms per token,    19.95 tokens per second)\n",
      "llama_perf_context_print:       total time =    3119.22 ms /    56 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2086.01 ms /    36 tokens (   57.94 ms per token,    17.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2373.98 ms /    48 runs   (   49.46 ms per token,    20.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    4467.28 ms /    84 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     990.13 ms /    25 tokens (   39.61 ms per token,    25.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =     960.31 ms /    19 runs   (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    1953.39 ms /    44 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2046.22 ms /    41 tokens (   49.91 ms per token,    20.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2379.99 ms /    47 runs   (   50.64 ms per token,    19.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    4433.26 ms /    88 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     857.60 ms /    20 tokens (   42.88 ms per token,    23.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1239.78 ms /    25 runs   (   49.59 ms per token,    20.16 tokens per second)\n",
      "llama_perf_context_print:       total time =    2101.15 ms /    45 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1912.84 ms /    53 tokens (   36.09 ms per token,    27.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2975.37 ms /    59 runs   (   50.43 ms per token,    19.83 tokens per second)\n",
      "llama_perf_context_print:       total time =    4897.34 ms /   112 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     893.89 ms /    23 tokens (   38.86 ms per token,    25.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =     797.76 ms /    16 runs   (   49.86 ms per token,    20.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    1694.23 ms /    39 tokens\n",
      "Llama.generate: 31 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     711.04 ms /    20 tokens (   35.55 ms per token,    28.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =     800.22 ms /    16 runs   (   50.01 ms per token,    19.99 tokens per second)\n",
      "llama_perf_context_print:       total time =    1513.79 ms /    36 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1984.11 ms /    37 tokens (   53.62 ms per token,    18.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1951.46 ms /    39 runs   (   50.04 ms per token,    19.99 tokens per second)\n",
      "llama_perf_context_print:       total time =    3941.62 ms /    76 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     563.65 ms /    17 tokens (   33.16 ms per token,    30.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1397.56 ms /    28 runs   (   49.91 ms per token,    20.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    1965.38 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     716.95 ms /    21 tokens (   34.14 ms per token,    29.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =     775.63 ms /    16 runs   (   48.48 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    1494.95 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     915.77 ms /    27 tokens (   33.92 ms per token,    29.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =     537.18 ms /    11 runs   (   48.83 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    1454.75 ms /    38 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1835.23 ms /    60 tokens (   30.59 ms per token,    32.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3044.05 ms /    61 runs   (   49.90 ms per token,    20.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    4888.77 ms /   121 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     874.45 ms /    22 tokens (   39.75 ms per token,    25.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1199.15 ms /    24 runs   (   49.96 ms per token,    20.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    2077.20 ms /    46 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     873.03 ms /    29 tokens (   30.10 ms per token,    33.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1082.93 ms /    22 runs   (   49.22 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    1959.24 ms /    51 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1664.44 ms /    47 tokens (   35.41 ms per token,    28.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2687.91 ms /    54 runs   (   49.78 ms per token,    20.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    4360.53 ms /   101 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1651.60 ms /    53 tokens (   31.16 ms per token,    32.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3197.64 ms /    64 runs   (   49.96 ms per token,    20.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    4859.38 ms /   117 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     747.93 ms /    25 tokens (   29.92 ms per token,    33.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =     847.77 ms /    17 runs   (   49.87 ms per token,    20.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    1598.33 ms /    42 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1657.73 ms /    54 tokens (   30.70 ms per token,    32.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3409.83 ms /    68 runs   (   50.14 ms per token,    19.94 tokens per second)\n",
      "llama_perf_context_print:       total time =    5078.12 ms /   122 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1632.34 ms /    57 tokens (   28.64 ms per token,    34.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2658.60 ms /    53 runs   (   50.16 ms per token,    19.94 tokens per second)\n",
      "llama_perf_context_print:       total time =    4299.19 ms /   110 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1767.95 ms /    57 tokens (   31.02 ms per token,    32.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3220.94 ms /    64 runs   (   50.33 ms per token,    19.87 tokens per second)\n",
      "llama_perf_context_print:       total time =    4998.86 ms /   121 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     747.89 ms /    24 tokens (   31.16 ms per token,    32.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1000.59 ms /    20 runs   (   50.03 ms per token,    19.99 tokens per second)\n",
      "llama_perf_context_print:       total time =    1751.45 ms /    44 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1715.51 ms /    51 tokens (   33.64 ms per token,    29.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2193.12 ms /    43 runs   (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    3915.29 ms /    94 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     697.18 ms /    22 tokens (   31.69 ms per token,    31.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =     645.54 ms /    13 runs   (   49.66 ms per token,    20.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    1344.73 ms /    35 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     775.36 ms /    25 tokens (   31.01 ms per token,    32.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1048.99 ms /    21 runs   (   49.95 ms per token,    20.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    1827.55 ms /    46 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     895.88 ms /    27 tokens (   33.18 ms per token,    30.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1197.26 ms /    24 runs   (   49.89 ms per token,    20.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    2096.76 ms /    51 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     729.94 ms /    23 tokens (   31.74 ms per token,    31.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1390.59 ms /    28 runs   (   49.66 ms per token,    20.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    2124.67 ms /    51 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     924.23 ms /    25 tokens (   36.97 ms per token,    27.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =     801.04 ms /    16 runs   (   50.06 ms per token,    19.97 tokens per second)\n",
      "llama_perf_context_print:       total time =    1727.76 ms /    41 tokens\n",
      "Llama.generate: 32 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     558.64 ms /    17 tokens (   32.86 ms per token,    30.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =     953.48 ms /    19 runs   (   50.18 ms per token,    19.93 tokens per second)\n",
      "llama_perf_context_print:       total time =    1514.88 ms /    36 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     731.43 ms /    23 tokens (   31.80 ms per token,    31.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =     843.81 ms /    17 runs   (   49.64 ms per token,    20.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    1577.95 ms /    40 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     663.21 ms /    21 tokens (   31.58 ms per token,    31.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =     940.45 ms /    19 runs   (   49.50 ms per token,    20.20 tokens per second)\n",
      "llama_perf_context_print:       total time =    1606.54 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1787.98 ms /    37 tokens (   48.32 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1546.96 ms /    31 runs   (   49.90 ms per token,    20.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    3339.72 ms /    68 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     777.41 ms /    20 tokens (   38.87 ms per token,    25.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =     499.89 ms /    10 runs   (   49.99 ms per token,    20.00 tokens per second)\n",
      "llama_perf_context_print:       total time =    1279.03 ms /    30 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1793.24 ms /    60 tokens (   29.89 ms per token,    33.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2485.54 ms /    50 runs   (   49.71 ms per token,    20.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4286.24 ms /   110 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1687.64 ms /    44 tokens (   38.36 ms per token,    26.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2662.99 ms /    53 runs   (   50.25 ms per token,    19.90 tokens per second)\n",
      "llama_perf_context_print:       total time =    4358.79 ms /    97 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     678.23 ms /    19 tokens (   35.70 ms per token,    28.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =     492.54 ms /    10 runs   (   49.25 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    1172.36 ms /    29 tokens\n",
      "Llama.generate: 29 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1927.78 ms /    46 tokens (   41.91 ms per token,    23.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3054.59 ms /    61 runs   (   50.08 ms per token,    19.97 tokens per second)\n",
      "llama_perf_context_print:       total time =    4991.81 ms /   107 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     924.80 ms /    26 tokens (   35.57 ms per token,    28.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1139.07 ms /    23 runs   (   49.52 ms per token,    20.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    2067.31 ms /    49 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1754.53 ms /    39 tokens (   44.99 ms per token,    22.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3193.05 ms /    64 runs   (   49.89 ms per token,    20.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    4957.49 ms /   103 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     658.55 ms /    15 tokens (   43.90 ms per token,    22.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1392.69 ms /    28 runs   (   49.74 ms per token,    20.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    2055.40 ms /    43 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     579.19 ms /    15 tokens (   38.61 ms per token,    25.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1247.45 ms /    25 runs   (   49.90 ms per token,    20.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    1830.37 ms /    40 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     846.00 ms /    24 tokens (   35.25 ms per token,    28.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =     890.87 ms /    18 runs   (   49.49 ms per token,    20.21 tokens per second)\n",
      "llama_perf_context_print:       total time =    1739.66 ms /    42 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     986.46 ms /    27 tokens (   36.54 ms per token,    27.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1090.48 ms /    22 runs   (   49.57 ms per token,    20.17 tokens per second)\n",
      "llama_perf_context_print:       total time =    2080.13 ms /    49 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     861.59 ms /    24 tokens (   35.90 ms per token,    27.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1041.13 ms /    21 runs   (   49.58 ms per token,    20.17 tokens per second)\n",
      "llama_perf_context_print:       total time =    1905.94 ms /    45 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     908.42 ms /    26 tokens (   34.94 ms per token,    28.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1104.45 ms /    22 runs   (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_perf_context_print:       total time =    2016.24 ms /    48 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1675.16 ms /    39 tokens (   42.95 ms per token,    23.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1514.52 ms /    31 runs   (   48.86 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    3194.36 ms /    70 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1912.68 ms /    57 tokens (   33.56 ms per token,    29.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2727.16 ms /    55 runs   (   49.58 ms per token,    20.17 tokens per second)\n",
      "llama_perf_context_print:       total time =    4648.17 ms /   112 tokens\n",
      "Llama.generate: 44 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     595.02 ms /    13 tokens (   45.77 ms per token,    21.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1635.19 ms /    33 runs   (   49.55 ms per token,    20.18 tokens per second)\n",
      "llama_perf_context_print:       total time =    2234.95 ms /    46 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     351.70 ms /     8 tokens (   43.96 ms per token,    22.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1230.49 ms /    25 runs   (   49.22 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    1585.89 ms /    33 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     874.90 ms /    23 tokens (   38.04 ms per token,    26.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1186.00 ms /    24 runs   (   49.42 ms per token,    20.24 tokens per second)\n",
      "llama_perf_context_print:       total time =    2064.45 ms /    47 tokens\n",
      "Llama.generate: 31 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1903.18 ms /    45 tokens (   42.29 ms per token,    23.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =     544.11 ms /    11 runs   (   49.46 ms per token,    20.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    2449.20 ms /    56 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1799.03 ms /    43 tokens (   41.84 ms per token,    23.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2062.22 ms /    42 runs   (   49.10 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    3867.59 ms /    85 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     804.37 ms /    20 tokens (   40.22 ms per token,    24.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =     797.85 ms /    16 runs   (   49.87 ms per token,    20.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    1604.64 ms /    36 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     265.81 ms /     6 tokens (   44.30 ms per token,    22.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1022.24 ms /    21 runs   (   48.68 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1291.15 ms /    27 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1112.77 ms /    29 tokens (   38.37 ms per token,    26.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =     937.99 ms /    19 runs   (   49.37 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    2053.59 ms /    48 tokens\n",
      "Llama.generate: 32 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     658.63 ms /    14 tokens (   47.04 ms per token,    21.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =     589.37 ms /    12 runs   (   49.11 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    1249.81 ms /    26 tokens\n",
      "Llama.generate: 32 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     763.57 ms /    21 tokens (   36.36 ms per token,    27.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =     982.54 ms /    20 runs   (   49.13 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    1749.12 ms /    41 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     660.81 ms /    16 tokens (   41.30 ms per token,    24.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =     852.37 ms /    17 runs   (   50.14 ms per token,    19.94 tokens per second)\n",
      "llama_perf_context_print:       total time =    1515.66 ms /    33 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     838.36 ms /    25 tokens (   33.53 ms per token,    29.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =     756.86 ms /    15 runs   (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_perf_context_print:       total time =    1597.51 ms /    40 tokens\n",
      "Llama.generate: 29 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     659.14 ms /    16 tokens (   41.20 ms per token,    24.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =     589.98 ms /    12 runs   (   49.17 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    1251.10 ms /    28 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     896.35 ms /    25 tokens (   35.85 ms per token,    27.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1591.04 ms /    32 runs   (   49.72 ms per token,    20.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    2492.07 ms /    57 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1764.04 ms /    39 tokens (   45.23 ms per token,    22.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1734.03 ms /    35 runs   (   49.54 ms per token,    20.18 tokens per second)\n",
      "llama_perf_context_print:       total time =    3503.31 ms /    74 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     812.21 ms /    22 tokens (   36.92 ms per token,    27.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =     822.55 ms /    17 runs   (   48.39 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    1637.26 ms /    39 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     691.68 ms /    20 tokens (   34.58 ms per token,    28.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1337.86 ms /    27 runs   (   49.55 ms per token,    20.18 tokens per second)\n",
      "llama_perf_context_print:       total time =    2033.59 ms /    47 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 433 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    4735.81 ms /   433 tokens (   10.94 ms per token,    91.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2728.23 ms /    53 runs   (   51.48 ms per token,    19.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    7472.61 ms /   486 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 293 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    3467.61 ms /   293 tokens (   11.83 ms per token,    84.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8930.29 ms /   176 runs   (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_perf_context_print:       total time =   12431.50 ms /   469 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     827.59 ms /    23 tokens (   35.98 ms per token,    27.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =     835.36 ms /    17 runs   (   49.14 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    1665.60 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     848.71 ms /    25 tokens (   33.95 ms per token,    29.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =     838.04 ms /    17 runs   (   49.30 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    1689.35 ms /    42 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     778.21 ms /    20 tokens (   38.91 ms per token,    25.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =     635.86 ms /    13 runs   (   48.91 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    1416.05 ms /    33 tokens\n",
      "Llama.generate: 29 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     446.18 ms /    11 tokens (   40.56 ms per token,    24.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =     794.78 ms /    16 runs   (   49.67 ms per token,    20.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    1243.33 ms /    27 tokens\n",
      "Llama.generate: 29 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     410.93 ms /     9 tokens (   45.66 ms per token,    21.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =     490.92 ms /    10 runs   (   49.09 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =     903.40 ms /    19 tokens\n",
      "Llama.generate: 31 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     360.82 ms /     9 tokens (   40.09 ms per token,    24.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =     644.67 ms /    13 runs   (   49.59 ms per token,    20.17 tokens per second)\n",
      "llama_perf_context_print:       total time =    1007.54 ms /    22 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     861.95 ms /    28 tokens (   30.78 ms per token,    32.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1124.88 ms /    23 runs   (   48.91 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    1990.24 ms /    51 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     820.49 ms /    22 tokens (   37.29 ms per token,    26.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =     745.85 ms /    15 runs   (   49.72 ms per token,    20.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    1568.61 ms /    37 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1739.41 ms /    34 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =     892.38 ms /    18 runs   (   49.58 ms per token,    20.17 tokens per second)\n",
      "llama_perf_context_print:       total time =    2635.12 ms /    52 tokens\n",
      "Llama.generate: 33 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     591.31 ms /    14 tokens (   42.24 ms per token,    23.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =     681.51 ms /    14 runs   (   48.68 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1274.94 ms /    28 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     922.67 ms /    22 tokens (   41.94 ms per token,    23.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =     769.77 ms /    15 runs   (   51.32 ms per token,    19.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    1694.75 ms /    37 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     996.54 ms /    30 tokens (   33.22 ms per token,    30.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1424.68 ms /    29 runs   (   49.13 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    2425.45 ms /    59 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     823.43 ms /    24 tokens (   34.31 ms per token,    29.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1130.22 ms /    23 runs   (   49.14 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    1957.09 ms /    47 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     939.00 ms /    26 tokens (   36.12 ms per token,    27.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1100.37 ms /    22 runs   (   50.02 ms per token,    19.99 tokens per second)\n",
      "llama_perf_context_print:       total time =    2042.70 ms /    48 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     885.71 ms /    22 tokens (   40.26 ms per token,    24.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =     636.59 ms /    13 runs   (   48.97 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    1524.41 ms /    35 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     525.83 ms /    12 tokens (   43.82 ms per token,    22.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =     971.15 ms /    20 runs   (   48.56 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    1499.85 ms /    32 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1131.18 ms /    30 tokens (   37.71 ms per token,    26.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1414.07 ms /    29 runs   (   48.76 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    2549.45 ms /    59 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     730.54 ms /    20 tokens (   36.53 ms per token,    27.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =     733.24 ms /    15 runs   (   48.88 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    1466.02 ms /    35 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     842.62 ms /    25 tokens (   33.70 ms per token,    29.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1233.34 ms /    25 runs   (   49.33 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    2079.59 ms /    50 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     870.62 ms /    26 tokens (   33.49 ms per token,    29.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1138.03 ms /    23 runs   (   49.48 ms per token,    20.21 tokens per second)\n",
      "llama_perf_context_print:       total time =    2012.04 ms /    49 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     989.38 ms /    29 tokens (   34.12 ms per token,    29.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1046.60 ms /    21 runs   (   49.84 ms per token,    20.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    2038.97 ms /    50 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 79 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1993.67 ms /    79 tokens (   25.24 ms per token,    39.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3187.57 ms /    64 runs   (   49.81 ms per token,    20.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    5191.06 ms /   143 tokens\n",
      "Llama.generate: 32 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     544.34 ms /    14 tokens (   38.88 ms per token,    25.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1099.02 ms /    22 runs   (   49.96 ms per token,    20.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    1646.54 ms /    36 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     852.61 ms /    26 tokens (   32.79 ms per token,    30.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1231.00 ms /    25 runs   (   49.24 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    2087.25 ms /    51 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     681.61 ms /    21 tokens (   32.46 ms per token,    30.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =     906.67 ms /    18 runs   (   50.37 ms per token,    19.85 tokens per second)\n",
      "llama_perf_context_print:       total time =    1590.98 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1788.56 ms /    33 tokens (   54.20 ms per token,    18.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1177.99 ms /    24 runs   (   49.08 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    2970.66 ms /    57 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1689.52 ms /    43 tokens (   39.29 ms per token,    25.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1474.19 ms /    30 runs   (   49.14 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    3168.10 ms /    73 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     890.21 ms /    24 tokens (   37.09 ms per token,    26.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =     642.85 ms /    13 runs   (   49.45 ms per token,    20.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    1535.34 ms /    37 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 8 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     979.41 ms /    28 tokens (   34.98 ms per token,    28.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1220.68 ms /    25 runs   (   48.83 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    2204.84 ms /    53 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1696.72 ms /    35 tokens (   48.48 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2261.21 ms /    46 runs   (   49.16 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    3964.94 ms /    81 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     370.13 ms /    12 tokens (   30.84 ms per token,    32.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1068.12 ms /    22 runs   (   48.55 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    1441.55 ms /    34 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     755.38 ms /    26 tokens (   29.05 ms per token,    34.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =     727.72 ms /    15 runs   (   48.51 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    1485.34 ms /    41 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     955.71 ms /    27 tokens (   35.40 ms per token,    28.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =     836.85 ms /    17 runs   (   49.23 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    1794.90 ms /    44 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     926.25 ms /    31 tokens (   29.88 ms per token,    33.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =     928.90 ms /    19 runs   (   48.89 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    1857.92 ms /    50 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     797.94 ms /    27 tokens (   29.55 ms per token,    33.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1115.81 ms /    23 runs   (   48.51 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    1917.06 ms /    50 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     796.75 ms /    25 tokens (   31.87 ms per token,    31.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =     532.43 ms /    11 runs   (   48.40 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    1330.94 ms /    36 tokens\n",
      "Llama.generate: 44 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     272.30 ms /     8 tokens (   34.04 ms per token,    29.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1162.68 ms /    24 runs   (   48.45 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    1438.42 ms /    32 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     826.34 ms /    28 tokens (   29.51 ms per token,    33.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =     776.30 ms /    16 runs   (   48.52 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    1605.10 ms /    44 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     246.97 ms /     7 tokens (   35.28 ms per token,    28.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1028.79 ms /    21 runs   (   48.99 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    1279.02 ms /    28 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     614.97 ms /    21 tokens (   29.28 ms per token,    34.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =     685.55 ms /    14 runs   (   48.97 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    1302.67 ms /    35 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     771.06 ms /    23 tokens (   33.52 ms per token,    29.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =     577.95 ms /    12 runs   (   48.16 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1350.78 ms /    35 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1005.67 ms /    30 tokens (   33.52 ms per token,    29.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1123.76 ms /    23 runs   (   48.86 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    2132.81 ms /    53 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     869.90 ms /    28 tokens (   31.07 ms per token,    32.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1160.22 ms /    24 runs   (   48.34 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    2033.42 ms /    52 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     792.20 ms /    27 tokens (   29.34 ms per token,    34.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =     968.27 ms /    20 runs   (   48.41 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    1763.31 ms /    47 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     807.68 ms /    28 tokens (   28.85 ms per token,    34.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =     776.54 ms /    16 runs   (   48.53 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    1586.73 ms /    44 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     900.95 ms /    29 tokens (   31.07 ms per token,    32.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1134.65 ms /    23 runs   (   49.33 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    2038.85 ms /    52 tokens\n",
      "Llama.generate: 29 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1622.37 ms /    44 tokens (   36.87 ms per token,    27.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =     782.57 ms /    16 runs   (   48.91 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    2407.53 ms /    60 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     565.04 ms /    19 tokens (   29.74 ms per token,    33.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =     535.85 ms /    11 runs   (   48.71 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    1102.66 ms /    30 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     741.27 ms /    24 tokens (   30.89 ms per token,    32.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =     680.46 ms /    14 runs   (   48.60 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    1423.99 ms /    38 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     641.44 ms /    21 tokens (   30.54 ms per token,    32.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =     630.40 ms /    13 runs   (   48.49 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    1273.94 ms /    34 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1494.76 ms /    32 tokens (   46.71 ms per token,    21.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1376.81 ms /    28 runs   (   49.17 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    2875.71 ms /    60 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     655.57 ms /    22 tokens (   29.80 ms per token,    33.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =     792.30 ms /    16 runs   (   49.52 ms per token,    20.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    1450.19 ms /    38 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     639.19 ms /    21 tokens (   30.44 ms per token,    32.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =     785.27 ms /    16 runs   (   49.08 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    1426.95 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     621.36 ms /    20 tokens (   31.07 ms per token,    32.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =     681.43 ms /    14 runs   (   48.67 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1305.00 ms /    34 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     828.17 ms /    25 tokens (   33.13 ms per token,    30.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =     844.71 ms /    17 runs   (   49.69 ms per token,    20.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    1675.46 ms /    42 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     785.20 ms /    22 tokens (   35.69 ms per token,    28.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =     778.25 ms /    16 runs   (   48.64 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    1565.81 ms /    38 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     993.49 ms /    26 tokens (   38.21 ms per token,    26.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1034.72 ms /    21 runs   (   49.27 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    2031.26 ms /    47 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     833.45 ms /    20 tokens (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =     840.36 ms /    17 runs   (   49.43 ms per token,    20.23 tokens per second)\n",
      "llama_perf_context_print:       total time =    1676.43 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1038.48 ms /    26 tokens (   39.94 ms per token,    25.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =     938.57 ms /    19 runs   (   49.40 ms per token,    20.24 tokens per second)\n",
      "llama_perf_context_print:       total time =    1979.87 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     882.44 ms /    20 tokens (   44.12 ms per token,    22.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =     700.60 ms /    14 runs   (   50.04 ms per token,    19.98 tokens per second)\n",
      "llama_perf_context_print:       total time =    1585.21 ms /    34 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1145.33 ms /    25 tokens (   45.81 ms per token,    21.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1041.28 ms /    21 runs   (   49.58 ms per token,    20.17 tokens per second)\n",
      "llama_perf_context_print:       total time =    2189.71 ms /    46 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     914.26 ms /    25 tokens (   36.57 ms per token,    27.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1183.39 ms /    24 runs   (   49.31 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    2101.17 ms /    49 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     913.45 ms /    24 tokens (   38.06 ms per token,    26.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =     899.16 ms /    18 runs   (   49.95 ms per token,    20.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    1815.35 ms /    42 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     880.12 ms /    21 tokens (   41.91 ms per token,    23.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =     837.77 ms /    17 runs   (   49.28 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    1720.51 ms /    38 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     935.36 ms /    25 tokens (   37.41 ms per token,    26.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1040.50 ms /    21 runs   (   49.55 ms per token,    20.18 tokens per second)\n",
      "llama_perf_context_print:       total time =    1979.05 ms /    46 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     773.02 ms /    20 tokens (   38.65 ms per token,    25.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =     715.04 ms /    14 runs   (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    1490.31 ms /    34 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     967.80 ms /    26 tokens (   37.22 ms per token,    26.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =     803.47 ms /    16 runs   (   50.22 ms per token,    19.91 tokens per second)\n",
      "llama_perf_context_print:       total time =    1773.81 ms /    42 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1040.73 ms /    25 tokens (   41.63 ms per token,    24.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1010.61 ms /    20 runs   (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    2054.33 ms /    45 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     966.19 ms /    25 tokens (   38.65 ms per token,    25.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1195.89 ms /    24 runs   (   49.83 ms per token,    20.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    2165.65 ms /    49 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     941.46 ms /    24 tokens (   39.23 ms per token,    25.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =     986.61 ms /    20 runs   (   49.33 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    1931.18 ms /    44 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1039.98 ms /    29 tokens (   35.86 ms per token,    27.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1241.31 ms /    25 runs   (   49.65 ms per token,    20.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    2285.02 ms /    54 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1046.85 ms /    26 tokens (   40.26 ms per token,    24.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1895.91 ms /    38 runs   (   49.89 ms per token,    20.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    2948.34 ms /    64 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1064.10 ms /    30 tokens (   35.47 ms per token,    28.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =     938.41 ms /    19 runs   (   49.39 ms per token,    20.25 tokens per second)\n",
      "llama_perf_context_print:       total time =    2005.38 ms /    49 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     675.00 ms /    12 tokens (   56.25 ms per token,    17.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =     932.11 ms /    19 runs   (   49.06 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    1609.89 ms /    31 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     838.85 ms /    20 tokens (   41.94 ms per token,    23.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =     636.98 ms /    13 runs   (   49.00 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    1477.92 ms /    33 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     679.20 ms /    18 tokens (   37.73 ms per token,    26.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =     634.95 ms /    13 runs   (   48.84 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    1316.23 ms /    31 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1652.31 ms /    32 tokens (   51.63 ms per token,    19.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1155.52 ms /    23 runs   (   50.24 ms per token,    19.90 tokens per second)\n",
      "llama_perf_context_print:       total time =    2811.33 ms /    55 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     861.28 ms /    24 tokens (   35.89 ms per token,    27.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =     748.21 ms /    15 runs   (   49.88 ms per token,    20.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    1611.86 ms /    39 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     946.32 ms /    27 tokens (   35.05 ms per token,    28.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =     862.99 ms /    17 runs   (   50.76 ms per token,    19.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1812.01 ms /    44 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     895.86 ms /    22 tokens (   40.72 ms per token,    24.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =     540.44 ms /    11 runs   (   49.13 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    1437.95 ms /    33 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     982.56 ms /    26 tokens (   37.79 ms per token,    26.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1134.82 ms /    23 runs   (   49.34 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    2120.77 ms /    49 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1041.63 ms /    28 tokens (   37.20 ms per token,    26.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1041.95 ms /    21 runs   (   49.62 ms per token,    20.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    2086.69 ms /    49 tokens\n",
      "Llama.generate: 31 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     680.21 ms /    15 tokens (   45.35 ms per token,    22.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =     645.85 ms /    13 runs   (   49.68 ms per token,    20.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    1328.15 ms /    28 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1048.36 ms /    29 tokens (   36.15 ms per token,    27.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1135.47 ms /    23 runs   (   49.37 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    2187.21 ms /    52 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     936.79 ms /    24 tokens (   39.03 ms per token,    25.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =     922.00 ms /    19 runs   (   48.53 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    1861.51 ms /    43 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     736.25 ms /    19 tokens (   38.75 ms per token,    25.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =     559.26 ms /    11 runs   (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    1297.36 ms /    30 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     848.47 ms /    23 tokens (   36.89 ms per token,    27.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1371.98 ms /    28 runs   (   49.00 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    2224.55 ms /    51 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     864.12 ms /    24 tokens (   36.01 ms per token,    27.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1318.55 ms /    27 runs   (   48.84 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    2186.65 ms /    51 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     790.81 ms /    20 tokens (   39.54 ms per token,    25.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =     937.57 ms /    19 runs   (   49.35 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    1731.26 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     680.11 ms /    20 tokens (   34.01 ms per token,    29.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =     659.10 ms /    13 runs   (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1341.30 ms /    33 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     317.78 ms /     6 tokens (   52.96 ms per token,    18.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =     643.59 ms /    13 runs   (   49.51 ms per token,    20.20 tokens per second)\n",
      "llama_perf_context_print:       total time =     963.39 ms /    19 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1026.11 ms /    28 tokens (   36.65 ms per token,    27.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =     984.83 ms /    20 runs   (   49.24 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    2013.96 ms /    48 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     772.75 ms /    18 tokens (   42.93 ms per token,    23.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =     801.48 ms /    16 runs   (   50.09 ms per token,    19.96 tokens per second)\n",
      "llama_perf_context_print:       total time =    1576.73 ms /    34 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     736.89 ms /    19 tokens (   38.78 ms per token,    25.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =     693.73 ms /    14 runs   (   49.55 ms per token,    20.18 tokens per second)\n",
      "llama_perf_context_print:       total time =    1432.82 ms /    33 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     704.08 ms /    19 tokens (   37.06 ms per token,    26.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =     798.09 ms /    16 runs   (   49.88 ms per token,    20.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    1504.63 ms /    35 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1795.14 ms /    43 tokens (   41.75 ms per token,    23.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =     591.43 ms /    12 runs   (   49.29 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    2388.82 ms /    55 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1103.97 ms /    30 tokens (   36.80 ms per token,    27.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =     943.30 ms /    19 runs   (   49.65 ms per token,    20.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    2049.98 ms /    49 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1035.90 ms /    24 tokens (   43.16 ms per token,    23.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =     689.37 ms /    14 runs   (   49.24 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    1727.39 ms /    38 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     954.83 ms /    28 tokens (   34.10 ms per token,    29.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1872.59 ms /    38 runs   (   49.28 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    2832.98 ms /    66 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1094.08 ms /    26 tokens (   42.08 ms per token,    23.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =     931.41 ms /    19 runs   (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    2028.38 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 331 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    3778.91 ms /   331 tokens (   11.42 ms per token,    87.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1063.71 ms /    21 runs   (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    4846.22 ms /   352 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1026.47 ms /    29 tokens (   35.40 ms per token,    28.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1045.60 ms /    21 runs   (   49.79 ms per token,    20.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    2075.29 ms /    50 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1951.12 ms /    50 tokens (   39.02 ms per token,    25.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2039.55 ms /    41 runs   (   49.75 ms per token,    20.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    3997.10 ms /    91 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     862.50 ms /    22 tokens (   39.20 ms per token,    25.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =     787.03 ms /    16 runs   (   49.19 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    1651.93 ms /    38 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1013.61 ms /    28 tokens (   36.20 ms per token,    27.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =     833.23 ms /    17 runs   (   49.01 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    1849.48 ms /    45 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     738.92 ms /    17 tokens (   43.47 ms per token,    23.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1145.42 ms /    23 runs   (   49.80 ms per token,    20.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    1887.76 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     789.34 ms /    21 tokens (   37.59 ms per token,    26.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =     988.62 ms /    20 runs   (   49.43 ms per token,    20.23 tokens per second)\n",
      "llama_perf_context_print:       total time =    1780.92 ms /    41 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1684.82 ms /    33 tokens (   51.05 ms per token,    19.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1035.37 ms /    21 runs   (   49.30 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    2723.52 ms /    54 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     955.80 ms /    27 tokens (   35.40 ms per token,    28.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =     835.96 ms /    17 runs   (   49.17 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    1794.23 ms /    44 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     633.01 ms /    15 tokens (   42.20 ms per token,    23.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =     982.80 ms /    20 runs   (   49.14 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    1618.77 ms /    35 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1803.94 ms /    35 tokens (   51.54 ms per token,    19.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1717.10 ms /    35 runs   (   49.06 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    3526.40 ms /    70 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     657.59 ms /    19 tokens (   34.61 ms per token,    28.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1273.19 ms /    26 runs   (   48.97 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    1934.56 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     865.36 ms /    25 tokens (   34.61 ms per token,    28.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =     808.01 ms /    16 runs   (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1675.90 ms /    41 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     643.16 ms /    12 tokens (   53.60 ms per token,    18.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1385.17 ms /    28 runs   (   49.47 ms per token,    20.21 tokens per second)\n",
      "llama_perf_context_print:       total time =    2032.48 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     948.65 ms /    26 tokens (   36.49 ms per token,    27.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =     853.78 ms /    17 runs   (   50.22 ms per token,    19.91 tokens per second)\n",
      "llama_perf_context_print:       total time =    1805.10 ms /    43 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     939.57 ms /    25 tokens (   37.58 ms per token,    26.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =     589.25 ms /    12 runs   (   49.10 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    1530.69 ms /    37 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     930.83 ms /    25 tokens (   37.23 ms per token,    26.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1087.22 ms /    22 runs   (   49.42 ms per token,    20.24 tokens per second)\n",
      "llama_perf_context_print:       total time =    2021.21 ms /    47 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     554.05 ms /    14 tokens (   39.57 ms per token,    25.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =     636.94 ms /    13 runs   (   49.00 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    1193.05 ms /    27 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1016.37 ms /    27 tokens (   37.64 ms per token,    26.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =     991.55 ms /    20 runs   (   49.58 ms per token,    20.17 tokens per second)\n",
      "llama_perf_context_print:       total time =    2010.86 ms /    47 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1023.26 ms /    29 tokens (   35.28 ms per token,    28.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1227.89 ms /    25 runs   (   49.12 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    2254.82 ms /    54 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1019.90 ms /    25 tokens (   40.80 ms per token,    24.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =     786.64 ms /    16 runs   (   49.17 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    1808.94 ms /    41 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     306.70 ms /     6 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =     597.38 ms /    12 runs   (   49.78 ms per token,    20.09 tokens per second)\n",
      "llama_perf_context_print:       total time =     906.03 ms /    18 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     559.46 ms /    13 tokens (   43.04 ms per token,    23.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =     978.19 ms /    20 runs   (   48.91 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    1540.55 ms /    33 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     927.14 ms /    27 tokens (   34.34 ms per token,    29.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =     994.50 ms /    20 runs   (   49.72 ms per token,    20.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    1924.59 ms /    47 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1088.63 ms /    31 tokens (   35.12 ms per token,    28.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =     898.20 ms /    18 runs   (   49.90 ms per token,    20.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    1989.61 ms /    49 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     958.15 ms /    28 tokens (   34.22 ms per token,    29.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1082.23 ms /    22 runs   (   49.19 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    2043.62 ms /    50 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1053.42 ms /    30 tokens (   35.11 ms per token,    28.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =     876.96 ms /    18 runs   (   48.72 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    1933.06 ms /    48 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     986.06 ms /    27 tokens (   36.52 ms per token,    27.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =     777.45 ms /    16 runs   (   48.59 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    1765.95 ms /    43 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 9 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 34 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     596.73 ms /    16 tokens (   37.30 ms per token,    26.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =     933.80 ms /    19 runs   (   49.15 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    1533.93 ms /    35 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     873.49 ms /    25 tokens (   34.94 ms per token,    28.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =     975.24 ms /    20 runs   (   48.76 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    1851.59 ms /    45 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     917.37 ms /    24 tokens (   38.22 ms per token,    26.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =     700.93 ms /    14 runs   (   50.07 ms per token,    19.97 tokens per second)\n",
      "llama_perf_context_print:       total time =    1620.50 ms /    38 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     525.37 ms /    14 tokens (   37.53 ms per token,    26.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =     583.85 ms /    12 runs   (   48.65 ms per token,    20.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    1111.10 ms /    26 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1161.10 ms /    31 tokens (   37.45 ms per token,    26.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =     631.44 ms /    13 runs   (   48.57 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    1794.52 ms /    44 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1081.14 ms /    30 tokens (   36.04 ms per token,    27.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1175.77 ms /    24 runs   (   48.99 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    2260.38 ms /    54 tokens\n",
      "Llama.generate: 31 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     563.34 ms /    14 tokens (   40.24 ms per token,    24.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =     690.55 ms /    14 runs   (   49.32 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    1256.09 ms /    28 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1026.14 ms /    30 tokens (   34.20 ms per token,    29.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1224.74 ms /    25 runs   (   48.99 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    2254.52 ms /    55 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1043.98 ms /    29 tokens (   36.00 ms per token,    27.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1091.65 ms /    22 runs   (   49.62 ms per token,    20.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    2138.80 ms /    51 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     831.96 ms /    23 tokens (   36.17 ms per token,    27.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =     920.45 ms /    19 runs   (   48.44 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    1755.06 ms /    42 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     908.00 ms /    24 tokens (   37.83 ms per token,    26.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1023.93 ms /    21 runs   (   48.76 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    1934.96 ms /    45 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     893.12 ms /    23 tokens (   38.83 ms per token,    25.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =     644.71 ms /    13 runs   (   49.59 ms per token,    20.16 tokens per second)\n",
      "llama_perf_context_print:       total time =    1539.84 ms /    36 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     787.74 ms /    22 tokens (   35.81 ms per token,    27.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1071.49 ms /    22 runs   (   48.70 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    1862.44 ms /    44 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     817.05 ms /    23 tokens (   35.52 ms per token,    28.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =     874.55 ms /    18 runs   (   48.59 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    1694.27 ms /    41 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1748.57 ms /    48 tokens (   36.43 ms per token,    27.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =     963.35 ms /    19 runs   (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    2715.23 ms /    67 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1670.02 ms /    36 tokens (   46.39 ms per token,    21.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1572.80 ms /    32 runs   (   49.15 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    3247.76 ms /    68 tokens\n",
      "Llama.generate: 30 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     532.30 ms /    13 tokens (   40.95 ms per token,    24.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =     689.78 ms /    14 runs   (   49.27 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    1224.21 ms /    27 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     660.67 ms /    17 tokens (   38.86 ms per token,    25.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1578.67 ms /    32 runs   (   49.33 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    2244.03 ms /    49 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1038.40 ms /    29 tokens (   35.81 ms per token,    27.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =     885.47 ms /    18 runs   (   49.19 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    1926.64 ms /    47 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     983.81 ms /    25 tokens (   39.35 ms per token,    25.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =     891.28 ms /    18 runs   (   49.52 ms per token,    20.20 tokens per second)\n",
      "llama_perf_context_print:       total time =    1877.88 ms /    43 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     475.12 ms /    12 tokens (   39.59 ms per token,    25.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =     870.56 ms /    18 runs   (   48.36 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1348.22 ms /    30 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     675.68 ms /    21 tokens (   32.18 ms per token,    31.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =     627.54 ms /    13 runs   (   48.27 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1305.10 ms /    34 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     868.21 ms /    26 tokens (   33.39 ms per token,    29.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =     887.78 ms /    18 runs   (   49.32 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    1758.61 ms /    44 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     895.97 ms /    22 tokens (   40.73 ms per token,    24.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1142.18 ms /    23 runs   (   49.66 ms per token,    20.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    2041.51 ms /    45 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     839.54 ms /    22 tokens (   38.16 ms per token,    26.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =     438.46 ms /     9 runs   (   48.72 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    1279.51 ms /    31 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     428.57 ms /    12 tokens (   35.71 ms per token,    28.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =     538.76 ms /    11 runs   (   48.98 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =     969.04 ms /    23 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1027.04 ms /    30 tokens (   34.23 ms per token,    29.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =     975.32 ms /    20 runs   (   48.77 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    2005.19 ms /    50 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1641.45 ms /    62 tokens (   26.48 ms per token,    37.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2872.27 ms /    58 runs   (   49.52 ms per token,    20.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    4522.29 ms /   120 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1850.70 ms /    74 tokens (   25.01 ms per token,    39.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3199.43 ms /    65 runs   (   49.22 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    5060.34 ms /   139 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     783.98 ms /    27 tokens (   29.04 ms per token,    34.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1028.23 ms /    21 runs   (   48.96 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    1815.23 ms /    48 tokens\n",
      "Llama.generate: 30 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     742.81 ms /    25 tokens (   29.71 ms per token,    33.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =     980.65 ms /    20 runs   (   49.03 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    1726.37 ms /    45 tokens\n",
      "Llama.generate: 32 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     860.53 ms /    21 tokens (   40.98 ms per token,    24.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1130.43 ms /    23 runs   (   49.15 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    1994.29 ms /    44 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1501.10 ms /    32 tokens (   46.91 ms per token,    21.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1097.88 ms /    22 runs   (   49.90 ms per token,    20.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    2602.47 ms /    54 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     872.77 ms /    27 tokens (   32.32 ms per token,    30.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1182.51 ms /    24 runs   (   49.27 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    2058.95 ms /    51 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     920.31 ms /    28 tokens (   32.87 ms per token,    30.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1371.17 ms /    28 runs   (   48.97 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    2295.50 ms /    56 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1616.74 ms /    33 tokens (   48.99 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1320.38 ms /    27 runs   (   48.90 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    2941.17 ms /    60 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1706.51 ms /    34 tokens (   50.19 ms per token,    19.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1513.24 ms /    31 runs   (   48.81 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    3224.70 ms /    65 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1474.73 ms /    32 tokens (   46.09 ms per token,    21.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1181.87 ms /    24 runs   (   49.24 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    2660.25 ms /    56 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     875.61 ms /    30 tokens (   29.19 ms per token,    34.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1282.25 ms /    26 runs   (   49.32 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    2161.68 ms /    56 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     804.23 ms /    27 tokens (   29.79 ms per token,    33.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1625.98 ms /    33 runs   (   49.27 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    2435.05 ms /    60 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1546.27 ms /    32 tokens (   48.32 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1092.04 ms /    22 runs   (   49.64 ms per token,    20.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    2641.56 ms /    54 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     921.55 ms /    30 tokens (   30.72 ms per token,    32.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1272.00 ms /    26 runs   (   48.92 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    2197.24 ms /    56 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     905.18 ms /    28 tokens (   32.33 ms per token,    30.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =     830.61 ms /    17 runs   (   48.86 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    1738.41 ms /    45 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     238.91 ms /     7 tokens (   34.13 ms per token,    29.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =     932.76 ms /    19 runs   (   49.09 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    1174.46 ms /    26 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     255.92 ms /     7 tokens (   36.56 ms per token,    27.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =     883.87 ms /    18 runs   (   49.10 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    1142.44 ms /    25 tokens\n",
      "Llama.generate: 31 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     477.84 ms /    15 tokens (   31.86 ms per token,    31.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1297.77 ms /    26 runs   (   49.91 ms per token,    20.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    1779.42 ms /    41 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1594.98 ms /    34 tokens (   46.91 ms per token,    21.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1089.29 ms /    22 runs   (   49.51 ms per token,    20.20 tokens per second)\n",
      "llama_perf_context_print:       total time =    2687.70 ms /    56 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     470.00 ms /    15 tokens (   31.33 ms per token,    31.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =     878.95 ms /    18 runs   (   48.83 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    1351.63 ms /    33 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     300.41 ms /     8 tokens (   37.55 ms per token,    26.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =     930.80 ms /    19 runs   (   48.99 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    1233.87 ms /    27 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     711.67 ms /    24 tokens (   29.65 ms per token,    33.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =     586.59 ms /    12 runs   (   48.88 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    1300.15 ms /    36 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     788.12 ms /    26 tokens (   30.31 ms per token,    32.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =     832.31 ms /    17 runs   (   48.96 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    1622.83 ms /    43 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     894.91 ms /    31 tokens (   28.87 ms per token,    34.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =     985.62 ms /    20 runs   (   49.28 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    1883.45 ms /    51 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     864.15 ms /    27 tokens (   32.01 ms per token,    31.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1027.20 ms /    21 runs   (   48.91 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    1894.45 ms /    48 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     891.94 ms /    30 tokens (   29.73 ms per token,    33.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1514.62 ms /    31 runs   (   48.86 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    2410.86 ms /    61 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     752.38 ms /    25 tokens (   30.10 ms per token,    33.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =     984.75 ms /    20 runs   (   49.24 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    1740.10 ms /    45 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     964.70 ms /    31 tokens (   31.12 ms per token,    32.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1516.21 ms /    31 runs   (   48.91 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    2485.34 ms /    62 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     883.35 ms /    30 tokens (   29.44 ms per token,    33.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =     989.32 ms /    20 runs   (   49.47 ms per token,    20.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    1875.72 ms /    50 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     782.79 ms /    24 tokens (   32.62 ms per token,    30.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =     640.41 ms /    13 runs   (   49.26 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    1425.37 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     912.97 ms /    25 tokens (   36.52 ms per token,    27.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1122.01 ms /    23 runs   (   48.78 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    2038.31 ms /    48 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1735.04 ms /    33 tokens (   52.58 ms per token,    19.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =     899.50 ms /    18 runs   (   49.97 ms per token,    20.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    2637.39 ms /    51 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     847.85 ms /    28 tokens (   30.28 ms per token,    33.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1279.35 ms /    26 runs   (   49.21 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    2131.08 ms /    54 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     878.08 ms /    26 tokens (   33.77 ms per token,    29.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =     848.62 ms /    17 runs   (   49.92 ms per token,    20.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    1729.34 ms /    43 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1788.47 ms /    33 tokens (   54.20 ms per token,    18.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =     684.97 ms /    14 runs   (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    2475.84 ms /    47 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     936.75 ms /    31 tokens (   30.22 ms per token,    33.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1038.42 ms /    21 runs   (   49.45 ms per token,    20.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    1978.44 ms /    52 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1686.87 ms /    37 tokens (   45.59 ms per token,    21.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1930.03 ms /    39 runs   (   49.49 ms per token,    20.21 tokens per second)\n",
      "llama_perf_context_print:       total time =    3622.65 ms /    76 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     878.02 ms /    24 tokens (   36.58 ms per token,    27.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =     902.24 ms /    18 runs   (   50.12 ms per token,    19.95 tokens per second)\n",
      "llama_perf_context_print:       total time =    1782.97 ms /    42 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1809.91 ms /    33 tokens (   54.85 ms per token,    18.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =     892.79 ms /    18 runs   (   49.60 ms per token,    20.16 tokens per second)\n",
      "llama_perf_context_print:       total time =    2705.58 ms /    51 tokens\n",
      "Llama.generate: 32 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     406.81 ms /     9 tokens (   45.20 ms per token,    22.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =     843.81 ms /    17 runs   (   49.64 ms per token,    20.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    1253.15 ms /    26 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1726.88 ms /    37 tokens (   46.67 ms per token,    21.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1537.99 ms /    31 runs   (   49.61 ms per token,    20.16 tokens per second)\n",
      "llama_perf_context_print:       total time =    3269.75 ms /    68 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     510.81 ms /    16 tokens (   31.93 ms per token,    31.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1491.36 ms /    30 runs   (   49.71 ms per token,    20.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    2006.51 ms /    46 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     965.65 ms /    28 tokens (   34.49 ms per token,    29.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1027.49 ms /    21 runs   (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    1996.26 ms /    49 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     648.04 ms /    19 tokens (   34.11 ms per token,    29.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =     996.35 ms /    20 runs   (   49.82 ms per token,    20.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    1647.26 ms /    39 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     884.31 ms /    27 tokens (   32.75 ms per token,    30.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =     927.33 ms /    19 runs   (   48.81 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    1814.50 ms /    46 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     881.77 ms /    26 tokens (   33.91 ms per token,    29.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =     786.11 ms /    16 runs   (   49.13 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    1670.37 ms /    42 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     255.57 ms /     7 tokens (   36.51 ms per token,    27.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =     941.63 ms /    19 runs   (   49.56 ms per token,    20.18 tokens per second)\n",
      "llama_perf_context_print:       total time =    1199.91 ms /    26 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1029.12 ms /    30 tokens (   34.30 ms per token,    29.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1131.44 ms /    23 runs   (   49.19 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    2163.94 ms /    53 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1003.51 ms /    26 tokens (   38.60 ms per token,    25.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =     936.30 ms /    19 runs   (   49.28 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    1942.58 ms /    45 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     492.93 ms /    12 tokens (   41.08 ms per token,    24.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =     975.61 ms /    20 runs   (   48.78 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    1471.44 ms /    32 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1597.77 ms /    32 tokens (   49.93 ms per token,    20.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =     935.90 ms /    19 runs   (   49.26 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    2536.59 ms /    51 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1069.52 ms /    30 tokens (   35.65 ms per token,    28.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1541.06 ms /    31 runs   (   49.71 ms per token,    20.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    2615.27 ms /    61 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     961.05 ms /    28 tokens (   34.32 ms per token,    29.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1057.00 ms /    21 runs   (   50.33 ms per token,    19.87 tokens per second)\n",
      "llama_perf_context_print:       total time =    2021.22 ms /    49 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1734.26 ms /    34 tokens (   51.01 ms per token,    19.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1033.81 ms /    21 runs   (   49.23 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    2771.67 ms /    55 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1000.99 ms /    29 tokens (   34.52 ms per token,    28.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =     734.34 ms /    15 runs   (   48.96 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    1737.76 ms /    44 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     912.11 ms /    30 tokens (   30.40 ms per token,    32.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1384.45 ms /    28 runs   (   49.44 ms per token,    20.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    2300.75 ms /    58 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     895.87 ms /    24 tokens (   37.33 ms per token,    26.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =     983.65 ms /    20 runs   (   49.18 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    1882.53 ms /    44 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     785.73 ms /    24 tokens (   32.74 ms per token,    30.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =     886.21 ms /    18 runs   (   49.23 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    1674.74 ms /    42 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1005.85 ms /    31 tokens (   32.45 ms per token,    30.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =     978.43 ms /    20 runs   (   48.92 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    1987.43 ms /    51 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     468.36 ms /    12 tokens (   39.03 ms per token,    25.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =     932.73 ms /    19 runs   (   49.09 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    1404.05 ms /    31 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     936.44 ms /    26 tokens (   36.02 ms per token,    27.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1138.56 ms /    16 runs   (   71.16 ms per token,    14.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    2077.34 ms /    42 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     538.00 ms /     7 tokens (   76.86 ms per token,    13.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =     793.63 ms /    16 runs   (   49.60 ms per token,    20.16 tokens per second)\n",
      "llama_perf_context_print:       total time =    1334.02 ms /    23 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     960.78 ms /    27 tokens (   35.58 ms per token,    28.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =     947.59 ms /    19 runs   (   49.87 ms per token,    20.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    1911.27 ms /    46 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     397.45 ms /    11 tokens (   36.13 ms per token,    27.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =     836.90 ms /    17 runs   (   49.23 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    1236.84 ms /    28 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     460.50 ms /    11 tokens (   41.86 ms per token,    23.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =     977.45 ms /    20 runs   (   48.87 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    1440.88 ms /    31 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     762.64 ms /    24 tokens (   31.78 ms per token,    31.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =     685.05 ms /    14 runs   (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    1449.93 ms /    38 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1628.41 ms /    32 tokens (   50.89 ms per token,    19.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1575.37 ms /    32 runs   (   49.23 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    3208.64 ms /    64 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     814.10 ms /    25 tokens (   32.56 ms per token,    30.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1024.20 ms /    21 runs   (   48.77 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    1841.46 ms /    46 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     876.90 ms /    29 tokens (   30.24 ms per token,    33.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1376.18 ms /    28 runs   (   49.15 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    2257.25 ms /    57 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     823.56 ms /    28 tokens (   29.41 ms per token,    34.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =     982.15 ms /    20 runs   (   49.11 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    1808.51 ms /    48 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1652.55 ms /    39 tokens (   42.37 ms per token,    23.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1033.85 ms /    21 runs   (   49.23 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    2689.54 ms /    60 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     898.51 ms /    22 tokens (   40.84 ms per token,    24.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =     726.89 ms /    15 runs   (   48.46 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    1627.55 ms /    37 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 10 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 20 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1620.20 ms /    37 tokens (   43.79 ms per token,    22.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1603.66 ms /    33 runs   (   48.60 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    3229.94 ms /    70 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     515.37 ms /    16 tokens (   32.21 ms per token,    31.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =     985.25 ms /    20 runs   (   49.26 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    1503.66 ms /    36 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     672.03 ms /    24 tokens (   28.00 ms per token,    35.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =     826.94 ms /    17 runs   (   48.64 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    1501.47 ms /    41 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1612.35 ms /    34 tokens (   47.42 ms per token,    21.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1022.44 ms /    21 runs   (   48.69 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    2638.51 ms /    55 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1125.19 ms /    27 tokens (   41.67 ms per token,    24.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1188.66 ms /    24 runs   (   49.53 ms per token,    20.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    2317.47 ms /    51 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1843.06 ms /    33 tokens (   55.85 ms per token,    17.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1031.14 ms /    20 runs   (   51.56 ms per token,    19.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    2877.36 ms /    53 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1846.90 ms /    33 tokens (   55.97 ms per token,    17.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1476.17 ms /    30 runs   (   49.21 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    3327.56 ms /    63 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1036.36 ms /    28 tokens (   37.01 ms per token,    27.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1047.61 ms /    21 runs   (   49.89 ms per token,    20.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    2087.11 ms /    49 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2027.61 ms /    35 tokens (   57.93 ms per token,    17.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1782.04 ms /    36 runs   (   49.50 ms per token,    20.20 tokens per second)\n",
      "llama_perf_context_print:       total time =    3815.13 ms /    71 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1663.56 ms /    32 tokens (   51.99 ms per token,    19.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1151.34 ms /    23 runs   (   50.06 ms per token,    19.98 tokens per second)\n",
      "llama_perf_context_print:       total time =    2818.65 ms /    55 tokens\n",
      "Llama.generate: 48 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     344.32 ms /     7 tokens (   49.19 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =     936.08 ms /    19 runs   (   49.27 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    1283.24 ms /    26 tokens\n",
      "Llama.generate: 47 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     358.12 ms /     7 tokens (   51.16 ms per token,    19.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =     981.60 ms /    20 runs   (   49.08 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    1342.63 ms /    27 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     950.46 ms /    25 tokens (   38.02 ms per token,    26.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =     938.11 ms /    19 runs   (   49.37 ms per token,    20.25 tokens per second)\n",
      "llama_perf_context_print:       total time =    1891.32 ms /    44 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1133.96 ms /    30 tokens (   37.80 ms per token,    26.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1138.11 ms /    23 runs   (   49.48 ms per token,    20.21 tokens per second)\n",
      "llama_perf_context_print:       total time =    2275.46 ms /    53 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     892.37 ms /    21 tokens (   42.49 ms per token,    23.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1182.35 ms /    24 runs   (   49.26 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    2078.20 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1103.84 ms /    30 tokens (   36.79 ms per token,    27.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1015.11 ms /    21 runs   (   48.34 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    2121.97 ms /    51 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     517.63 ms /    14 tokens (   36.97 ms per token,    27.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1208.77 ms /    25 runs   (   48.35 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1729.71 ms /    39 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     293.42 ms /     6 tokens (   48.90 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1111.14 ms /    23 runs   (   48.31 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1407.61 ms /    29 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1690.92 ms /    41 tokens (   41.24 ms per token,    24.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1720.11 ms /    35 runs   (   49.15 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    3416.09 ms /    76 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1041.64 ms /    30 tokens (   34.72 ms per token,    28.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1211.21 ms /    25 runs   (   48.45 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    2256.15 ms /    55 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     820.44 ms /    19 tokens (   43.18 ms per token,    23.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1072.49 ms /    22 runs   (   48.75 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    1896.06 ms /    41 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1635.04 ms /    33 tokens (   49.55 ms per token,    20.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1331.18 ms /    27 runs   (   49.30 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    2970.31 ms /    60 tokens\n",
      "Llama.generate: 45 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     434.48 ms /    12 tokens (   36.21 ms per token,    27.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1475.49 ms /    30 runs   (   49.18 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    1914.24 ms /    42 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1659.99 ms /    35 tokens (   47.43 ms per token,    21.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1125.57 ms /    23 runs   (   48.94 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    2789.13 ms /    58 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     990.31 ms /    30 tokens (   33.01 ms per token,    30.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1096.26 ms /    22 runs   (   49.83 ms per token,    20.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    2089.95 ms /    52 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1514.70 ms /    32 tokens (   47.33 ms per token,    21.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1034.46 ms /    21 runs   (   49.26 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    2552.44 ms /    53 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1645.22 ms /    33 tokens (   49.86 ms per token,    20.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =     948.56 ms /    19 runs   (   49.92 ms per token,    20.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    2596.72 ms /    52 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1010.45 ms /    28 tokens (   36.09 ms per token,    27.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =     842.22 ms /    17 runs   (   49.54 ms per token,    20.18 tokens per second)\n",
      "llama_perf_context_print:       total time =    1855.16 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     792.74 ms /    23 tokens (   34.47 ms per token,    29.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =     651.94 ms /    13 runs   (   50.15 ms per token,    19.94 tokens per second)\n",
      "llama_perf_context_print:       total time =    1446.92 ms /    36 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     899.68 ms /    26 tokens (   34.60 ms per token,    28.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =     952.00 ms /    19 runs   (   50.11 ms per token,    19.96 tokens per second)\n",
      "llama_perf_context_print:       total time =    1854.57 ms /    45 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     392.87 ms /    10 tokens (   39.29 ms per token,    25.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =     957.81 ms /    19 runs   (   50.41 ms per token,    19.84 tokens per second)\n",
      "llama_perf_context_print:       total time =    1353.52 ms /    29 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     506.40 ms /    11 tokens (   46.04 ms per token,    21.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1220.89 ms /    24 runs   (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    1730.87 ms /    35 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     942.77 ms /    25 tokens (   37.71 ms per token,    26.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =     915.91 ms /    18 runs   (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    1861.59 ms /    43 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     755.06 ms /    21 tokens (   35.96 ms per token,    27.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =     676.61 ms /    13 runs   (   52.05 ms per token,    19.21 tokens per second)\n",
      "llama_perf_context_print:       total time =    1433.76 ms /    34 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1024.72 ms /    28 tokens (   36.60 ms per token,    27.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =     919.18 ms /    18 runs   (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    1946.73 ms /    46 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     996.89 ms /    29 tokens (   34.38 ms per token,    29.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =     546.48 ms /    11 runs   (   49.68 ms per token,    20.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    1545.08 ms /    40 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     481.15 ms /    11 tokens (   43.74 ms per token,    22.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1259.61 ms /    25 runs   (   50.38 ms per token,    19.85 tokens per second)\n",
      "llama_perf_context_print:       total time =    1744.36 ms /    36 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     985.11 ms /    28 tokens (   35.18 ms per token,    28.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =     997.61 ms /    20 runs   (   49.88 ms per token,    20.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    1985.61 ms /    48 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1691.64 ms /    33 tokens (   51.26 ms per token,    19.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1507.37 ms /    30 runs   (   50.25 ms per token,    19.90 tokens per second)\n",
      "llama_perf_context_print:       total time =    3203.86 ms /    63 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     799.31 ms /    22 tokens (   36.33 ms per token,    27.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =     856.64 ms /    17 runs   (   50.39 ms per token,    19.84 tokens per second)\n",
      "llama_perf_context_print:       total time =    1658.46 ms /    39 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     443.65 ms /     9 tokens (   49.29 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =     796.49 ms /    16 runs   (   49.78 ms per token,    20.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    1242.52 ms /    25 tokens\n",
      "Llama.generate: 30 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     696.74 ms /    19 tokens (   36.67 ms per token,    27.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1051.12 ms /    21 runs   (   50.05 ms per token,    19.98 tokens per second)\n",
      "llama_perf_context_print:       total time =    1750.95 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     697.92 ms /    22 tokens (   31.72 ms per token,    31.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =     844.15 ms /    17 runs   (   49.66 ms per token,    20.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    1544.65 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     832.54 ms /    27 tokens (   30.83 ms per token,    32.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =     559.27 ms /    11 runs   (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    1393.57 ms /    38 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     792.49 ms /    26 tokens (   30.48 ms per token,    32.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =     644.39 ms /    13 runs   (   49.57 ms per token,    20.17 tokens per second)\n",
      "llama_perf_context_print:       total time =    1438.89 ms /    39 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     979.15 ms /    26 tokens (   37.66 ms per token,    26.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1047.53 ms /    21 runs   (   49.88 ms per token,    20.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    2029.65 ms /    47 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     780.82 ms /    25 tokens (   31.23 ms per token,    32.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1046.30 ms /    21 runs   (   49.82 ms per token,    20.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    1830.28 ms /    46 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     247.08 ms /     7 tokens (   35.30 ms per token,    28.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =     539.64 ms /    11 runs   (   49.06 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =     788.48 ms /    18 tokens\n",
      "Llama.generate: 33 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     515.91 ms /    16 tokens (   32.24 ms per token,    31.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1010.12 ms /    20 runs   (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1529.09 ms /    36 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     486.81 ms /    15 tokens (   32.45 ms per token,    30.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1055.61 ms /    21 runs   (   50.27 ms per token,    19.89 tokens per second)\n",
      "llama_perf_context_print:       total time =    1545.74 ms /    36 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     294.04 ms /     8 tokens (   36.76 ms per token,    27.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1058.38 ms /    21 runs   (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_perf_context_print:       total time =    1355.59 ms /    29 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     747.64 ms /    23 tokens (   32.51 ms per token,    30.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =     872.24 ms /    17 runs   (   51.31 ms per token,    19.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    1622.57 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     943.10 ms /    29 tokens (   32.52 ms per token,    30.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =     796.16 ms /    16 runs   (   49.76 ms per token,    20.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    1741.88 ms /    45 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     813.04 ms /    27 tokens (   30.11 ms per token,    33.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1046.13 ms /    21 runs   (   49.82 ms per token,    20.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    1862.46 ms /    48 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 79 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1876.45 ms /    79 tokens (   23.75 ms per token,    42.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3716.00 ms /    75 runs   (   49.55 ms per token,    20.18 tokens per second)\n",
      "llama_perf_context_print:       total time =    5603.80 ms /   154 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1893.20 ms /    74 tokens (   25.58 ms per token,    39.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3848.11 ms /    78 runs   (   49.33 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    5753.28 ms /   152 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 71 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1854.58 ms /    71 tokens (   26.12 ms per token,    38.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3060.22 ms /    62 runs   (   49.36 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    4924.10 ms /   133 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1743.18 ms /    59 tokens (   29.55 ms per token,    33.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =     592.62 ms /    12 runs   (   49.38 ms per token,    20.25 tokens per second)\n",
      "llama_perf_context_print:       total time =    2337.77 ms /    71 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1633.81 ms /    52 tokens (   31.42 ms per token,    31.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2038.07 ms /    42 runs   (   48.53 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    3678.09 ms /    94 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1669.41 ms /    37 tokens (   45.12 ms per token,    22.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1564.10 ms /    32 runs   (   48.88 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    3238.44 ms /    69 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 71 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1854.94 ms /    71 tokens (   26.13 ms per token,    38.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3041.86 ms /    62 runs   (   49.06 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    4906.31 ms /   133 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1612.05 ms /    42 tokens (   38.38 ms per token,    26.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1858.10 ms /    38 runs   (   48.90 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    3476.07 ms /    80 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     812.64 ms /    25 tokens (   32.51 ms per token,    30.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =     778.15 ms /    16 runs   (   48.63 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    1593.18 ms /    41 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     740.96 ms /    23 tokens (   32.22 ms per token,    31.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =     979.46 ms /    20 runs   (   48.97 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    1723.27 ms /    43 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     724.91 ms /    25 tokens (   29.00 ms per token,    34.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =     789.74 ms /    16 runs   (   49.36 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    1516.99 ms /    41 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     881.33 ms /    29 tokens (   30.39 ms per token,    32.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1220.36 ms /    25 runs   (   48.81 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    2105.46 ms /    54 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     650.91 ms /    22 tokens (   29.59 ms per token,    33.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1111.92 ms /    23 runs   (   48.34 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1766.12 ms /    45 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     855.58 ms /    28 tokens (   30.56 ms per token,    32.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1324.84 ms /    27 runs   (   49.07 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    2184.37 ms /    55 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     664.33 ms /    22 tokens (   30.20 ms per token,    33.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1133.28 ms /    23 runs   (   49.27 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    1800.88 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     685.64 ms /    22 tokens (   31.17 ms per token,    32.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =     732.37 ms /    15 runs   (   48.82 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    1420.34 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1695.49 ms /    46 tokens (   36.86 ms per token,    27.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1745.29 ms /    36 runs   (   48.48 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    3445.98 ms /    82 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     781.56 ms /    25 tokens (   31.26 ms per token,    31.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =     725.43 ms /    15 runs   (   48.36 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1509.24 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     676.06 ms /    23 tokens (   29.39 ms per token,    34.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =     770.67 ms /    16 runs   (   48.17 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1449.10 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1006.92 ms /    31 tokens (   32.48 ms per token,    30.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =     977.19 ms /    20 runs   (   48.86 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    1987.03 ms /    51 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     841.14 ms /    28 tokens (   30.04 ms per token,    33.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1307.05 ms /    27 runs   (   48.41 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    2151.97 ms /    55 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     740.46 ms /    24 tokens (   30.85 ms per token,    32.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =     934.66 ms /    19 runs   (   49.19 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    1677.79 ms /    43 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     486.25 ms /    15 tokens (   32.42 ms per token,    30.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1084.00 ms /    22 runs   (   49.27 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    1573.34 ms /    37 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     468.00 ms /    14 tokens (   33.43 ms per token,    29.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =     969.58 ms /    20 runs   (   48.48 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    1440.49 ms /    34 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     807.52 ms /    27 tokens (   29.91 ms per token,    33.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1273.90 ms /    26 runs   (   49.00 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    2084.99 ms /    53 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     642.29 ms /    21 tokens (   30.59 ms per token,    32.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =     844.31 ms /    17 runs   (   49.67 ms per token,    20.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    1489.14 ms /    38 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     506.56 ms /    16 tokens (   31.66 ms per token,    31.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =     241.83 ms /     5 runs   (   48.37 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =     749.40 ms /    21 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1633.55 ms /    45 tokens (   36.30 ms per token,    27.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =     788.94 ms /    16 runs   (   49.31 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    2425.27 ms /    61 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     973.81 ms /    31 tokens (   31.41 ms per token,    31.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =     780.58 ms /    16 runs   (   48.79 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    1756.74 ms /    47 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1619.27 ms /    39 tokens (   41.52 ms per token,    24.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =     678.17 ms /    14 runs   (   48.44 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    2299.87 ms /    53 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     728.89 ms /    25 tokens (   29.16 ms per token,    34.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =     981.06 ms /    20 runs   (   49.05 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    1712.82 ms /    45 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     403.49 ms /    13 tokens (   31.04 ms per token,    32.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =     784.62 ms /    16 runs   (   49.04 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    1190.41 ms /    29 tokens\n",
      "Llama.generate: 31 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     547.79 ms /    18 tokens (   30.43 ms per token,    32.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =     825.36 ms /    17 runs   (   48.55 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    1375.75 ms /    35 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     723.61 ms /    25 tokens (   28.94 ms per token,    34.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1111.88 ms /    23 runs   (   48.34 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1838.68 ms /    48 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     639.30 ms /    21 tokens (   30.44 ms per token,    32.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =     591.80 ms /    12 runs   (   49.32 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    1232.97 ms /    33 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     830.13 ms /    24 tokens (   34.59 ms per token,    28.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =     626.93 ms /    13 runs   (   48.23 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1459.06 ms /    37 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     827.27 ms /    22 tokens (   37.60 ms per token,    26.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =     577.76 ms /    12 runs   (   48.15 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    1406.77 ms /    34 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1029.86 ms /    27 tokens (   38.14 ms per token,    26.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =     831.79 ms /    17 runs   (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    1864.24 ms /    44 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     950.11 ms /    24 tokens (   39.59 ms per token,    25.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =     726.86 ms /    15 runs   (   48.46 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    1679.25 ms /    39 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     757.62 ms /    25 tokens (   30.30 ms per token,    33.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =     820.72 ms /    17 runs   (   48.28 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1580.82 ms /    42 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     813.49 ms /    28 tokens (   29.05 ms per token,    34.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1268.61 ms /    26 runs   (   48.79 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    2085.79 ms /    54 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     682.61 ms /    21 tokens (   32.51 ms per token,    30.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =     436.95 ms /     9 runs   (   48.55 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    1120.95 ms /    30 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     736.93 ms /    25 tokens (   29.48 ms per token,    33.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1014.55 ms /    21 runs   (   48.31 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1754.49 ms /    46 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     768.35 ms /    23 tokens (   33.41 ms per token,    29.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1165.39 ms /    24 runs   (   48.56 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    1937.17 ms /    47 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1544.04 ms /    32 tokens (   48.25 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1319.32 ms /    27 runs   (   48.86 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    2867.74 ms /    59 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     969.46 ms /    30 tokens (   32.32 ms per token,    30.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1067.24 ms /    22 runs   (   48.51 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    2039.86 ms /    52 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 11 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     693.97 ms /    23 tokens (   30.17 ms per token,    33.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =     724.29 ms /    15 runs   (   48.29 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1421.61 ms /    38 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     365.32 ms /     8 tokens (   45.67 ms per token,    21.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =     584.14 ms /    12 runs   (   48.68 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =     951.29 ms /    20 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     611.97 ms /    21 tokens (   29.14 ms per token,    34.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =     385.99 ms /     8 runs   (   48.25 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =     999.32 ms /    29 tokens\n",
      "Llama.generate: 32 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     315.00 ms /     9 tokens (   35.00 ms per token,    28.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1070.01 ms /    22 runs   (   48.64 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    1388.15 ms /    31 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     923.98 ms /    29 tokens (   31.86 ms per token,    31.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1072.22 ms /    22 runs   (   48.74 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    1999.40 ms /    51 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error translating query: '[GICSIndustry] IN 'Aerospace & Defense|Air Freight & Logistics|Auto Components|Automobile Components|Automobiles|Banks|Beverages|Biotechnology|Broadline Retail|Building Products|Capital Markets|Chemicals|Commercial Services & Supplies|Communications Equipment|Construction & Engineering|Construction Materials|Consumer Finance|Consumer Staples Distribution & Retail|Containers & Packaging|Distributors|Diversified Consumer Services|Diversified Financial Services|Diversified REITs|Diversified Telecommunication Services|Electric Utilities|Electrical Equipment|Electronic Equipment, Instruments & Components|Energy Equipment & Services|Entertainment|Equity Real Estate Investment Trusts (REITs)|Financial Services|Food & Staples Retailing|Food Products|Gas Utilities|Ground Transportation|Health Care Equipment & Supplies|Health Care Providers & Services|Health Care REITs|Health Care Technology|Hotel & Resort REITs|Hotels, Restaurants & Leisure|Household Durables|Household Products|IT Services|Independent Power & Renewable Electricity Producers|Industrial Conglomerates|Industrial REITs|Insurance|Interactive Media & Services|Internet & Direct Marketing Retail|Internet Software & Services|Leisure Products|Life Sciences Tools & Services|Machinery|Marine|Marine Transportation|Media|Metals & Mining|Mortgage Real Estate Investment Trusts (REITs)|Multi-Utilities|Multiline Retail|Office Electronics|Office REITs|Oil, Gas & Consumable Fuels|Paper & Forest Products|Passenger Airlines|Personal Care Products|Personal Products|Pharmaceuticals|Professional Services|Real Estate|Real Estate Investment Trusts (REITs)|Real Estate Management & Development|Residential REITs|Retail REITs|Road & Rail|Semiconductor Equipment & Products|Semiconductors & Semiconductor Equipment|Software|Specialized REITs|Specialty Retail|Technology Hardware, Storage & Peripherals|Textiles, Apparel & Luxury Goods|Thrifts & Mortgage Finance|Tobacco|Trading Companies & Distributors|Transportation Infrastructure|Water Utilities|Wireless Telecommunication Services''\n",
      "Error: Requested tokens (591) exceed context window of 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     712.21 ms /    20 tokens (   35.61 ms per token,    28.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =     627.98 ms /    13 runs   (   48.31 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1342.07 ms /    33 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1635.02 ms /    44 tokens (   37.16 ms per token,    26.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1812.50 ms /    37 runs   (   48.99 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    3453.08 ms /    81 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 110 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2063.74 ms /   110 tokens (   18.76 ms per token,    53.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4611.49 ms /    93 runs   (   49.59 ms per token,    20.17 tokens per second)\n",
      "llama_perf_context_print:       total time =    6690.19 ms /   203 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1625.44 ms /    45 tokens (   36.12 ms per token,    27.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1950.17 ms /    40 runs   (   48.75 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    3581.67 ms /    85 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1641.19 ms /    35 tokens (   46.89 ms per token,    21.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1651.76 ms /    34 runs   (   48.58 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    3298.28 ms /    69 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1652.12 ms /    49 tokens (   33.72 ms per token,    29.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1960.79 ms /    40 runs   (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    3618.97 ms /    89 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     743.42 ms /    26 tokens (   28.59 ms per token,    34.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =     689.03 ms /    14 runs   (   49.22 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    1434.55 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1593.66 ms /    37 tokens (   43.07 ms per token,    23.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1316.49 ms /    27 runs   (   48.76 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    2914.03 ms /    64 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 102 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2051.26 ms /   102 tokens (   20.11 ms per token,    49.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4100.39 ms /    83 runs   (   49.40 ms per token,    20.24 tokens per second)\n",
      "llama_perf_context_print:       total time =    6165.06 ms /   185 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     716.96 ms /    25 tokens (   28.68 ms per token,    34.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1170.21 ms /    24 runs   (   48.76 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    1890.69 ms /    49 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     381.48 ms /    12 tokens (   31.79 ms per token,    31.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1257.00 ms /    26 runs   (   48.35 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1642.10 ms /    38 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     467.39 ms /    16 tokens (   29.21 ms per token,    34.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1600.51 ms /    33 runs   (   48.50 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    2072.70 ms /    49 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     740.28 ms /    25 tokens (   29.61 ms per token,    33.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =     777.72 ms /    16 runs   (   48.61 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    1520.41 ms /    41 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     774.80 ms /    26 tokens (   29.80 ms per token,    33.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =     778.79 ms /    16 runs   (   48.67 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1556.00 ms /    42 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1044.50 ms /    29 tokens (   36.02 ms per token,    27.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1481.99 ms /    30 runs   (   49.40 ms per token,    20.24 tokens per second)\n",
      "llama_perf_context_print:       total time =    2530.84 ms /    59 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1458.17 ms /    32 tokens (   45.57 ms per token,    21.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1519.43 ms /    31 runs   (   49.01 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    2982.13 ms /    63 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     716.62 ms /    24 tokens (   29.86 ms per token,    33.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =     537.78 ms /    11 runs   (   48.89 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    1256.11 ms /    35 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     958.98 ms /    30 tokens (   31.97 ms per token,    31.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1182.30 ms /    24 runs   (   49.26 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    2144.70 ms /    54 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     258.47 ms /     8 tokens (   32.31 ms per token,    30.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1278.99 ms /    26 runs   (   49.19 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    1541.23 ms /    34 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     648.77 ms /    21 tokens (   30.89 ms per token,    32.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =     754.91 ms /    15 runs   (   50.33 ms per token,    19.87 tokens per second)\n",
      "llama_perf_context_print:       total time =    1405.79 ms /    36 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     703.54 ms /    21 tokens (   33.50 ms per token,    29.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =     392.21 ms /     8 runs   (   49.03 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    1097.01 ms /    29 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     798.92 ms /    26 tokens (   30.73 ms per token,    32.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =     683.96 ms /    14 runs   (   48.85 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    1484.90 ms /    40 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     443.86 ms /    14 tokens (   31.70 ms per token,    31.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1272.20 ms /    26 runs   (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    1719.79 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 155 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2339.61 ms /   155 tokens (   15.09 ms per token,    66.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6495.76 ms /   130 runs   (   49.97 ms per token,    20.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    8858.70 ms /   285 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     780.74 ms /    26 tokens (   30.03 ms per token,    33.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1375.85 ms /    28 runs   (   49.14 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    2160.56 ms /    54 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1746.62 ms /    60 tokens (   29.11 ms per token,    34.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2652.43 ms /    54 runs   (   49.12 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    4407.54 ms /   114 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     700.41 ms /    24 tokens (   29.18 ms per token,    34.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1439.39 ms /    29 runs   (   49.63 ms per token,    20.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    2144.11 ms /    53 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     776.93 ms /    27 tokens (   28.78 ms per token,    34.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =     884.52 ms /    18 runs   (   49.14 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    1664.10 ms /    45 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     300.44 ms /     9 tokens (   33.38 ms per token,    29.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =     884.78 ms /    18 runs   (   49.15 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    1187.88 ms /    27 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     782.59 ms /    24 tokens (   32.61 ms per token,    30.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1047.31 ms /    21 runs   (   49.87 ms per token,    20.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    1833.00 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     629.95 ms /    20 tokens (   31.50 ms per token,    31.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =     682.40 ms /    14 runs   (   48.74 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    1314.48 ms /    34 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     752.60 ms /    25 tokens (   30.10 ms per token,    33.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =     739.13 ms /    15 runs   (   49.28 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    1494.23 ms /    40 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     673.49 ms /    22 tokens (   30.61 ms per token,    32.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =     882.13 ms /    18 runs   (   49.01 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    1558.31 ms /    40 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     296.15 ms /     8 tokens (   37.02 ms per token,    27.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1028.60 ms /    21 runs   (   48.98 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    1327.74 ms /    29 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     810.13 ms /    21 tokens (   38.58 ms per token,    25.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =     743.29 ms /    15 runs   (   49.55 ms per token,    20.18 tokens per second)\n",
      "llama_perf_context_print:       total time =    1555.66 ms /    36 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     268.77 ms /     8 tokens (   33.60 ms per token,    29.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =     736.27 ms /    15 runs   (   49.08 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    1007.31 ms /    23 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     657.21 ms /    19 tokens (   34.59 ms per token,    28.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =     731.96 ms /    15 runs   (   48.80 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    1391.51 ms /    34 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     912.91 ms /    26 tokens (   35.11 ms per token,    28.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1077.34 ms /    22 runs   (   48.97 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    1993.50 ms /    48 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1668.15 ms /    60 tokens (   27.80 ms per token,    35.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2844.79 ms /    58 runs   (   49.05 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    4521.92 ms /   118 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1467.73 ms /    32 tokens (   45.87 ms per token,    21.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1115.07 ms /    23 runs   (   48.48 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    2586.05 ms /    55 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     641.40 ms /    21 tokens (   30.54 ms per token,    32.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =     645.09 ms /    13 runs   (   49.62 ms per token,    20.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    1288.40 ms /    34 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     820.47 ms /    28 tokens (   29.30 ms per token,    34.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =     585.93 ms /    12 runs   (   48.83 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    1408.49 ms /    40 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     833.23 ms /    29 tokens (   28.73 ms per token,    34.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1364.87 ms /    28 runs   (   48.75 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    2201.95 ms /    57 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     772.82 ms /    26 tokens (   29.72 ms per token,    33.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1083.71 ms /    22 runs   (   49.26 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    1859.69 ms /    48 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     560.76 ms /    19 tokens (   29.51 ms per token,    33.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =     679.58 ms /    14 runs   (   48.54 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    1242.53 ms /    33 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     730.12 ms /    25 tokens (   29.20 ms per token,    34.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =     966.80 ms /    20 runs   (   48.34 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1699.72 ms /    45 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     686.18 ms /    19 tokens (   36.11 ms per token,    27.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =     792.27 ms /    16 runs   (   49.52 ms per token,    20.20 tokens per second)\n",
      "llama_perf_context_print:       total time =    1480.82 ms /    35 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     706.12 ms /    24 tokens (   29.42 ms per token,    33.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =     874.74 ms /    18 runs   (   48.60 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    1583.60 ms /    42 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     551.72 ms /    18 tokens (   30.65 ms per token,    32.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1466.31 ms /    30 runs   (   48.88 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    2022.35 ms /    48 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     749.01 ms /    26 tokens (   28.81 ms per token,    34.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =     774.24 ms /    16 runs   (   48.39 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    1525.66 ms /    42 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     828.58 ms /    28 tokens (   29.59 ms per token,    33.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1366.12 ms /    28 runs   (   48.79 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    2198.54 ms /    56 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     721.19 ms /    24 tokens (   30.05 ms per token,    33.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =     818.42 ms /    17 runs   (   48.14 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    1542.04 ms /    41 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     447.76 ms /    14 tokens (   31.98 ms per token,    31.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1228.27 ms /    25 runs   (   49.13 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    1679.79 ms /    39 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     833.81 ms /    28 tokens (   29.78 ms per token,    33.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1264.40 ms /    26 runs   (   48.63 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    2101.90 ms /    54 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     752.78 ms /    26 tokens (   28.95 ms per token,    34.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =     779.77 ms /    16 runs   (   48.74 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    1534.95 ms /    42 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     853.38 ms /    30 tokens (   28.45 ms per token,    35.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1508.09 ms /    31 runs   (   48.65 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    2365.87 ms /    61 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     898.81 ms /    28 tokens (   32.10 ms per token,    31.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =     821.08 ms /    17 runs   (   48.30 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1722.29 ms /    45 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     809.79 ms /    28 tokens (   28.92 ms per token,    34.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1355.39 ms /    28 runs   (   48.41 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    2169.18 ms /    56 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     732.49 ms /    24 tokens (   30.52 ms per token,    32.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =     723.49 ms /    15 runs   (   48.23 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1458.15 ms /    39 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     537.58 ms /    17 tokens (   31.62 ms per token,    31.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1320.79 ms /    27 runs   (   48.92 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    1862.26 ms /    44 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     295.77 ms /     9 tokens (   32.86 ms per token,    30.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1012.39 ms /    21 runs   (   48.21 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1311.13 ms /    30 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 241 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2917.97 ms /   241 tokens (   12.11 ms per token,    82.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =     890.92 ms /    18 runs   (   49.50 ms per token,    20.20 tokens per second)\n",
      "llama_perf_context_print:       total time =    3812.04 ms /   259 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1649.88 ms /    37 tokens (   44.59 ms per token,    22.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1321.47 ms /    27 runs   (   48.94 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    2975.66 ms /    64 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 76 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1913.91 ms /    76 tokens (   25.18 ms per token,    39.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3223.48 ms /    66 runs   (   48.84 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    5147.44 ms /   142 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1698.89 ms /    55 tokens (   30.89 ms per token,    32.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1461.98 ms /    30 runs   (   48.73 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    3165.30 ms /    85 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1812.24 ms /    62 tokens (   29.23 ms per token,    34.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1408.38 ms /    29 runs   (   48.56 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    3224.96 ms /    91 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1737.48 ms /    58 tokens (   29.96 ms per token,    33.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2377.88 ms /    49 runs   (   48.53 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    4122.34 ms /   107 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 147 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2381.95 ms /   147 tokens (   16.20 ms per token,    61.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1041.50 ms /    21 runs   (   49.60 ms per token,    20.16 tokens per second)\n",
      "llama_perf_context_print:       total time =    3426.97 ms /   168 tokens\n",
      "Llama.generate: 44 prefix-match hit, remaining 123 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2075.62 ms /   123 tokens (   16.88 ms per token,    59.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1240.42 ms /    25 runs   (   49.62 ms per token,    20.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    3319.93 ms /   148 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1937.55 ms /    67 tokens (   28.92 ms per token,    34.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2628.41 ms /    54 runs   (   48.67 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    4573.92 ms /   121 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1785.35 ms /    43 tokens (   41.52 ms per token,    24.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1356.72 ms /    28 runs   (   48.45 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    3146.17 ms /    71 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1547.90 ms /    32 tokens (   48.37 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1994.57 ms /    41 runs   (   48.65 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    3548.23 ms /    73 tokens\n",
      "Llama.generate: 51 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     435.99 ms /    11 tokens (   39.64 ms per token,    25.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1792.00 ms /    37 runs   (   48.43 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    2233.11 ms /    48 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     586.63 ms /    16 tokens (   36.66 ms per token,    27.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1950.33 ms /    40 runs   (   48.76 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    2542.56 ms /    56 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 140 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2361.22 ms /   140 tokens (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1523.01 ms /    31 runs   (   49.13 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    3889.19 ms /   171 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1966.67 ms /    72 tokens (   27.31 ms per token,    36.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1610.60 ms /    33 runs   (   48.81 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    3581.90 ms /   105 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 108 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2032.72 ms /   108 tokens (   18.82 ms per token,    53.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4387.52 ms /    89 runs   (   49.30 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    6434.17 ms /   197 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1724.12 ms /    57 tokens (   30.25 ms per token,    33.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1471.77 ms /    30 runs   (   49.06 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    3200.57 ms /    87 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1713.75 ms /    34 tokens (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1760.85 ms /    36 runs   (   48.91 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    3479.96 ms /    70 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1579.14 ms /    32 tokens (   49.35 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1226.55 ms /    25 runs   (   49.06 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    2809.49 ms /    57 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1026.96 ms /    28 tokens (   36.68 ms per token,    27.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1126.38 ms /    23 runs   (   48.97 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    2156.66 ms /    51 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 142 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2440.12 ms /   142 tokens (   17.18 ms per token,    58.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6144.69 ms /   122 runs   (   50.37 ms per token,    19.85 tokens per second)\n",
      "llama_perf_context_print:       total time =    8605.86 ms /   264 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1671.36 ms /    47 tokens (   35.56 ms per token,    28.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2291.46 ms /    45 runs   (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    3969.60 ms /    92 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1893.71 ms /    66 tokens (   28.69 ms per token,    34.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2590.17 ms /    51 runs   (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    4492.21 ms /   117 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1706.32 ms /    58 tokens (   29.42 ms per token,    33.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2376.16 ms /    47 runs   (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    4089.97 ms /   105 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 184 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2668.48 ms /   184 tokens (   14.50 ms per token,    68.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8378.07 ms /   161 runs   (   52.04 ms per token,    19.22 tokens per second)\n",
      "llama_perf_context_print:       total time =   11077.78 ms /   345 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 459 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    4910.31 ms /   459 tokens (   10.70 ms per token,    93.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1682.23 ms /    32 runs   (   52.57 ms per token,    19.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    6598.00 ms /   491 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1099.09 ms /    30 tokens (   36.64 ms per token,    27.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =     805.48 ms /    16 runs   (   50.34 ms per token,    19.86 tokens per second)\n",
      "llama_perf_context_print:       total time =    1907.26 ms /    46 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 63 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1674.83 ms /    63 tokens (   26.58 ms per token,    37.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =     921.03 ms /    18 runs   (   51.17 ms per token,    19.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    2598.80 ms /    81 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1722.20 ms /    64 tokens (   26.91 ms per token,    37.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2535.89 ms /    50 runs   (   50.72 ms per token,    19.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    4266.01 ms /   114 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1728.11 ms /    43 tokens (   40.19 ms per token,    24.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1591.87 ms /    32 runs   (   49.75 ms per token,    20.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    3324.61 ms /    75 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     701.69 ms /    18 tokens (   38.98 ms per token,    25.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1216.37 ms /    24 runs   (   50.68 ms per token,    19.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1921.60 ms /    42 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1815.07 ms /    38 tokens (   47.77 ms per token,    20.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =     695.43 ms /    14 runs   (   49.67 ms per token,    20.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    2512.88 ms /    52 tokens\n",
      "Llama.generate: 30 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     587.53 ms /    18 tokens (   32.64 ms per token,    30.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =     904.14 ms /    18 runs   (   50.23 ms per token,    19.91 tokens per second)\n",
      "llama_perf_context_print:       total time =    1494.41 ms /    36 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 12 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 20 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1658.65 ms /    36 tokens (   46.07 ms per token,    21.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1074.76 ms /    22 runs   (   48.85 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    2738.00 ms /    58 tokens\n",
      "Llama.generate: 48 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     329.85 ms /     7 tokens (   47.12 ms per token,    21.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1119.53 ms /    23 runs   (   48.68 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1452.57 ms /    30 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     723.53 ms /    24 tokens (   30.15 ms per token,    33.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =     584.36 ms /    12 runs   (   48.70 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1309.66 ms /    36 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     829.38 ms /    29 tokens (   28.60 ms per token,    34.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1229.88 ms /    25 runs   (   49.20 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    2062.77 ms /    54 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1684.46 ms /    33 tokens (   51.04 ms per token,    19.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1504.21 ms /    31 runs   (   48.52 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    3193.56 ms /    64 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     852.73 ms /    29 tokens (   29.40 ms per token,    34.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1122.33 ms /    23 runs   (   48.80 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    1978.42 ms /    52 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     840.12 ms /    26 tokens (   32.31 ms per token,    30.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1124.77 ms /    23 runs   (   48.90 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    1968.17 ms /    49 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     900.38 ms /    30 tokens (   30.01 ms per token,    33.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1034.82 ms /    21 runs   (   49.28 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    1938.20 ms /    51 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     736.20 ms /    24 tokens (   30.68 ms per token,    32.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =     884.26 ms /    18 runs   (   49.13 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    1623.06 ms /    42 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1020.08 ms /    29 tokens (   35.18 ms per token,    28.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =     896.30 ms /    18 runs   (   49.79 ms per token,    20.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    1919.19 ms /    47 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     724.76 ms /    23 tokens (   31.51 ms per token,    31.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =     849.84 ms /    17 runs   (   49.99 ms per token,    20.00 tokens per second)\n",
      "llama_perf_context_print:       total time =    1577.21 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1842.78 ms /    70 tokens (   26.33 ms per token,    37.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2918.53 ms /    58 runs   (   50.32 ms per token,    19.87 tokens per second)\n",
      "llama_perf_context_print:       total time =    4770.29 ms /   128 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     941.96 ms /    29 tokens (   32.48 ms per token,    30.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1260.37 ms /    25 runs   (   50.41 ms per token,    19.84 tokens per second)\n",
      "llama_perf_context_print:       total time =    2206.10 ms /    54 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1515.15 ms /    32 tokens (   47.35 ms per token,    21.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1401.54 ms /    28 runs   (   50.06 ms per token,    19.98 tokens per second)\n",
      "llama_perf_context_print:       total time =    2920.91 ms /    60 tokens\n",
      "Llama.generate: 29 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     485.69 ms /    14 tokens (   34.69 ms per token,    28.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =     745.28 ms /    15 runs   (   49.69 ms per token,    20.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    1233.31 ms /    29 tokens\n",
      "Llama.generate: 30 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     498.37 ms /    15 tokens (   33.22 ms per token,    30.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =     596.40 ms /    12 runs   (   49.70 ms per token,    20.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    1096.64 ms /    27 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     881.25 ms /    27 tokens (   32.64 ms per token,    30.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1008.82 ms /    20 runs   (   50.44 ms per token,    19.83 tokens per second)\n",
      "llama_perf_context_print:       total time =    1893.13 ms /    47 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     606.07 ms /    18 tokens (   33.67 ms per token,    29.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =     604.49 ms /    12 runs   (   50.37 ms per token,    19.85 tokens per second)\n",
      "llama_perf_context_print:       total time =    1212.52 ms /    30 tokens\n",
      "Llama.generate: 30 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     370.01 ms /    11 tokens (   33.64 ms per token,    29.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =     351.50 ms /     7 runs   (   50.21 ms per token,    19.91 tokens per second)\n",
      "llama_perf_context_print:       total time =     722.86 ms /    18 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     827.91 ms /    25 tokens (   33.12 ms per token,    30.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1161.35 ms /    23 runs   (   50.49 ms per token,    19.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1992.69 ms /    48 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1599.33 ms /    35 tokens (   45.70 ms per token,    21.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1558.60 ms /    31 runs   (   50.28 ms per token,    19.89 tokens per second)\n",
      "llama_perf_context_print:       total time =    3162.59 ms /    66 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     758.42 ms /    24 tokens (   31.60 ms per token,    31.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1102.15 ms /    22 runs   (   50.10 ms per token,    19.96 tokens per second)\n",
      "llama_perf_context_print:       total time =    1864.05 ms /    46 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     813.63 ms /    26 tokens (   31.29 ms per token,    31.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =     994.02 ms /    20 runs   (   49.70 ms per token,    20.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    1810.65 ms /    46 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1611.66 ms /    33 tokens (   48.84 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1492.38 ms /    30 runs   (   49.75 ms per token,    20.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    3108.54 ms /    63 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     562.49 ms /    15 tokens (   37.50 ms per token,    26.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1494.44 ms /    30 runs   (   49.81 ms per token,    20.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    2061.51 ms /    45 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     787.76 ms /    24 tokens (   32.82 ms per token,    30.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1093.12 ms /    22 runs   (   49.69 ms per token,    20.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    1884.10 ms /    46 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     762.40 ms /    21 tokens (   36.30 ms per token,    27.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1104.52 ms /    22 runs   (   50.21 ms per token,    19.92 tokens per second)\n",
      "llama_perf_context_print:       total time =    1870.14 ms /    43 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1640.35 ms /    53 tokens (   30.95 ms per token,    32.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1841.26 ms /    37 runs   (   49.76 ms per token,    20.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    3487.64 ms /    90 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1689.26 ms /    41 tokens (   41.20 ms per token,    24.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1372.72 ms /    28 runs   (   49.03 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    3066.66 ms /    69 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1625.54 ms /    41 tokens (   39.65 ms per token,    25.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =     987.47 ms /    20 runs   (   49.37 ms per token,    20.25 tokens per second)\n",
      "llama_perf_context_print:       total time =    2615.91 ms /    61 tokens\n",
      "Llama.generate: 57 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     513.65 ms /    13 tokens (   39.51 ms per token,    25.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1150.78 ms /    23 runs   (   50.03 ms per token,    19.99 tokens per second)\n",
      "llama_perf_context_print:       total time =    1667.85 ms /    36 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     926.38 ms /    31 tokens (   29.88 ms per token,    33.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1135.58 ms /    23 runs   (   49.37 ms per token,    20.25 tokens per second)\n",
      "llama_perf_context_print:       total time =    2065.37 ms /    54 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     780.53 ms /    23 tokens (   33.94 ms per token,    29.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =     830.75 ms /    17 runs   (   48.87 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    1613.90 ms /    40 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 78 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1845.43 ms /    78 tokens (   23.66 ms per token,    42.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3204.60 ms /    65 runs   (   49.30 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    5060.34 ms /   143 tokens\n",
      "Llama.generate: 45 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     269.72 ms /     8 tokens (   33.72 ms per token,    29.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1232.47 ms /    25 runs   (   49.30 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    1505.79 ms /    33 tokens\n",
      "Llama.generate: 47 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     336.49 ms /    10 tokens (   33.65 ms per token,    29.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1514.74 ms /    31 runs   (   48.86 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    1855.67 ms /    41 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     931.59 ms /    31 tokens (   30.05 ms per token,    33.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2109.25 ms /    43 runs   (   49.05 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    3047.07 ms /    74 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1694.88 ms /    52 tokens (   32.59 ms per token,    30.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3211.34 ms /    65 runs   (   49.41 ms per token,    20.24 tokens per second)\n",
      "llama_perf_context_print:       total time =    4916.43 ms /   117 tokens\n",
      "Llama.generate: 54 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     778.62 ms /    23 tokens (   33.85 ms per token,    29.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2217.66 ms /    45 runs   (   49.28 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    3002.79 ms /    68 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     528.95 ms /    17 tokens (   31.11 ms per token,    32.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1074.12 ms /    22 runs   (   48.82 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    1606.35 ms /    39 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1542.15 ms /    32 tokens (   48.19 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =     879.81 ms /    18 runs   (   48.88 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    2424.90 ms /    50 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1471.70 ms /    32 tokens (   45.99 ms per token,    21.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1359.87 ms /    28 runs   (   48.57 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    2835.52 ms /    60 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1643.52 ms /    36 tokens (   45.65 ms per token,    21.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1667.50 ms /    34 runs   (   49.04 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    3316.28 ms /    70 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1632.92 ms /    56 tokens (   29.16 ms per token,    34.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3210.34 ms /    65 runs   (   49.39 ms per token,    20.25 tokens per second)\n",
      "llama_perf_context_print:       total time =    4853.29 ms /   121 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 94 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1908.98 ms /    94 tokens (   20.31 ms per token,    49.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4234.89 ms /    86 runs   (   49.24 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    6157.52 ms /   180 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1601.15 ms /    36 tokens (   44.48 ms per token,    22.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =     778.01 ms /    16 runs   (   48.63 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    2381.78 ms /    52 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1649.95 ms /    35 tokens (   47.14 ms per token,    21.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1611.71 ms /    33 runs   (   48.84 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    3266.34 ms /    68 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1470.15 ms /    32 tokens (   45.94 ms per token,    21.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1441.28 ms /    29 runs   (   49.70 ms per token,    20.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    2915.74 ms /    61 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1603.95 ms /    34 tokens (   47.18 ms per token,    21.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1811.44 ms /    37 runs   (   48.96 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    3420.90 ms /    71 tokens\n",
      "Llama.generate: 33 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     391.35 ms /    12 tokens (   32.61 ms per token,    30.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =     723.31 ms /    15 runs   (   48.22 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1116.90 ms /    27 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1688.94 ms /    53 tokens (   31.87 ms per token,    31.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2353.04 ms /    48 runs   (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    4049.12 ms /   101 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     956.88 ms /    29 tokens (   33.00 ms per token,    30.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =     506.34 ms /    10 runs   (   50.63 ms per token,    19.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    1464.76 ms /    39 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 80 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1818.67 ms /    80 tokens (   22.73 ms per token,    43.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1217.41 ms /    25 runs   (   48.70 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    3039.76 ms /   105 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1630.45 ms /    45 tokens (   36.23 ms per token,    27.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1961.40 ms /    40 runs   (   49.04 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    3597.65 ms /    85 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1607.63 ms /    37 tokens (   43.45 ms per token,    23.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2000.65 ms /    41 runs   (   48.80 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    3614.63 ms /    78 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1680.12 ms /    61 tokens (   27.54 ms per token,    36.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2195.26 ms /    45 runs   (   48.78 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    3882.71 ms /   106 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1685.89 ms /    52 tokens (   32.42 ms per token,    30.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1762.02 ms /    36 runs   (   48.95 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    3453.74 ms /    88 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1749.25 ms /    48 tokens (   36.44 ms per token,    27.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2948.61 ms /    31 runs   (   95.12 ms per token,    10.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    4703.59 ms /    79 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     417.78 ms /    10 tokens (   41.78 ms per token,    23.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1178.30 ms /    16 runs   (   73.64 ms per token,    13.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    1598.73 ms /    26 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     977.64 ms /    23 tokens (   42.51 ms per token,    23.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =     899.18 ms /    16 runs   (   56.20 ms per token,    17.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    1879.22 ms /    39 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 217 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    3095.73 ms /   217 tokens (   14.27 ms per token,    70.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =   12531.13 ms /   197 runs   (   63.61 ms per token,    15.72 tokens per second)\n",
      "llama_perf_context_print:       total time =   15669.30 ms /   414 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 189 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2953.18 ms /   189 tokens (   15.63 ms per token,    64.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2470.96 ms /    41 runs   (   60.27 ms per token,    16.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    5430.95 ms /   230 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1263.84 ms /    24 tokens (   52.66 ms per token,    18.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =     936.69 ms /    18 runs   (   52.04 ms per token,    19.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    2203.37 ms /    42 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     937.38 ms /    18 tokens (   52.08 ms per token,    19.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =     778.36 ms /    15 runs   (   51.89 ms per token,    19.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    1718.16 ms /    33 tokens\n",
      "Llama.generate: 27 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     637.80 ms /    10 tokens (   63.78 ms per token,    15.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =     516.16 ms /    10 runs   (   51.62 ms per token,    19.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    1155.72 ms /    20 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     860.76 ms /    12 tokens (   71.73 ms per token,    13.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =     699.37 ms /    14 runs   (   49.95 ms per token,    20.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    1562.38 ms /    26 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     814.15 ms /    27 tokens (   30.15 ms per token,    33.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =     785.59 ms /    16 runs   (   49.10 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    1602.23 ms /    43 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     577.60 ms /    18 tokens (   32.09 ms per token,    31.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =     637.27 ms /    13 runs   (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    1216.85 ms /    31 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 196 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error translating query: '[GSOFACSanctionsPrograms] ANY '561-Related|Anti-terrorism-FSE|Balkans|Balkans-EO14033|Belarus|Belarus-EO14038|BPI-Foreign Narcotics Kingpin Sanctions Regulations|BPI-Patriot Act|Burundi|Burma-EO14014|CAATSA|Central African Republic|Chinese Military Companies|Cote d\\'Ivoire|Counter Narcotics Trafficking|Counter Terrorism|Cuba|Cyber-related|Darfur|Democratic Republic Of Congo|Foreign Interference in a United States Election|Foreign Narcotics Kingpin|Global Magnitsky|Global Terrorism|HIFPAA|Hong Kong-EO13936|ICCP-EO13928|IFCA|Illicit-Drugs-EO|Iran-Con Arms EO|Iran-EO13553|Iran-EO13846|Iran-EO13871|Iran-EO13876|Iran-EO13902|Iran-FSE|Iran-HRIT|Iranian Financial|Iranian Transactions|Iran-IRGC|Iran-ISA|Iran-TRA|Iraq|Lebanon|Liberia|Libya|Magnitsky Act|Mali-EO13882|NDAA|Nicaragua|Nicaragua-NHRAA|Non-SDN-ISA|Non-SDN-PLC|North Korea|OFAC SDN Board Member|PEESA|Rough Diamond Trade Controls|Somalia|Russia-EO14024|South Sudan|Syria|Syria-Caesar|Syria-EO13894|Syria-FSE|Syria-HRIT|Terrorism|Transnational Criminal Organization|Ukraine-EO13660|Ukraine-EO13661|Ukraine-EO13662|Ukraine-EO13685|Venezuela|Venezuela-EO13850|Venezuela-EO13884|WMD Proliferators|WMD Proliferators Supporters|Yemen|Zimbabwe''\n",
      "Error: Requested tokens (593) exceed context window of 512\n",
      "Error translating query: '[GSOFACSanctionsPrograms] ANY '561-Related|Anti-terrorism-FSE|Balkans|Belarus|BPI-Foreign Narcotics Kingpin Sanctions Regulations|BPI-Patriot Act|Burundi|Burma-EO14014|CAATSA|Central African Republic|Chinese Military Companies|Cote d\\'Ivoire|Counter Narcotics Trafficking|Counter Terrorism|Cuba|Cyber-related|Darfur|Democratic Republic Of Congo|Foreign Interference in a United States Election|Foreign Narcotics Kingpin|Global Magnitsky|Global Terrorism|HIFPAA|Hong Kong-EO13936|ICCP-EO13928|IFCA|Iran-Con Arms EO|Iran-EO13553|Iran-EO13846|Iran-EO13871|Iran-EO13876|Iran-EO13902|Iran-FSE|Iran-HRIT|Iranian Financial|Iranian Transactions|Iran-IRGC|Iran-ISA|Iran-TRA|Iraq|Lebanon|Liberia|Libya|Magnitsky Act|Mali-EO13882|NDAA|Nicaragua|Nicaragua-NHRAA|Non-SDN-ISA|Non-SDN-PLC|North Korea|PEESA|Rough Diamond Trade Controls|Somalia|Russia-EO14024|South Sudan|Syria|Syria-FSE|Syria-HRIT|Terrorism|Transnational Criminal Organization|Ukraine-EO13660|Ukraine-EO13661|Ukraine-EO13662|Ukraine-EO13685|Venezuela|Venezuela-EO13850|Venezuela-EO13884|WMD Proliferators|WMD Proliferators Supporters|Yemen|Zimbabwe''\n",
      "Error: Requested tokens (537) exceed context window of 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2715.41 ms /   196 tokens (   13.85 ms per token,    72.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8637.96 ms /   166 runs   (   52.04 ms per token,    19.22 tokens per second)\n",
      "llama_perf_context_print:       total time =   11385.75 ms /   362 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1699.10 ms /    42 tokens (   40.45 ms per token,    24.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1911.56 ms /    38 runs   (   50.30 ms per token,    19.88 tokens per second)\n",
      "llama_perf_context_print:       total time =    3616.56 ms /    80 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     726.86 ms /    24 tokens (   30.29 ms per token,    33.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =     612.69 ms /    12 runs   (   51.06 ms per token,    19.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    1341.43 ms /    36 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1708.89 ms /    50 tokens (   34.18 ms per token,    29.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2222.86 ms /    44 runs   (   50.52 ms per token,    19.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    3938.61 ms /    94 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     686.77 ms /    19 tokens (   36.15 ms per token,    27.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1007.22 ms /    20 runs   (   50.36 ms per token,    19.86 tokens per second)\n",
      "llama_perf_context_print:       total time =    1696.87 ms /    39 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     985.82 ms /    31 tokens (   31.80 ms per token,    31.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =     896.58 ms /    18 runs   (   49.81 ms per token,    20.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    1885.10 ms /    49 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     704.65 ms /    21 tokens (   33.55 ms per token,    29.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1693.61 ms /    34 runs   (   49.81 ms per token,    20.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    2403.13 ms /    55 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     719.95 ms /    23 tokens (   31.30 ms per token,    31.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1104.33 ms /    22 runs   (   50.20 ms per token,    19.92 tokens per second)\n",
      "llama_perf_context_print:       total time =    1827.49 ms /    45 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 87 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1835.08 ms /    87 tokens (   21.09 ms per token,    47.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =     866.55 ms /    17 runs   (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    2704.26 ms /   104 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 82 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1834.72 ms /    82 tokens (   22.37 ms per token,    44.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3146.18 ms /    64 runs   (   49.16 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    4990.45 ms /   146 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     631.80 ms /    21 tokens (   30.09 ms per token,    33.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =     868.05 ms /    18 runs   (   48.22 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1502.44 ms /    39 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     691.44 ms /    23 tokens (   30.06 ms per token,    33.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =     845.91 ms /    17 runs   (   49.76 ms per token,    20.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    1539.89 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     460.12 ms /    15 tokens (   30.67 ms per token,    32.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =     489.00 ms /    10 runs   (   48.90 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =     950.75 ms /    25 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1691.88 ms /    36 tokens (   47.00 ms per token,    21.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =     971.49 ms /    20 runs   (   48.57 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    2666.32 ms /    56 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1667.17 ms /    37 tokens (   45.06 ms per token,    22.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1226.78 ms /    25 runs   (   49.07 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    2897.72 ms /    62 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     610.48 ms /    21 tokens (   29.07 ms per token,    34.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =     578.07 ms /    12 runs   (   48.17 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1190.42 ms /    33 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     640.08 ms /    22 tokens (   29.09 ms per token,    34.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =     729.22 ms /    15 runs   (   48.61 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    1371.54 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1705.25 ms /    33 tokens (   51.67 ms per token,    19.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =     732.16 ms /    15 runs   (   48.81 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    2439.77 ms /    48 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     727.52 ms /    24 tokens (   30.31 ms per token,    32.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =     770.16 ms /    16 runs   (   48.14 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    1500.03 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1639.91 ms /    38 tokens (   43.16 ms per token,    23.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1381.09 ms /    28 runs   (   49.32 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    3025.48 ms /    66 tokens\n",
      "Llama.generate: 49 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     229.79 ms /     7 tokens (   32.83 ms per token,    30.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1167.70 ms /    24 runs   (   48.65 ms per token,    20.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    1400.87 ms /    31 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     786.12 ms /    27 tokens (   29.12 ms per token,    34.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1064.15 ms /    22 runs   (   48.37 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    1853.35 ms /    49 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     838.97 ms /    29 tokens (   28.93 ms per token,    34.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1320.98 ms /    27 runs   (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    2163.83 ms /    56 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     442.30 ms /    14 tokens (   31.59 ms per token,    31.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1207.51 ms /    25 runs   (   48.30 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1653.16 ms /    39 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     793.42 ms /    27 tokens (   29.39 ms per token,    34.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1003.30 ms /    20 runs   (   50.16 ms per token,    19.93 tokens per second)\n",
      "llama_perf_context_print:       total time =    1799.62 ms /    47 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     904.66 ms /    28 tokens (   32.31 ms per token,    30.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =     979.15 ms /    20 runs   (   48.96 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    1886.74 ms /    48 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     774.94 ms /    26 tokens (   29.81 ms per token,    33.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =     824.96 ms /    17 runs   (   48.53 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    1602.33 ms /    43 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     707.30 ms /    24 tokens (   29.47 ms per token,    33.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1063.60 ms /    22 runs   (   48.35 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1774.01 ms /    46 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1600.80 ms /    32 tokens (   50.02 ms per token,    19.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1419.22 ms /    29 runs   (   48.94 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    3024.29 ms /    61 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     629.53 ms /    21 tokens (   29.98 ms per token,    33.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =     433.21 ms /     9 runs   (   48.13 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1064.18 ms /    30 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 13 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     788.70 ms /    28 tokens (   28.17 ms per token,    35.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =     676.05 ms /    14 runs   (   48.29 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1467.60 ms /    42 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     463.04 ms /    14 tokens (   33.07 ms per token,    30.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =     970.11 ms /    20 runs   (   48.51 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    1435.95 ms /    34 tokens\n",
      "Llama.generate: 30 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     703.23 ms /    15 tokens (   46.88 ms per token,    21.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =     731.94 ms /    15 runs   (   48.80 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    1437.41 ms /    30 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     261.66 ms /     8 tokens (   32.71 ms per token,    30.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =     817.37 ms /    17 runs   (   48.08 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1081.44 ms /    25 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1011.40 ms /    26 tokens (   38.90 ms per token,    25.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1160.40 ms /    24 runs   (   48.35 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    2175.25 ms /    50 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     813.07 ms /    25 tokens (   32.52 ms per token,    30.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =     871.77 ms /    18 runs   (   48.43 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    1687.55 ms /    43 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     190.85 ms /     6 tokens (   31.81 ms per token,    31.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =     722.58 ms /    15 runs   (   48.17 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =     915.56 ms /    21 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     585.13 ms /    19 tokens (   30.80 ms per token,    32.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =     481.93 ms /    10 runs   (   48.19 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    1068.58 ms /    29 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     919.51 ms /    31 tokens (   29.66 ms per token,    33.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1109.33 ms /    23 runs   (   48.23 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    2032.00 ms /    54 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     893.25 ms /    29 tokens (   30.80 ms per token,    32.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1109.59 ms /    23 runs   (   48.24 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    2006.00 ms /    52 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     536.28 ms /    17 tokens (   31.55 ms per token,    31.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1156.55 ms /    24 runs   (   48.19 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    1696.17 ms /    41 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     569.64 ms /    16 tokens (   35.60 ms per token,    28.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1157.10 ms /    24 runs   (   48.21 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1729.94 ms /    40 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     962.15 ms /    31 tokens (   31.04 ms per token,    32.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1108.79 ms /    23 runs   (   48.21 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    2074.13 ms /    54 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     781.62 ms /    26 tokens (   30.06 ms per token,    33.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1022.94 ms /    21 runs   (   48.71 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    1807.99 ms /    47 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     841.94 ms /    26 tokens (   32.38 ms per token,    30.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1017.23 ms /    21 runs   (   48.44 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    1862.13 ms /    47 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     882.01 ms /    30 tokens (   29.40 ms per token,    34.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1402.68 ms /    29 runs   (   48.37 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    2288.76 ms /    59 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     911.33 ms /    31 tokens (   29.40 ms per token,    34.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1123.91 ms /    23 runs   (   48.87 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    2038.51 ms /    54 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     957.99 ms /    26 tokens (   36.85 ms per token,    27.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1016.50 ms /    21 runs   (   48.40 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    1977.45 ms /    47 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1008.60 ms /    31 tokens (   32.54 ms per token,    30.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1211.08 ms /    25 runs   (   48.44 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    2223.14 ms /    56 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     364.11 ms /     9 tokens (   40.46 ms per token,    24.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1209.78 ms /    25 runs   (   48.39 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    1577.27 ms /    34 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     409.38 ms /     9 tokens (   45.49 ms per token,    21.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1220.36 ms /    25 runs   (   48.81 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    1633.33 ms /    34 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     881.55 ms /    28 tokens (   31.48 ms per token,    31.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1121.78 ms /    23 runs   (   48.77 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    2006.56 ms /    51 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     995.75 ms /    31 tokens (   32.12 ms per token,    31.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1170.34 ms /    24 runs   (   48.76 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    2169.47 ms /    55 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     975.90 ms /    26 tokens (   37.53 ms per token,    26.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1033.92 ms /    21 runs   (   49.23 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    2012.97 ms /    47 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     449.99 ms /    13 tokens (   34.61 ms per token,    28.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1221.53 ms /    25 runs   (   48.86 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    1675.01 ms /    38 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     891.51 ms /    30 tokens (   29.72 ms per token,    33.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1177.96 ms /    24 runs   (   49.08 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    2072.89 ms /    54 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     782.83 ms /    25 tokens (   31.31 ms per token,    31.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1418.14 ms /    29 runs   (   48.90 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    2205.06 ms /    54 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     889.41 ms /    28 tokens (   31.76 ms per token,    31.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1122.20 ms /    23 runs   (   48.79 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    2014.94 ms /    51 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1631.95 ms /    32 tokens (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1123.78 ms /    23 runs   (   48.86 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    2759.11 ms /    55 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     913.49 ms /    28 tokens (   32.62 ms per token,    30.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1117.20 ms /    23 runs   (   48.57 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    2033.95 ms /    51 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     886.82 ms /    26 tokens (   34.11 ms per token,    29.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1065.93 ms /    22 runs   (   48.45 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    1955.80 ms /    48 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1505.22 ms /    32 tokens (   47.04 ms per token,    21.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1071.62 ms /    22 runs   (   48.71 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    2580.09 ms /    54 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     864.68 ms /    27 tokens (   32.03 ms per token,    31.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1412.93 ms /    29 runs   (   48.72 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    2281.75 ms /    56 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1686.23 ms /    35 tokens (   48.18 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1162.90 ms /    24 runs   (   48.45 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    2852.59 ms /    59 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1477.76 ms /    32 tokens (   46.18 ms per token,    21.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1168.30 ms /    24 runs   (   48.68 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    2649.52 ms /    56 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     861.64 ms /    26 tokens (   33.14 ms per token,    30.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1352.96 ms /    28 runs   (   48.32 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    2218.49 ms /    54 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1641.50 ms /    36 tokens (   45.60 ms per token,    21.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1130.60 ms /    23 runs   (   49.16 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    2775.62 ms /    59 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     823.20 ms /    26 tokens (   31.66 ms per token,    31.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1476.79 ms /    30 runs   (   49.23 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    2304.15 ms /    56 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     967.86 ms /    30 tokens (   32.26 ms per token,    31.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1171.82 ms /    24 runs   (   48.83 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    2143.06 ms /    54 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     569.98 ms /    15 tokens (   38.00 ms per token,    26.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1168.17 ms /    24 runs   (   48.67 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1741.54 ms /    39 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     568.36 ms /    16 tokens (   35.52 ms per token,    28.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1162.64 ms /    24 runs   (   48.44 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    1734.40 ms /    40 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     823.64 ms /    26 tokens (   31.68 ms per token,    31.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1464.61 ms /    30 runs   (   48.82 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    2292.52 ms /    56 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     938.88 ms /    30 tokens (   31.30 ms per token,    31.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1169.82 ms /    24 runs   (   48.74 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    2112.04 ms /    54 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     880.74 ms /    28 tokens (   31.46 ms per token,    31.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1117.52 ms /    23 runs   (   48.59 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    2001.48 ms /    51 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1547.68 ms /    32 tokens (   48.37 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1109.82 ms /    23 runs   (   48.25 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    2661.02 ms /    55 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     923.44 ms /    27 tokens (   34.20 ms per token,    29.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1071.80 ms /    22 runs   (   48.72 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    1998.34 ms /    49 tokens\n",
      "Llama.generate: 31 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     578.18 ms /    16 tokens (   36.14 ms per token,    27.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1123.88 ms /    23 runs   (   48.86 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    1705.19 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1636.27 ms /    35 tokens (   46.75 ms per token,    21.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1175.83 ms /    24 runs   (   48.99 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    2815.86 ms /    59 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     589.72 ms /    17 tokens (   34.69 ms per token,    28.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =     673.71 ms /    14 runs   (   48.12 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1265.60 ms /    31 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     330.16 ms /     7 tokens (   47.17 ms per token,    21.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1063.88 ms /    22 runs   (   48.36 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1397.23 ms /    29 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1510.72 ms /    32 tokens (   47.21 ms per token,    21.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1535.26 ms /    31 runs   (   49.52 ms per token,    20.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    3050.34 ms /    63 tokens\n",
      "Llama.generate: 47 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     465.49 ms /    10 tokens (   46.55 ms per token,    21.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1535.34 ms /    31 runs   (   49.53 ms per token,    20.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    2005.13 ms /    41 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     840.00 ms /    27 tokens (   31.11 ms per token,    32.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1209.50 ms /    25 runs   (   48.38 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    2053.00 ms /    52 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1698.93 ms /    34 tokens (   49.97 ms per token,    20.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1361.00 ms /    28 runs   (   48.61 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    3063.93 ms /    62 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     860.92 ms /    27 tokens (   31.89 ms per token,    31.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1553.54 ms /    32 runs   (   48.55 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    2418.96 ms /    59 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1599.72 ms /    32 tokens (   49.99 ms per token,    20.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1520.18 ms /    31 runs   (   49.04 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    3124.37 ms /    63 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     965.66 ms /    31 tokens (   31.15 ms per token,    32.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1556.36 ms /    32 runs   (   48.64 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    2526.40 ms /    63 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     433.36 ms /    12 tokens (   36.11 ms per token,    27.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1794.63 ms /    37 runs   (   48.50 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    2233.21 ms /    49 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     919.71 ms /    27 tokens (   34.06 ms per token,    29.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1553.55 ms /    32 runs   (   48.55 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    2477.66 ms /    59 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     354.42 ms /    10 tokens (   35.44 ms per token,    28.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1563.58 ms /    32 runs   (   48.86 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    1922.48 ms /    42 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1562.89 ms /    32 tokens (   48.84 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1507.46 ms /    31 runs   (   48.63 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    3074.76 ms /    63 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1508.40 ms /    32 tokens (   47.14 ms per token,    21.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1310.50 ms /    27 runs   (   48.54 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    2822.77 ms /    59 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     717.40 ms /    20 tokens (   35.87 ms per token,    27.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =     771.61 ms /    16 runs   (   48.23 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1491.32 ms /    36 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     610.25 ms /    19 tokens (   32.12 ms per token,    31.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1121.76 ms /    23 runs   (   48.77 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    1735.34 ms /    42 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     613.82 ms /    19 tokens (   32.31 ms per token,    30.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =     868.71 ms /    18 runs   (   48.26 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1485.08 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 454 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    4954.89 ms /   454 tokens (   10.91 ms per token,    91.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1870.67 ms /    37 runs   (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    6831.48 ms /   491 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     670.32 ms /    19 tokens (   35.28 ms per token,    28.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1271.97 ms /    26 runs   (   48.92 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    1946.13 ms /    45 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     755.24 ms /    22 tokens (   34.33 ms per token,    29.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =     727.62 ms /    15 runs   (   48.51 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    1485.15 ms /    37 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     767.16 ms /    22 tokens (   34.87 ms per token,    28.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =     838.03 ms /    17 runs   (   49.30 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    1607.61 ms /    39 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     332.40 ms /     8 tokens (   41.55 ms per token,    24.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =     967.21 ms /    20 runs   (   48.36 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1302.26 ms /    28 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     788.70 ms /    22 tokens (   35.85 ms per token,    27.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =     737.80 ms /    15 runs   (   49.19 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    1528.61 ms /    37 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     653.60 ms /    20 tokens (   32.68 ms per token,    30.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =     350.89 ms /     7 runs   (   50.13 ms per token,    19.95 tokens per second)\n",
      "llama_perf_context_print:       total time =    1005.60 ms /    27 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     602.82 ms /    19 tokens (   31.73 ms per token,    31.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =     392.51 ms /     8 runs   (   49.06 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =     996.55 ms /    27 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 460 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    4908.07 ms /   460 tokens (   10.67 ms per token,    93.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =     710.51 ms /    14 runs   (   50.75 ms per token,    19.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    5621.30 ms /   474 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1867.49 ms /    66 tokens (   28.30 ms per token,    35.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5246.52 ms /   107 runs   (   49.03 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    7131.20 ms /   173 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 82 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1867.59 ms /    82 tokens (   22.78 ms per token,    43.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5136.99 ms /   105 runs   (   48.92 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    7021.07 ms /   187 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     589.55 ms /    19 tokens (   31.03 ms per token,    32.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =     343.92 ms /     7 runs   (   49.13 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =     934.74 ms /    26 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1041.65 ms /    28 tokens (   37.20 ms per token,    26.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =     728.93 ms /    15 runs   (   48.60 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    1772.79 ms /    43 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     314.05 ms /     9 tokens (   34.89 ms per token,    28.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =     531.54 ms /    11 runs   (   48.32 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =     847.32 ms /    20 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 79 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1872.29 ms /    79 tokens (   23.70 ms per token,    42.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2792.46 ms /    57 runs   (   48.99 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    4673.07 ms /   136 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     822.18 ms /    27 tokens (   30.45 ms per token,    32.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =     823.36 ms /    17 runs   (   48.43 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    1648.02 ms /    44 tokens\n",
      "Llama.generate: 26 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     677.51 ms /    21 tokens (   32.26 ms per token,    31.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =     875.06 ms /    18 runs   (   48.61 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    1555.12 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1739.55 ms /    36 tokens (   48.32 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1311.29 ms /    27 runs   (   48.57 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    3054.68 ms /    63 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     851.19 ms /    25 tokens (   34.05 ms per token,    29.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =     878.73 ms /    18 runs   (   48.82 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    1732.57 ms /    43 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1725.80 ms /    35 tokens (   49.31 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1549.34 ms /    32 runs   (   48.42 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    3280.00 ms /    67 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     905.11 ms /    27 tokens (   33.52 ms per token,    29.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =     986.47 ms /    20 runs   (   49.32 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    1894.56 ms /    47 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1006.05 ms /    30 tokens (   33.54 ms per token,    29.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1326.78 ms /    27 runs   (   49.14 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    2336.65 ms /    57 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1010.11 ms /    30 tokens (   33.67 ms per token,    29.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1214.80 ms /    25 runs   (   48.59 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    2228.43 ms /    55 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1741.31 ms /    37 tokens (   47.06 ms per token,    21.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1704.72 ms /    35 runs   (   48.71 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    3451.38 ms /    72 tokens\n",
      "Llama.generate: 48 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     283.54 ms /     7 tokens (   40.51 ms per token,    24.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1322.18 ms /    27 runs   (   48.97 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    1609.46 ms /    34 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     824.22 ms /    25 tokens (   32.97 ms per token,    30.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =     928.13 ms /    19 runs   (   48.85 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    1754.97 ms /    44 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1721.92 ms /    33 tokens (   52.18 ms per token,    19.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1212.36 ms /    25 runs   (   48.49 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    2938.23 ms /    58 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     775.34 ms /    24 tokens (   32.31 ms per token,    30.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1022.68 ms /    21 runs   (   48.70 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    1801.17 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     626.27 ms /    19 tokens (   32.96 ms per token,    30.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =     487.26 ms /    10 runs   (   48.73 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    1115.12 ms /    29 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1069.13 ms /    31 tokens (   34.49 ms per token,    29.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =     890.25 ms /    17 runs   (   52.37 ms per token,    19.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    1962.10 ms /    48 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     710.56 ms /    22 tokens (   32.30 ms per token,    30.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =     752.84 ms /    15 runs   (   50.19 ms per token,    19.92 tokens per second)\n",
      "llama_perf_context_print:       total time =    1465.71 ms /    37 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     571.38 ms /    14 tokens (   40.81 ms per token,    24.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1125.25 ms /    23 runs   (   48.92 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    1699.88 ms /    37 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     375.71 ms /     8 tokens (   46.96 ms per token,    21.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =     635.19 ms /    13 runs   (   48.86 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    1012.93 ms /    21 tokens\n",
      "Llama.generate: 31 prefix-match hit, remaining 79 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1952.45 ms /    79 tokens (   24.71 ms per token,    40.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =     825.49 ms /    17 runs   (   48.56 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    2780.47 ms /    96 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 79 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2255.66 ms /    79 tokens (   28.55 ms per token,    35.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3101.81 ms /    63 runs   (   49.24 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    5367.17 ms /   142 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 14 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 34 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     282.31 ms /     8 tokens (   35.29 ms per token,    28.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =     769.92 ms /    16 runs   (   48.12 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1055.32 ms /    24 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     722.90 ms /    22 tokens (   32.86 ms per token,    30.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =     685.94 ms /    14 runs   (   49.00 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    1410.96 ms /    36 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     817.66 ms /    28 tokens (   29.20 ms per token,    34.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1159.76 ms /    24 runs   (   48.32 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1980.67 ms /    52 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     649.68 ms /    17 tokens (   38.22 ms per token,    26.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =     917.78 ms /    19 runs   (   48.30 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1570.14 ms /    36 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     923.77 ms /    23 tokens (   40.16 ms per token,    24.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =     823.95 ms /    17 runs   (   48.47 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    1750.17 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     615.55 ms /    20 tokens (   30.78 ms per token,    32.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =     674.35 ms /    14 runs   (   48.17 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1291.94 ms /    34 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     984.91 ms /    31 tokens (   31.77 ms per token,    31.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =     971.97 ms /    20 runs   (   48.60 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    1959.69 ms /    51 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     386.55 ms /    11 tokens (   35.14 ms per token,    28.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =     970.53 ms /    20 runs   (   48.53 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    1359.81 ms /    31 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     769.97 ms /    24 tokens (   32.08 ms per token,    31.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =     868.61 ms /    18 runs   (   48.26 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1641.13 ms /    42 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     347.47 ms /    10 tokens (   34.75 ms per token,    28.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =     776.53 ms /    16 runs   (   48.53 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    1126.37 ms /    26 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     861.75 ms /    29 tokens (   29.72 ms per token,    33.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1011.71 ms /    21 runs   (   48.18 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1876.38 ms /    50 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     851.52 ms /    27 tokens (   31.54 ms per token,    31.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1013.36 ms /    21 runs   (   48.26 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1867.84 ms /    48 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     405.90 ms /    11 tokens (   36.90 ms per token,    27.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =     940.12 ms /    19 runs   (   49.48 ms per token,    20.21 tokens per second)\n",
      "llama_perf_context_print:       total time =    1348.67 ms /    30 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     883.69 ms /    24 tokens (   36.82 ms per token,    27.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =     901.18 ms /    18 runs   (   50.07 ms per token,    19.97 tokens per second)\n",
      "llama_perf_context_print:       total time =    1787.62 ms /    42 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     705.32 ms /    22 tokens (   32.06 ms per token,    31.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =     698.76 ms /    14 runs   (   49.91 ms per token,    20.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    1406.30 ms /    36 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     894.60 ms /    28 tokens (   31.95 ms per token,    31.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =     891.40 ms /    18 runs   (   49.52 ms per token,    20.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    1788.72 ms /    46 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     872.78 ms /    28 tokens (   31.17 ms per token,    32.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =     994.27 ms /    20 runs   (   49.71 ms per token,    20.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    1870.01 ms /    48 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     426.92 ms /    11 tokens (   38.81 ms per token,    25.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1000.55 ms /    20 runs   (   50.03 ms per token,    19.99 tokens per second)\n",
      "llama_perf_context_print:       total time =    1430.57 ms /    31 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     849.00 ms /    22 tokens (   38.59 ms per token,    25.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =     797.13 ms /    16 runs   (   49.82 ms per token,    20.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    1648.50 ms /    38 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     945.66 ms /    31 tokens (   30.51 ms per token,    32.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =     976.25 ms /    20 runs   (   48.81 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    1924.75 ms /    51 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     399.58 ms /    12 tokens (   33.30 ms per token,    30.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =     978.58 ms /    20 runs   (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    1381.05 ms /    32 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     719.89 ms /    22 tokens (   32.72 ms per token,    30.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =     795.19 ms /    16 runs   (   49.70 ms per token,    20.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    1517.41 ms /    38 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1005.59 ms /    25 tokens (   40.22 ms per token,    24.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =     730.95 ms /    15 runs   (   48.73 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    1738.85 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     640.61 ms /    17 tokens (   37.68 ms per token,    26.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =     532.47 ms /    11 runs   (   48.41 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    1174.79 ms /    28 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     849.02 ms /    26 tokens (   32.65 ms per token,    30.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =     838.83 ms /    17 runs   (   49.34 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    1690.52 ms /    43 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1661.09 ms /    34 tokens (   48.86 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1369.13 ms /    28 runs   (   48.90 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    3034.52 ms /    62 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1675.34 ms /    41 tokens (   40.86 ms per token,    24.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1797.63 ms /    37 runs   (   48.58 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    3478.27 ms /    78 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     896.03 ms /    23 tokens (   38.96 ms per token,    25.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =     631.86 ms /    13 runs   (   48.60 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    1529.78 ms /    36 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     822.58 ms /    24 tokens (   34.27 ms per token,    29.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =     579.53 ms /    12 runs   (   48.29 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1403.93 ms /    36 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1023.54 ms /    25 tokens (   40.94 ms per token,    24.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =     925.26 ms /    19 runs   (   48.70 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    1951.51 ms /    44 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     366.79 ms /    10 tokens (   36.68 ms per token,    27.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =     729.03 ms /    15 runs   (   48.60 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    1097.98 ms /    25 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     605.29 ms /    19 tokens (   31.86 ms per token,    31.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =     435.37 ms /     9 runs   (   48.37 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    1042.10 ms /    28 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     958.66 ms /    26 tokens (   36.87 ms per token,    27.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1032.33 ms /    21 runs   (   49.16 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    1993.96 ms /    47 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     794.93 ms /    24 tokens (   33.12 ms per token,    30.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =     731.87 ms /    15 runs   (   48.79 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    1528.93 ms /    39 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     734.12 ms /    23 tokens (   31.92 ms per token,    31.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =     583.24 ms /    12 runs   (   48.60 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    1319.19 ms /    35 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     891.00 ms /    27 tokens (   33.00 ms per token,    30.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =     971.02 ms /    20 runs   (   48.55 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    1864.85 ms /    47 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     894.14 ms /    23 tokens (   38.88 ms per token,    25.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =     819.50 ms /    17 runs   (   48.21 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1715.92 ms /    40 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     835.11 ms /    27 tokens (   30.93 ms per token,    32.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =     826.62 ms /    17 runs   (   48.62 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    1664.08 ms /    44 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     749.40 ms /    24 tokens (   31.22 ms per token,    32.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =     927.65 ms /    19 runs   (   48.82 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    1679.74 ms /    43 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     756.42 ms /    21 tokens (   36.02 ms per token,    27.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =     640.94 ms /    13 runs   (   49.30 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    1399.26 ms /    34 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     695.91 ms /    22 tokens (   31.63 ms per token,    31.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =     826.84 ms /    17 runs   (   48.64 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    1525.25 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     954.73 ms /    29 tokens (   32.92 ms per token,    30.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =     827.22 ms /    17 runs   (   48.66 ms per token,    20.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    1784.41 ms /    46 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     795.15 ms /    24 tokens (   33.13 ms per token,    30.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =     878.85 ms /    18 runs   (   48.83 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    1676.59 ms /    42 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     691.76 ms /    22 tokens (   31.44 ms per token,    31.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =     872.85 ms /    18 runs   (   48.49 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    1567.12 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     851.40 ms /    27 tokens (   31.53 ms per token,    31.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =     692.12 ms /    14 runs   (   49.44 ms per token,    20.23 tokens per second)\n",
      "llama_perf_context_print:       total time =    1545.58 ms /    41 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     802.38 ms /    24 tokens (   33.43 ms per token,    29.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1018.36 ms /    21 runs   (   48.49 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    1823.62 ms /    45 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     639.36 ms /    20 tokens (   31.97 ms per token,    31.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =     775.17 ms /    16 runs   (   48.45 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    1416.91 ms /    36 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     784.47 ms /    25 tokens (   31.38 ms per token,    31.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1066.90 ms /    22 runs   (   48.50 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    1854.62 ms /    47 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     715.80 ms /    19 tokens (   37.67 ms per token,    26.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1071.12 ms /    22 runs   (   48.69 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1789.98 ms /    41 tokens\n",
      "Llama.generate: 31 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     324.55 ms /     8 tokens (   40.57 ms per token,    24.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =     626.71 ms /    13 runs   (   48.21 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =     953.16 ms /    21 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     848.33 ms /    26 tokens (   32.63 ms per token,    30.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =     637.68 ms /    13 runs   (   49.05 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    1487.92 ms /    39 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     782.92 ms /    25 tokens (   31.32 ms per token,    31.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =     774.53 ms /    16 runs   (   48.41 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    1559.79 ms /    41 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     800.67 ms /    24 tokens (   33.36 ms per token,    29.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1216.09 ms /    25 runs   (   48.64 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    2020.16 ms /    49 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     682.89 ms /    20 tokens (   34.14 ms per token,    29.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1014.97 ms /    21 runs   (   48.33 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1700.88 ms /    41 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     858.80 ms /    27 tokens (   31.81 ms per token,    31.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =     601.50 ms /    12 runs   (   50.13 ms per token,    19.95 tokens per second)\n",
      "llama_perf_context_print:       total time =    1462.10 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     640.51 ms /    20 tokens (   32.03 ms per token,    31.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =     578.86 ms /    12 runs   (   48.24 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1221.19 ms /    32 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     869.10 ms /    26 tokens (   33.43 ms per token,    29.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1060.84 ms /    22 runs   (   48.22 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1932.95 ms /    48 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     751.75 ms /    21 tokens (   35.80 ms per token,    27.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1157.37 ms /    24 runs   (   48.22 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1912.42 ms /    45 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     724.94 ms /    23 tokens (   31.52 ms per token,    31.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =     981.18 ms /    20 runs   (   49.06 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    1708.97 ms /    43 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     738.00 ms /    23 tokens (   32.09 ms per token,    31.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =     728.12 ms /    15 runs   (   48.54 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    1468.22 ms /    38 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     317.24 ms /     9 tokens (   35.25 ms per token,    28.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =     773.39 ms /    16 runs   (   48.34 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1092.96 ms /    25 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     826.12 ms /    25 tokens (   33.04 ms per token,    30.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1364.48 ms /    28 runs   (   48.73 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    2194.47 ms /    53 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     447.82 ms /    10 tokens (   44.78 ms per token,    22.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1111.08 ms /    23 runs   (   48.31 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1562.05 ms /    33 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     641.51 ms /    20 tokens (   32.08 ms per token,    31.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =     433.66 ms /     9 runs   (   48.18 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    1076.68 ms /    29 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     700.90 ms /    22 tokens (   31.86 ms per token,    31.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =     675.34 ms /    14 runs   (   48.24 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1378.27 ms /    36 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     696.86 ms /    19 tokens (   36.68 ms per token,    27.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =     770.55 ms /    16 runs   (   48.16 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1469.64 ms /    35 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1605.36 ms /    32 tokens (   50.17 ms per token,    19.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =     967.51 ms /    20 runs   (   48.38 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    2575.72 ms /    52 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     825.77 ms /    20 tokens (   41.29 ms per token,    24.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =     770.44 ms /    16 runs   (   48.15 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    1598.64 ms /    36 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     790.95 ms /    23 tokens (   34.39 ms per token,    29.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =     729.74 ms /    15 runs   (   48.65 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    1522.83 ms /    38 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     412.69 ms /     8 tokens (   51.59 ms per token,    19.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =     727.29 ms /    15 runs   (   48.49 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    1142.08 ms /    23 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     644.33 ms /    20 tokens (   32.22 ms per token,    31.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =     775.67 ms /    16 runs   (   48.48 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    1422.21 ms /    36 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     782.16 ms /    24 tokens (   32.59 ms per token,    30.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =     771.37 ms /    16 runs   (   48.21 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1555.90 ms /    40 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     884.09 ms /    25 tokens (   35.36 ms per token,    28.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =     772.50 ms /    16 runs   (   48.28 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1658.97 ms /    41 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     912.46 ms /    26 tokens (   35.09 ms per token,    28.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1071.30 ms /    22 runs   (   48.70 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1986.88 ms /    48 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     705.05 ms /    22 tokens (   32.05 ms per token,    31.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =     869.03 ms /    18 runs   (   48.28 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1576.58 ms /    40 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     784.27 ms /    25 tokens (   31.37 ms per token,    31.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =     836.30 ms /    17 runs   (   49.19 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    1623.00 ms /    42 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     808.41 ms /    23 tokens (   35.15 ms per token,    28.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =     627.57 ms /    13 runs   (   48.27 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1437.80 ms /    36 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     934.74 ms /    28 tokens (   33.38 ms per token,    29.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1160.89 ms /    24 runs   (   48.37 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    2098.95 ms /    52 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     343.35 ms /     9 tokens (   38.15 ms per token,    26.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1070.27 ms /    22 runs   (   48.65 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    1416.70 ms /    31 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     854.41 ms /    25 tokens (   34.18 ms per token,    29.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =     832.90 ms /    17 runs   (   48.99 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    1689.69 ms /    42 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     371.85 ms /    10 tokens (   37.18 ms per token,    26.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =     675.48 ms /    14 runs   (   48.25 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1049.43 ms /    24 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     692.90 ms /    20 tokens (   34.64 ms per token,    28.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =     727.72 ms /    15 runs   (   48.51 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    1422.71 ms /    35 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     929.63 ms /    28 tokens (   33.20 ms per token,    30.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =     629.11 ms /    13 runs   (   48.39 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    1560.66 ms /    41 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     775.80 ms /    24 tokens (   32.32 ms per token,    30.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =     485.67 ms /    10 runs   (   48.57 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    1263.00 ms /    34 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     347.92 ms /     8 tokens (   43.49 ms per token,    22.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =     734.26 ms /    15 runs   (   48.95 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    1084.39 ms /    23 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     748.34 ms /    23 tokens (   32.54 ms per token,    30.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1515.43 ms /    31 runs   (   48.88 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    2268.08 ms /    54 tokens\n",
      "Llama.generate: 31 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     369.34 ms /     8 tokens (   46.17 ms per token,    21.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =     626.70 ms /    13 runs   (   48.21 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =     997.97 ms /    21 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     936.52 ms /    29 tokens (   32.29 ms per token,    30.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =     775.76 ms /    16 runs   (   48.49 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    1714.53 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     691.71 ms /    20 tokens (   34.59 ms per token,    28.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1407.15 ms /    29 runs   (   48.52 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    2102.97 ms /    49 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     847.96 ms /    24 tokens (   35.33 ms per token,    28.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =     770.81 ms /    16 runs   (   48.18 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1621.03 ms /    40 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     806.15 ms /    24 tokens (   33.59 ms per token,    29.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1011.83 ms /    21 runs   (   48.18 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    1820.78 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     882.59 ms /    24 tokens (   36.77 ms per token,    27.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =     772.67 ms /    16 runs   (   48.29 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1657.64 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1048.17 ms /    29 tokens (   36.14 ms per token,    27.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1318.57 ms /    27 runs   (   48.84 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    2370.59 ms /    56 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     821.60 ms /    23 tokens (   35.72 ms per token,    27.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =     774.92 ms /    16 runs   (   48.43 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    1598.84 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     919.20 ms /    25 tokens (   36.77 ms per token,    27.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =     832.72 ms /    17 runs   (   48.98 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    1754.45 ms /    42 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     375.25 ms /    10 tokens (   37.53 ms per token,    26.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =     915.85 ms /    19 runs   (   48.20 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    1293.72 ms /    29 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     853.75 ms /    26 tokens (   32.84 ms per token,    30.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1407.77 ms /    29 runs   (   48.54 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    2265.53 ms /    55 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     876.36 ms /    26 tokens (   33.71 ms per token,    29.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =     875.66 ms /    18 runs   (   48.65 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    1754.77 ms /    44 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     837.79 ms /    24 tokens (   34.91 ms per token,    28.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1207.49 ms /    25 runs   (   48.30 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    2048.77 ms /    49 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     672.35 ms /    21 tokens (   32.02 ms per token,    31.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =     678.50 ms /    14 runs   (   48.46 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    1352.90 ms /    35 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 15 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     764.75 ms /    21 tokens (   36.42 ms per token,    27.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =     819.29 ms /    17 runs   (   48.19 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    1587.59 ms /    38 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     931.50 ms /    25 tokens (   37.26 ms per token,    26.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =     775.62 ms /    16 runs   (   48.48 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    1709.44 ms /    41 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     878.37 ms /    23 tokens (   38.19 ms per token,    26.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =     723.03 ms /    15 runs   (   48.20 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    1603.54 ms /    38 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     469.36 ms /    11 tokens (   42.67 ms per token,    23.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =     867.11 ms /    18 runs   (   48.17 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1338.95 ms /    29 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     703.83 ms /    20 tokens (   35.19 ms per token,    28.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =     931.69 ms /    19 runs   (   49.04 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    1638.21 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     940.98 ms /    29 tokens (   32.45 ms per token,    30.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1062.65 ms /    22 runs   (   48.30 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    2006.61 ms /    51 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     744.54 ms /    22 tokens (   33.84 ms per token,    29.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =     921.13 ms /    19 runs   (   48.48 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    1668.31 ms /    41 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     877.91 ms /    28 tokens (   31.35 ms per token,    31.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1162.95 ms /    24 runs   (   48.46 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    2044.20 ms /    52 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     742.14 ms /    23 tokens (   32.27 ms per token,    30.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =     578.93 ms /    12 runs   (   48.24 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1322.81 ms /    35 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     916.57 ms /    28 tokens (   32.73 ms per token,    30.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =     964.69 ms /    20 runs   (   48.23 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1883.89 ms /    48 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     458.10 ms /    10 tokens (   45.81 ms per token,    21.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =     823.16 ms /    17 runs   (   48.42 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    1283.70 ms /    27 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     656.31 ms /    19 tokens (   34.54 ms per token,    28.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =     722.17 ms /    15 runs   (   48.14 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    1380.51 ms /    34 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     474.23 ms /    12 tokens (   39.52 ms per token,    25.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =     584.79 ms /    12 runs   (   48.73 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    1060.83 ms /    24 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     721.15 ms /    21 tokens (   34.34 ms per token,    29.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =     675.08 ms /    14 runs   (   48.22 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1398.21 ms /    35 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     840.87 ms /    26 tokens (   32.34 ms per token,    30.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1114.57 ms /    23 runs   (   48.46 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    1958.61 ms /    49 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     762.19 ms /    24 tokens (   31.76 ms per token,    31.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1013.58 ms /    21 runs   (   48.27 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1778.71 ms /    45 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     398.97 ms /    10 tokens (   39.90 ms per token,    25.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =     823.64 ms /    17 runs   (   48.45 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    1224.99 ms /    27 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     745.02 ms /    21 tokens (   35.48 ms per token,    28.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =     831.26 ms /    17 runs   (   48.90 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    1578.77 ms /    38 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     363.89 ms /    10 tokens (   36.39 ms per token,    27.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =     824.09 ms /    17 runs   (   48.48 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    1190.43 ms /    27 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     839.62 ms /    25 tokens (   33.58 ms per token,    29.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =     878.85 ms /    18 runs   (   48.82 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    1720.93 ms /    43 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     716.90 ms /    22 tokens (   32.59 ms per token,    30.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1065.35 ms /    22 runs   (   48.43 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    1785.34 ms /    44 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     784.32 ms /    22 tokens (   35.65 ms per token,    28.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1128.45 ms /    23 runs   (   49.06 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    1915.95 ms /    45 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     691.58 ms /    21 tokens (   32.93 ms per token,    30.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1071.49 ms /    22 runs   (   48.70 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    1766.05 ms /    43 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     956.36 ms /    28 tokens (   34.16 ms per token,    29.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1318.84 ms /    27 runs   (   48.85 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    2279.04 ms /    55 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     359.55 ms /    10 tokens (   35.96 ms per token,    27.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1218.05 ms /    25 runs   (   48.72 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    1581.19 ms /    35 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     729.82 ms /    22 tokens (   33.17 ms per token,    30.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =     874.37 ms /    18 runs   (   48.58 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    1606.58 ms /    40 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     812.54 ms /    24 tokens (   33.86 ms per token,    29.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =     627.92 ms /    13 runs   (   48.30 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1442.37 ms /    37 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     318.82 ms /     8 tokens (   39.85 ms per token,    25.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1029.46 ms /    21 runs   (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    1351.25 ms /    29 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     639.96 ms /    20 tokens (   32.00 ms per token,    31.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =     735.69 ms /    15 runs   (   49.05 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    1377.88 ms /    35 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     326.96 ms /     8 tokens (   40.87 ms per token,    24.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =     838.46 ms /    17 runs   (   49.32 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    1167.88 ms /    25 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     861.93 ms /    27 tokens (   31.92 ms per token,    31.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1125.30 ms /    23 runs   (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    1990.44 ms /    50 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     868.73 ms /    27 tokens (   32.18 ms per token,    31.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1218.97 ms /    25 runs   (   48.76 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    2091.17 ms /    52 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     704.39 ms /    21 tokens (   33.54 ms per token,    29.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =     699.45 ms /    14 runs   (   49.96 ms per token,    20.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    1405.95 ms /    35 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     967.46 ms /    30 tokens (   32.25 ms per token,    31.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1140.17 ms /    23 runs   (   49.57 ms per token,    20.17 tokens per second)\n",
      "llama_perf_context_print:       total time =    2110.95 ms /    53 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     350.32 ms /     9 tokens (   38.92 ms per token,    25.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1069.66 ms /    22 runs   (   48.62 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    1423.06 ms /    31 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     315.82 ms /     7 tokens (   45.12 ms per token,    22.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =     987.88 ms /    20 runs   (   49.39 ms per token,    20.25 tokens per second)\n",
      "llama_perf_context_print:       total time =    1306.53 ms /    27 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     750.75 ms /    23 tokens (   32.64 ms per token,    30.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =     682.83 ms /    14 runs   (   48.77 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    1435.68 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     733.28 ms /    19 tokens (   38.59 ms per token,    25.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =     828.66 ms /    17 runs   (   48.74 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    1564.36 ms /    36 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     750.16 ms /    24 tokens (   31.26 ms per token,    31.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =     634.18 ms /    13 runs   (   48.78 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    1386.25 ms /    37 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     345.51 ms /     8 tokens (   43.19 ms per token,    23.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =     732.50 ms /    15 runs   (   48.83 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    1080.25 ms /    23 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     665.04 ms /    21 tokens (   31.67 ms per token,    31.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =     826.52 ms /    17 runs   (   48.62 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    1494.09 ms /    38 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1006.62 ms /    28 tokens (   35.95 ms per token,    27.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1128.13 ms /    23 runs   (   49.05 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    2138.02 ms /    51 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     471.89 ms /     9 tokens (   52.43 ms per token,    19.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1363.42 ms /    28 runs   (   48.69 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1839.13 ms /    37 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     909.49 ms /    28 tokens (   32.48 ms per token,    30.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =     984.52 ms /    20 runs   (   49.23 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    1896.91 ms /    48 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     317.16 ms /     8 tokens (   39.64 ms per token,    25.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1024.02 ms /    21 runs   (   48.76 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    1344.09 ms /    29 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     352.93 ms /     9 tokens (   39.21 ms per token,    25.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =     830.19 ms /    17 runs   (   48.83 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    1185.46 ms /    26 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     759.74 ms /    22 tokens (   34.53 ms per token,    28.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =     874.98 ms /    18 runs   (   48.61 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    1637.35 ms /    40 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     765.27 ms /    23 tokens (   33.27 ms per token,    30.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =     791.28 ms /    16 runs   (   49.45 ms per token,    20.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    1558.81 ms /    39 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     830.08 ms /    26 tokens (   31.93 ms per token,    31.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =     880.86 ms /    18 runs   (   48.94 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    1713.55 ms /    44 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     320.33 ms /     8 tokens (   40.04 ms per token,    24.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =     726.51 ms /    15 runs   (   48.43 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    1049.00 ms /    23 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     434.70 ms /    11 tokens (   39.52 ms per token,    25.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =     869.19 ms /    18 runs   (   48.29 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1306.43 ms /    29 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     853.66 ms /    24 tokens (   35.57 ms per token,    28.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1305.02 ms /    27 runs   (   48.33 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    2162.40 ms /    51 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     710.52 ms /    20 tokens (   35.53 ms per token,    28.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =     530.67 ms /    11 runs   (   48.24 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1242.90 ms /    31 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     835.02 ms /    26 tokens (   32.12 ms per token,    31.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =     868.18 ms /    18 runs   (   48.23 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1705.79 ms /    44 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     798.33 ms /    22 tokens (   36.29 ms per token,    27.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =     772.28 ms /    16 runs   (   48.27 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1572.96 ms /    38 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     763.47 ms /    21 tokens (   36.36 ms per token,    27.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =     836.66 ms /    17 runs   (   49.22 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    1602.62 ms /    38 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     871.44 ms /    26 tokens (   33.52 ms per token,    29.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =     724.30 ms /    15 runs   (   48.29 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1597.83 ms /    41 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     723.92 ms /    23 tokens (   31.47 ms per token,    31.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =     926.61 ms /    19 runs   (   48.77 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    1653.30 ms /    42 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     335.31 ms /     8 tokens (   41.91 ms per token,    23.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =     817.62 ms /    17 runs   (   48.10 ms per token,    20.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    1155.31 ms /    25 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     909.19 ms /    25 tokens (   36.37 ms per token,    27.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1117.47 ms /    23 runs   (   48.59 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    2029.86 ms /    48 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     844.35 ms /    24 tokens (   35.18 ms per token,    28.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =     676.01 ms /    14 runs   (   48.29 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1522.36 ms /    38 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     993.46 ms /    27 tokens (   36.79 ms per token,    27.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1210.11 ms /    25 runs   (   48.40 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    2207.09 ms /    52 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     647.99 ms /    19 tokens (   34.10 ms per token,    29.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =     722.85 ms /    15 runs   (   48.19 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    1372.96 ms /    34 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     797.57 ms /    21 tokens (   37.98 ms per token,    26.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =     782.64 ms /    16 runs   (   48.91 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    1582.52 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     868.36 ms /    25 tokens (   34.73 ms per token,    28.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =     774.27 ms /    16 runs   (   48.39 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    1644.94 ms /    41 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     859.16 ms /    27 tokens (   31.82 ms per token,    31.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =     971.78 ms /    20 runs   (   48.59 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    1833.76 ms /    47 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     872.28 ms /    27 tokens (   32.31 ms per token,    30.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =     921.75 ms /    19 runs   (   48.51 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    1796.75 ms /    46 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     988.89 ms /    29 tokens (   34.10 ms per token,    29.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1358.86 ms /    28 runs   (   48.53 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    2351.65 ms /    57 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     826.41 ms /    26 tokens (   31.78 ms per token,    31.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =     874.61 ms /    18 runs   (   48.59 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    1703.62 ms /    44 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     548.43 ms /    16 tokens (   34.28 ms per token,    29.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =     723.78 ms /    15 runs   (   48.25 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1274.36 ms /    31 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     815.29 ms /    23 tokens (   35.45 ms per token,    28.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =     535.50 ms /    11 runs   (   48.68 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1352.39 ms /    34 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     708.91 ms /    22 tokens (   32.22 ms per token,    31.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1065.36 ms /    22 runs   (   48.43 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    1777.28 ms /    44 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     840.78 ms /    20 tokens (   42.04 ms per token,    23.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =     724.17 ms /    15 runs   (   48.28 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1567.17 ms /    35 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1009.92 ms /    25 tokens (   40.40 ms per token,    24.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =     771.12 ms /    16 runs   (   48.19 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    1783.30 ms /    41 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     826.74 ms /    22 tokens (   37.58 ms per token,    26.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =     970.28 ms /    20 runs   (   48.51 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    1799.83 ms /    42 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     799.19 ms /    24 tokens (   33.30 ms per token,    30.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =     579.28 ms /    12 runs   (   48.27 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1380.27 ms /    36 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     747.53 ms /    23 tokens (   32.50 ms per token,    30.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1119.53 ms /    23 runs   (   48.68 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1870.34 ms /    46 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     615.23 ms /    20 tokens (   30.76 ms per token,    32.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =     632.81 ms /    13 runs   (   48.68 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1249.89 ms /    33 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     801.76 ms /    26 tokens (   30.84 ms per token,    32.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =     675.33 ms /    14 runs   (   48.24 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1479.13 ms /    40 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     720.41 ms /    22 tokens (   32.75 ms per token,    30.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =     734.00 ms /    15 runs   (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    1456.64 ms /    37 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     852.81 ms /    25 tokens (   34.11 ms per token,    29.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =     822.14 ms /    17 runs   (   48.36 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1677.42 ms /    42 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     659.70 ms /    19 tokens (   34.72 ms per token,    28.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =     625.30 ms /    13 runs   (   48.10 ms per token,    20.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    1286.85 ms /    32 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     349.44 ms /     9 tokens (   38.83 ms per token,    25.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =     776.86 ms /    16 runs   (   48.55 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    1128.60 ms /    25 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     792.90 ms /    24 tokens (   33.04 ms per token,    30.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =     970.57 ms /    20 runs   (   48.53 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    1766.23 ms /    44 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     323.32 ms /     8 tokens (   40.42 ms per token,    24.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1011.80 ms /    21 runs   (   48.18 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1338.01 ms /    29 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     877.33 ms /    27 tokens (   32.49 ms per token,    30.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1112.97 ms /    23 runs   (   48.39 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    1993.59 ms /    50 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     746.25 ms /    22 tokens (   33.92 ms per token,    29.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =     721.93 ms /    15 runs   (   48.13 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1470.44 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1037.43 ms /    30 tokens (   34.58 ms per token,    28.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1013.31 ms /    21 runs   (   48.25 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    2053.77 ms /    51 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     999.34 ms /    30 tokens (   33.31 ms per token,    30.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1254.09 ms /    26 runs   (   48.23 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    2256.98 ms /    56 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     570.52 ms /    17 tokens (   33.56 ms per token,    29.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =     432.18 ms /     9 runs   (   48.02 ms per token,    20.82 tokens per second)\n",
      "llama_perf_context_print:       total time =    1004.10 ms /    26 tokens\n",
      "Llama.generate: 28 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     604.33 ms /    13 tokens (   46.49 ms per token,    21.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =     625.54 ms /    13 runs   (   48.12 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1231.69 ms /    26 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     674.96 ms /    21 tokens (   32.14 ms per token,    31.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =     533.43 ms /    11 runs   (   48.49 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    1210.10 ms /    32 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     916.71 ms /    27 tokens (   33.95 ms per token,    29.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =     774.80 ms /    16 runs   (   48.43 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    1693.88 ms /    43 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     539.94 ms /    15 tokens (   36.00 ms per token,    27.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =     733.29 ms /    15 runs   (   48.89 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    1275.35 ms /    30 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     361.11 ms /     8 tokens (   45.14 ms per token,    22.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =     480.70 ms /    10 runs   (   48.07 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =     843.26 ms /    18 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     686.10 ms /    20 tokens (   34.30 ms per token,    29.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =     481.79 ms /    10 runs   (   48.18 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1169.42 ms /    30 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1832.72 ms /    48 tokens (   38.18 ms per token,    26.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2338.73 ms /    48 runs   (   48.72 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    4178.49 ms /    96 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1740.02 ms /    46 tokens (   37.83 ms per token,    26.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2349.70 ms /    48 runs   (   48.95 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    4096.74 ms /    94 tokens\n",
      "Llama.generate: 57 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     587.39 ms /    13 tokens (   45.18 ms per token,    22.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2190.51 ms /    45 runs   (   48.68 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    2784.03 ms /    58 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     706.25 ms /    21 tokens (   33.63 ms per token,    29.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =     581.63 ms /    12 runs   (   48.47 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    1289.68 ms /    33 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 16 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 25 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1715.60 ms /    41 tokens (   41.84 ms per token,    23.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1365.57 ms /    28 runs   (   48.77 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    3086.52 ms /    69 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1744.14 ms /    39 tokens (   44.72 ms per token,    22.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1305.99 ms /    27 runs   (   48.37 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    3054.00 ms /    66 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     957.23 ms /    31 tokens (   30.88 ms per token,    32.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =     684.63 ms /    14 runs   (   48.90 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    1644.16 ms /    45 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1644.74 ms /    36 tokens (   45.69 ms per token,    21.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1599.49 ms /    33 runs   (   48.47 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    3249.17 ms /    69 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     911.59 ms /    29 tokens (   31.43 ms per token,    31.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1259.54 ms /    26 runs   (   48.44 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    2174.81 ms /    55 tokens\n",
      "Llama.generate: 30 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     482.63 ms /    13 tokens (   37.13 ms per token,    26.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =     645.10 ms /    13 runs   (   49.62 ms per token,    20.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    1129.69 ms /    26 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1040.75 ms /    31 tokens (   33.57 ms per token,    29.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1081.32 ms /    22 runs   (   49.15 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    2125.23 ms /    53 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     682.60 ms /    21 tokens (   32.50 ms per token,    30.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =     625.27 ms /    13 runs   (   48.10 ms per token,    20.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    1309.86 ms /    34 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     288.34 ms /     6 tokens (   48.06 ms per token,    20.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =     768.37 ms /    16 runs   (   48.02 ms per token,    20.82 tokens per second)\n",
      "llama_perf_context_print:       total time =    1058.96 ms /    22 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     864.41 ms /    26 tokens (   33.25 ms per token,    30.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1061.45 ms /    22 runs   (   48.25 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1928.84 ms /    48 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     752.06 ms /    23 tokens (   32.70 ms per token,    30.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =     682.04 ms /    14 runs   (   48.72 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    1436.07 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     877.58 ms /    26 tokens (   33.75 ms per token,    29.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =     587.44 ms /    12 runs   (   48.95 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    1466.79 ms /    38 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     856.34 ms /    23 tokens (   37.23 ms per token,    26.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =     768.41 ms /    16 runs   (   48.03 ms per token,    20.82 tokens per second)\n",
      "llama_perf_context_print:       total time =    1627.03 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     608.64 ms /    18 tokens (   33.81 ms per token,    29.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =     480.77 ms /    10 runs   (   48.08 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1090.88 ms /    28 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     919.04 ms /    27 tokens (   34.04 ms per token,    29.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =     624.28 ms /    13 runs   (   48.02 ms per token,    20.82 tokens per second)\n",
      "llama_perf_context_print:       total time =    1545.22 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     867.34 ms /    22 tokens (   39.42 ms per token,    25.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1350.05 ms /    28 runs   (   48.22 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    2221.30 ms /    50 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     821.82 ms /    27 tokens (   30.44 ms per token,    32.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =     918.10 ms /    19 runs   (   48.32 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1742.60 ms /    46 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     607.57 ms /    17 tokens (   35.74 ms per token,    27.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =     533.55 ms /    11 runs   (   48.50 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    1142.77 ms /    28 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1735.84 ms /    43 tokens (   40.37 ms per token,    24.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2008.47 ms /    41 runs   (   48.99 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    3750.27 ms /    84 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     780.39 ms /    23 tokens (   33.93 ms per token,    29.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =     923.34 ms /    19 runs   (   48.60 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    1706.44 ms /    42 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     995.24 ms /    27 tokens (   36.86 ms per token,    27.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1164.17 ms /    24 runs   (   48.51 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    2162.69 ms /    51 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1747.53 ms /    40 tokens (   43.69 ms per token,    22.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =     774.18 ms /    16 runs   (   48.39 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    2524.25 ms /    56 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     751.18 ms /    22 tokens (   34.14 ms per token,    29.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =     900.29 ms /    18 runs   (   50.02 ms per token,    19.99 tokens per second)\n",
      "llama_perf_context_print:       total time =    1654.33 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     952.67 ms /    27 tokens (   35.28 ms per token,    28.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =     836.97 ms /    17 runs   (   49.23 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    1792.06 ms /    44 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1828.01 ms /    44 tokens (   41.55 ms per token,    24.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2721.81 ms /    55 runs   (   49.49 ms per token,    20.21 tokens per second)\n",
      "llama_perf_context_print:       total time =    4557.87 ms /    99 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1672.26 ms /    35 tokens (   47.78 ms per token,    20.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1983.61 ms /    40 runs   (   49.59 ms per token,    20.17 tokens per second)\n",
      "llama_perf_context_print:       total time =    3661.95 ms /    75 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1826.12 ms /    36 tokens (   50.73 ms per token,    19.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =     637.67 ms /    13 runs   (   49.05 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    2465.93 ms /    49 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1120.13 ms /    31 tokens (   36.13 ms per token,    27.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1234.01 ms /    25 runs   (   49.36 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    2357.72 ms /    56 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1105.20 ms /    26 tokens (   42.51 ms per token,    23.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =     893.45 ms /    18 runs   (   49.64 ms per token,    20.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    2001.27 ms /    44 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1102.95 ms /    30 tokens (   36.76 ms per token,    27.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =     753.58 ms /    15 runs   (   50.24 ms per token,    19.91 tokens per second)\n",
      "llama_perf_context_print:       total time =    1858.81 ms /    45 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     942.75 ms /    25 tokens (   37.71 ms per token,    26.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =     999.98 ms /    20 runs   (   50.00 ms per token,    20.00 tokens per second)\n",
      "llama_perf_context_print:       total time =    1945.79 ms /    45 tokens\n",
      "Llama.generate: 29 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     858.35 ms /    22 tokens (   39.02 ms per token,    25.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1010.02 ms /    20 runs   (   50.50 ms per token,    19.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1871.36 ms /    42 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1552.50 ms /    32 tokens (   48.52 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1093.88 ms /    22 runs   (   49.72 ms per token,    20.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    2649.67 ms /    54 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1010.08 ms /    27 tokens (   37.41 ms per token,    26.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1047.54 ms /    21 runs   (   49.88 ms per token,    20.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    2060.86 ms /    48 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1011.18 ms /    27 tokens (   37.45 ms per token,    26.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1002.75 ms /    20 runs   (   50.14 ms per token,    19.95 tokens per second)\n",
      "llama_perf_context_print:       total time =    2016.77 ms /    47 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     936.26 ms /    22 tokens (   42.56 ms per token,    23.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =     754.50 ms /    15 runs   (   50.30 ms per token,    19.88 tokens per second)\n",
      "llama_perf_context_print:       total time =    1692.93 ms /    37 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     913.86 ms /    22 tokens (   41.54 ms per token,    24.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =     642.13 ms /    13 runs   (   49.39 ms per token,    20.24 tokens per second)\n",
      "llama_perf_context_print:       total time =    1558.01 ms /    35 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     513.98 ms /    11 tokens (   46.73 ms per token,    21.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =     745.55 ms /    15 runs   (   49.70 ms per token,    20.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    1261.77 ms /    26 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1744.05 ms /    33 tokens (   52.85 ms per token,    18.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =     838.85 ms /    17 runs   (   49.34 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    2585.55 ms /    50 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     912.31 ms /    25 tokens (   36.49 ms per token,    27.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =     886.77 ms /    18 runs   (   49.27 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    1801.86 ms /    43 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1021.37 ms /    28 tokens (   36.48 ms per token,    27.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =     762.66 ms /    15 runs   (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    1786.34 ms /    43 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     927.48 ms /    27 tokens (   34.35 ms per token,    29.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =     788.91 ms /    16 runs   (   49.31 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    1718.67 ms /    43 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1651.91 ms /    33 tokens (   50.06 ms per token,    19.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =     980.54 ms /    20 runs   (   49.03 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    2635.66 ms /    53 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     975.94 ms /    31 tokens (   31.48 ms per token,    31.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =     983.00 ms /    20 runs   (   49.15 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    1962.14 ms /    51 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     457.85 ms /     9 tokens (   50.87 ms per token,    19.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =     792.76 ms /    16 runs   (   49.55 ms per token,    20.18 tokens per second)\n",
      "llama_perf_context_print:       total time =    1252.88 ms /    25 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     989.53 ms /    27 tokens (   36.65 ms per token,    27.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =     839.23 ms /    17 runs   (   49.37 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    1831.24 ms /    44 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1041.20 ms /    26 tokens (   40.05 ms per token,    24.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =     937.79 ms /    19 runs   (   49.36 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    1981.63 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1796.55 ms /    36 tokens (   49.90 ms per token,    20.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1030.73 ms /    21 runs   (   49.08 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    2830.78 ms /    57 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1041.94 ms /    30 tokens (   34.73 ms per token,    28.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =     988.13 ms /    20 runs   (   49.41 ms per token,    20.24 tokens per second)\n",
      "llama_perf_context_print:       total time =    2032.95 ms /    50 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     988.14 ms /    29 tokens (   34.07 ms per token,    29.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1032.62 ms /    21 runs   (   49.17 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    2023.74 ms /    50 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     888.44 ms /    27 tokens (   32.91 ms per token,    30.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =     996.97 ms /    20 runs   (   49.85 ms per token,    20.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    1888.40 ms /    47 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     683.71 ms /    20 tokens (   34.19 ms per token,    29.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =     448.44 ms /     9 runs   (   49.83 ms per token,    20.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    1133.59 ms /    29 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1728.92 ms /    33 tokens (   52.39 ms per token,    19.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =     730.02 ms /    15 runs   (   48.67 ms per token,    20.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    2461.40 ms /    48 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     905.37 ms /    30 tokens (   30.18 ms per token,    33.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1125.89 ms /    23 runs   (   48.95 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    2034.59 ms /    53 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     888.50 ms /    25 tokens (   35.54 ms per token,    28.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =     880.64 ms /    18 runs   (   48.92 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    1771.93 ms /    43 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     836.78 ms /    23 tokens (   36.38 ms per token,    27.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =     926.41 ms /    19 runs   (   48.76 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    1766.02 ms /    42 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     836.53 ms /    23 tokens (   36.37 ms per token,    27.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =     779.60 ms /    16 runs   (   48.72 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    1618.41 ms /    39 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     931.35 ms /    26 tokens (   35.82 ms per token,    27.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =     682.50 ms /    14 runs   (   48.75 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    1615.93 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     930.90 ms /    22 tokens (   42.31 ms per token,    23.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =     533.98 ms /    11 runs   (   48.54 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    1466.54 ms /    33 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1684.93 ms /    35 tokens (   48.14 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1453.22 ms /    30 runs   (   48.44 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    3142.78 ms /    65 tokens\n",
      "Llama.generate: 49 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     346.79 ms /     8 tokens (   43.35 ms per token,    23.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1668.89 ms /    34 runs   (   49.08 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    2020.38 ms /    42 tokens\n",
      "Llama.generate: 44 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     303.03 ms /     7 tokens (   43.29 ms per token,    23.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1033.28 ms /    21 runs   (   49.20 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    1339.24 ms /    28 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     741.28 ms /    20 tokens (   37.06 ms per token,    26.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1708.39 ms /    35 runs   (   48.81 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    2454.61 ms /    55 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     922.83 ms /    25 tokens (   36.91 ms per token,    27.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =     677.47 ms /    14 runs   (   48.39 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    1602.31 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     937.11 ms /    26 tokens (   36.04 ms per token,    27.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =     975.05 ms /    20 runs   (   48.75 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    1915.12 ms /    46 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1730.82 ms /    35 tokens (   49.45 ms per token,    20.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1465.64 ms /    30 runs   (   48.85 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    3201.32 ms /    65 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     864.84 ms /    26 tokens (   33.26 ms per token,    30.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1062.36 ms /    22 runs   (   48.29 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1930.22 ms /    48 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     279.50 ms /     7 tokens (   39.93 ms per token,    25.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =     966.14 ms /    20 runs   (   48.31 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1248.36 ms /    27 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1100.53 ms /    27 tokens (   40.76 ms per token,    24.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1071.84 ms /    22 runs   (   48.72 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    2175.47 ms /    49 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     477.67 ms /    12 tokens (   39.81 ms per token,    25.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1225.04 ms /    25 runs   (   49.00 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    1706.25 ms /    37 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     583.63 ms /    15 tokens (   38.91 ms per token,    25.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =     969.29 ms /    20 runs   (   48.46 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    1555.71 ms /    35 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 80 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2177.28 ms /    80 tokens (   27.22 ms per token,    36.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3832.81 ms /    78 runs   (   49.14 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    6021.75 ms /   158 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 84 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1996.49 ms /    84 tokens (   23.77 ms per token,    42.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3953.99 ms /    80 runs   (   49.42 ms per token,    20.23 tokens per second)\n",
      "llama_perf_context_print:       total time =    5962.48 ms /   164 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1910.54 ms /    69 tokens (   27.69 ms per token,    36.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2898.96 ms /    59 runs   (   49.13 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    4818.50 ms /   128 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1874.62 ms /    60 tokens (   31.24 ms per token,    32.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.50 ms /    54 runs   (   48.94 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    4525.14 ms /   114 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1795.79 ms /    54 tokens (   33.26 ms per token,    30.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2053.87 ms /    42 runs   (   48.90 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    3856.09 ms /    96 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     997.33 ms /    29 tokens (   34.39 ms per token,    29.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1111.68 ms /    23 runs   (   48.33 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    2112.32 ms /    52 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1978.67 ms /    67 tokens (   29.53 ms per token,    33.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2976.49 ms /    60 runs   (   49.61 ms per token,    20.16 tokens per second)\n",
      "llama_perf_context_print:       total time =    4964.01 ms /   127 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1719.28 ms /    34 tokens (   50.57 ms per token,    19.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1069.68 ms /    22 runs   (   48.62 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    2792.56 ms /    56 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     785.64 ms /    24 tokens (   32.74 ms per token,    30.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =     725.95 ms /    15 runs   (   48.40 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    1513.99 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1780.88 ms /    33 tokens (   53.97 ms per token,    18.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1173.84 ms /    24 runs   (   48.91 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    2958.17 ms /    57 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     902.06 ms /    26 tokens (   34.69 ms per token,    28.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =     725.89 ms /    15 runs   (   48.39 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    1630.18 ms /    41 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     818.48 ms /    24 tokens (   34.10 ms per token,    29.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =     835.92 ms /    17 runs   (   49.17 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    1656.88 ms /    41 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     995.93 ms /    29 tokens (   34.34 ms per token,    29.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1306.34 ms /    27 runs   (   48.38 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    2306.03 ms /    56 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     940.00 ms /    24 tokens (   39.17 ms per token,    25.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =     773.56 ms /    16 runs   (   48.35 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1715.74 ms /    40 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     935.05 ms /    25 tokens (   37.40 ms per token,    26.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =     780.14 ms /    16 runs   (   48.76 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    1717.50 ms /    41 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     872.31 ms /    23 tokens (   37.93 ms per token,    26.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =     773.22 ms /    16 runs   (   48.33 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1647.91 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     917.53 ms /    26 tokens (   35.29 ms per token,    28.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =     580.12 ms /    12 runs   (   48.34 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1499.45 ms /    38 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1019.28 ms /    26 tokens (   39.20 ms per token,    25.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1211.33 ms /    25 runs   (   48.45 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    2234.15 ms /    51 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     894.61 ms /    24 tokens (   37.28 ms per token,    26.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1366.04 ms /    28 runs   (   48.79 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    2264.45 ms /    52 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1134.86 ms /    30 tokens (   37.83 ms per token,    26.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =     979.58 ms /    20 runs   (   48.98 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    2117.27 ms /    50 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1004.47 ms /    29 tokens (   34.64 ms per token,    28.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1229.97 ms /    25 runs   (   49.20 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    2237.83 ms /    54 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     883.96 ms /    27 tokens (   32.74 ms per token,    30.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1139.29 ms /    23 runs   (   49.53 ms per token,    20.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    2026.62 ms /    50 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     898.42 ms /    27 tokens (   33.27 ms per token,    30.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1188.87 ms /    24 runs   (   49.54 ms per token,    20.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    2090.72 ms /    51 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     978.39 ms /    29 tokens (   33.74 ms per token,    29.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1809.91 ms /    37 runs   (   48.92 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    2793.57 ms /    66 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     851.52 ms /    23 tokens (   37.02 ms per token,    27.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =     977.53 ms /    20 runs   (   48.88 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    1831.83 ms /    43 tokens\n",
      "Llama.generate: 31 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     616.31 ms /    16 tokens (   38.52 ms per token,    25.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =     972.01 ms /    20 runs   (   48.60 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    1591.17 ms /    36 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     852.37 ms /    25 tokens (   34.09 ms per token,    29.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =     889.61 ms /    18 runs   (   49.42 ms per token,    20.23 tokens per second)\n",
      "llama_perf_context_print:       total time =    1744.67 ms /    43 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1726.36 ms /    37 tokens (   46.66 ms per token,    21.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1610.83 ms /    33 runs   (   48.81 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    3342.22 ms /    70 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1023.11 ms /    29 tokens (   35.28 ms per token,    28.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1565.15 ms /    32 runs   (   48.91 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    2592.65 ms /    61 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 17 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1014.35 ms /    27 tokens (   37.57 ms per token,    26.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =     881.17 ms /    18 runs   (   48.95 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    1899.51 ms /    45 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     992.55 ms /    23 tokens (   43.15 ms per token,    23.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1025.63 ms /    21 runs   (   48.84 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    2021.29 ms /    44 tokens\n",
      "Llama.generate: 33 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     708.73 ms /    16 tokens (   44.30 ms per token,    22.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =     880.85 ms /    18 runs   (   48.94 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    1592.09 ms /    34 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1082.21 ms /    28 tokens (   38.65 ms per token,    25.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =     775.55 ms /    16 runs   (   48.47 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    1860.01 ms /    44 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1243.33 ms /    28 tokens (   44.40 ms per token,    22.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =     582.83 ms /    12 runs   (   48.57 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    1827.88 ms /    40 tokens\n",
      "Llama.generate: 30 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     769.24 ms /    18 tokens (   42.74 ms per token,    23.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =     868.41 ms /    18 runs   (   48.25 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1640.20 ms /    36 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1034.16 ms /    26 tokens (   39.78 ms per token,    25.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =     869.24 ms /    18 runs   (   48.29 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1905.96 ms /    44 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1249.89 ms /    27 tokens (   46.29 ms per token,    21.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =     822.29 ms /    17 runs   (   48.37 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    2074.54 ms /    44 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1052.25 ms /    25 tokens (   42.09 ms per token,    23.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =     772.21 ms /    16 runs   (   48.26 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1826.80 ms /    41 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     837.77 ms /    22 tokens (   38.08 ms per token,    26.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =     830.75 ms /    17 runs   (   48.87 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    1670.87 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1007.56 ms /    29 tokens (   34.74 ms per token,    28.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =     776.35 ms /    16 runs   (   48.52 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    1786.22 ms /    45 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     450.11 ms /    10 tokens (   45.01 ms per token,    22.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =     775.32 ms /    16 runs   (   48.46 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    1227.66 ms /    26 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     420.65 ms /     8 tokens (   52.58 ms per token,    19.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =     628.66 ms /    13 runs   (   48.36 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1051.20 ms /    21 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1214.66 ms /    30 tokens (   40.49 ms per token,    24.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1315.85 ms /    27 runs   (   48.74 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    2534.25 ms /    57 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1933.40 ms /    42 tokens (   46.03 ms per token,    21.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2065.84 ms /    42 runs   (   49.19 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    4005.26 ms /    84 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     754.88 ms /    20 tokens (   37.74 ms per token,    26.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1366.35 ms /    28 runs   (   48.80 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    2125.16 ms /    48 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     924.76 ms /    25 tokens (   36.99 ms per token,    27.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =     581.20 ms /    12 runs   (   48.43 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    1507.80 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1106.62 ms /    31 tokens (   35.70 ms per token,    28.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1037.65 ms /    21 runs   (   49.41 ms per token,    20.24 tokens per second)\n",
      "llama_perf_context_print:       total time =    2147.19 ms /    52 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1721.68 ms /    39 tokens (   44.15 ms per token,    22.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =     883.76 ms /    18 runs   (   49.10 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    2608.13 ms /    57 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 94 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2129.49 ms /    94 tokens (   22.65 ms per token,    44.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2214.73 ms /    45 runs   (   49.22 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    4350.89 ms /   139 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     448.17 ms /    10 tokens (   44.82 ms per token,    22.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1559.31 ms /    32 runs   (   48.73 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    2012.04 ms /    42 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 195 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    3003.35 ms /   195 tokens (   15.40 ms per token,    64.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9910.20 ms /   196 runs   (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_perf_context_print:       total time =   12950.86 ms /   391 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2012.11 ms /    46 tokens (   43.74 ms per token,    22.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2712.08 ms /    54 runs   (   50.22 ms per token,    19.91 tokens per second)\n",
      "llama_perf_context_print:       total time =    4732.64 ms /   100 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1714.49 ms /    34 tokens (   50.43 ms per token,    19.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1360.89 ms /    27 runs   (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_perf_context_print:       total time =    3079.58 ms /    61 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1100.55 ms /    29 tokens (   37.95 ms per token,    26.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1458.71 ms /    29 runs   (   50.30 ms per token,    19.88 tokens per second)\n",
      "llama_perf_context_print:       total time =    2563.50 ms /    58 tokens\n",
      "Llama.generate: 28 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1835.25 ms /    47 tokens (   39.05 ms per token,    25.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2004.61 ms /    40 runs   (   50.12 ms per token,    19.95 tokens per second)\n",
      "llama_perf_context_print:       total time =    3845.88 ms /    87 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 91 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2023.79 ms /    91 tokens (   22.24 ms per token,    44.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3604.38 ms /    71 runs   (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    5639.48 ms /   162 tokens\n",
      "Llama.generate: 105 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1729.21 ms /    44 tokens (   39.30 ms per token,    25.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1831.73 ms /    36 runs   (   50.88 ms per token,    19.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    3566.59 ms /    80 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 142 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2374.08 ms /   142 tokens (   16.72 ms per token,    59.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2548.29 ms /    50 runs   (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    4930.12 ms /   192 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 123 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2335.71 ms /   123 tokens (   18.99 ms per token,    52.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4225.64 ms /    82 runs   (   51.53 ms per token,    19.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    6574.66 ms /   205 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 108 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2430.31 ms /   108 tokens (   22.50 ms per token,    44.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2805.92 ms /    53 runs   (   52.94 ms per token,    18.89 tokens per second)\n",
      "llama_perf_context_print:       total time =    5245.07 ms /   161 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2180.82 ms /    69 tokens (   31.61 ms per token,    31.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1269.80 ms /    25 runs   (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    3454.78 ms /    94 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 103 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2261.04 ms /   103 tokens (   21.95 ms per token,    45.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1787.79 ms /    35 runs   (   51.08 ms per token,    19.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    4054.27 ms /   138 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1167.15 ms /    31 tokens (   37.65 ms per token,    26.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =     970.72 ms /    19 runs   (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    2140.82 ms /    50 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1896.17 ms /    57 tokens (   33.27 ms per token,    30.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1844.23 ms /    36 runs   (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    3746.78 ms /    93 tokens\n",
      "Llama.generate: 49 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     355.49 ms /    10 tokens (   35.55 ms per token,    28.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1181.80 ms /    22 runs   (   53.72 ms per token,    18.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    1540.84 ms /    32 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1002.46 ms /    31 tokens (   32.34 ms per token,    30.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =     841.55 ms /    16 runs   (   52.60 ms per token,    19.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    1846.66 ms /    47 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1118.00 ms /    30 tokens (   37.27 ms per token,    26.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1813.90 ms /    36 runs   (   50.39 ms per token,    19.85 tokens per second)\n",
      "llama_perf_context_print:       total time =    2937.27 ms /    66 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1706.23 ms /    40 tokens (   42.66 ms per token,    23.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =     702.41 ms /    14 runs   (   50.17 ms per token,    19.93 tokens per second)\n",
      "llama_perf_context_print:       total time =    2411.09 ms /    54 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1090.25 ms /    31 tokens (   35.17 ms per token,    28.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1620.74 ms /    32 runs   (   50.65 ms per token,    19.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    2716.03 ms /    63 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1479.55 ms /    32 tokens (   46.24 ms per token,    21.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1085.06 ms /    22 runs   (   49.32 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    2568.22 ms /    54 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 91 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1885.18 ms /    91 tokens (   20.72 ms per token,    48.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4605.57 ms /    92 runs   (   50.06 ms per token,    19.98 tokens per second)\n",
      "llama_perf_context_print:       total time =    6505.83 ms /   183 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 79 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1834.97 ms /    79 tokens (   23.23 ms per token,    43.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3721.55 ms /    75 runs   (   49.62 ms per token,    20.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    5568.23 ms /   154 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 77 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1827.77 ms /    77 tokens (   23.74 ms per token,    42.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3108.98 ms /    63 runs   (   49.35 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    4946.63 ms /   140 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     308.40 ms /     9 tokens (   34.27 ms per token,    29.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1128.88 ms /    23 runs   (   49.08 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    1440.67 ms /    32 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     289.18 ms /     8 tokens (   36.15 ms per token,    27.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =     832.93 ms /    17 runs   (   49.00 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    1124.68 ms /    25 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1712.47 ms /    46 tokens (   37.23 ms per token,    26.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1664.56 ms /    34 runs   (   48.96 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    3382.05 ms /    80 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     815.15 ms /    28 tokens (   29.11 ms per token,    34.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1269.69 ms /    26 runs   (   48.83 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    2088.63 ms /    54 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1686.70 ms /    54 tokens (   31.24 ms per token,    32.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2932.43 ms /    60 runs   (   48.87 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    4628.36 ms /   114 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1717.32 ms /    49 tokens (   35.05 ms per token,    28.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1945.58 ms /    40 runs   (   48.64 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    3669.07 ms /    89 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     807.87 ms /    28 tokens (   28.85 ms per token,    34.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =     725.35 ms /    15 runs   (   48.36 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1535.54 ms /    43 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     839.78 ms /    29 tokens (   28.96 ms per token,    34.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1070.88 ms /    22 runs   (   48.68 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1913.67 ms /    51 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     369.22 ms /    11 tokens (   33.57 ms per token,    29.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1163.77 ms /    24 runs   (   48.49 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    1536.37 ms /    35 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     404.61 ms /    12 tokens (   33.72 ms per token,    29.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =     774.22 ms /    16 runs   (   48.39 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    1181.22 ms /    28 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     663.20 ms /    22 tokens (   30.15 ms per token,    33.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =     682.70 ms /    14 runs   (   48.76 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    1348.05 ms /    36 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     644.71 ms /    21 tokens (   30.70 ms per token,    32.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =     830.92 ms /    17 runs   (   48.88 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    1478.05 ms /    38 tokens\n",
      "Llama.generate: 32 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     383.87 ms /    11 tokens (   34.90 ms per token,    28.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =     869.31 ms /    18 runs   (   48.29 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1255.63 ms /    29 tokens\n",
      "Llama.generate: 32 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     382.19 ms /    11 tokens (   34.74 ms per token,    28.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =     582.57 ms /    12 runs   (   48.55 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =     966.51 ms /    23 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 203 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2762.53 ms /   203 tokens (   13.61 ms per token,    73.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10795.65 ms /   218 runs   (   49.52 ms per token,    20.19 tokens per second)\n",
      "llama_perf_context_print:       total time =   13602.78 ms /   421 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 188 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2502.10 ms /   188 tokens (   13.31 ms per token,    75.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8320.17 ms /   169 runs   (   49.23 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =   10853.29 ms /   357 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     286.88 ms /     8 tokens (   35.86 ms per token,    27.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =     771.74 ms /    16 runs   (   48.23 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1061.06 ms /    24 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 76 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1843.11 ms /    76 tokens (   24.25 ms per token,    41.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3936.28 ms /    81 runs   (   48.60 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    5791.96 ms /   157 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1655.27 ms /    52 tokens (   31.83 ms per token,    31.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1996.53 ms /    41 runs   (   48.70 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    3658.12 ms /    93 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1866.38 ms /    70 tokens (   26.66 ms per token,    37.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3739.70 ms /    77 runs   (   48.57 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    5618.06 ms /   147 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     792.36 ms /    26 tokens (   30.48 ms per token,    32.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1070.01 ms /    21 runs   (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    1865.35 ms /    47 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     686.56 ms /    23 tokens (   29.85 ms per token,    33.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1453.42 ms /    30 runs   (   48.45 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    2144.25 ms /    53 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 90 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1874.24 ms /    90 tokens (   20.82 ms per token,    48.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3656.30 ms /    75 runs   (   48.75 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    5542.30 ms /   165 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1629.11 ms /    36 tokens (   45.25 ms per token,    22.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1302.18 ms /    27 runs   (   48.23 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    2935.64 ms /    63 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     665.53 ms /    21 tokens (   31.69 ms per token,    31.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1398.55 ms /    29 runs   (   48.23 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    2068.22 ms /    50 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     743.99 ms /    24 tokens (   31.00 ms per token,    32.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =     625.60 ms /    13 runs   (   48.12 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1371.57 ms /    37 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     803.53 ms /    24 tokens (   33.48 ms per token,    29.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =     914.76 ms /    19 runs   (   48.15 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    1721.06 ms /    43 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1631.73 ms /    36 tokens (   45.33 ms per token,    22.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1353.32 ms /    28 runs   (   48.33 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    2989.28 ms /    64 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 135 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2206.38 ms /   135 tokens (   16.34 ms per token,    61.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4019.35 ms /    82 runs   (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    6238.54 ms /   217 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1798.86 ms /    65 tokens (   27.67 ms per token,    36.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1937.03 ms /    40 runs   (   48.43 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    3741.96 ms /   105 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 152 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2278.03 ms /   152 tokens (   14.99 ms per token,    66.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6372.97 ms /   130 runs   (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    8672.90 ms /   282 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1865.72 ms /    70 tokens (   26.65 ms per token,    37.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1791.27 ms /    37 runs   (   48.41 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    3662.53 ms /   107 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 148 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2328.51 ms /   148 tokens (   15.73 ms per token,    63.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6404.11 ms /   130 runs   (   49.26 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    8754.62 ms /   278 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     754.50 ms /    24 tokens (   31.44 ms per token,    31.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =     627.59 ms /    13 runs   (   48.28 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1384.02 ms /    37 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     811.57 ms /    27 tokens (   30.06 ms per token,    33.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1014.95 ms /    21 runs   (   48.33 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1829.66 ms /    48 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     878.62 ms /    28 tokens (   31.38 ms per token,    31.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =     841.66 ms /    17 runs   (   49.51 ms per token,    20.20 tokens per second)\n",
      "llama_perf_context_print:       total time =    1722.79 ms /    45 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     719.77 ms /    23 tokens (   31.29 ms per token,    31.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =     774.88 ms /    16 runs   (   48.43 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    1497.02 ms /    39 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     415.56 ms /    10 tokens (   41.56 ms per token,    24.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1068.63 ms /    22 runs   (   48.57 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    1487.37 ms /    32 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1713.78 ms /    40 tokens (   42.84 ms per token,    23.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2135.14 ms /    44 runs   (   48.53 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    3855.32 ms /    84 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     715.58 ms /    22 tokens (   32.53 ms per token,    30.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1504.86 ms /    31 runs   (   48.54 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    2225.00 ms /    53 tokens\n",
      "Llama.generate: 49 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     361.64 ms /    10 tokens (   36.16 ms per token,    27.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1526.26 ms /    31 runs   (   49.23 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    1892.43 ms /    41 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1650.34 ms /    42 tokens (   39.29 ms per token,    25.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1696.00 ms /    35 runs   (   48.46 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    3351.60 ms /    77 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     736.01 ms /    22 tokens (   33.46 ms per token,    29.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =     778.63 ms /    16 runs   (   48.66 ms per token,    20.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    1516.91 ms /    38 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     656.00 ms /    19 tokens (   34.53 ms per token,    28.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =     727.57 ms /    15 runs   (   48.50 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    1385.74 ms /    34 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1629.41 ms /    33 tokens (   49.38 ms per token,    20.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1355.21 ms /    28 runs   (   48.40 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    2988.81 ms /    61 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1681.35 ms /    35 tokens (   48.04 ms per token,    20.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =     883.02 ms /    18 runs   (   49.06 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    2567.17 ms /    53 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     948.34 ms /    29 tokens (   32.70 ms per token,    30.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1110.49 ms /    23 runs   (   48.28 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    2061.94 ms /    52 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1250.85 ms /    31 tokens (   40.35 ms per token,    24.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1157.35 ms /    24 runs   (   48.22 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    2411.65 ms /    55 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1659.75 ms /    40 tokens (   41.49 ms per token,    24.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1513.20 ms /    31 runs   (   48.81 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    3177.83 ms /    71 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1687.00 ms /    43 tokens (   39.23 ms per token,    25.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1689.79 ms /    35 runs   (   48.28 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    3382.09 ms /    78 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     623.88 ms /    21 tokens (   29.71 ms per token,    33.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1012.40 ms /    21 runs   (   48.21 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1639.23 ms /    42 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     802.21 ms /    25 tokens (   32.09 ms per token,    31.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1358.90 ms /    28 runs   (   48.53 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    2164.98 ms /    53 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     804.60 ms /    26 tokens (   30.95 ms per token,    32.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1300.42 ms /    27 runs   (   48.16 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    2108.81 ms /    53 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     488.10 ms /    14 tokens (   34.86 ms per token,    28.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1646.12 ms /    34 runs   (   48.42 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    2138.99 ms /    48 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     503.81 ms /    16 tokens (   31.49 ms per token,    31.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =     915.05 ms /    19 runs   (   48.16 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1421.54 ms /    35 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     886.02 ms /    30 tokens (   29.53 ms per token,    33.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1109.75 ms /    23 runs   (   48.25 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1999.15 ms /    53 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 18 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 24 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     887.40 ms /    31 tokens (   28.63 ms per token,    34.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1355.89 ms /    28 runs   (   48.42 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    2248.38 ms /    59 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1608.37 ms /    38 tokens (   42.33 ms per token,    23.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1796.93 ms /    37 runs   (   48.57 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    3410.76 ms /    75 tokens\n",
      "Llama.generate: 31 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     827.33 ms /    23 tokens (   35.97 ms per token,    27.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1317.08 ms /    27 runs   (   48.78 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    2148.11 ms /    50 tokens\n",
      "Llama.generate: 30 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     553.67 ms /    19 tokens (   29.14 ms per token,    34.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1114.87 ms /    23 runs   (   48.47 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    1671.63 ms /    42 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     723.82 ms /    25 tokens (   28.95 ms per token,    34.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1155.00 ms /    24 runs   (   48.13 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1882.10 ms /    49 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     746.81 ms /    27 tokens (   27.66 ms per token,    36.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =     774.60 ms /    16 runs   (   48.41 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    1523.78 ms /    43 tokens\n",
      "Llama.generate: 31 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     888.95 ms /    31 tokens (   28.68 ms per token,    34.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1703.47 ms /    35 runs   (   48.67 ms per token,    20.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    2597.34 ms /    66 tokens\n",
      "Llama.generate: 30 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1632.05 ms /    48 tokens (   34.00 ms per token,    29.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1985.34 ms /    41 runs   (   48.42 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    3623.39 ms /    89 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 401 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    4506.26 ms /   401 tokens (   11.24 ms per token,    88.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4232.23 ms /    85 runs   (   49.79 ms per token,    20.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    8752.20 ms /   486 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1840.83 ms /    67 tokens (   27.48 ms per token,    36.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3066.90 ms /    63 runs   (   48.68 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    4917.11 ms /   130 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 117 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2077.45 ms /   117 tokens (   17.76 ms per token,    56.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4498.57 ms /    92 runs   (   48.90 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    6590.98 ms /   209 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1638.10 ms /    64 tokens (   25.60 ms per token,    39.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1889.13 ms /    39 runs   (   48.44 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    3533.12 ms /   103 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1689.31 ms /    59 tokens (   28.63 ms per token,    34.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1817.41 ms /    37 runs   (   49.12 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    3512.20 ms /    96 tokens\n",
      "Llama.generate: 44 prefix-match hit, remaining 208 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2718.46 ms /   208 tokens (   13.07 ms per token,    76.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8638.01 ms /   173 runs   (   49.93 ms per token,    20.03 tokens per second)\n",
      "llama_perf_context_print:       total time =   11389.29 ms /   381 tokens\n",
      "Llama.generate: 54 prefix-match hit, remaining 118 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2093.50 ms /   118 tokens (   17.74 ms per token,    56.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4698.91 ms /    94 runs   (   49.99 ms per token,    20.00 tokens per second)\n",
      "llama_perf_context_print:       total time =    6807.78 ms /   212 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     936.09 ms /    28 tokens (   33.43 ms per token,    29.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1304.27 ms /    26 runs   (   50.16 ms per token,    19.93 tokens per second)\n",
      "llama_perf_context_print:       total time =    2244.18 ms /    54 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1687.62 ms /    36 tokens (   46.88 ms per token,    21.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1188.73 ms /    24 runs   (   49.53 ms per token,    20.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    2879.99 ms /    60 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     990.81 ms /    31 tokens (   31.96 ms per token,    31.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =     844.55 ms /    17 runs   (   49.68 ms per token,    20.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    1838.03 ms /    48 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1662.39 ms /    60 tokens (   27.71 ms per token,    36.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2100.18 ms /    42 runs   (   50.00 ms per token,    20.00 tokens per second)\n",
      "llama_perf_context_print:       total time =    3769.13 ms /   102 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 172 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2475.04 ms /   172 tokens (   14.39 ms per token,    69.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4270.30 ms /    85 runs   (   50.24 ms per token,    19.90 tokens per second)\n",
      "llama_perf_context_print:       total time =    6759.49 ms /   257 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     864.63 ms /    28 tokens (   30.88 ms per token,    32.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =     648.00 ms /    13 runs   (   49.85 ms per token,    20.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    1514.75 ms /    41 tokens\n",
      "Llama.generate: 47 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     411.78 ms /    12 tokens (   34.31 ms per token,    29.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =     797.59 ms /    16 runs   (   49.85 ms per token,    20.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    1211.89 ms /    28 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     916.17 ms /    28 tokens (   32.72 ms per token,    30.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =     949.60 ms /    19 runs   (   49.98 ms per token,    20.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    1868.75 ms /    47 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1878.28 ms /    44 tokens (   42.69 ms per token,    23.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1440.11 ms /    29 runs   (   49.66 ms per token,    20.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    3323.08 ms /    73 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1678.62 ms /    34 tokens (   49.37 ms per token,    20.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1535.13 ms /    31 runs   (   49.52 ms per token,    20.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    3218.96 ms /    65 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1618.71 ms /    37 tokens (   43.75 ms per token,    22.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1480.01 ms /    30 runs   (   49.33 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    3103.28 ms /    67 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1647.01 ms /    42 tokens (   39.21 ms per token,    25.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1231.17 ms /    25 runs   (   49.25 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    2882.33 ms /    67 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1694.75 ms /    34 tokens (   49.85 ms per token,    20.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =     683.36 ms /    14 runs   (   48.81 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    2380.19 ms /    48 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1624.21 ms /    48 tokens (   33.84 ms per token,    29.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2419.47 ms /    49 runs   (   49.38 ms per token,    20.25 tokens per second)\n",
      "llama_perf_context_print:       total time =    4050.99 ms /    97 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     775.24 ms /    25 tokens (   31.01 ms per token,    32.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =     804.08 ms /    16 runs   (   50.26 ms per token,    19.90 tokens per second)\n",
      "llama_perf_context_print:       total time =    1581.86 ms /    41 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1625.67 ms /    37 tokens (   43.94 ms per token,    22.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1321.51 ms /    27 runs   (   48.94 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    2951.12 ms /    64 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     902.19 ms /    29 tokens (   31.11 ms per token,    32.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =     687.46 ms /    14 runs   (   49.10 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    1591.72 ms /    43 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     816.19 ms /    22 tokens (   37.10 ms per token,    26.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =     638.16 ms /    13 runs   (   49.09 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    1456.38 ms /    35 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1468.38 ms /    32 tokens (   45.89 ms per token,    21.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1291.52 ms /    26 runs   (   49.67 ms per token,    20.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    2763.80 ms /    58 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     856.97 ms /    25 tokens (   34.28 ms per token,    29.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =     646.01 ms /    13 runs   (   49.69 ms per token,    20.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    1505.00 ms /    38 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     439.63 ms /     9 tokens (   48.85 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =     636.23 ms /    13 runs   (   48.94 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    1077.77 ms /    22 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     670.81 ms /    21 tokens (   31.94 ms per token,    31.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =     494.70 ms /    10 runs   (   49.47 ms per token,    20.21 tokens per second)\n",
      "llama_perf_context_print:       total time =    1167.21 ms /    31 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     756.54 ms /    22 tokens (   34.39 ms per token,    29.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =     492.14 ms /    10 runs   (   49.21 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    1250.30 ms /    32 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     981.49 ms /    30 tokens (   32.72 ms per token,    30.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =     697.87 ms /    14 runs   (   49.85 ms per token,    20.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    1681.41 ms /    44 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     946.75 ms /    26 tokens (   36.41 ms per token,    27.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =     638.76 ms /    13 runs   (   49.14 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    1587.46 ms /    39 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     804.77 ms /    24 tokens (   33.53 ms per token,    29.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =     704.64 ms /    14 runs   (   50.33 ms per token,    19.87 tokens per second)\n",
      "llama_perf_context_print:       total time =    1511.59 ms /    38 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1017.15 ms /    30 tokens (   33.90 ms per token,    29.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1289.48 ms /    26 runs   (   49.60 ms per token,    20.16 tokens per second)\n",
      "llama_perf_context_print:       total time =    2310.20 ms /    56 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1741.13 ms /    36 tokens (   48.36 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =     979.89 ms /    20 runs   (   48.99 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    2724.12 ms /    56 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     832.69 ms /    22 tokens (   37.85 ms per token,    26.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =     540.20 ms /    11 runs   (   49.11 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    1374.54 ms /    33 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     970.89 ms /    23 tokens (   42.21 ms per token,    23.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =     883.02 ms /    18 runs   (   49.06 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    1856.59 ms /    41 tokens\n",
      "Llama.generate: 26 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     527.92 ms /    14 tokens (   37.71 ms per token,    26.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =     682.14 ms /    14 runs   (   48.72 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    1212.08 ms /    28 tokens\n",
      "Llama.generate: 32 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     251.52 ms /     7 tokens (   35.93 ms per token,    27.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =     986.46 ms /    20 runs   (   49.32 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    1240.92 ms /    27 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     858.01 ms /    24 tokens (   35.75 ms per token,    27.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =     839.81 ms /    17 runs   (   49.40 ms per token,    20.24 tokens per second)\n",
      "llama_perf_context_print:       total time =    1700.33 ms /    41 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     668.38 ms /    20 tokens (   33.42 ms per token,    29.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =     592.38 ms /    12 runs   (   49.37 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    1262.75 ms /    32 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     909.76 ms /    31 tokens (   29.35 ms per token,    34.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1077.18 ms /    22 runs   (   48.96 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    1990.03 ms /    53 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1036.26 ms /    26 tokens (   39.86 ms per token,    25.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1031.36 ms /    21 runs   (   49.11 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    2070.56 ms /    47 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     695.01 ms /    20 tokens (   34.75 ms per token,    28.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =     883.70 ms /    18 runs   (   49.09 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    1581.22 ms /    38 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     392.57 ms /     7 tokens (   56.08 ms per token,    17.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =     732.13 ms /    15 runs   (   48.81 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    1126.86 ms /    22 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     383.33 ms /     9 tokens (   42.59 ms per token,    23.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1067.60 ms /    22 runs   (   48.53 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    1453.92 ms /    31 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     830.77 ms /    24 tokens (   34.62 ms per token,    28.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1080.25 ms /    22 runs   (   49.10 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    1914.20 ms /    46 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     392.53 ms /    10 tokens (   39.25 ms per token,    25.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1065.65 ms /    22 runs   (   48.44 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    1461.14 ms /    32 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     807.44 ms /    24 tokens (   33.64 ms per token,    29.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =     736.76 ms /    15 runs   (   49.12 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    1546.30 ms /    39 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     879.50 ms /    24 tokens (   36.65 ms per token,    27.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =     977.55 ms /    20 runs   (   48.88 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    1859.98 ms /    44 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     753.92 ms /    22 tokens (   34.27 ms per token,    29.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =     832.79 ms /    17 runs   (   48.99 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    1589.15 ms /    39 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     897.36 ms /    25 tokens (   35.89 ms per token,    27.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =     824.99 ms /    17 runs   (   48.53 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    1724.73 ms /    42 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     728.17 ms /    21 tokens (   34.67 ms per token,    28.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =     738.33 ms /    15 runs   (   49.22 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    1468.60 ms /    36 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1042.27 ms /    25 tokens (   41.69 ms per token,    23.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =     972.32 ms /    20 runs   (   48.62 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    2017.37 ms /    45 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     705.93 ms /    21 tokens (   33.62 ms per token,    29.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =     870.46 ms /    18 runs   (   48.36 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1579.02 ms /    39 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     688.39 ms /    20 tokens (   34.42 ms per token,    29.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =     916.01 ms /    19 runs   (   48.21 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1607.09 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     762.70 ms /    19 tokens (   40.14 ms per token,    24.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =     584.72 ms /    12 runs   (   48.73 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    1349.29 ms /    31 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1083.83 ms /    29 tokens (   37.37 ms per token,    26.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =     823.33 ms /    17 runs   (   48.43 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    1909.54 ms /    46 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     649.70 ms /    19 tokens (   34.19 ms per token,    29.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =     489.75 ms /    10 runs   (   48.97 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    1141.11 ms /    29 tokens\n",
      "Llama.generate: 32 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     291.33 ms /     7 tokens (   41.62 ms per token,    24.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =     481.91 ms /    10 runs   (   48.19 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =     774.74 ms /    17 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1028.44 ms /    29 tokens (   35.46 ms per token,    28.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =     967.78 ms /    20 runs   (   48.39 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    1999.06 ms /    49 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     798.34 ms /    21 tokens (   38.02 ms per token,    26.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =     723.94 ms /    15 runs   (   48.26 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1524.43 ms /    36 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     597.22 ms /    19 tokens (   31.43 ms per token,    31.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =     592.77 ms /    12 runs   (   49.40 ms per token,    20.24 tokens per second)\n",
      "llama_perf_context_print:       total time =    1191.83 ms /    31 tokens\n",
      "Llama.generate: 32 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     287.75 ms /     7 tokens (   41.11 ms per token,    24.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =     581.60 ms /    12 runs   (   48.47 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =     871.22 ms /    19 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     785.67 ms /    24 tokens (   32.74 ms per token,    30.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =     787.17 ms /    16 runs   (   49.20 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    1575.12 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     773.72 ms /    20 tokens (   38.69 ms per token,    25.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =     626.64 ms /    13 runs   (   48.20 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    1402.27 ms /    33 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1026.01 ms /    29 tokens (   35.38 ms per token,    28.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =     917.02 ms /    19 runs   (   48.26 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1945.70 ms /    48 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     737.43 ms /    19 tokens (   38.81 ms per token,    25.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =     578.14 ms /    12 runs   (   48.18 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1317.36 ms /    31 tokens\n",
      "Llama.generate: 32 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     316.82 ms /     7 tokens (   45.26 ms per token,    22.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =     576.84 ms /    12 runs   (   48.07 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =     895.36 ms /    19 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     922.21 ms /    25 tokens (   36.89 ms per token,    27.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =     723.14 ms /    15 runs   (   48.21 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1647.56 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     717.68 ms /    19 tokens (   37.77 ms per token,    26.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =     578.29 ms /    12 runs   (   48.19 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    1297.80 ms /    31 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1039.69 ms /    29 tokens (   35.85 ms per token,    27.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1058.75 ms /    22 runs   (   48.12 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    2101.50 ms /    51 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     871.17 ms /    24 tokens (   36.30 ms per token,    27.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =     915.50 ms /    19 runs   (   48.18 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    1789.23 ms /    43 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     704.01 ms /    19 tokens (   37.05 ms per token,    26.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =     577.09 ms /    12 runs   (   48.09 ms per token,    20.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    1282.96 ms /    31 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     941.77 ms /    24 tokens (   39.24 ms per token,    25.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =     768.89 ms /    16 runs   (   48.06 ms per token,    20.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    1712.95 ms /    40 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     828.36 ms /    23 tokens (   36.02 ms per token,    27.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =     866.47 ms /    18 runs   (   48.14 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    1697.42 ms /    41 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     330.76 ms /     7 tokens (   47.25 ms per token,    21.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =     865.16 ms /    18 runs   (   48.06 ms per token,    20.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    1198.40 ms /    25 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     677.89 ms /    19 tokens (   35.68 ms per token,    28.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =     798.90 ms /    16 runs   (   49.93 ms per token,    20.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    1479.17 ms /    35 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     297.16 ms /     7 tokens (   42.45 ms per token,    23.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =     772.46 ms /    16 runs   (   48.28 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1071.81 ms /    23 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     770.95 ms /    24 tokens (   32.12 ms per token,    31.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1064.23 ms /    22 runs   (   48.37 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    1838.20 ms /    46 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     829.65 ms /    22 tokens (   37.71 ms per token,    26.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =     769.79 ms /    16 runs   (   48.11 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1601.70 ms /    38 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     903.75 ms /    23 tokens (   39.29 ms per token,    25.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =     673.53 ms /    14 runs   (   48.11 ms per token,    20.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    1579.38 ms /    37 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     378.62 ms /     9 tokens (   42.07 ms per token,    23.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =     871.24 ms /    18 runs   (   48.40 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    1252.29 ms /    27 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     742.99 ms /    20 tokens (   37.15 ms per token,    26.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1375.82 ms /    28 runs   (   49.14 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    2122.99 ms /    48 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     945.68 ms /    26 tokens (   36.37 ms per token,    27.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =     688.19 ms /    14 runs   (   49.16 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    1635.99 ms /    40 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     752.67 ms /    21 tokens (   35.84 ms per token,    27.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =     628.20 ms /    13 runs   (   48.32 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1382.89 ms /    34 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     690.61 ms /    20 tokens (   34.53 ms per token,    28.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =     627.39 ms /    13 runs   (   48.26 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1320.04 ms /    33 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1795.94 ms /    37 tokens (   48.54 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1254.37 ms /    26 runs   (   48.25 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    3054.27 ms /    63 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1024.05 ms /    30 tokens (   34.13 ms per token,    29.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1111.49 ms /    23 runs   (   48.33 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    2138.62 ms /    53 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1741.56 ms /    33 tokens (   52.77 ms per token,    18.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1741.25 ms /    36 runs   (   48.37 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    3488.31 ms /    69 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     484.41 ms /    14 tokens (   34.60 ms per token,    28.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1637.75 ms /    34 runs   (   48.17 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    2126.75 ms /    48 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     908.75 ms /    20 tokens (   45.44 ms per token,    22.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =     870.12 ms /    18 runs   (   48.34 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1781.43 ms /    38 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 19 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 25 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     546.57 ms /    15 tokens (   36.44 ms per token,    27.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =     528.08 ms /    11 runs   (   48.01 ms per token,    20.83 tokens per second)\n",
      "llama_perf_context_print:       total time =    1077.16 ms /    26 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     814.68 ms /    25 tokens (   32.59 ms per token,    30.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =     864.71 ms /    18 runs   (   48.04 ms per token,    20.82 tokens per second)\n",
      "llama_perf_context_print:       total time =    1681.76 ms /    43 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     841.05 ms /    25 tokens (   33.64 ms per token,    29.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =     723.24 ms /    15 runs   (   48.22 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1566.42 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     874.10 ms /    28 tokens (   31.22 ms per token,    32.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1155.30 ms /    24 runs   (   48.14 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    2032.68 ms /    52 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     950.31 ms /    23 tokens (   41.32 ms per token,    24.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =     823.45 ms /    17 runs   (   48.44 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    1776.04 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1693.01 ms /    33 tokens (   51.30 ms per token,    19.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1072.91 ms /    22 runs   (   48.77 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    2769.19 ms /    55 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     824.38 ms /    24 tokens (   34.35 ms per token,    29.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =     962.55 ms /    20 runs   (   48.13 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1789.68 ms /    44 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1032.54 ms /    28 tokens (   36.88 ms per token,    27.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =     961.75 ms /    20 runs   (   48.09 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1997.02 ms /    48 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     895.98 ms /    25 tokens (   35.84 ms per token,    27.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =     919.15 ms /    19 runs   (   48.38 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    1817.78 ms /    44 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1009.23 ms /    30 tokens (   33.64 ms per token,    29.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1061.35 ms /    22 runs   (   48.24 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    2073.49 ms /    52 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     744.96 ms /    22 tokens (   33.86 ms per token,    29.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =     579.48 ms /    12 runs   (   48.29 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1326.26 ms /    34 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1250.03 ms /    28 tokens (   44.64 ms per token,    22.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =     637.35 ms /    13 runs   (   49.03 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    1889.35 ms /    41 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     480.05 ms /    13 tokens (   36.93 ms per token,    27.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =     549.12 ms /    11 runs   (   49.92 ms per token,    20.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    1030.83 ms /    24 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     672.88 ms /    19 tokens (   35.41 ms per token,    28.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =     444.57 ms /     9 runs   (   49.40 ms per token,    20.24 tokens per second)\n",
      "llama_perf_context_print:       total time =    1118.79 ms /    28 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     772.15 ms /    24 tokens (   32.17 ms per token,    31.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =     579.16 ms /    12 runs   (   48.26 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1352.99 ms /    36 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     765.88 ms /    21 tokens (   36.47 ms per token,    27.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =     581.10 ms /    12 runs   (   48.43 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    1348.73 ms /    33 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     853.58 ms /    25 tokens (   34.14 ms per token,    29.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1058.10 ms /    22 runs   (   48.10 ms per token,    20.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    1914.62 ms /    47 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     908.78 ms /    23 tokens (   39.51 ms per token,    25.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =     625.44 ms /    13 runs   (   48.11 ms per token,    20.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    1536.11 ms /    36 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     834.70 ms /    24 tokens (   34.78 ms per token,    28.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1075.66 ms /    22 runs   (   48.89 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    1913.46 ms /    46 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     766.01 ms /    21 tokens (   36.48 ms per token,    27.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =     530.35 ms /    11 runs   (   48.21 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1297.99 ms /    32 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     671.53 ms /    19 tokens (   35.34 ms per token,    28.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =     432.74 ms /     9 runs   (   48.08 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1105.63 ms /    28 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     952.53 ms /    31 tokens (   30.73 ms per token,    32.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =     930.93 ms /    19 runs   (   49.00 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    1886.20 ms /    50 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1477.70 ms /    32 tokens (   46.18 ms per token,    21.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =     883.34 ms /    18 runs   (   49.07 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    2363.76 ms /    50 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     715.91 ms /    24 tokens (   29.83 ms per token,    33.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =     635.80 ms /    13 runs   (   48.91 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    1353.68 ms /    37 tokens\n",
      "Llama.generate: 28 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     430.15 ms /    12 tokens (   35.85 ms per token,    27.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =     626.34 ms /    13 runs   (   48.18 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1058.42 ms /    25 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     981.14 ms /    30 tokens (   32.70 ms per token,    30.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1014.62 ms /    21 runs   (   48.32 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1998.72 ms /    51 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     753.56 ms /    24 tokens (   31.40 ms per token,    31.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =     728.80 ms /    15 runs   (   48.59 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    1484.56 ms /    39 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     678.85 ms /    22 tokens (   30.86 ms per token,    32.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =     545.09 ms /    11 runs   (   49.55 ms per token,    20.18 tokens per second)\n",
      "llama_perf_context_print:       total time =    1225.54 ms /    33 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     765.00 ms /    25 tokens (   30.60 ms per token,    32.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =     735.62 ms /    15 runs   (   49.04 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    1502.80 ms /    40 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     260.56 ms /     7 tokens (   37.22 ms per token,    26.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =     730.97 ms /    15 runs   (   48.73 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =     993.72 ms /    22 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     612.91 ms /    20 tokens (   30.65 ms per token,    32.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =     487.77 ms /    10 runs   (   48.78 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    1102.15 ms /    30 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     748.55 ms /    25 tokens (   29.94 ms per token,    33.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1170.32 ms /    24 runs   (   48.76 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    1922.28 ms /    49 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     820.49 ms /    24 tokens (   34.19 ms per token,    29.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =     732.38 ms /    15 runs   (   48.83 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    1555.13 ms /    39 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     682.19 ms /    22 tokens (   31.01 ms per token,    32.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =     497.21 ms /    10 runs   (   49.72 ms per token,    20.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    1180.91 ms /    32 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     316.46 ms /     9 tokens (   35.16 ms per token,    28.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =     775.76 ms /    16 runs   (   48.49 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    1094.66 ms /    25 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     645.49 ms /    22 tokens (   29.34 ms per token,    34.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =     782.66 ms /    16 runs   (   48.92 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    1430.43 ms /    38 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     989.41 ms /    31 tokens (   31.92 ms per token,    31.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =     731.12 ms /    15 runs   (   48.74 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    1722.75 ms /    46 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     986.91 ms /    30 tokens (   32.90 ms per token,    30.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1221.48 ms /    25 runs   (   48.86 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    2212.00 ms /    55 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     581.13 ms /    18 tokens (   32.29 ms per token,    30.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1218.54 ms /    25 runs   (   48.74 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    1803.22 ms /    43 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     884.64 ms /    28 tokens (   31.59 ms per token,    31.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =     732.04 ms /    15 runs   (   48.80 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    1618.88 ms /    43 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     274.17 ms /     7 tokens (   39.17 ms per token,    25.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =     631.83 ms /    13 runs   (   48.60 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =     907.86 ms /    20 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1064.58 ms /    29 tokens (   36.71 ms per token,    27.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1262.59 ms /    26 runs   (   48.56 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    2330.66 ms /    55 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1037.01 ms /    26 tokens (   39.88 ms per token,    25.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =     878.31 ms /    18 runs   (   48.79 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    1917.98 ms /    44 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1140.35 ms /    26 tokens (   43.86 ms per token,    22.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =     827.71 ms /    17 runs   (   48.69 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1970.55 ms /    43 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1474.11 ms /    32 tokens (   46.07 ms per token,    21.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =     781.16 ms /    16 runs   (   48.82 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    2257.58 ms /    48 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1140.85 ms /    30 tokens (   38.03 ms per token,    26.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =     973.76 ms /    20 runs   (   48.69 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    2117.49 ms /    50 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1053.35 ms /    27 tokens (   39.01 ms per token,    25.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =     786.83 ms /    16 runs   (   49.18 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    1842.60 ms /    43 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1241.66 ms /    29 tokens (   42.82 ms per token,    23.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =     838.33 ms /    17 runs   (   49.31 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    2082.40 ms /    46 tokens\n",
      "Llama.generate: 46 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     353.69 ms /     7 tokens (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1136.26 ms /    23 runs   (   49.40 ms per token,    20.24 tokens per second)\n",
      "llama_perf_context_print:       total time =    1493.23 ms /    30 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1040.91 ms /    25 tokens (   41.64 ms per token,    24.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =     969.12 ms /    20 runs   (   48.46 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    2012.78 ms /    45 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1237.37 ms /    29 tokens (   42.67 ms per token,    23.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1261.83 ms /    26 runs   (   48.53 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    2502.92 ms /    55 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     979.43 ms /    21 tokens (   46.64 ms per token,    21.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =     482.32 ms /    10 runs   (   48.23 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1463.25 ms /    31 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1158.85 ms /    29 tokens (   39.96 ms per token,    25.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1574.98 ms /    30 runs   (   52.50 ms per token,    19.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    2737.99 ms /    59 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1065.73 ms /    27 tokens (   39.47 ms per token,    25.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =     921.24 ms /    19 runs   (   48.49 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    1989.63 ms /    46 tokens\n",
      "Llama.generate: 45 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     401.97 ms /     8 tokens (   50.25 ms per token,    19.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =     918.93 ms /    19 runs   (   48.36 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1323.54 ms /    27 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     976.76 ms /    24 tokens (   40.70 ms per token,    24.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =     754.62 ms /    15 runs   (   50.31 ms per token,    19.88 tokens per second)\n",
      "llama_perf_context_print:       total time =    1733.58 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1829.51 ms /    33 tokens (   55.44 ms per token,    18.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1259.69 ms /    26 runs   (   48.45 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    3092.95 ms /    59 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1012.41 ms /    26 tokens (   38.94 ms per token,    25.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1126.33 ms /    23 runs   (   48.97 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    2141.91 ms /    49 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1096.27 ms /    28 tokens (   39.15 ms per token,    25.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =     965.28 ms /    20 runs   (   48.26 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    2064.39 ms /    48 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     949.88 ms /    24 tokens (   39.58 ms per token,    25.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =     770.11 ms /    16 runs   (   48.13 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1722.29 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1196.34 ms /    29 tokens (   41.25 ms per token,    24.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =     530.61 ms /    11 runs   (   48.24 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1728.52 ms /    40 tokens\n",
      "Llama.generate: 33 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     774.25 ms /    18 tokens (   43.01 ms per token,    23.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1015.22 ms /    21 runs   (   48.34 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1792.33 ms /    39 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1118.28 ms /    29 tokens (   38.56 ms per token,    25.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1304.91 ms /    27 runs   (   48.33 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    2426.91 ms /    56 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1103.79 ms /    26 tokens (   42.45 ms per token,    23.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =     968.38 ms /    20 runs   (   48.42 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    2074.96 ms /    46 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1697.43 ms /    36 tokens (   47.15 ms per token,    21.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1133.89 ms /    23 runs   (   49.30 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    2835.01 ms /    59 tokens\n",
      "Llama.generate: 47 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     299.39 ms /     6 tokens (   49.90 ms per token,    20.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1119.51 ms /    23 runs   (   48.67 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1422.05 ms /    29 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     999.32 ms /    26 tokens (   38.44 ms per token,    26.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1063.29 ms /    22 runs   (   48.33 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    2065.60 ms /    48 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1117.68 ms /    26 tokens (   42.99 ms per token,    23.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1061.40 ms /    22 runs   (   48.25 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    2182.07 ms /    48 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1048.98 ms /    26 tokens (   40.35 ms per token,    24.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =     915.22 ms /    19 runs   (   48.17 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1966.75 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1238.56 ms /    31 tokens (   39.95 ms per token,    25.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =     866.88 ms /    18 runs   (   48.16 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    2107.81 ms /    49 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1059.84 ms /    26 tokens (   40.76 ms per token,    24.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =     920.34 ms /    19 runs   (   48.44 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    1982.86 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1921.60 ms /    39 tokens (   49.27 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1495.73 ms /    31 runs   (   48.25 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    3421.64 ms /    70 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1090.26 ms /    28 tokens (   38.94 ms per token,    25.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1882.14 ms /    39 runs   (   48.26 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    2977.78 ms /    67 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     886.70 ms /    24 tokens (   36.95 ms per token,    27.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =     769.77 ms /    16 runs   (   48.11 ms per token,    20.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    1658.76 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1910.81 ms /    34 tokens (   56.20 ms per token,    17.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1168.22 ms /    24 runs   (   48.68 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    3082.51 ms /    58 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     783.43 ms /    25 tokens (   31.34 ms per token,    31.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =     577.06 ms /    12 runs   (   48.09 ms per token,    20.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    1362.17 ms /    37 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     754.05 ms /    24 tokens (   31.42 ms per token,    31.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =     529.92 ms /    11 runs   (   48.17 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1285.53 ms /    35 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     828.70 ms /    28 tokens (   29.60 ms per token,    33.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1118.12 ms /    23 runs   (   48.61 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    1950.10 ms /    51 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     879.92 ms /    28 tokens (   31.43 ms per token,    31.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1109.22 ms /    23 runs   (   48.23 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1992.30 ms /    51 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1630.41 ms /    32 tokens (   50.95 ms per token,    19.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1358.68 ms /    28 runs   (   48.52 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    2993.09 ms /    60 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1743.84 ms /    39 tokens (   44.71 ms per token,    22.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1300.94 ms /    27 runs   (   48.18 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    3048.87 ms /    66 tokens\n",
      "Llama.generate: 45 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     483.32 ms /    13 tokens (   37.18 ms per token,    26.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1068.81 ms /    22 runs   (   48.58 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    1555.15 ms /    35 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     950.74 ms /    26 tokens (   36.57 ms per token,    27.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =     935.63 ms /    19 runs   (   49.24 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    1889.12 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1770.98 ms /    33 tokens (   53.67 ms per token,    18.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =     772.81 ms /    16 runs   (   48.30 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    2546.02 ms /    49 tokens\n",
      "Llama.generate: 45 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     326.04 ms /     8 tokens (   40.75 ms per token,    24.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =     779.59 ms /    16 runs   (   48.72 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    1108.20 ms /    24 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     820.30 ms /    24 tokens (   34.18 ms per token,    29.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1156.18 ms /    24 runs   (   48.17 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1979.74 ms /    48 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     949.29 ms /    29 tokens (   32.73 ms per token,    30.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1444.82 ms /    30 runs   (   48.16 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    2398.13 ms /    59 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     864.14 ms /    23 tokens (   37.57 ms per token,    26.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =     817.32 ms /    17 runs   (   48.08 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1683.94 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     911.53 ms /    24 tokens (   37.98 ms per token,    26.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =     638.58 ms /    13 runs   (   49.12 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    1552.04 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1489.15 ms /    32 tokens (   46.54 ms per token,    21.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =     769.27 ms /    16 runs   (   48.08 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    2260.91 ms /    48 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     810.66 ms /    25 tokens (   32.43 ms per token,    30.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =     624.07 ms /    13 runs   (   48.01 ms per token,    20.83 tokens per second)\n",
      "llama_perf_context_print:       total time =    1436.74 ms /    38 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     918.15 ms /    29 tokens (   31.66 ms per token,    31.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =     821.56 ms /    17 runs   (   48.33 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1742.10 ms /    46 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     876.18 ms /    29 tokens (   30.21 ms per token,    33.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1302.00 ms /    27 runs   (   48.22 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    2181.89 ms /    56 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     777.90 ms /    24 tokens (   32.41 ms per token,    30.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1156.28 ms /    24 runs   (   48.18 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1937.55 ms /    48 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     804.45 ms /    26 tokens (   30.94 ms per token,    32.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =     683.15 ms /    14 runs   (   48.80 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    1489.68 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     700.89 ms /    24 tokens (   29.20 ms per token,    34.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =     722.41 ms /    15 runs   (   48.16 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1425.48 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1749.05 ms /    34 tokens (   51.44 ms per token,    19.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1302.10 ms /    27 runs   (   48.23 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    3054.81 ms /    61 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     745.81 ms /    25 tokens (   29.83 ms per token,    33.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =     627.90 ms /    13 runs   (   48.30 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1375.71 ms /    38 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     313.67 ms /     9 tokens (   34.85 ms per token,    28.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =     624.45 ms /    13 runs   (   48.03 ms per token,    20.82 tokens per second)\n",
      "llama_perf_context_print:       total time =     940.28 ms /    22 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     913.26 ms /    30 tokens (   30.44 ms per token,    32.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1303.20 ms /    27 runs   (   48.27 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    2220.28 ms /    57 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 20 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     595.72 ms /    20 tokens (   29.79 ms per token,    33.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =     529.53 ms /    11 runs   (   48.14 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    1128.03 ms /    31 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     858.52 ms /    29 tokens (   29.60 ms per token,    33.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =     721.04 ms /    15 runs   (   48.07 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1581.71 ms /    44 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     816.01 ms /    23 tokens (   35.48 ms per token,    28.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1789.68 ms /    37 runs   (   48.37 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    2610.66 ms /    60 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1645.88 ms /    36 tokens (   45.72 ms per token,    21.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1012.23 ms /    21 runs   (   48.20 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    2661.25 ms /    57 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1700.23 ms /    44 tokens (   38.64 ms per token,    25.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =     933.10 ms /    19 runs   (   49.11 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    2636.34 ms /    63 tokens\n",
      "Llama.generate: 62 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     437.00 ms /    14 tokens (   31.21 ms per token,    32.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =     918.12 ms /    19 runs   (   48.32 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1357.78 ms /    33 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1620.30 ms /    37 tokens (   43.79 ms per token,    22.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =     490.55 ms /    10 runs   (   49.05 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    2112.58 ms /    47 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     933.47 ms /    30 tokens (   31.12 ms per token,    32.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1639.86 ms /    34 runs   (   48.23 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    2578.16 ms /    64 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     736.11 ms /    26 tokens (   28.31 ms per token,    35.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1110.95 ms /    23 runs   (   48.30 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1850.31 ms /    49 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     862.00 ms /    27 tokens (   31.93 ms per token,    31.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =     740.07 ms /    15 runs   (   49.34 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    1604.13 ms /    42 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     967.78 ms /    26 tokens (   37.22 ms per token,    26.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =     820.21 ms /    17 runs   (   48.25 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1790.30 ms /    43 tokens\n",
      "Llama.generate: 44 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     321.33 ms /     7 tokens (   45.90 ms per token,    21.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =     818.60 ms /    17 runs   (   48.15 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    1142.25 ms /    24 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     473.03 ms /    15 tokens (   31.54 ms per token,    31.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =     962.82 ms /    20 runs   (   48.14 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    1438.58 ms /    35 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1669.41 ms /    37 tokens (   45.12 ms per token,    22.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1833.28 ms /    38 runs   (   48.24 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    3508.42 ms /    75 tokens\n",
      "Llama.generate: 55 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     646.15 ms /    22 tokens (   29.37 ms per token,    34.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2395.38 ms /    49 runs   (   48.89 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    3048.42 ms /    71 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     780.76 ms /    28 tokens (   27.88 ms per token,    35.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1158.32 ms /    24 runs   (   48.26 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1942.35 ms /    52 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1022.49 ms /    29 tokens (   35.26 ms per token,    28.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1012.76 ms /    21 runs   (   48.23 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    2038.17 ms /    50 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     687.02 ms /    20 tokens (   34.35 ms per token,    29.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =     577.39 ms /    12 runs   (   48.12 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1266.20 ms /    32 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1624.78 ms /    36 tokens (   45.13 ms per token,    22.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1257.84 ms /    26 runs   (   48.38 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    2886.85 ms /    62 tokens\n",
      "Llama.generate: 48 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     283.71 ms /     8 tokens (   35.46 ms per token,    28.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1268.51 ms /    26 runs   (   48.79 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    1555.97 ms /    34 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     806.44 ms /    26 tokens (   31.02 ms per token,    32.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =     967.45 ms /    20 runs   (   48.37 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    1776.67 ms /    46 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     836.44 ms /    28 tokens (   29.87 ms per token,    33.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1116.95 ms /    23 runs   (   48.56 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    1956.59 ms /    51 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     395.52 ms /    12 tokens (   32.96 ms per token,    30.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =     978.13 ms /    20 runs   (   48.91 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    1376.56 ms /    32 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     753.06 ms /    23 tokens (   32.74 ms per token,    30.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =     781.93 ms /    16 runs   (   48.87 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    1537.38 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     748.89 ms /    25 tokens (   29.96 ms per token,    33.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =     490.68 ms /    10 runs   (   49.07 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    1241.11 ms /    35 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     889.22 ms /    30 tokens (   29.64 ms per token,    33.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =     735.74 ms /    15 runs   (   49.05 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    1627.23 ms /    45 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     838.88 ms /    27 tokens (   31.07 ms per token,    32.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =     686.50 ms /    14 runs   (   49.04 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    1527.41 ms /    41 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     965.40 ms /    28 tokens (   34.48 ms per token,    29.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1172.85 ms /    24 runs   (   48.87 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    2141.49 ms /    52 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     993.68 ms /    29 tokens (   34.26 ms per token,    29.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =     879.73 ms /    18 runs   (   48.87 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    1875.98 ms /    47 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1146.09 ms /    31 tokens (   36.97 ms per token,    27.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1314.11 ms /    27 runs   (   48.67 ms per token,    20.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    2463.91 ms /    58 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     985.20 ms /    28 tokens (   35.19 ms per token,    28.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =     686.14 ms /    14 runs   (   49.01 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    1673.46 ms /    42 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     368.63 ms /     9 tokens (   40.96 ms per token,    24.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =     648.53 ms /    13 runs   (   49.89 ms per token,    20.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    1019.10 ms /    22 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     454.99 ms /    12 tokens (   37.92 ms per token,    26.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =     787.85 ms /    16 runs   (   49.24 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    1245.23 ms /    28 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     990.79 ms /    29 tokens (   34.17 ms per token,    29.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =     785.39 ms /    16 runs   (   49.09 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    1778.55 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1085.59 ms /    31 tokens (   35.02 ms per token,    28.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =     681.06 ms /    14 runs   (   48.65 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    1768.63 ms /    45 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     873.01 ms /    25 tokens (   34.92 ms per token,    28.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =     590.61 ms /    12 runs   (   49.22 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    1465.54 ms /    37 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     785.82 ms /    26 tokens (   30.22 ms per token,    33.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1123.23 ms /    23 runs   (   48.84 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    1912.25 ms /    49 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     849.30 ms /    27 tokens (   31.46 ms per token,    31.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =     643.71 ms /    13 runs   (   49.52 ms per token,    20.20 tokens per second)\n",
      "llama_perf_context_print:       total time =    1495.00 ms /    40 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1078.66 ms /    31 tokens (   34.80 ms per token,    28.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1319.36 ms /    27 runs   (   48.87 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    2401.68 ms /    58 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1284.57 ms /    28 tokens (   45.88 ms per token,    21.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =     829.02 ms /    17 runs   (   48.77 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    2116.03 ms /    45 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     875.90 ms /    29 tokens (   30.20 ms per token,    33.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1266.63 ms /    26 runs   (   48.72 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    2145.98 ms /    55 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     991.05 ms /    28 tokens (   35.39 ms per token,    28.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =     924.73 ms /    19 runs   (   48.67 ms per token,    20.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    1918.42 ms /    47 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     873.19 ms /    26 tokens (   33.58 ms per token,    29.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1130.43 ms /    23 runs   (   49.15 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    2006.74 ms /    49 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     438.92 ms /    11 tokens (   39.90 ms per token,    25.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1322.60 ms /    27 runs   (   48.99 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    1765.21 ms /    38 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 133 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2358.13 ms /   133 tokens (   17.73 ms per token,    56.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5696.14 ms /   115 runs   (   49.53 ms per token,    20.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    8073.57 ms /   248 tokens\n",
      "Llama.generate: 147 prefix-match hit, remaining 336 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    3688.33 ms /   336 tokens (   10.98 ms per token,    91.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1408.09 ms /    28 runs   (   50.29 ms per token,    19.89 tokens per second)\n",
      "llama_perf_context_print:       total time =    5101.08 ms /   364 tokens\n",
      "Llama.generate: 50 prefix-match hit, remaining 133 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2286.20 ms /   133 tokens (   17.19 ms per token,    58.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =     633.51 ms /    13 runs   (   48.73 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    2922.04 ms /   146 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 373 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    4049.19 ms /   373 tokens (   10.86 ms per token,    92.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5892.16 ms /   118 runs   (   49.93 ms per token,    20.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    9960.91 ms /   491 tokens\n",
      "Llama.generate: 56 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1638.21 ms /    54 tokens (   30.34 ms per token,    32.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =     794.70 ms /    16 runs   (   49.67 ms per token,    20.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    2435.71 ms /    70 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 90 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1880.67 ms /    90 tokens (   20.90 ms per token,    47.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3089.38 ms /    63 runs   (   49.04 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    4979.49 ms /   153 tokens\n",
      "Llama.generate: 103 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     316.30 ms /     9 tokens (   35.14 ms per token,    28.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2931.73 ms /    60 runs   (   48.86 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    3256.76 ms /    69 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1851.15 ms /    74 tokens (   25.02 ms per token,    39.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3401.95 ms /    70 runs   (   48.60 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    5263.79 ms /   144 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1812.88 ms /    65 tokens (   27.89 ms per token,    35.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2961.00 ms /    61 runs   (   48.54 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    4783.13 ms /   126 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     530.08 ms /    15 tokens (   35.34 ms per token,    28.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1559.23 ms /    30 runs   (   51.97 ms per token,    19.24 tokens per second)\n",
      "llama_perf_context_print:       total time =    2093.51 ms /    45 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     330.36 ms /     8 tokens (   41.29 ms per token,    24.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1015.44 ms /    21 runs   (   48.35 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1348.95 ms /    29 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     847.21 ms /    26 tokens (   32.58 ms per token,    30.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =     483.43 ms /    10 runs   (   48.34 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1332.12 ms /    36 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     342.21 ms /    10 tokens (   34.22 ms per token,    29.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =     584.18 ms /    12 runs   (   48.68 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =     928.34 ms /    22 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     828.23 ms /    28 tokens (   29.58 ms per token,    33.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1257.56 ms /    26 runs   (   48.37 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    2089.32 ms /    54 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     816.84 ms /    26 tokens (   31.42 ms per token,    31.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =     776.79 ms /    16 runs   (   48.55 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    1595.99 ms /    42 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     889.31 ms /    27 tokens (   32.94 ms per token,    30.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =     795.70 ms /    16 runs   (   49.73 ms per token,    20.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    1687.32 ms /    43 tokens\n",
      "Llama.generate: 46 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     481.39 ms /    11 tokens (   43.76 ms per token,    22.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1356.60 ms /    28 runs   (   48.45 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    1841.91 ms /    39 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     873.02 ms /    28 tokens (   31.18 ms per token,    32.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1259.71 ms /    26 runs   (   48.45 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    2136.41 ms /    54 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     738.05 ms /    23 tokens (   32.09 ms per token,    31.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =     635.91 ms /    13 runs   (   48.92 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    1375.96 ms /    36 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     676.63 ms /    22 tokens (   30.76 ms per token,    32.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =     728.75 ms /    15 runs   (   48.58 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    1407.57 ms /    37 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     786.88 ms /    26 tokens (   30.26 ms per token,    33.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1161.37 ms /    24 runs   (   48.39 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    1951.62 ms /    50 tokens\n",
      "Llama.generate: 44 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     257.20 ms /     7 tokens (   36.74 ms per token,    27.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1168.57 ms /    24 runs   (   48.69 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1429.12 ms /    31 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     680.15 ms /    21 tokens (   32.39 ms per token,    30.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =     677.14 ms /    14 runs   (   48.37 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1359.39 ms /    35 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     896.81 ms /    31 tokens (   28.93 ms per token,    34.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1157.87 ms /    24 runs   (   48.24 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    2057.89 ms /    55 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     801.18 ms /    24 tokens (   33.38 ms per token,    29.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =     869.87 ms /    18 runs   (   48.33 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1673.71 ms /    42 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     863.54 ms /    27 tokens (   31.98 ms per token,    31.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1317.57 ms /    27 runs   (   48.80 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    2184.86 ms /    54 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     771.62 ms /    25 tokens (   30.86 ms per token,    32.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =     870.23 ms /    18 runs   (   48.35 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1644.56 ms /    43 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     304.94 ms /     8 tokens (   38.12 ms per token,    26.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =     869.34 ms /    18 runs   (   48.30 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1176.82 ms /    26 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     771.72 ms /    21 tokens (   36.75 ms per token,    27.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =     873.74 ms /    18 runs   (   48.54 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    1648.08 ms /    39 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     417.71 ms /    10 tokens (   41.77 ms per token,    23.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =     652.44 ms /    13 runs   (   50.19 ms per token,    19.93 tokens per second)\n",
      "llama_perf_context_print:       total time =    1072.30 ms /    23 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     916.60 ms /    25 tokens (   36.66 ms per token,    27.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1196.53 ms /    23 runs   (   52.02 ms per token,    19.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    2116.52 ms /    48 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     779.00 ms /    21 tokens (   37.10 ms per token,    26.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =     784.07 ms /    15 runs   (   52.27 ms per token,    19.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    1565.32 ms /    36 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1014.70 ms /    31 tokens (   32.73 ms per token,    30.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1197.64 ms /    24 runs   (   49.90 ms per token,    20.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    2215.75 ms /    55 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    3034.76 ms /    25 tokens (  121.39 ms per token,     8.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1096.98 ms /    17 runs   (   64.53 ms per token,    15.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    4134.28 ms /    42 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2690.63 ms /    21 tokens (  128.13 ms per token,     7.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1027.59 ms /    15 runs   (   68.51 ms per token,    14.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    3720.59 ms /    36 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1964.13 ms /    31 tokens (   63.36 ms per token,    15.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1265.21 ms /    24 runs   (   52.72 ms per token,    18.97 tokens per second)\n",
      "llama_perf_context_print:       total time =    3233.06 ms /    55 tokens\n",
      "Llama.generate: 44 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     394.64 ms /     7 tokens (   56.38 ms per token,    17.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1274.71 ms /    24 runs   (   53.11 ms per token,    18.83 tokens per second)\n",
      "llama_perf_context_print:       total time =    1672.94 ms /    31 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     972.48 ms /    25 tokens (   38.90 ms per token,    25.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =     909.83 ms /    18 runs   (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1885.10 ms /    43 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     818.49 ms /    21 tokens (   38.98 ms per token,    25.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1146.87 ms /    16 runs   (   71.68 ms per token,    13.95 tokens per second)\n",
      "llama_perf_context_print:       total time =    1967.77 ms /    37 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1237.13 ms /    25 tokens (   49.49 ms per token,    20.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =     969.92 ms /    18 runs   (   53.88 ms per token,    18.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    2209.88 ms /    43 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1212.11 ms /    23 tokens (   52.70 ms per token,    18.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =     690.28 ms /    14 runs   (   49.31 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    1904.61 ms /    37 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     515.39 ms /     9 tokens (   57.27 ms per token,    17.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =     758.66 ms /    15 runs   (   50.58 ms per token,    19.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    1276.27 ms /    24 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     397.91 ms /     7 tokens (   56.84 ms per token,    17.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =     651.57 ms /    13 runs   (   50.12 ms per token,    19.95 tokens per second)\n",
      "llama_perf_context_print:       total time =    1051.51 ms /    20 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     514.63 ms /     8 tokens (   64.33 ms per token,    15.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =     701.59 ms /    14 runs   (   50.11 ms per token,    19.95 tokens per second)\n",
      "llama_perf_context_print:       total time =    1218.36 ms /    22 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     393.64 ms /     8 tokens (   49.21 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =     681.02 ms /    14 runs   (   48.64 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    1076.76 ms /    22 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1227.48 ms /    26 tokens (   47.21 ms per token,    21.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =     917.26 ms /    18 runs   (   50.96 ms per token,    19.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    2147.50 ms /    44 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     818.12 ms /    21 tokens (   38.96 ms per token,    25.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =     888.22 ms /    17 runs   (   52.25 ms per token,    19.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    1708.83 ms /    38 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     775.60 ms /    21 tokens (   36.93 ms per token,    27.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =     747.02 ms /    15 runs   (   49.80 ms per token,    20.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    1524.80 ms /    36 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1031.30 ms /    26 tokens (   39.67 ms per token,    25.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =     817.86 ms /    17 runs   (   48.11 ms per token,    20.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    1851.64 ms /    43 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     859.44 ms /    25 tokens (   34.38 ms per token,    29.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =     982.44 ms /    19 runs   (   51.71 ms per token,    19.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    1844.52 ms /    44 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     331.87 ms /     8 tokens (   41.48 ms per token,    24.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =     913.92 ms /    19 runs   (   48.10 ms per token,    20.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    1248.45 ms /    27 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     692.59 ms /    21 tokens (   32.98 ms per token,    30.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =     720.47 ms /    15 runs   (   48.03 ms per token,    20.82 tokens per second)\n",
      "llama_perf_context_print:       total time =    1415.29 ms /    36 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     854.83 ms /    27 tokens (   31.66 ms per token,    31.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =     961.11 ms /    20 runs   (   48.06 ms per token,    20.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    1818.62 ms /    47 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1565.79 ms /    19 tokens (   82.41 ms per token,    12.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =     628.79 ms /    13 runs   (   48.37 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    2196.55 ms /    32 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1189.03 ms /    26 tokens (   45.73 ms per token,    21.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1112.09 ms /    23 runs   (   48.35 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    2304.31 ms /    49 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     603.52 ms /    20 tokens (   30.18 ms per token,    33.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =     919.42 ms /    19 runs   (   48.39 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    1525.64 ms /    39 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 21 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     828.92 ms /    25 tokens (   33.16 ms per token,    30.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =     965.05 ms /    20 runs   (   48.25 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1797.98 ms /    45 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     611.60 ms /    20 tokens (   30.58 ms per token,    32.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =     914.58 ms /    19 runs   (   48.14 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    1528.89 ms /    39 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     301.16 ms /     8 tokens (   37.64 ms per token,    26.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1297.19 ms /    27 runs   (   48.04 ms per token,    20.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    1602.06 ms /    35 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     816.61 ms /    25 tokens (   32.66 ms per token,    30.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1106.80 ms /    23 runs   (   48.12 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1926.58 ms /    48 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     609.84 ms /    19 tokens (   32.10 ms per token,    31.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =     482.36 ms /    10 runs   (   48.24 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1093.73 ms /    29 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     713.66 ms /    25 tokens (   28.55 ms per token,    35.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =     918.09 ms /    19 runs   (   48.32 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1634.40 ms /    44 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     425.98 ms /    12 tokens (   35.50 ms per token,    28.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =     720.55 ms /    15 runs   (   48.04 ms per token,    20.82 tokens per second)\n",
      "llama_perf_context_print:       total time =    1148.74 ms /    27 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     653.52 ms /    20 tokens (   32.68 ms per token,    30.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =     624.41 ms /    13 runs   (   48.03 ms per token,    20.82 tokens per second)\n",
      "llama_perf_context_print:       total time =    1279.89 ms /    33 tokens\n",
      "Llama.generate: 30 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     534.20 ms /    18 tokens (   29.68 ms per token,    33.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =     528.88 ms /    11 runs   (   48.08 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1064.77 ms /    29 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1617.12 ms /    39 tokens (   41.46 ms per token,    24.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1643.85 ms /    34 runs   (   48.35 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    3265.79 ms /    73 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1663.69 ms /    41 tokens (   40.58 ms per token,    24.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1882.21 ms /    39 runs   (   48.26 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    3551.68 ms /    80 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     970.62 ms /    30 tokens (   32.35 ms per token,    30.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1497.65 ms /    31 runs   (   48.31 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    2472.64 ms /    61 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1606.67 ms /    35 tokens (   45.91 ms per token,    21.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1745.73 ms /    36 runs   (   48.49 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    3357.69 ms /    71 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1693.65 ms /    36 tokens (   47.05 ms per token,    21.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =     869.79 ms /    18 runs   (   48.32 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    2566.13 ms /    54 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1708.80 ms /    43 tokens (   39.74 ms per token,    25.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2341.29 ms /    48 runs   (   48.78 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    4057.39 ms /    91 tokens\n",
      "Llama.generate: 62 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     321.22 ms /     9 tokens (   35.69 ms per token,    28.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2526.44 ms /    52 runs   (   48.59 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    2854.98 ms /    61 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1773.65 ms /    47 tokens (   37.74 ms per token,    26.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1800.29 ms /    37 runs   (   48.66 ms per token,    20.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    3579.52 ms /    84 tokens\n",
      "Llama.generate: 66 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     405.41 ms /    12 tokens (   33.78 ms per token,    29.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1983.76 ms /    41 runs   (   48.38 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    2394.89 ms /    53 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     833.77 ms /    30 tokens (   27.79 ms per token,    35.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1307.01 ms /    27 runs   (   48.41 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    2144.57 ms /    57 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     744.39 ms /    25 tokens (   29.78 ms per token,    33.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =     533.40 ms /    11 runs   (   48.49 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    1279.40 ms /    36 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1611.25 ms /    39 tokens (   41.31 ms per token,    24.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1764.22 ms /    36 runs   (   49.01 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    3380.82 ms /    75 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     993.90 ms /    25 tokens (   39.76 ms per token,    25.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =     866.62 ms /    18 runs   (   48.15 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    1863.05 ms /    43 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     886.24 ms /    30 tokens (   29.54 ms per token,    33.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1507.59 ms /    31 runs   (   48.63 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    2398.17 ms /    61 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     305.82 ms /     9 tokens (   33.98 ms per token,    29.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1318.96 ms /    27 runs   (   48.85 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    1628.65 ms /    36 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     546.10 ms /    18 tokens (   30.34 ms per token,    32.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =     776.41 ms /    16 runs   (   48.53 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    1324.85 ms /    34 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     701.03 ms /    23 tokens (   30.48 ms per token,    32.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =     730.53 ms /    15 runs   (   48.70 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    1433.68 ms /    38 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     800.95 ms /    24 tokens (   33.37 ms per token,    29.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1380.28 ms /    28 runs   (   49.30 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    2185.25 ms /    52 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     259.45 ms /     7 tokens (   37.06 ms per token,    26.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1079.02 ms /    22 runs   (   49.05 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    1341.57 ms /    29 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     746.00 ms /    24 tokens (   31.08 ms per token,    32.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =     782.77 ms /    16 runs   (   48.92 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    1531.05 ms /    40 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     764.64 ms /    25 tokens (   30.59 ms per token,    32.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =     936.24 ms /    19 runs   (   49.28 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    1703.62 ms /    44 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     762.96 ms /    25 tokens (   30.52 ms per token,    32.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =     888.50 ms /    18 runs   (   49.36 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    1653.97 ms /    43 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     806.42 ms /    26 tokens (   31.02 ms per token,    32.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1080.62 ms /    22 runs   (   49.12 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    1890.16 ms /    48 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     280.36 ms /     8 tokens (   35.05 ms per token,    28.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1089.50 ms /    22 runs   (   49.52 ms per token,    20.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    1373.06 ms /    30 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     747.54 ms /    21 tokens (   35.60 ms per token,    28.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =     683.91 ms /    14 runs   (   48.85 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    1433.60 ms /    35 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     834.27 ms /    26 tokens (   32.09 ms per token,    31.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =     884.76 ms /    18 runs   (   49.15 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    1721.58 ms /    44 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     660.95 ms /    21 tokens (   31.47 ms per token,    31.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =     740.10 ms /    15 runs   (   49.34 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    1403.32 ms /    36 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     635.23 ms /    21 tokens (   30.25 ms per token,    33.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =     841.47 ms /    17 runs   (   49.50 ms per token,    20.20 tokens per second)\n",
      "llama_perf_context_print:       total time =    1479.28 ms /    38 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     760.53 ms /    26 tokens (   29.25 ms per token,    34.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =     736.22 ms /    15 runs   (   49.08 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    1498.98 ms /    41 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1660.22 ms /    40 tokens (   41.51 ms per token,    24.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2159.74 ms /    44 runs   (   49.08 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    3826.53 ms /    84 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1644.78 ms /    55 tokens (   29.91 ms per token,    33.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3078.44 ms /    63 runs   (   48.86 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    4732.57 ms /   118 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     685.38 ms /    23 tokens (   29.80 ms per token,    33.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =     630.80 ms /    13 runs   (   48.52 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    1318.19 ms /    36 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     823.44 ms /    28 tokens (   29.41 ms per token,    34.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1229.32 ms /    25 runs   (   49.17 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    2056.20 ms /    53 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     993.60 ms /    31 tokens (   32.05 ms per token,    31.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =     844.18 ms /    17 runs   (   49.66 ms per token,    20.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    1840.31 ms /    48 tokens\n",
      "Llama.generate: 26 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     482.74 ms /    15 tokens (   32.18 ms per token,    31.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1169.69 ms /    24 runs   (   48.74 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    1655.73 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     793.47 ms /    27 tokens (   29.39 ms per token,    34.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =     536.92 ms /    11 runs   (   48.81 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    1332.23 ms /    38 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     820.45 ms /    28 tokens (   29.30 ms per token,    34.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1116.61 ms /    23 runs   (   48.55 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    1940.22 ms /    51 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     593.52 ms /    18 tokens (   32.97 ms per token,    30.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1413.26 ms /    29 runs   (   48.73 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    2010.90 ms /    47 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     783.78 ms /    25 tokens (   31.35 ms per token,    31.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1117.09 ms /    21 runs   (   53.19 ms per token,    18.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1903.82 ms /    46 tokens\n",
      "Llama.generate: 33 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     446.73 ms /    14 tokens (   31.91 ms per token,    31.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =     678.51 ms /    14 runs   (   48.46 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    1127.40 ms /    28 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     945.51 ms /    30 tokens (   31.52 ms per token,    31.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =     777.69 ms /    16 runs   (   48.61 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    1725.54 ms /    46 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1604.49 ms /    33 tokens (   48.62 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1703.21 ms /    35 runs   (   48.66 ms per token,    20.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    3312.82 ms /    68 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     886.43 ms /    26 tokens (   34.09 ms per token,    29.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =     867.57 ms /    18 runs   (   48.20 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    1756.60 ms /    44 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     906.79 ms /    31 tokens (   29.25 ms per token,    34.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1458.81 ms /    30 runs   (   48.63 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    2370.14 ms /    61 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     741.39 ms /    24 tokens (   30.89 ms per token,    32.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =     770.90 ms /    16 runs   (   48.18 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    1514.57 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     936.47 ms /    30 tokens (   31.22 ms per token,    32.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =     915.83 ms /    19 runs   (   48.20 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    1855.12 ms /    49 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     837.55 ms /    28 tokens (   29.91 ms per token,    33.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =     873.75 ms /    18 runs   (   48.54 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    1713.82 ms /    46 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     702.05 ms /    23 tokens (   30.52 ms per token,    32.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =     769.63 ms /    16 runs   (   48.10 ms per token,    20.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    1473.96 ms /    39 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     927.46 ms /    30 tokens (   30.92 ms per token,    32.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1258.95 ms /    26 runs   (   48.42 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    2190.07 ms /    56 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     764.18 ms /    24 tokens (   31.84 ms per token,    31.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =     784.76 ms /    16 runs   (   49.05 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    1551.21 ms /    40 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     294.09 ms /     8 tokens (   36.76 ms per token,    27.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =     879.04 ms /    18 runs   (   48.84 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    1175.71 ms /    26 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1082.71 ms /    29 tokens (   37.33 ms per token,    26.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =     878.62 ms /    18 runs   (   48.81 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    1963.96 ms /    47 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     755.10 ms /    18 tokens (   41.95 ms per token,    23.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =     640.26 ms /    13 runs   (   49.25 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    1397.52 ms /    31 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     806.38 ms /    26 tokens (   31.01 ms per token,    32.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1062.58 ms /    22 runs   (   48.30 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1872.09 ms /    48 tokens\n",
      "Llama.generate: 29 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     953.05 ms /    30 tokens (   31.77 ms per token,    31.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =     627.16 ms /    13 runs   (   48.24 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1582.06 ms /    43 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1688.07 ms /    39 tokens (   43.28 ms per token,    23.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1109.33 ms /    23 runs   (   48.23 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    2800.76 ms /    62 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     649.30 ms /    21 tokens (   30.92 ms per token,    32.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =     585.66 ms /    12 runs   (   48.81 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    1237.05 ms /    33 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     856.56 ms /    25 tokens (   34.26 ms per token,    29.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =     768.78 ms /    16 runs   (   48.05 ms per token,    20.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    1627.67 ms /    41 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     305.61 ms /     9 tokens (   33.96 ms per token,    29.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =     819.68 ms /    17 runs   (   48.22 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1127.79 ms /    26 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     738.97 ms /    25 tokens (   29.56 ms per token,    33.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =     866.06 ms /    18 runs   (   48.11 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1607.55 ms /    43 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     737.57 ms /    25 tokens (   29.50 ms per token,    33.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1111.30 ms /    23 runs   (   48.32 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1852.11 ms /    48 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     760.35 ms /    24 tokens (   31.68 ms per token,    31.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =     818.81 ms /    17 runs   (   48.17 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1581.57 ms /    41 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     665.74 ms /    22 tokens (   30.26 ms per token,    33.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =     864.56 ms /    18 runs   (   48.03 ms per token,    20.82 tokens per second)\n",
      "llama_perf_context_print:       total time =    1532.88 ms /    40 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     313.87 ms /     9 tokens (   34.87 ms per token,    28.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =     721.56 ms /    15 runs   (   48.10 ms per token,    20.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    1037.53 ms /    24 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     768.22 ms /    22 tokens (   34.92 ms per token,    28.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =     957.40 ms /    18 runs   (   53.19 ms per token,    18.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1728.22 ms /    40 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     713.00 ms /    25 tokens (   28.52 ms per token,    35.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =     876.13 ms /    18 runs   (   48.67 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1591.74 ms /    43 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     729.24 ms /    24 tokens (   30.38 ms per token,    32.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =     817.51 ms /    17 runs   (   48.09 ms per token,    20.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    1549.19 ms /    41 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     598.32 ms /    20 tokens (   29.92 ms per token,    33.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =     729.49 ms /    15 runs   (   48.63 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    1329.97 ms /    35 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     644.91 ms /    20 tokens (   32.25 ms per token,    31.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =     528.70 ms /    11 runs   (   48.06 ms per token,    20.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    1175.31 ms /    31 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     831.99 ms /    29 tokens (   28.69 ms per token,    34.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =     865.71 ms /    18 runs   (   48.09 ms per token,    20.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    1700.23 ms /    47 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     245.06 ms /     7 tokens (   35.01 ms per token,    28.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =     866.08 ms /    18 runs   (   48.12 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1113.56 ms /    25 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     603.02 ms /    20 tokens (   30.15 ms per token,    33.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =     535.83 ms /    11 runs   (   48.71 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    1140.57 ms /    31 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     266.92 ms /     7 tokens (   38.13 ms per token,    26.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =     577.39 ms /    12 runs   (   48.12 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =     846.04 ms /    19 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     914.35 ms /    30 tokens (   30.48 ms per token,    32.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1063.42 ms /    22 runs   (   48.34 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1980.86 ms /    52 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     865.36 ms /    20 tokens (   43.27 ms per token,    23.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =     527.83 ms /    11 runs   (   47.98 ms per token,    20.84 tokens per second)\n",
      "llama_perf_context_print:       total time =    1394.89 ms /    31 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1022.08 ms /    26 tokens (   39.31 ms per token,    25.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =     720.68 ms /    15 runs   (   48.05 ms per token,    20.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    1744.83 ms /    41 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     619.04 ms /    20 tokens (   30.95 ms per token,    32.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =     724.21 ms /    15 runs   (   48.28 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1345.39 ms /    35 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     760.35 ms /    25 tokens (   30.41 ms per token,    32.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =     576.99 ms /    12 runs   (   48.08 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1339.06 ms /    37 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     793.64 ms /    26 tokens (   30.52 ms per token,    32.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1401.17 ms /    29 runs   (   48.32 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    2198.82 ms /    55 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     758.89 ms /    25 tokens (   30.36 ms per token,    32.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1348.59 ms /    28 runs   (   48.16 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    2111.41 ms /    53 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     669.59 ms /    21 tokens (   31.89 ms per token,    31.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =     816.93 ms /    17 runs   (   48.05 ms per token,    20.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    1488.89 ms /    38 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1719.35 ms /    39 tokens (   44.09 ms per token,    22.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1595.42 ms /    33 runs   (   48.35 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    3319.34 ms /    72 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1721.55 ms /    41 tokens (   41.99 ms per token,    23.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =     965.24 ms /    20 runs   (   48.26 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    2689.86 ms /    61 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     838.73 ms /    26 tokens (   32.26 ms per token,    31.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1014.76 ms /    21 runs   (   48.32 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1856.42 ms /    47 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     737.20 ms /    24 tokens (   30.72 ms per token,    32.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1340.85 ms /    25 runs   (   53.63 ms per token,    18.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    2081.62 ms /    49 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     489.12 ms /    15 tokens (   32.61 ms per token,    30.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =     795.42 ms /    16 runs   (   49.71 ms per token,    20.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    1286.86 ms /    31 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     985.49 ms /    29 tokens (   33.98 ms per token,    29.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =     915.73 ms /    19 runs   (   48.20 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    1903.97 ms /    48 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1638.21 ms /    36 tokens (   45.51 ms per token,    21.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2470.80 ms /    51 runs   (   48.45 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    4116.55 ms /    87 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     873.97 ms /    31 tokens (   28.19 ms per token,    35.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1058.94 ms /    22 runs   (   48.13 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1936.22 ms /    53 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     677.89 ms /    21 tokens (   32.28 ms per token,    30.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =     720.49 ms /    15 runs   (   48.03 ms per token,    20.82 tokens per second)\n",
      "llama_perf_context_print:       total time =    1400.40 ms /    36 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     498.99 ms /    12 tokens (   41.58 ms per token,    24.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =     737.98 ms /    15 runs   (   49.20 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    1239.12 ms /    27 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 22 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     718.25 ms /    22 tokens (   32.65 ms per token,    30.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1685.67 ms /    35 runs   (   48.16 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    2410.00 ms /    57 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     504.65 ms /    16 tokens (   31.54 ms per token,    31.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =     528.42 ms /    11 runs   (   48.04 ms per token,    20.82 tokens per second)\n",
      "llama_perf_context_print:       total time =    1034.73 ms /    27 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1749.12 ms /    33 tokens (   53.00 ms per token,    18.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =     923.29 ms /    19 runs   (   48.59 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    2675.73 ms /    52 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     723.00 ms /    26 tokens (   27.81 ms per token,    35.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1158.43 ms /    24 runs   (   48.27 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1884.80 ms /    50 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1733.64 ms /    48 tokens (   36.12 ms per token,    27.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =     915.94 ms /    19 runs   (   48.21 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    2652.34 ms /    67 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1652.97 ms /    33 tokens (   50.09 ms per token,    19.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1204.27 ms /    25 runs   (   48.17 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    2860.86 ms /    58 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     601.52 ms /    20 tokens (   30.08 ms per token,    33.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =     673.73 ms /    14 runs   (   48.12 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1277.47 ms /    34 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     721.50 ms /    25 tokens (   28.86 ms per token,    34.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =     816.64 ms /    17 runs   (   48.04 ms per token,    20.82 tokens per second)\n",
      "llama_perf_context_print:       total time =    1540.56 ms /    42 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1838.20 ms /    66 tokens (   27.85 ms per token,    35.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2836.30 ms /    58 runs   (   48.90 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    4682.96 ms /   124 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     822.77 ms /    26 tokens (   31.64 ms per token,    31.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1012.99 ms /    21 runs   (   48.24 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1838.74 ms /    47 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     794.12 ms /    27 tokens (   29.41 ms per token,    34.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1011.53 ms /    21 runs   (   48.17 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1808.60 ms /    48 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     741.70 ms /    24 tokens (   30.90 ms per token,    32.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1010.48 ms /    21 runs   (   48.12 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1755.04 ms /    45 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     709.61 ms /    22 tokens (   32.26 ms per token,    31.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =     480.12 ms /    10 runs   (   48.01 ms per token,    20.83 tokens per second)\n",
      "llama_perf_context_print:       total time =    1191.24 ms /    32 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     868.93 ms /    26 tokens (   33.42 ms per token,    29.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =     769.57 ms /    16 runs   (   48.10 ms per token,    20.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    1641.00 ms /    42 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     655.36 ms /    22 tokens (   29.79 ms per token,    33.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =     576.84 ms /    12 runs   (   48.07 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1234.06 ms /    34 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     787.88 ms /    28 tokens (   28.14 ms per token,    35.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =     768.92 ms /    16 runs   (   48.06 ms per token,    20.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    1559.10 ms /    44 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     744.41 ms /    23 tokens (   32.37 ms per token,    30.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =     480.42 ms /    10 runs   (   48.04 ms per token,    20.82 tokens per second)\n",
      "llama_perf_context_print:       total time =    1226.41 ms /    33 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     837.89 ms /    29 tokens (   28.89 ms per token,    34.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =     673.15 ms /    14 runs   (   48.08 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1513.04 ms /    43 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     867.74 ms /    29 tokens (   29.92 ms per token,    33.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1116.24 ms /    23 runs   (   48.53 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    1987.18 ms /    52 tokens\n",
      "Llama.generate: 46 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     273.03 ms /     8 tokens (   34.13 ms per token,    29.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1510.28 ms /    31 runs   (   48.72 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    1787.56 ms /    39 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     773.29 ms /    25 tokens (   30.93 ms per token,    32.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =     875.92 ms /    18 runs   (   48.66 ms per token,    20.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    1651.71 ms /    43 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 81 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1819.55 ms /    81 tokens (   22.46 ms per token,    44.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3859.76 ms /    79 runs   (   48.86 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    5691.34 ms /   160 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 80 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1849.35 ms /    80 tokens (   23.12 ms per token,    43.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3435.46 ms /    70 runs   (   49.08 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    5295.53 ms /   150 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 89 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1868.69 ms /    89 tokens (   21.00 ms per token,    47.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1726.61 ms /    35 runs   (   49.33 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    3600.42 ms /   124 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1825.64 ms /    72 tokens (   25.36 ms per token,    39.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =     585.17 ms /    12 runs   (   48.76 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    2412.91 ms /    84 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1855.13 ms /    72 tokens (   25.77 ms per token,    38.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2949.54 ms /    60 runs   (   49.16 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    4813.58 ms /   132 tokens\n",
      "Llama.generate: 72 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     428.30 ms /    13 tokens (   32.95 ms per token,    30.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2666.85 ms /    54 runs   (   49.39 ms per token,    20.25 tokens per second)\n",
      "llama_perf_context_print:       total time =    3102.94 ms /    67 tokens\n",
      "Llama.generate: 56 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     665.01 ms /    21 tokens (   31.67 ms per token,    31.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2319.75 ms /    47 runs   (   49.36 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    2991.45 ms /    68 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1792.12 ms /    48 tokens (   37.34 ms per token,    26.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2120.44 ms /    43 runs   (   49.31 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    3919.18 ms /    91 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1835.23 ms /    68 tokens (   26.99 ms per token,    37.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3004.07 ms /    60 runs   (   50.07 ms per token,    19.97 tokens per second)\n",
      "llama_perf_context_print:       total time =    4848.83 ms /   128 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1069.49 ms /    28 tokens (   38.20 ms per token,    26.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1184.29 ms /    24 runs   (   49.35 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    2257.09 ms /    52 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1561.08 ms /    32 tokens (   48.78 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1483.66 ms /    30 runs   (   49.46 ms per token,    20.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    3049.25 ms /    62 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     815.91 ms /    27 tokens (   30.22 ms per token,    33.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =     834.75 ms /    17 runs   (   49.10 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    1653.19 ms /    44 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     664.28 ms /    22 tokens (   30.19 ms per token,    33.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =     736.08 ms /    15 runs   (   49.07 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    1402.68 ms /    37 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     789.17 ms /    25 tokens (   31.57 ms per token,    31.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =     784.14 ms /    16 runs   (   49.01 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    1575.82 ms /    41 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     873.57 ms /    29 tokens (   30.12 ms per token,    33.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1426.75 ms /    29 runs   (   49.20 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    2304.38 ms /    58 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     863.56 ms /    23 tokens (   37.55 ms per token,    26.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =     778.73 ms /    16 runs   (   48.67 ms per token,    20.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    1644.52 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     853.17 ms /    22 tokens (   38.78 ms per token,    25.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =     742.28 ms /    15 runs   (   49.49 ms per token,    20.21 tokens per second)\n",
      "llama_perf_context_print:       total time =    1597.82 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     951.55 ms /    31 tokens (   30.70 ms per token,    32.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =     996.55 ms /    20 runs   (   49.83 ms per token,    20.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    1951.02 ms /    51 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     433.25 ms /    14 tokens (   30.95 ms per token,    32.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1000.91 ms /    20 runs   (   50.05 ms per token,    19.98 tokens per second)\n",
      "llama_perf_context_print:       total time =    1437.14 ms /    34 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     665.33 ms /    22 tokens (   30.24 ms per token,    33.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =     787.15 ms /    16 runs   (   49.20 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    1454.88 ms /    38 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     892.68 ms /    30 tokens (   29.76 ms per token,    33.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1274.30 ms /    26 runs   (   49.01 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    2170.74 ms /    56 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     872.66 ms /    26 tokens (   33.56 ms per token,    29.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1033.17 ms /    21 runs   (   49.20 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    1908.85 ms /    47 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     939.43 ms /    31 tokens (   30.30 ms per token,    33.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1472.47 ms /    30 runs   (   49.08 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    2416.27 ms /    61 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     783.94 ms /    25 tokens (   31.36 ms per token,    31.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =     886.73 ms /    18 runs   (   49.26 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    1673.46 ms /    43 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     890.89 ms /    27 tokens (   33.00 ms per token,    30.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1079.84 ms /    22 runs   (   49.08 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    1974.01 ms /    49 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     754.49 ms /    25 tokens (   30.18 ms per token,    33.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1036.50 ms /    21 runs   (   49.36 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    1794.00 ms /    46 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1004.06 ms /    28 tokens (   35.86 ms per token,    27.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1178.95 ms /    24 runs   (   49.12 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    2186.59 ms /    52 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     785.30 ms /    26 tokens (   30.20 ms per token,    33.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =     827.88 ms /    17 runs   (   48.70 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    1615.68 ms /    43 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     719.12 ms /    23 tokens (   31.27 ms per token,    31.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =     737.09 ms /    15 runs   (   49.14 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    1458.61 ms /    38 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     742.17 ms /    23 tokens (   32.27 ms per token,    30.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =     442.91 ms /     9 runs   (   49.21 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    1186.53 ms /    32 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     811.44 ms /    24 tokens (   33.81 ms per token,    29.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =     783.53 ms /    16 runs   (   48.97 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    1597.41 ms /    40 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     866.49 ms /    28 tokens (   30.95 ms per token,    32.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1170.78 ms /    24 runs   (   48.78 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    2040.67 ms /    52 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     746.91 ms /    23 tokens (   32.47 ms per token,    30.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1120.40 ms /    23 runs   (   48.71 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    1870.61 ms /    46 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     951.63 ms /    29 tokens (   32.81 ms per token,    30.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =     885.02 ms /    18 runs   (   49.17 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    1839.31 ms /    47 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     725.67 ms /    24 tokens (   30.24 ms per token,    33.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =     843.48 ms /    17 runs   (   49.62 ms per token,    20.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    1571.74 ms /    41 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     780.21 ms /    25 tokens (   31.21 ms per token,    32.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =     683.79 ms /    14 runs   (   48.84 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    1466.25 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     977.31 ms /    30 tokens (   32.58 ms per token,    30.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =     779.54 ms /    16 runs   (   48.72 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    1759.20 ms /    46 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     932.00 ms /    31 tokens (   30.06 ms per token,    33.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1467.82 ms /    30 runs   (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    2404.19 ms /    61 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     729.63 ms /    24 tokens (   30.40 ms per token,    32.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =     877.97 ms /    18 runs   (   48.78 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    1610.30 ms /    42 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     307.69 ms /     7 tokens (   43.96 ms per token,    22.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =     964.29 ms /    20 runs   (   48.21 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1274.88 ms /    27 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     848.92 ms /    29 tokens (   29.27 ms per token,    34.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1121.64 ms /    23 runs   (   48.77 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    1973.98 ms /    52 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     878.39 ms /    29 tokens (   30.29 ms per token,    33.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1216.13 ms /    25 runs   (   48.65 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    2098.19 ms /    54 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     778.29 ms /    25 tokens (   31.13 ms per token,    32.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1067.38 ms /    22 runs   (   48.52 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    1848.93 ms /    47 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1683.15 ms /    45 tokens (   37.40 ms per token,    26.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1790.62 ms /    37 runs   (   48.40 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    3479.33 ms /    82 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     839.03 ms /    29 tokens (   28.93 ms per token,    34.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =     965.54 ms /    20 runs   (   48.28 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1807.39 ms /    49 tokens\n",
      "Llama.generate: 46 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     278.34 ms /     7 tokens (   39.76 ms per token,    25.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1058.61 ms /    22 runs   (   48.12 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1339.96 ms /    29 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     879.39 ms /    29 tokens (   30.32 ms per token,    32.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1263.09 ms /    26 runs   (   48.58 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    2146.06 ms /    55 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     731.85 ms /    24 tokens (   30.49 ms per token,    32.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =     817.81 ms /    17 runs   (   48.11 ms per token,    20.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    1552.15 ms /    41 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1699.98 ms /    46 tokens (   36.96 ms per token,    27.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1856.50 ms /    38 runs   (   48.86 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    3562.22 ms /    84 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     739.10 ms /    26 tokens (   28.43 ms per token,    35.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =     817.66 ms /    17 runs   (   48.10 ms per token,    20.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    1559.20 ms /    43 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     608.25 ms /    19 tokens (   32.01 ms per token,    31.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =     962.35 ms /    20 runs   (   48.12 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1573.36 ms /    39 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     485.12 ms /    16 tokens (   30.32 ms per token,    32.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1251.78 ms /    26 runs   (   48.15 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    1740.50 ms /    42 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     676.63 ms /    20 tokens (   33.83 ms per token,    29.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =     629.81 ms /    13 runs   (   48.45 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    1308.48 ms /    33 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1601.27 ms /    32 tokens (   50.04 ms per token,    19.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =     962.42 ms /    20 runs   (   48.12 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    2566.68 ms /    52 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1474.46 ms /    32 tokens (   46.08 ms per token,    21.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1406.26 ms /    29 runs   (   48.49 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    2884.87 ms /    61 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     697.32 ms /    24 tokens (   29.05 ms per token,    34.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =     769.48 ms /    16 runs   (   48.09 ms per token,    20.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    1469.08 ms /    40 tokens\n",
      "Llama.generate: 29 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     496.42 ms /    16 tokens (   31.03 ms per token,    32.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =     817.42 ms /    17 runs   (   48.08 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1316.23 ms /    33 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1671.49 ms /    35 tokens (   47.76 ms per token,    20.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1463.59 ms /    30 runs   (   48.79 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    3139.36 ms /    65 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     810.95 ms /    26 tokens (   31.19 ms per token,    32.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1301.04 ms /    27 runs   (   48.19 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    2115.80 ms /    53 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     822.23 ms /    28 tokens (   29.37 ms per token,    34.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1069.27 ms /    22 runs   (   48.60 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    1894.69 ms /    50 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     890.49 ms /    30 tokens (   29.68 ms per token,    33.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1495.78 ms /    31 runs   (   48.25 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    2390.63 ms /    61 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     537.02 ms /    18 tokens (   29.83 ms per token,    33.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =     580.25 ms /    12 runs   (   48.35 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1119.03 ms /    30 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1676.67 ms /    36 tokens (   46.57 ms per token,    21.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1034.20 ms /    21 runs   (   49.25 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    2714.10 ms /    57 tokens\n",
      "Llama.generate: 33 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     591.43 ms /    16 tokens (   36.96 ms per token,    27.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =     962.30 ms /    20 runs   (   48.11 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1556.48 ms /    36 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     436.34 ms /    13 tokens (   33.56 ms per token,    29.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1063.82 ms /    22 runs   (   48.36 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1503.21 ms /    35 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1692.81 ms /    37 tokens (   45.75 ms per token,    21.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =     916.09 ms /    19 runs   (   48.22 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    2611.96 ms /    56 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     638.20 ms /    22 tokens (   29.01 ms per token,    34.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =     816.79 ms /    17 runs   (   48.05 ms per token,    20.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    1457.36 ms /    39 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     580.33 ms /    19 tokens (   30.54 ms per token,    32.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =     527.93 ms /    11 runs   (   47.99 ms per token,    20.84 tokens per second)\n",
      "llama_perf_context_print:       total time =    1109.85 ms /    30 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     941.16 ms /    26 tokens (   36.20 ms per token,    27.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =     879.82 ms /    18 runs   (   48.88 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    1823.48 ms /    44 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     679.45 ms /    23 tokens (   29.54 ms per token,    33.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =     768.55 ms /    16 runs   (   48.03 ms per token,    20.82 tokens per second)\n",
      "llama_perf_context_print:       total time =    1450.29 ms /    39 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     609.12 ms /    20 tokens (   30.46 ms per token,    32.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =     528.62 ms /    11 runs   (   48.06 ms per token,    20.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    1139.42 ms /    31 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     716.24 ms /    24 tokens (   29.84 ms per token,    33.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =     826.07 ms /    17 runs   (   48.59 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    1544.89 ms /    41 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     687.32 ms /    21 tokens (   32.73 ms per token,    30.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =     677.88 ms /    14 runs   (   48.42 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    1367.28 ms /    35 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     695.94 ms /    19 tokens (   36.63 ms per token,    27.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =     575.98 ms /    12 runs   (   48.00 ms per token,    20.83 tokens per second)\n",
      "llama_perf_context_print:       total time =    1273.79 ms /    31 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     982.75 ms /    25 tokens (   39.31 ms per token,    25.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =     676.34 ms /    14 runs   (   48.31 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1661.13 ms /    39 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     756.05 ms /    23 tokens (   32.87 ms per token,    30.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =     726.92 ms /    15 runs   (   48.46 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    1485.25 ms /    38 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 91 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1868.35 ms /    91 tokens (   20.53 ms per token,    48.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4965.82 ms /   102 runs   (   48.68 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    6850.31 ms /   193 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 85 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1850.76 ms /    85 tokens (   21.77 ms per token,    45.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =     745.30 ms /    15 runs   (   49.69 ms per token,    20.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    2598.61 ms /   100 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1746.26 ms /    45 tokens (   38.81 ms per token,    25.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1608.13 ms /    33 runs   (   48.73 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    3359.11 ms /    78 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 23 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 41 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     300.01 ms /     8 tokens (   37.50 ms per token,    26.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =     817.32 ms /    17 runs   (   48.08 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1120.97 ms /    25 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     883.90 ms /    31 tokens (   28.51 ms per token,    35.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1401.34 ms /    29 runs   (   48.32 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    2289.19 ms /    60 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1604.42 ms /    36 tokens (   44.57 ms per token,    22.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1216.67 ms /    25 runs   (   48.67 ms per token,    20.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    2825.01 ms /    61 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     736.49 ms /    25 tokens (   29.46 ms per token,    33.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =     970.53 ms /    20 runs   (   48.53 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    1709.92 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     567.12 ms /    19 tokens (   29.85 ms per token,    33.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =     769.30 ms /    16 runs   (   48.08 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1338.67 ms /    35 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1511.79 ms /    32 tokens (   47.24 ms per token,    21.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =     818.46 ms /    17 runs   (   48.14 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    2332.90 ms /    49 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     697.57 ms /    23 tokens (   30.33 ms per token,    32.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =     822.57 ms /    17 runs   (   48.39 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    1522.58 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1005.78 ms /    29 tokens (   34.68 ms per token,    28.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1108.46 ms /    23 runs   (   48.19 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    2117.48 ms /    52 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     799.39 ms /    26 tokens (   30.75 ms per token,    32.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1170.29 ms /    24 runs   (   48.76 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    1973.10 ms /    50 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     739.66 ms /    24 tokens (   30.82 ms per token,    32.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =     824.16 ms /    17 runs   (   48.48 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    1566.29 ms /    41 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     879.40 ms /    31 tokens (   28.37 ms per token,    35.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1111.18 ms /    23 runs   (   48.31 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1993.75 ms /    54 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     586.86 ms /    20 tokens (   29.34 ms per token,    34.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =     769.93 ms /    16 runs   (   48.12 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1359.12 ms /    36 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     749.66 ms /    27 tokens (   27.77 ms per token,    36.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1017.87 ms /    21 runs   (   48.47 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    1770.64 ms /    48 tokens\n",
      "Llama.generate: 44 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     240.75 ms /     7 tokens (   34.39 ms per token,    29.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1061.87 ms /    22 runs   (   48.27 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1305.61 ms /    29 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     883.04 ms /    28 tokens (   31.54 ms per token,    31.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1157.22 ms /    24 runs   (   48.22 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    2043.66 ms /    52 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     776.66 ms /    24 tokens (   32.36 ms per token,    30.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =     881.44 ms /    18 runs   (   48.97 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    1660.69 ms /    42 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     800.94 ms /    28 tokens (   28.61 ms per token,    34.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1111.46 ms /    23 runs   (   48.32 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1915.75 ms /    51 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     811.35 ms /    28 tokens (   28.98 ms per token,    34.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1306.14 ms /    27 runs   (   48.38 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    2121.26 ms /    55 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     600.78 ms /    20 tokens (   30.04 ms per token,    33.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =     591.50 ms /    12 runs   (   49.29 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    1194.08 ms /    32 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     779.17 ms /    25 tokens (   31.17 ms per token,    32.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =     966.93 ms /    20 runs   (   48.35 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1748.88 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     677.36 ms /    22 tokens (   30.79 ms per token,    32.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =     726.91 ms /    15 runs   (   48.46 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    1406.56 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     896.32 ms /    28 tokens (   32.01 ms per token,    31.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =     869.59 ms /    18 runs   (   48.31 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1768.37 ms /    46 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     884.16 ms /    28 tokens (   31.58 ms per token,    31.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1120.70 ms /    23 runs   (   48.73 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    2008.05 ms /    51 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     620.45 ms /    20 tokens (   31.02 ms per token,    32.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =     725.31 ms /    15 runs   (   48.35 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1347.93 ms /    35 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     808.64 ms /    27 tokens (   29.95 ms per token,    33.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1266.73 ms /    26 runs   (   48.72 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    2078.93 ms /    53 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     660.13 ms /    22 tokens (   30.01 ms per token,    33.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =     727.59 ms /    15 runs   (   48.51 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    1389.95 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     837.02 ms /    28 tokens (   29.89 ms per token,    33.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =     877.45 ms /    18 runs   (   48.75 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    1717.04 ms /    46 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     215.14 ms /     6 tokens (   35.86 ms per token,    27.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =     874.35 ms /    18 runs   (   48.58 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    1092.09 ms /    24 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     973.33 ms /    30 tokens (   32.44 ms per token,    30.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =     972.22 ms /    20 runs   (   48.61 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    1948.45 ms /    50 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     782.89 ms /    26 tokens (   30.11 ms per token,    33.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =     826.68 ms /    17 runs   (   48.63 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    1612.08 ms /    43 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     738.56 ms /    25 tokens (   29.54 ms per token,    33.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =     727.48 ms /    15 runs   (   48.50 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    1468.13 ms /    40 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1640.51 ms /    33 tokens (   49.71 ms per token,    20.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1070.34 ms /    22 runs   (   48.65 ms per token,    20.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    2714.10 ms /    55 tokens\n",
      "Llama.generate: 47 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     228.70 ms /     7 tokens (   32.67 ms per token,    30.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1125.69 ms /    23 runs   (   48.94 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    1357.81 ms /    30 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     718.83 ms /    25 tokens (   28.75 ms per token,    34.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =     727.96 ms /    15 runs   (   48.53 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    1449.06 ms /    40 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     232.54 ms /     7 tokens (   33.22 ms per token,    30.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =     734.27 ms /    15 runs   (   48.95 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =     968.95 ms /    22 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     225.35 ms /     7 tokens (   32.19 ms per token,    31.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =     726.70 ms /    15 runs   (   48.45 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =     954.28 ms /    22 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     904.64 ms /    29 tokens (   31.19 ms per token,    32.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1022.55 ms /    21 runs   (   48.69 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1930.15 ms /    50 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     217.57 ms /     6 tokens (   36.26 ms per token,    27.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =     872.51 ms /    18 runs   (   48.47 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    1092.61 ms /    24 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     750.12 ms /    27 tokens (   27.78 ms per token,    35.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =     975.00 ms /    20 runs   (   48.75 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    1728.01 ms /    47 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     953.70 ms /    29 tokens (   32.89 ms per token,    30.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =     986.31 ms /    20 runs   (   49.32 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    1942.87 ms /    49 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     714.46 ms /    25 tokens (   28.58 ms per token,    34.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =     823.36 ms /    17 runs   (   48.43 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    1540.29 ms /    42 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     737.50 ms /    26 tokens (   28.37 ms per token,    35.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =     878.77 ms /    18 runs   (   48.82 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    1618.85 ms /    44 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     280.40 ms /     9 tokens (   31.16 ms per token,    32.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =     881.62 ms /    18 runs   (   48.98 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    1164.50 ms /    27 tokens\n",
      "Llama.generate: 30 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     342.57 ms /    11 tokens (   31.14 ms per token,    32.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =     434.50 ms /     9 runs   (   48.28 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =     778.57 ms /    20 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     882.82 ms /    30 tokens (   29.43 ms per token,    33.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =     975.46 ms /    20 runs   (   48.77 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    1861.12 ms /    50 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     550.49 ms /    18 tokens (   30.58 ms per token,    32.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =     492.64 ms /    10 runs   (   49.26 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    1044.60 ms /    28 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1607.04 ms /    37 tokens (   43.43 ms per token,    23.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1316.34 ms /    27 runs   (   48.75 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    2927.62 ms /    64 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1467.06 ms /    32 tokens (   45.85 ms per token,    21.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1418.44 ms /    29 runs   (   48.91 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    2889.68 ms /    61 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     630.08 ms /    21 tokens (   30.00 ms per token,    33.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1396.99 ms /    29 runs   (   48.17 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    2031.24 ms /    50 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     775.39 ms /    26 tokens (   29.82 ms per token,    33.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1061.67 ms /    22 runs   (   48.26 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1840.22 ms /    48 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     855.56 ms /    22 tokens (   38.89 ms per token,    25.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =     818.73 ms /    17 runs   (   48.16 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1676.65 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     646.89 ms /    20 tokens (   32.34 ms per token,    30.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =     576.92 ms /    12 runs   (   48.08 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1225.61 ms /    32 tokens\n",
      "Llama.generate: 31 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     331.66 ms /    10 tokens (   33.17 ms per token,    30.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1202.89 ms /    25 runs   (   48.12 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1538.02 ms /    35 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     851.88 ms /    30 tokens (   28.40 ms per token,    35.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =     835.66 ms /    17 runs   (   49.16 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    1689.86 ms /    47 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     713.39 ms /    20 tokens (   35.67 ms per token,    28.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =     725.64 ms /    15 runs   (   48.38 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    1441.27 ms /    35 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     887.44 ms /    25 tokens (   35.50 ms per token,    28.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =     772.73 ms /    16 runs   (   48.30 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1662.47 ms /    41 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     813.91 ms /    20 tokens (   40.70 ms per token,    24.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =     968.60 ms /    20 runs   (   48.43 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    1785.37 ms /    40 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     403.50 ms /     9 tokens (   44.83 ms per token,    22.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =     799.30 ms /    16 runs   (   49.96 ms per token,    20.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    1205.06 ms /    25 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     428.22 ms /    13 tokens (   32.94 ms per token,    30.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1261.10 ms /    26 runs   (   48.50 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    1692.87 ms /    39 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     775.39 ms /    27 tokens (   28.72 ms per token,    34.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1154.65 ms /    24 runs   (   48.11 ms per token,    20.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    1933.36 ms /    51 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     801.45 ms /    26 tokens (   30.83 ms per token,    32.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1253.04 ms /    26 runs   (   48.19 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    2058.23 ms /    52 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     718.99 ms /    24 tokens (   29.96 ms per token,    33.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1009.82 ms /    21 runs   (   48.09 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1731.82 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     545.36 ms /    19 tokens (   28.70 ms per token,    34.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =     672.56 ms /    14 runs   (   48.04 ms per token,    20.82 tokens per second)\n",
      "llama_perf_context_print:       total time =    1220.00 ms /    33 tokens\n",
      "Llama.generate: 30 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     302.02 ms /     9 tokens (   33.56 ms per token,    29.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =     675.29 ms /    14 runs   (   48.24 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =     979.25 ms /    23 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1025.37 ms /    25 tokens (   41.01 ms per token,    24.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =     912.42 ms /    19 runs   (   48.02 ms per token,    20.82 tokens per second)\n",
      "llama_perf_context_print:       total time =    1940.39 ms /    44 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     631.76 ms /    21 tokens (   30.08 ms per token,    33.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =     768.91 ms /    16 runs   (   48.06 ms per token,    20.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    1402.93 ms /    37 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     689.52 ms /    24 tokens (   28.73 ms per token,    34.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =     818.11 ms /    17 runs   (   48.12 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1510.02 ms /    41 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     633.01 ms /    19 tokens (   33.32 ms per token,    30.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =     720.19 ms /    15 runs   (   48.01 ms per token,    20.83 tokens per second)\n",
      "llama_perf_context_print:       total time =    1355.37 ms /    34 tokens\n",
      "Llama.generate: 31 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     412.28 ms /    13 tokens (   31.71 ms per token,    31.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =     817.94 ms /    17 runs   (   48.11 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1232.55 ms /    30 tokens\n",
      "Llama.generate: 31 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     444.57 ms /    14 tokens (   31.75 ms per token,    31.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =     769.18 ms /    16 runs   (   48.07 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1215.97 ms /    30 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     282.10 ms /     9 tokens (   31.34 ms per token,    31.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =     534.86 ms /    11 runs   (   48.62 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =     818.67 ms /    20 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     596.09 ms /    21 tokens (   28.39 ms per token,    35.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1228.06 ms /    25 runs   (   49.12 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    1827.64 ms /    46 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     837.95 ms /    28 tokens (   29.93 ms per token,    33.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1155.54 ms /    24 runs   (   48.15 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    1996.76 ms /    52 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     635.06 ms /    22 tokens (   28.87 ms per token,    34.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =     723.85 ms /    15 runs   (   48.26 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1361.07 ms /    37 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     655.22 ms /    23 tokens (   28.49 ms per token,    35.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1160.08 ms /    24 runs   (   48.34 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1818.68 ms /    47 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     297.81 ms /     9 tokens (   33.09 ms per token,    30.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1008.97 ms /    21 runs   (   48.05 ms per token,    20.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    1309.81 ms /    30 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     595.17 ms /    21 tokens (   28.34 ms per token,    35.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =     673.09 ms /    14 runs   (   48.08 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1270.27 ms /    35 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     755.98 ms /    27 tokens (   28.00 ms per token,    35.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1126.06 ms /    23 runs   (   48.96 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    1885.33 ms /    50 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     672.52 ms /    24 tokens (   28.02 ms per token,    35.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1010.09 ms /    21 runs   (   48.10 ms per token,    20.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    1685.43 ms /    45 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     403.28 ms /    13 tokens (   31.02 ms per token,    32.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =     961.24 ms /    20 runs   (   48.06 ms per token,    20.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    1367.31 ms /    33 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     601.56 ms /    20 tokens (   30.08 ms per token,    33.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =     675.29 ms /    14 runs   (   48.23 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1278.83 ms /    34 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     677.77 ms /    23 tokens (   29.47 ms per token,    33.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =     726.02 ms /    15 runs   (   48.40 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    1405.96 ms /    38 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     254.39 ms /     8 tokens (   31.80 ms per token,    31.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =     384.55 ms /     8 runs   (   48.07 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =     640.11 ms /    16 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     682.30 ms /    24 tokens (   28.43 ms per token,    35.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1058.54 ms /    22 runs   (   48.12 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1743.87 ms /    46 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     280.14 ms /     9 tokens (   31.13 ms per token,    32.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1009.57 ms /    21 runs   (   48.07 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1292.51 ms /    30 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     629.91 ms /    19 tokens (   33.15 ms per token,    30.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =     635.96 ms /    13 runs   (   48.92 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    1267.80 ms /    32 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     820.38 ms /    28 tokens (   29.30 ms per token,    34.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =     962.43 ms /    20 runs   (   48.12 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1785.50 ms /    48 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     535.37 ms /    18 tokens (   29.74 ms per token,    33.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =     576.68 ms /    12 runs   (   48.06 ms per token,    20.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    1113.81 ms /    30 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     807.25 ms /    27 tokens (   29.90 ms per token,    33.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =     870.85 ms /    18 runs   (   48.38 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    1680.66 ms /    45 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     657.98 ms /    20 tokens (   32.90 ms per token,    30.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =     672.60 ms /    14 runs   (   48.04 ms per token,    20.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    1332.63 ms /    34 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     570.04 ms /    20 tokens (   28.50 ms per token,    35.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =     868.41 ms /    18 runs   (   48.24 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1440.94 ms /    38 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     699.80 ms /    23 tokens (   30.43 ms per token,    32.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =     913.11 ms /    19 runs   (   48.06 ms per token,    20.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    1615.63 ms /    42 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     631.86 ms /    20 tokens (   31.59 ms per token,    31.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =     829.95 ms /    17 runs   (   48.82 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    1464.24 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     785.59 ms /    27 tokens (   29.10 ms per token,    34.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =     865.12 ms /    18 runs   (   48.06 ms per token,    20.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    1653.26 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     551.99 ms /    18 tokens (   30.67 ms per token,    32.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1153.29 ms /    24 runs   (   48.05 ms per token,    20.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    1708.55 ms /    42 tokens\n",
      "Llama.generate: 29 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     278.78 ms /     8 tokens (   34.85 ms per token,    28.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =     480.78 ms /    10 runs   (   48.08 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =     761.12 ms /    18 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     768.24 ms /    27 tokens (   28.45 ms per token,    35.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =     870.93 ms /    18 runs   (   48.39 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    1641.75 ms /    45 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     881.59 ms /    30 tokens (   29.39 ms per token,    34.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1253.83 ms /    26 runs   (   48.22 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    2138.95 ms /    56 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     683.93 ms /    23 tokens (   29.74 ms per token,    33.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =     636.10 ms /    13 runs   (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    1321.87 ms /    36 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     553.92 ms /    19 tokens (   29.15 ms per token,    34.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =     726.20 ms /    15 runs   (   48.41 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    1282.29 ms /    34 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 24 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     743.20 ms /    23 tokens (   32.31 ms per token,    30.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =     722.76 ms /    15 runs   (   48.18 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    1469.24 ms /    38 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     732.91 ms /    25 tokens (   29.32 ms per token,    34.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1060.98 ms /    22 runs   (   48.23 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1796.93 ms /    47 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     634.41 ms /    21 tokens (   30.21 ms per token,    33.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1156.76 ms /    24 runs   (   48.20 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    1794.48 ms /    45 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     884.09 ms /    22 tokens (   40.19 ms per token,    24.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =     863.73 ms /    18 runs   (   47.99 ms per token,    20.84 tokens per second)\n",
      "llama_perf_context_print:       total time =    1750.22 ms /    40 tokens\n",
      "Llama.generate: 32 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     571.30 ms /    16 tokens (   35.71 ms per token,    28.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =     965.23 ms /    20 runs   (   48.26 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1539.32 ms /    36 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     665.78 ms /    23 tokens (   28.95 ms per token,    34.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =     816.56 ms /    17 runs   (   48.03 ms per token,    20.82 tokens per second)\n",
      "llama_perf_context_print:       total time =    1484.69 ms /    40 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     710.56 ms /    24 tokens (   29.61 ms per token,    33.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1402.13 ms /    29 runs   (   48.35 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    2116.78 ms /    53 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     762.47 ms /    26 tokens (   29.33 ms per token,    34.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1299.43 ms /    27 runs   (   48.13 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    2065.62 ms /    53 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     856.25 ms /    30 tokens (   28.54 ms per token,    35.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1023.26 ms /    21 runs   (   48.73 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    1882.47 ms /    51 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1632.66 ms /    36 tokens (   45.35 ms per token,    22.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1160.70 ms /    24 runs   (   48.36 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    2796.98 ms /    60 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     624.89 ms /    22 tokens (   28.40 ms per token,    35.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1114.43 ms /    23 runs   (   48.45 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    1742.57 ms /    45 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     581.09 ms /    21 tokens (   27.67 ms per token,    36.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =     772.26 ms /    16 runs   (   48.27 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1355.65 ms /    37 tokens\n",
      "Llama.generate: 29 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     647.92 ms /    20 tokens (   32.40 ms per token,    30.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =     770.21 ms /    16 runs   (   48.14 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    1420.47 ms /    36 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     855.19 ms /    30 tokens (   28.51 ms per token,    35.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =     867.08 ms /    18 runs   (   48.17 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1724.96 ms /    48 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     765.23 ms /    27 tokens (   28.34 ms per token,    35.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =     726.18 ms /    15 runs   (   48.41 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    1493.53 ms /    42 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     560.51 ms /    19 tokens (   29.50 ms per token,    33.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =     575.72 ms /    12 runs   (   47.98 ms per token,    20.84 tokens per second)\n",
      "llama_perf_context_print:       total time =    1137.92 ms /    31 tokens\n",
      "Llama.generate: 33 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     325.07 ms /     9 tokens (   36.12 ms per token,    27.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =     689.11 ms /    14 runs   (   49.22 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    1016.26 ms /    23 tokens\n",
      "Llama.generate: 33 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     283.70 ms /     9 tokens (   31.52 ms per token,    31.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =     672.48 ms /    14 runs   (   48.03 ms per token,    20.82 tokens per second)\n",
      "llama_perf_context_print:       total time =     958.15 ms /    23 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     830.00 ms /    28 tokens (   29.64 ms per token,    33.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1008.62 ms /    21 runs   (   48.03 ms per token,    20.82 tokens per second)\n",
      "llama_perf_context_print:       total time =    1841.50 ms /    49 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     655.20 ms /    21 tokens (   31.20 ms per token,    32.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =     674.89 ms /    14 runs   (   48.21 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1332.12 ms /    35 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     821.62 ms /    29 tokens (   28.33 ms per token,    35.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1300.14 ms /    27 runs   (   48.15 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    2125.55 ms /    56 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     452.79 ms /    15 tokens (   30.19 ms per token,    33.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1059.57 ms /    22 runs   (   48.16 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1515.34 ms /    37 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     594.00 ms /    17 tokens (   34.94 ms per token,    28.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =     817.44 ms /    17 runs   (   48.08 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1413.83 ms /    34 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     319.55 ms /     9 tokens (   35.51 ms per token,    28.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1271.60 ms /    26 runs   (   48.91 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    1594.83 ms /    35 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     678.99 ms /    23 tokens (   29.52 ms per token,    33.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =     723.48 ms /    15 runs   (   48.23 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1404.69 ms /    38 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 242 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    3055.47 ms /   242 tokens (   12.63 ms per token,    79.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =     785.37 ms /    16 runs   (   49.09 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    3843.23 ms /   258 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     809.08 ms /    25 tokens (   32.36 ms per token,    30.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1205.99 ms /    25 runs   (   48.24 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    2018.99 ms /    50 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     662.32 ms /    19 tokens (   34.86 ms per token,    28.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =     533.96 ms /    11 runs   (   48.54 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    1197.98 ms /    30 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     880.12 ms /    27 tokens (   32.60 ms per token,    30.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =     871.36 ms /    18 runs   (   48.41 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    1753.98 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1600.77 ms /    36 tokens (   44.47 ms per token,    22.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1168.95 ms /    24 runs   (   48.71 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    2773.20 ms /    60 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     521.76 ms /    15 tokens (   34.78 ms per token,    28.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =     529.64 ms /    11 runs   (   48.15 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    1053.36 ms /    26 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1024.53 ms /    30 tokens (   34.15 ms per token,    29.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1018.69 ms /    21 runs   (   48.51 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    2046.49 ms /    51 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     665.83 ms /    22 tokens (   30.27 ms per token,    33.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =     677.75 ms /    14 runs   (   48.41 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    1345.59 ms /    36 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1009.37 ms /    27 tokens (   37.38 ms per token,    26.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =     725.43 ms /    15 runs   (   48.36 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1736.92 ms /    42 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     550.45 ms /    11 tokens (   50.04 ms per token,    19.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =     828.96 ms /    17 runs   (   48.76 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    1381.88 ms /    28 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 85 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1815.69 ms /    85 tokens (   21.36 ms per token,    46.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3206.15 ms /    65 runs   (   49.33 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    5031.97 ms /   150 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 56 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error translating query: '[StockExchange] IN 'ASX|Abu Dhabi Securities Exchange|Aequitas NEO-N|Amman Stock Exchange|Athens Exchange|Athens Stock Exchange|BM&F Bovespa|BME - Bolsas Y Mercados Espanoles|BSE Ltd.|BX Swiss AG|Bahrain Bourse|Barbados Stock Exchange|Barcelona Stock Exchange|Beirut Stock Exchange|Belgrade Stock Exchange|Berlin Stock Exchange|Bermuda Stock Exchange|Bolsa Boliviana de Valores S.A.|Botswana Stock Exchange|Bratislava Stock Exchange|Bucharest Stock Exchange|Budapest Stock Exchange|Buenos Aires Stock Exchange|Bulgarian Stock Exchange|Canadian Securities Exchange|Caracas Stock Exchange|Casablanca Stock Exchange|Cboe Australia|Cboe BZX US Equities Exchange|Central Counterparty Clearing Center Mfb|Channel Islands Stock Exchange|Colombia Stock Exchange|Colombo Stock Exchange|Costa Rica Stock Exchange|Cyprus Stock Exchange|Damascus Securities Exchange|Dansk OTC|Dar es Salaam Stock Exchange|Dhaka Stock Exchange|Dubai Financial Market|Dusseldorf Stock Exchange|Egyptian Exchange|Euronext Amsterdam|Euronext Brussels|Euronext Lisbon|Euronext Paris|Frankfurt Stock Exchange|Fukuoka Stock Exchange|Ghana Stock Exchange|Guayaquil Stock Exchange|Hamburg Stock Exchange|Hannover Stock Exchange|Hanoi Stock Exchange|Ho Chi Minh Stock Exchange|Hong Kong Stock Exchange|Indonesia Exchange|Iraq Stock Exchange|Irish Stock Exchange|Istanbul Stock Exchange|Ivory Coast Stock Exchange|JASDAQ|Japan Exchange Group|Johannesburg Securities Exchange|Kazakhstan Stock Exchange|Korea Exchange|Korea KONEX|Kuwait Stock Exchange|Lima Stock Exchange|Ljubljana Stock Exchange|London Stock Exchange|Lusaka Stock Exchange|Luxembourg Stock Exchange|Macedonia Stock Exchange|Madrid Stock Exchange|Malawi Stock Exchange|Malaysia Stock Exchange|Malta Stock Exchange|Mauritius Stock Exchange|Mexican Stock Exchange|Milan Stock Exchange|Montenegro Stock Exchange|Moscow Exchange|Moscow Exchange - Derivatives Market|Munich Stock Exchange|Muscat Securities Market|NASDAQ|NASDAQ Dubai|NASDAQ OMX Copenhagen|NASDAQ OMX Helsinki|NASDAQ OMX Iceland|NASDAQ OMX Riga|NASDAQ OMX Stockholm|NASDAQ OMX Tallinn|NASDAQ OMX Vilnius|NEO Exchange|NEX Exchange|NYSE American|NYSE Arca|Nagoya Stock Exchange|Nairobi Stock Exchange|Namibian Stock Exchange|National Stock Exchange of Australia|National Stock Exchange of India|New York Stock Exchange|New Zealand Stock Exchange|Nigerian Stock Exchange|Nordic Growth Market|Norwegian OTC Market|OTC Markets|Osaka Exchange|Oslo Bors|Oslo Exchange|PFTS Exchange|Pakistan Stock Exchange|Palestine Securities Exchange|Panama Stock Exchange|Philippine Stock Exchange|Prague Stock Exchange|Qatar Exchange|RASDAQ|Rwanda Stock Exchange|SIX Swiss Exchange|Santiago Stock Exchange|Sapporo Securities Exchange|Sarajevo Stock Exchange|Saudi Arabia Stock Exchange|Shanghai Stock Exchange|Shenzhen Stock Exchange|Singapore Exchange|Spotlight Stock Market|Stock Exchange of Thailand|Stuttgart Stock Exchange|Swaziland Stock Exchange|TSX Venture Exchange|Taipei Exchange|Taiwan Stock Exchange|Teheran Stock Exchange|Tel Aviv Stock Exchange|Tokyo Stock Exchange|Toronto Stock Exchange|Trinidad and Tobago Stock Exchange|Tunis Stock Exchange|UNKNOWN|US OTC|Uganda Securities Exchange|Ukrainian Stock Exchange|Vienna Stock Exchange|Warsaw Stock Exchange|XETRA|Zagreb Stock Exchange|Zimbabwe Stock Exchange''\n",
      "Error: Requested tokens (1002) exceed context window of 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1702.57 ms /    56 tokens (   30.40 ms per token,    32.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =     778.27 ms /    16 runs   (   48.64 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    2483.17 ms /    72 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     546.14 ms /    18 tokens (   30.34 ms per token,    32.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =     982.69 ms /    20 runs   (   49.13 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    1531.82 ms /    38 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     726.65 ms /    24 tokens (   30.28 ms per token,    33.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1467.54 ms /    30 runs   (   48.92 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    2198.62 ms /    54 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     469.99 ms /    15 tokens (   31.33 ms per token,    31.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1222.03 ms /    25 runs   (   48.88 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    1695.46 ms /    40 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     911.32 ms /    28 tokens (   32.55 ms per token,    30.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =     635.65 ms /    13 runs   (   48.90 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    1548.91 ms /    41 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     777.53 ms /    26 tokens (   29.91 ms per token,    33.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =     977.18 ms /    20 runs   (   48.86 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    1757.61 ms /    46 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1603.76 ms /    34 tokens (   47.17 ms per token,    21.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1032.06 ms /    21 runs   (   49.15 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    2639.45 ms /    55 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     751.52 ms /    26 tokens (   28.90 ms per token,    34.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1416.21 ms /    29 runs   (   48.83 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    2171.93 ms /    55 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 113 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2023.56 ms /   113 tokens (   17.91 ms per token,    55.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2605.22 ms /    53 runs   (   49.16 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    4636.79 ms /   166 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1652.03 ms /    58 tokens (   28.48 ms per token,    35.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2076.45 ms /    42 runs   (   49.44 ms per token,    20.23 tokens per second)\n",
      "llama_perf_context_print:       total time =    3734.67 ms /   100 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     794.23 ms /    27 tokens (   29.42 ms per token,    34.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1124.85 ms /    23 runs   (   48.91 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    1922.44 ms /    50 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     454.38 ms /    15 tokens (   30.29 ms per token,    33.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1119.55 ms /    23 runs   (   48.68 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1577.21 ms /    38 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     377.17 ms /    12 tokens (   31.43 ms per token,    31.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1070.79 ms /    22 runs   (   48.67 ms per token,    20.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    1451.11 ms /    34 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     797.07 ms /    26 tokens (   30.66 ms per token,    32.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1226.44 ms /    25 runs   (   49.06 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    2027.05 ms /    51 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1604.87 ms /    35 tokens (   45.85 ms per token,    21.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1134.61 ms /    23 runs   (   49.33 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    2742.83 ms /    58 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     762.61 ms /    23 tokens (   33.16 ms per token,    30.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =     773.00 ms /    16 runs   (   48.31 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1538.15 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1140.19 ms /    31 tokens (   36.78 ms per token,    27.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =     868.96 ms /    18 runs   (   48.28 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    2011.84 ms /    49 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     801.07 ms /    28 tokens (   28.61 ms per token,    34.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1214.32 ms /    25 runs   (   48.57 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    2018.98 ms /    53 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     829.06 ms /    26 tokens (   31.89 ms per token,    31.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =     918.83 ms /    19 runs   (   48.36 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1750.61 ms /    45 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     329.56 ms /    10 tokens (   32.96 ms per token,    30.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =     821.44 ms /    17 runs   (   48.32 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1153.44 ms /    27 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     751.11 ms /    25 tokens (   30.04 ms per token,    33.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =     874.15 ms /    18 runs   (   48.56 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    1627.98 ms /    43 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1693.02 ms /    36 tokens (   47.03 ms per token,    21.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1257.24 ms /    26 runs   (   48.36 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    2954.36 ms /    62 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     679.45 ms /    23 tokens (   29.54 ms per token,    33.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =     769.95 ms /    16 runs   (   48.12 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1451.69 ms /    39 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     672.29 ms /    23 tokens (   29.23 ms per token,    34.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1017.51 ms /    21 runs   (   48.45 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    1692.70 ms /    44 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     287.54 ms /     8 tokens (   35.94 ms per token,    27.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =     967.60 ms /    20 runs   (   48.38 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    1258.33 ms /    28 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     734.76 ms /    26 tokens (   28.26 ms per token,    35.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =     966.04 ms /    20 runs   (   48.30 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1703.62 ms /    46 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     861.65 ms /    28 tokens (   30.77 ms per token,    32.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =     914.34 ms /    19 runs   (   48.12 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1778.75 ms /    47 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     606.14 ms /    19 tokens (   31.90 ms per token,    31.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1402.83 ms /    29 runs   (   48.37 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    2013.12 ms /    48 tokens\n",
      "Llama.generate: 49 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     221.18 ms /     7 tokens (   31.60 ms per token,    31.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1447.74 ms /    30 runs   (   48.26 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1673.03 ms /    37 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     460.36 ms /    15 tokens (   30.69 ms per token,    32.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1449.13 ms /    30 runs   (   48.30 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1913.57 ms /    45 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     895.27 ms /    27 tokens (   33.16 ms per token,    30.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1204.69 ms /    25 runs   (   48.19 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    2103.35 ms /    52 tokens\n",
      "Llama.generate: 33 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     544.86 ms /    18 tokens (   30.27 ms per token,    33.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1554.92 ms /    32 runs   (   48.59 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    2104.27 ms /    50 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     817.06 ms /    29 tokens (   28.17 ms per token,    35.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1069.28 ms /    22 runs   (   48.60 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    1889.60 ms /    51 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1463.12 ms /    32 tokens (   45.72 ms per token,    21.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1347.89 ms /    28 runs   (   48.14 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    2814.87 ms /    60 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     653.14 ms /    23 tokens (   28.40 ms per token,    35.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =     768.73 ms /    16 runs   (   48.05 ms per token,    20.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    1424.12 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     953.75 ms /    30 tokens (   31.79 ms per token,    31.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =     870.77 ms /    18 runs   (   48.38 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    1827.11 ms /    48 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     325.57 ms /    11 tokens (   29.60 ms per token,    33.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =     962.25 ms /    20 runs   (   48.11 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1290.59 ms /    31 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     353.93 ms /     9 tokens (   39.33 ms per token,    25.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =     914.44 ms /    19 runs   (   48.13 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1271.05 ms /    28 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     742.24 ms /    25 tokens (   29.69 ms per token,    33.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1013.02 ms /    21 runs   (   48.24 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1758.12 ms /    46 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     638.68 ms /    21 tokens (   30.41 ms per token,    32.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =     529.75 ms /    11 runs   (   48.16 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1169.99 ms /    32 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     765.15 ms /    27 tokens (   28.34 ms per token,    35.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =     768.71 ms /    16 runs   (   48.04 ms per token,    20.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    1536.17 ms /    43 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     228.43 ms /     7 tokens (   32.63 ms per token,    30.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =     818.20 ms /    17 runs   (   48.13 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1049.01 ms /    24 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     870.24 ms /    28 tokens (   31.08 ms per token,    32.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1059.44 ms /    22 runs   (   48.16 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    1932.68 ms /    50 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     686.07 ms /    24 tokens (   28.59 ms per token,    34.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =     818.02 ms /    17 runs   (   48.12 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1506.48 ms /    41 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     806.87 ms /    27 tokens (   29.88 ms per token,    33.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1010.75 ms /    21 runs   (   48.13 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1820.58 ms /    48 tokens\n",
      "Llama.generate: 44 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     234.21 ms /     7 tokens (   33.46 ms per token,    29.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1023.29 ms /    21 runs   (   48.73 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    1260.48 ms /    28 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     654.95 ms /    23 tokens (   28.48 ms per token,    35.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =     768.75 ms /    16 runs   (   48.05 ms per token,    20.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    1426.02 ms /    39 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     822.00 ms /    28 tokens (   29.36 ms per token,    34.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1203.81 ms /    25 runs   (   48.15 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    2029.17 ms /    53 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     736.04 ms /    23 tokens (   32.00 ms per token,    31.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1071.73 ms /    22 runs   (   48.71 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    1810.82 ms /    45 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     665.95 ms /    23 tokens (   28.95 ms per token,    34.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =     915.81 ms /    19 runs   (   48.20 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    1584.39 ms /    42 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     721.83 ms /    22 tokens (   32.81 ms per token,    30.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =     817.39 ms /    17 runs   (   48.08 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1541.62 ms /    39 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     747.82 ms /    25 tokens (   29.91 ms per token,    33.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =     776.14 ms /    16 runs   (   48.51 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    1526.29 ms /    41 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1785.80 ms /    41 tokens (   43.56 ms per token,    22.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1013.50 ms /    21 runs   (   48.26 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    2802.56 ms /    62 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     850.34 ms /    29 tokens (   29.32 ms per token,    34.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =     917.88 ms /    19 runs   (   48.31 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1771.17 ms /    48 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     525.95 ms /    18 tokens (   29.22 ms per token,    34.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =     686.28 ms /    14 runs   (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    1214.27 ms /    32 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     561.30 ms /    20 tokens (   28.06 ms per token,    35.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =     835.50 ms /    17 runs   (   49.15 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    1399.17 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     952.34 ms /    31 tokens (   30.72 ms per token,    32.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =     962.67 ms /    20 runs   (   48.13 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1917.91 ms /    51 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     217.58 ms /     7 tokens (   31.08 ms per token,    32.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1065.71 ms /    22 runs   (   48.44 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    1286.31 ms /    29 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     811.62 ms /    25 tokens (   32.46 ms per token,    30.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1251.07 ms /    26 runs   (   48.12 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    2066.29 ms /    51 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1610.05 ms /    33 tokens (   48.79 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =     914.68 ms /    19 runs   (   48.14 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    2527.74 ms /    52 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     793.25 ms /    24 tokens (   33.05 ms per token,    30.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =     537.78 ms /    11 runs   (   48.89 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    1332.67 ms /    35 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1083.71 ms /    25 tokens (   43.35 ms per token,    23.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =     968.67 ms /    20 runs   (   48.43 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    2055.38 ms /    45 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 83 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1818.69 ms /    83 tokens (   21.91 ms per token,    45.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1605.21 ms /    33 runs   (   48.64 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    3428.90 ms /   116 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 25 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 24 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1672.13 ms /    57 tokens (   29.34 ms per token,    34.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2140.59 ms /    44 runs   (   48.65 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    3820.46 ms /   101 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     670.18 ms /    23 tokens (   29.14 ms per token,    34.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1025.40 ms /    21 runs   (   48.83 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    1698.51 ms /    44 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1051.95 ms /    28 tokens (   37.57 ms per token,    26.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =     864.60 ms /    18 runs   (   48.03 ms per token,    20.82 tokens per second)\n",
      "llama_perf_context_print:       total time =    1918.99 ms /    46 tokens\n",
      "Llama.generate: 30 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     358.13 ms /    12 tokens (   29.84 ms per token,    33.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =     576.37 ms /    12 runs   (   48.03 ms per token,    20.82 tokens per second)\n",
      "llama_perf_context_print:       total time =     936.28 ms /    24 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     575.61 ms /    17 tokens (   33.86 ms per token,    29.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =     579.49 ms /    12 runs   (   48.29 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1156.92 ms /    29 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     716.24 ms /    23 tokens (   31.14 ms per token,    32.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =     673.79 ms /    14 runs   (   48.13 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1392.03 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     787.08 ms /    29 tokens (   27.14 ms per token,    36.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =     960.85 ms /    20 runs   (   48.04 ms per token,    20.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    1750.63 ms /    49 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1607.91 ms /    38 tokens (   42.31 ms per token,    23.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1470.15 ms /    30 runs   (   49.01 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    3082.51 ms /    68 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1602.51 ms /    33 tokens (   48.56 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1255.52 ms /    26 runs   (   48.29 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    2861.84 ms /    59 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     825.25 ms /    28 tokens (   29.47 ms per token,    33.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =     769.09 ms /    16 runs   (   48.07 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1596.62 ms /    44 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     933.21 ms /    28 tokens (   33.33 ms per token,    30.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =     817.32 ms /    17 runs   (   48.08 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1752.90 ms /    45 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1602.62 ms /    34 tokens (   47.14 ms per token,    21.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1592.79 ms /    33 runs   (   48.27 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    3200.28 ms /    67 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     922.61 ms /    28 tokens (   32.95 ms per token,    30.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1207.42 ms /    25 runs   (   48.30 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    2133.58 ms /    53 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1465.85 ms /    32 tokens (   45.81 ms per token,    21.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1303.55 ms /    27 runs   (   48.28 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    2773.28 ms /    59 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1652.51 ms /    34 tokens (   48.60 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1504.96 ms /    31 runs   (   48.55 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    3161.81 ms /    65 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     761.42 ms /    27 tokens (   28.20 ms per token,    35.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1397.68 ms /    29 runs   (   48.20 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    2163.20 ms /    56 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     723.72 ms /    23 tokens (   31.47 ms per token,    31.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =     731.85 ms /    15 runs   (   48.79 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    1457.80 ms /    38 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     228.87 ms /     7 tokens (   32.70 ms per token,    30.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =     672.79 ms /    14 runs   (   48.06 ms per token,    20.81 tokens per second)\n",
      "llama_perf_context_print:       total time =     903.68 ms /    21 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     637.90 ms /    21 tokens (   30.38 ms per token,    32.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =     768.83 ms /    16 runs   (   48.05 ms per token,    20.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    1408.95 ms /    37 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     525.53 ms /    18 tokens (   29.20 ms per token,    34.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1154.95 ms /    24 runs   (   48.12 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1683.73 ms /    42 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     791.96 ms /    25 tokens (   31.68 ms per token,    31.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1016.94 ms /    21 runs   (   48.43 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    1811.83 ms /    46 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     927.49 ms /    31 tokens (   29.92 ms per token,    33.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =     965.52 ms /    20 runs   (   48.28 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1895.86 ms /    51 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     752.31 ms /    25 tokens (   30.09 ms per token,    33.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =     932.07 ms /    19 runs   (   49.06 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    1687.03 ms /    44 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     947.65 ms /    27 tokens (   35.10 ms per token,    28.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =     973.47 ms /    20 runs   (   48.67 ms per token,    20.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    1924.09 ms /    47 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     794.13 ms /    27 tokens (   29.41 ms per token,    34.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1166.71 ms /    24 runs   (   48.61 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    1964.25 ms /    51 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     416.55 ms /    14 tokens (   29.75 ms per token,    33.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1167.13 ms /    24 runs   (   48.63 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    1587.00 ms /    38 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     745.56 ms /    23 tokens (   32.42 ms per token,    30.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =     775.43 ms /    16 runs   (   48.46 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    1523.31 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     882.21 ms /    30 tokens (   29.41 ms per token,    34.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1076.42 ms /    22 runs   (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    1961.70 ms /    52 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 19 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     631.57 ms /    19 tokens (   33.24 ms per token,    30.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =     681.21 ms /    14 runs   (   48.66 ms per token,    20.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    1314.91 ms /    33 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     862.64 ms /    26 tokens (   33.18 ms per token,    30.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =     630.70 ms /    13 runs   (   48.52 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    1495.34 ms /    39 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 10 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     320.31 ms /    10 tokens (   32.03 ms per token,    31.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =     781.07 ms /    16 runs   (   48.82 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    1103.81 ms /    26 tokens\n",
      "Llama.generate: 44 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     319.81 ms /     9 tokens (   35.53 ms per token,    28.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =     827.47 ms /    17 runs   (   48.67 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1149.69 ms /    26 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     911.79 ms /    31 tokens (   29.41 ms per token,    34.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1623.88 ms /    33 runs   (   49.21 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    2540.29 ms /    64 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     265.14 ms /     8 tokens (   33.14 ms per token,    30.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1123.68 ms /    23 runs   (   48.86 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    1392.14 ms /    31 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     786.56 ms /    26 tokens (   30.25 ms per token,    33.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =     730.15 ms /    15 runs   (   48.68 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1518.83 ms /    41 tokens\n",
      "Llama.generate: 44 prefix-match hit, remaining 8 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     313.51 ms /     8 tokens (   39.19 ms per token,    25.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =     926.41 ms /    19 runs   (   48.76 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    1242.58 ms /    27 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     911.83 ms /    29 tokens (   31.44 ms per token,    31.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1466.58 ms /    30 runs   (   48.89 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    2382.75 ms /    59 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     659.52 ms /    22 tokens (   29.98 ms per token,    33.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =     533.22 ms /    11 runs   (   48.47 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    1194.44 ms /    33 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1476.10 ms /    32 tokens (   46.13 ms per token,    21.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1025.39 ms /    21 runs   (   48.83 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    2504.58 ms /    53 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     470.21 ms /    15 tokens (   31.35 ms per token,    31.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1266.17 ms /    26 runs   (   48.70 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    1740.00 ms /    41 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     708.48 ms /    24 tokens (   29.52 ms per token,    33.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1034.96 ms /    21 runs   (   49.28 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    1746.49 ms /    45 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     751.11 ms /    26 tokens (   28.89 ms per token,    34.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1090.69 ms /    22 runs   (   49.58 ms per token,    20.17 tokens per second)\n",
      "llama_perf_context_print:       total time =    1845.05 ms /    48 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     705.60 ms /    24 tokens (   29.40 ms per token,    34.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1172.29 ms /    24 runs   (   48.85 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    1881.34 ms /    48 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     824.25 ms /    28 tokens (   29.44 ms per token,    33.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1363.43 ms /    28 runs   (   48.69 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    2191.63 ms /    56 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     686.44 ms /    24 tokens (   28.60 ms per token,    34.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =     744.31 ms /    15 runs   (   49.62 ms per token,    20.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    1432.93 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1606.30 ms /    33 tokens (   48.68 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1214.80 ms /    25 runs   (   48.59 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    2824.81 ms /    58 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     753.63 ms /    24 tokens (   31.40 ms per token,    31.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =     823.81 ms /    17 runs   (   48.46 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    1579.87 ms /    41 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     955.80 ms /    25 tokens (   38.23 ms per token,    26.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =     773.52 ms /    16 runs   (   48.35 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1731.52 ms /    41 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     302.77 ms /     6 tokens (   50.46 ms per token,    19.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =     630.89 ms /    13 runs   (   48.53 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =     935.62 ms /    19 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     694.94 ms /    24 tokens (   28.96 ms per token,    34.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =     724.13 ms /    15 runs   (   48.28 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    1421.13 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1670.24 ms /    33 tokens (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =     865.93 ms /    18 runs   (   48.11 ms per token,    20.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    2538.97 ms /    51 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     897.52 ms /    30 tokens (   29.92 ms per token,    33.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1020.54 ms /    21 runs   (   48.60 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    1921.22 ms /    51 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     636.95 ms /    18 tokens (   35.39 ms per token,    28.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1062.61 ms /    22 runs   (   48.30 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1702.64 ms /    40 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1826.73 ms /    68 tokens (   26.86 ms per token,    37.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3737.17 ms /    77 runs   (   48.53 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    5575.21 ms /   145 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 79 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1865.15 ms /    79 tokens (   23.61 ms per token,    42.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3608.62 ms /    74 runs   (   48.77 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    5484.96 ms /   153 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1622.74 ms /    43 tokens (   37.74 ms per token,    26.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2222.18 ms /    46 runs   (   48.31 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    3851.56 ms /    89 tokens\n",
      "Llama.generate: 62 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1684.84 ms /    40 tokens (   42.12 ms per token,    23.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3355.78 ms /    69 runs   (   48.63 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    5050.63 ms /   109 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1819.48 ms /    66 tokens (   27.57 ms per token,    36.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1546.19 ms /    32 runs   (   48.32 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    3370.23 ms /    98 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1634.27 ms /    64 tokens (   25.54 ms per token,    39.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2816.83 ms /    58 runs   (   48.57 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    4459.44 ms /   122 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1646.68 ms /    51 tokens (   32.29 ms per token,    30.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2084.42 ms /    43 runs   (   48.47 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    3737.21 ms /    94 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1667.62 ms /    48 tokens (   34.74 ms per token,    28.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2127.59 ms /    44 runs   (   48.35 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    3801.51 ms /    92 tokens\n",
      "Llama.generate: 44 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     575.28 ms /    21 tokens (   27.39 ms per token,    36.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1797.33 ms /    37 runs   (   48.58 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    2377.78 ms /    58 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1811.54 ms /    66 tokens (   27.45 ms per token,    36.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =     436.89 ms /     9 runs   (   48.54 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    2249.97 ms /    75 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     413.80 ms /    13 tokens (   31.83 ms per token,    31.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =     865.36 ms /    18 runs   (   48.08 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1281.68 ms /    31 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     798.25 ms /    29 tokens (   27.53 ms per token,    36.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =     638.11 ms /    13 runs   (   49.09 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    1438.23 ms /    42 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     887.25 ms /    27 tokens (   32.86 ms per token,    30.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =     817.70 ms /    17 runs   (   48.10 ms per token,    20.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    1707.34 ms /    44 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     752.85 ms /    25 tokens (   30.11 ms per token,    33.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1011.01 ms /    21 runs   (   48.14 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    1766.68 ms /    46 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     732.55 ms /    25 tokens (   29.30 ms per token,    34.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =     632.32 ms /    13 runs   (   48.64 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    1366.91 ms /    38 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     681.03 ms /    22 tokens (   30.96 ms per token,    32.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =     769.49 ms /    16 runs   (   48.09 ms per token,    20.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    1452.84 ms /    38 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     806.20 ms /    28 tokens (   28.79 ms per token,    34.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =     674.12 ms /    14 runs   (   48.15 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    1482.36 ms /    42 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     220.14 ms /     7 tokens (   31.45 ms per token,    31.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =     683.83 ms /    14 runs   (   48.85 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =     906.00 ms /    21 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     709.19 ms /    23 tokens (   30.83 ms per token,    32.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =     728.39 ms /    15 runs   (   48.56 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    1439.71 ms /    38 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     220.81 ms /     7 tokens (   31.54 ms per token,    31.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =     772.03 ms /    16 runs   (   48.25 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =     995.24 ms /    23 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1605.32 ms /    33 tokens (   48.65 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1107.66 ms /    23 runs   (   48.16 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    2716.38 ms /    56 tokens\n",
      "Llama.generate: 44 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     189.44 ms /     6 tokens (   31.57 ms per token,    31.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1063.31 ms /    22 runs   (   48.33 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1255.71 ms /    28 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1746.83 ms /    34 tokens (   51.38 ms per token,    19.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1301.52 ms /    27 runs   (   48.20 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    3052.39 ms /    61 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     825.49 ms /    29 tokens (   28.47 ms per token,    35.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =     916.51 ms /    19 runs   (   48.24 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1744.73 ms /    48 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1821.31 ms /    34 tokens (   53.57 ms per token,    18.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1255.89 ms /    26 runs   (   48.30 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    3081.12 ms /    60 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     659.11 ms /    22 tokens (   29.96 ms per token,    33.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1057.69 ms /    22 runs   (   48.08 ms per token,    20.80 tokens per second)\n",
      "llama_perf_context_print:       total time =    1719.81 ms /    44 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1707.61 ms /    39 tokens (   43.78 ms per token,    22.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1495.10 ms /    31 runs   (   48.23 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    3207.16 ms /    70 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     888.65 ms /    31 tokens (   28.67 ms per token,    34.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1494.24 ms /    31 runs   (   48.20 ms per token,    20.75 tokens per second)\n",
      "llama_perf_context_print:       total time =    2387.22 ms /    62 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     887.71 ms /    28 tokens (   31.70 ms per token,    31.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =     771.32 ms /    16 runs   (   48.21 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1661.38 ms /    44 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     745.86 ms /    24 tokens (   31.08 ms per token,    32.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =     917.08 ms /    19 runs   (   48.27 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1665.69 ms /    43 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     637.74 ms /    21 tokens (   30.37 ms per token,    32.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =     776.93 ms /    16 runs   (   48.56 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    1416.89 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1544.50 ms /    32 tokens (   48.27 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1014.16 ms /    21 runs   (   48.29 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    2561.72 ms /    53 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     784.52 ms /    26 tokens (   30.17 ms per token,    33.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1012.33 ms /    21 runs   (   48.21 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    1799.79 ms /    47 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     747.23 ms /    25 tokens (   29.89 ms per token,    33.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =     770.51 ms /    16 runs   (   48.16 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    1520.02 ms /    41 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     855.01 ms /    27 tokens (   31.67 ms per token,    31.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1255.08 ms /    26 runs   (   48.27 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    2113.73 ms /    53 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     754.78 ms /    25 tokens (   30.19 ms per token,    33.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =     966.12 ms /    20 runs   (   48.31 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1723.79 ms /    45 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     538.68 ms /    18 tokens (   29.93 ms per token,    33.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =     594.25 ms /    12 runs   (   49.52 ms per token,    20.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    1134.73 ms /    30 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     497.40 ms /    17 tokens (   29.26 ms per token,    34.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =     534.36 ms /    11 runs   (   48.58 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    1033.32 ms /    28 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     703.78 ms /    24 tokens (   29.32 ms per token,    34.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1061.41 ms /    22 runs   (   48.25 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    1768.18 ms /    46 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1461.68 ms /    32 tokens (   45.68 ms per token,    21.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1350.08 ms /    28 runs   (   48.22 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    2815.94 ms /    60 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1639.68 ms /    35 tokens (   46.85 ms per token,    21.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =     770.71 ms /    16 runs   (   48.17 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    2413.08 ms /    51 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1610.58 ms /    35 tokens (   46.02 ms per token,    21.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2140.29 ms /    44 runs   (   48.64 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    3757.18 ms /    79 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     795.76 ms /    27 tokens (   29.47 ms per token,    33.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =     820.41 ms /    17 runs   (   48.26 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    1618.80 ms /    44 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     838.31 ms /    30 tokens (   27.94 ms per token,    35.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1255.84 ms /    26 runs   (   48.30 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    2097.71 ms /    56 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     585.37 ms /    20 tokens (   29.27 ms per token,    34.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =     725.97 ms /    15 runs   (   48.40 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    1313.55 ms /    35 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     466.40 ms /    15 tokens (   31.09 ms per token,    32.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =     433.93 ms /     9 runs   (   48.21 ms per token,    20.74 tokens per second)\n",
      "llama_perf_context_print:       total time =     901.67 ms /    24 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     817.02 ms /    27 tokens (   30.26 ms per token,    33.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =     821.39 ms /    17 runs   (   48.32 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1640.99 ms /    44 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 26 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 24 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     739.79 ms /    22 tokens (   33.63 ms per token,    29.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1058.51 ms /    22 runs   (   48.11 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1802.52 ms /    44 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     482.12 ms /     9 tokens (   53.57 ms per token,    18.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =     676.52 ms /    14 runs   (   48.32 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    1160.64 ms /    23 tokens\n",
      "Llama.generate: 33 prefix-match hit, remaining 13 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     390.90 ms /    13 tokens (   30.07 ms per token,    33.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =     673.29 ms /    14 runs   (   48.09 ms per token,    20.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    1066.38 ms /    27 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     824.92 ms /    25 tokens (   33.00 ms per token,    30.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1205.83 ms /    25 runs   (   48.23 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    2034.22 ms /    50 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     518.75 ms /    18 tokens (   28.82 ms per token,    34.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =     481.66 ms /    10 runs   (   48.17 ms per token,    20.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1001.95 ms /    28 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     886.37 ms /    31 tokens (   28.59 ms per token,    34.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1547.27 ms /    32 runs   (   48.35 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    2438.19 ms /    63 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     912.80 ms /    21 tokens (   43.47 ms per token,    23.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =     539.02 ms /    11 runs   (   49.00 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    1453.55 ms /    32 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     759.89 ms /    26 tokens (   29.23 ms per token,    34.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =     625.40 ms /    13 runs   (   48.11 ms per token,    20.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    1387.33 ms /    39 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     719.17 ms /    25 tokens (   28.77 ms per token,    34.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1015.82 ms /    21 runs   (   48.37 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    1737.95 ms /    46 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1686.95 ms /    33 tokens (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1155.59 ms /    24 runs   (   48.15 ms per token,    20.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    2846.12 ms /    57 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1630.04 ms /    40 tokens (   40.75 ms per token,    24.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1213.35 ms /    25 runs   (   48.53 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    2847.42 ms /    65 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1801.44 ms /    65 tokens (   27.71 ms per token,    36.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2230.15 ms /    46 runs   (   48.48 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    4038.55 ms /   111 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1820.73 ms /    67 tokens (   27.18 ms per token,    36.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3051.21 ms /    63 runs   (   48.43 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    4881.24 ms /   130 tokens\n",
      "Llama.generate: 48 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     663.57 ms /    21 tokens (   31.60 ms per token,    31.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2233.64 ms /    46 runs   (   48.56 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    2903.70 ms /    67 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1628.49 ms /    46 tokens (   35.40 ms per token,    28.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1895.09 ms /    39 runs   (   48.59 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    3529.65 ms /    85 tokens\n",
      "Llama.generate: 45 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     495.53 ms /    16 tokens (   30.97 ms per token,    32.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1111.22 ms /    23 runs   (   48.31 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    1609.85 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 124 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2043.07 ms /   124 tokens (   16.48 ms per token,    60.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4158.92 ms /    85 runs   (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    6215.32 ms /   209 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 234 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2969.77 ms /   234 tokens (   12.69 ms per token,    78.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10931.77 ms /   220 runs   (   49.69 ms per token,    20.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   13945.26 ms /   454 tokens\n",
      "Llama.generate: 50 prefix-match hit, remaining 154 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2281.95 ms /   154 tokens (   14.82 ms per token,    67.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4587.89 ms /    92 runs   (   49.87 ms per token,    20.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    6884.80 ms /   246 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 153 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2312.71 ms /   153 tokens (   15.12 ms per token,    66.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1746.80 ms /    35 runs   (   49.91 ms per token,    20.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    4065.44 ms /   188 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1633.61 ms /    47 tokens (   34.76 ms per token,    28.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2543.73 ms /    51 runs   (   49.88 ms per token,    20.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    4185.22 ms /    98 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     877.28 ms /    28 tokens (   31.33 ms per token,    31.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1940.85 ms /    39 runs   (   49.77 ms per token,    20.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    2823.79 ms /    67 tokens\n",
      "Llama.generate: 31 prefix-match hit, remaining 165 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2532.26 ms /   165 tokens (   15.35 ms per token,    65.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6049.98 ms /   119 runs   (   50.84 ms per token,    19.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    8602.55 ms /   284 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1454.88 ms /    32 tokens (   45.47 ms per token,    21.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1183.06 ms /    24 runs   (   49.29 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    2641.40 ms /    56 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 320 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error translating query: 'AND([AbortionAnyTie] False,[AlcoholSpiritsProdMinRev] < '0.1',[AlcoholDistributionMinRev] < '0.1',[CivFAProdServMinRev] < '0.05',[CivFADistMinRev] < '0.05',[ContraceptivesProdMinRevRatio1Y] < '0.1',[APMinesOverallFlag] IN 'Amber|Green',[BiologicalWeaponsOverallFlag] IN 'Amber|Green',[ChemicalWeaponsOverallFlag] IN 'Amber|Green',[ClusterMunitionsOverallFlag] IN 'Amber|Green',[DepletedUraniumOverallFlag] IN 'Amber|Green',[IncendiaryWeaponsOverallFlag] IN 'Amber|Green',[NuclearWeaponsOverallFlag] IN 'Amber|Green',[NuclearWeaponsNonNPTOverallFlag] IN 'Amber|Green',[WhitePhosphorusOverallFlag] IN 'Amber|Green',[EuthanasiaActiveHasRisk] False,[FossilFuelCoalExtractRevShareMax] == '0',[FossilFuelCoalPowerRevShareMin] < '0.05',[FossilFuelCoalRefProcRevShareMin] < '0.05',[FossilFuelOilExtractRevShareMin] < '0.05',[FossilFuelOilPowerRevShareMin] < '0.05',[FossilFuelOilRefProcRevShareMin] < '0.05',[FossilFuelGasExtractRevShareMin] < '0.05',[OilSandsProdMaxRev] == '0',[GamblingProdMaxRev] == '0',[GamblingDistMinRev] < '0.1',[GamblingServMinRev] < '0.1',[GMOAgricultureProdMinRev] < '0.05',[MilitaryEqmtProdServMinRev] < '0.05',[MilitaryEqmtDistMinRev] < '0.05',[NuclearPowerRevShareMin] < '0.05',[NuclearPowerProdRevShareMax] == '0',[NuclearPowerUraniumRevShareMax] == '0',[NuclearPowerServRevShareMin] < '0.05',[TobaccoProdMaxRev] == '0',[TobaccoDistMinRev] < '0.1',[TobaccoServMinRev] < '0.1',[ViolentVideoGamesRevShareMax] == '0',[NBSOverallScore] < '10',[HazardousSubstThirdPartyLists] NONE 'REACH Authorisation List',[HazardousPestProdSigInvolvement] ANY 'Less than 5%',[GMOAgricultureUserSigInvolvement] ANY 'Less than 10%',[GMOAgricultureDistSigInvolvement] NONE 'Less than 10%|At least 10%',[AnimalWelfareInvolvement] ANY 'Animal Testing|Fur & Exotic Leather|Live Export',[AnimalWelfareFurOnlyProdSignInv] NONE 'Less than 5%|At least 5%',[AnimalWelfareFurOnlyDistSignInv] NONE 'Less than 5%|At least 5%',[AbortifacientsProdMaxRevRatio1Y] == '0',[AbortifacientsDistrMaxRevRatio1Y] == '0',[StemCellContractResearchOrg] False,[StemCellCloning] False,[StemCellHumanEmbryonicSCResearch] False,[StemCellSpecializedCompany] False,[StemCellEnablingTech] False,[AnimalWelAnimTestLegalReqStatem] NONE 'Beyond Legal Requirements')'\n",
      "Error: Requested tokens (975) exceed context window of 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    3380.86 ms /   320 tokens (   10.57 ms per token,    94.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8517.21 ms /   167 runs   (   51.00 ms per token,    19.61 tokens per second)\n",
      "llama_perf_context_print:       total time =   11928.85 ms /   487 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 416 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    4489.23 ms /   416 tokens (   10.79 ms per token,    92.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3551.77 ms /    70 runs   (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    8052.56 ms /   486 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 272 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    3132.22 ms /   272 tokens (   11.52 ms per token,    86.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10866.81 ms /   214 runs   (   50.78 ms per token,    19.69 tokens per second)\n",
      "llama_perf_context_print:       total time =   14041.91 ms /   486 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 414 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    4506.49 ms /   414 tokens (   10.89 ms per token,    91.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3881.71 ms /    77 runs   (   50.41 ms per token,    19.84 tokens per second)\n",
      "llama_perf_context_print:       total time =    8400.62 ms /   491 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1657.60 ms /    40 tokens (   41.44 ms per token,    24.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =     645.45 ms /    13 runs   (   49.65 ms per token,    20.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    2305.31 ms /    53 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     908.16 ms /    30 tokens (   30.27 ms per token,    33.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1386.12 ms /    28 runs   (   49.50 ms per token,    20.20 tokens per second)\n",
      "llama_perf_context_print:       total time =    2298.47 ms /    58 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1776.34 ms /    39 tokens (   45.55 ms per token,    21.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =     827.28 ms /    17 runs   (   48.66 ms per token,    20.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    2606.35 ms /    56 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1613.53 ms /    37 tokens (   43.61 ms per token,    22.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1411.73 ms /    29 runs   (   48.68 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    3029.43 ms /    66 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 198 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2750.97 ms /   198 tokens (   13.89 ms per token,    71.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =   12389.30 ms /   248 runs   (   49.96 ms per token,    20.02 tokens per second)\n",
      "llama_perf_context_print:       total time =   15193.27 ms /   446 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1672.41 ms /    43 tokens (   38.89 ms per token,    25.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1514.00 ms /    31 runs   (   48.84 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    3191.15 ms /    74 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     903.54 ms /    31 tokens (   29.15 ms per token,    34.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1120.93 ms /    23 runs   (   48.74 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    2027.77 ms /    54 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1767.51 ms /    38 tokens (   46.51 ms per token,    21.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1227.38 ms /    25 runs   (   49.10 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    2998.63 ms /    63 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1610.42 ms /    34 tokens (   47.37 ms per token,    21.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1259.80 ms /    26 runs   (   48.45 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    2874.15 ms /    60 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     917.18 ms /    29 tokens (   31.63 ms per token,    31.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1071.03 ms /    22 runs   (   48.68 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    1991.26 ms /    51 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1623.04 ms /    39 tokens (   41.62 ms per token,    24.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1404.80 ms /    29 runs   (   48.44 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    3032.35 ms /    68 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1694.64 ms /    33 tokens (   51.35 ms per token,    19.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1020.95 ms /    21 runs   (   48.62 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    2718.95 ms /    54 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     920.92 ms /    31 tokens (   29.71 ms per token,    33.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1161.22 ms /    24 runs   (   48.38 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    2085.66 ms /    55 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1652.58 ms /    46 tokens (   35.93 ms per token,    27.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1982.50 ms /    41 runs   (   48.35 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    3641.08 ms /    87 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     873.94 ms /    29 tokens (   30.14 ms per token,    33.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =     914.53 ms /    19 runs   (   48.13 ms per token,    20.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    1791.10 ms /    48 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1662.28 ms /    34 tokens (   48.89 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1214.83 ms /    25 runs   (   48.59 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    2880.80 ms /    59 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 93 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1916.54 ms /    93 tokens (   20.61 ms per token,    48.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2590.05 ms /    53 runs   (   48.87 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    4514.79 ms /   146 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 195 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2660.97 ms /   195 tokens (   13.65 ms per token,    73.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8504.61 ms /   172 runs   (   49.45 ms per token,    20.22 tokens per second)\n",
      "llama_perf_context_print:       total time =   11196.75 ms /   367 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 439 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    4620.09 ms /   439 tokens (   10.52 ms per token,    95.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2357.83 ms /    47 runs   (   50.17 ms per token,    19.93 tokens per second)\n",
      "llama_perf_context_print:       total time =    6985.59 ms /   486 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1691.47 ms /    49 tokens (   34.52 ms per token,    28.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1399.53 ms /    29 runs   (   48.26 ms per token,    20.72 tokens per second)\n",
      "llama_perf_context_print:       total time =    3095.18 ms /    78 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1626.68 ms /    37 tokens (   43.96 ms per token,    22.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2149.52 ms /    44 runs   (   48.85 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    3782.68 ms /    81 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1616.69 ms /    39 tokens (   41.45 ms per token,    24.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1545.55 ms /    32 runs   (   48.30 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    3166.88 ms /    71 tokens\n",
      "Llama.generate: 45 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     541.28 ms /    18 tokens (   30.07 ms per token,    33.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1551.21 ms /    32 runs   (   48.48 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    2096.83 ms /    50 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1642.14 ms /    50 tokens (   32.84 ms per token,    30.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =     967.59 ms /    20 runs   (   48.38 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    2612.86 ms /    70 tokens\n",
      "Llama.generate: 48 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     569.68 ms /    20 tokens (   28.48 ms per token,    35.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1323.40 ms /    27 runs   (   49.01 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    1897.05 ms /    47 tokens\n",
      "Llama.generate: 52 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1692.01 ms /    61 tokens (   27.74 ms per token,    36.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3567.52 ms /    73 runs   (   48.87 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    5270.30 ms /   134 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 73 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1857.02 ms /    73 tokens (   25.44 ms per token,    39.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2957.57 ms /    60 runs   (   49.29 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    4823.63 ms /   133 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 79 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1955.18 ms /    79 tokens (   24.75 ms per token,    40.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3383.21 ms /    69 runs   (   49.03 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    5348.87 ms /   148 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1801.65 ms /    43 tokens (   41.90 ms per token,    23.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1311.97 ms /    27 runs   (   48.59 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    3117.80 ms /    70 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1643.84 ms /    35 tokens (   46.97 ms per token,    21.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1263.04 ms /    26 runs   (   48.58 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    2910.66 ms /    61 tokens\n",
      "Llama.generate: 44 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     703.87 ms /    17 tokens (   41.40 ms per token,    24.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1167.34 ms /    24 runs   (   48.64 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    1874.65 ms /    41 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1606.01 ms /    37 tokens (   43.41 ms per token,    23.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1356.45 ms /    28 runs   (   48.44 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    2966.78 ms /    65 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1677.71 ms /    56 tokens (   29.96 ms per token,    33.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2438.82 ms /    50 runs   (   48.78 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    4124.13 ms /   106 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 100 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2157.51 ms /   100 tokens (   21.58 ms per token,    46.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1671.11 ms /    34 runs   (   49.15 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    3833.86 ms /   134 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1608.55 ms /    33 tokens (   48.74 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =     780.05 ms /    16 runs   (   48.75 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    2391.13 ms /    49 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 93 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1907.72 ms /    93 tokens (   20.51 ms per token,    48.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2462.37 ms /    50 runs   (   49.25 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    4377.39 ms /   143 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1680.89 ms /    54 tokens (   31.13 ms per token,    32.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1950.15 ms /    40 runs   (   48.75 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    3637.12 ms /    94 tokens\n",
      "Llama.generate: 57 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1632.07 ms /    53 tokens (   30.79 ms per token,    32.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3170.05 ms /    64 runs   (   49.53 ms per token,    20.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    4811.82 ms /   117 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1670.50 ms /    55 tokens (   30.37 ms per token,    32.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2705.99 ms /    55 runs   (   49.20 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    4384.95 ms /   110 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1635.01 ms /    60 tokens (   27.25 ms per token,    36.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1575.69 ms /    32 runs   (   49.24 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    3215.80 ms /    92 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1680.55 ms /    49 tokens (   34.30 ms per token,    29.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2220.96 ms /    45 runs   (   49.35 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    3908.32 ms /    94 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1687.56 ms /    39 tokens (   43.27 ms per token,    23.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1816.75 ms /    37 runs   (   49.10 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    3509.93 ms /    76 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1615.11 ms /    40 tokens (   40.38 ms per token,    24.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1666.77 ms /    34 runs   (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    3286.82 ms /    74 tokens\n",
      "Llama.generate: 48 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1840.51 ms /    68 tokens (   27.07 ms per token,    36.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2480.80 ms /    50 runs   (   49.62 ms per token,    20.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    4329.14 ms /   118 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 301 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    3343.14 ms /   301 tokens (   11.11 ms per token,    90.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9670.11 ms /   190 runs   (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_perf_context_print:       total time =   13049.33 ms /   491 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 94 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1844.44 ms /    94 tokens (   19.62 ms per token,    50.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4490.35 ms /    90 runs   (   49.89 ms per token,    20.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    6349.36 ms /   184 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1759.49 ms /    52 tokens (   33.84 ms per token,    29.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1925.21 ms /    39 runs   (   49.36 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    3690.60 ms /    91 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 87 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1836.78 ms /    87 tokens (   21.11 ms per token,    47.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3338.90 ms /    67 runs   (   49.83 ms per token,    20.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    5185.90 ms /   154 tokens\n",
      "Llama.generate: 55 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     430.37 ms /    14 tokens (   30.74 ms per token,    32.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1332.85 ms /    27 runs   (   49.36 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    1767.09 ms /    41 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 205 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2660.95 ms /   205 tokens (   12.98 ms per token,    77.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2933.38 ms /    59 runs   (   49.72 ms per token,    20.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    5603.96 ms /   264 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 105 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2105.52 ms /   105 tokens (   20.05 ms per token,    49.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2903.35 ms /    59 runs   (   49.21 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    5017.89 ms /   164 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 236 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2917.14 ms /   236 tokens (   12.36 ms per token,    80.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1683.56 ms /    34 runs   (   49.52 ms per token,    20.20 tokens per second)\n",
      "llama_perf_context_print:       total time =    4606.34 ms /   270 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 63 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1646.27 ms /    63 tokens (   26.13 ms per token,    38.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1871.36 ms /    38 runs   (   49.25 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    3523.36 ms /   101 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1696.09 ms /    39 tokens (   43.49 ms per token,    22.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1595.77 ms /    33 runs   (   48.36 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    3296.55 ms /    72 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1644.15 ms /    35 tokens (   46.98 ms per token,    21.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2180.59 ms /    45 runs   (   48.46 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    3831.32 ms /    80 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 84 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1893.11 ms /    84 tokens (   22.54 ms per token,    44.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2110.10 ms /    43 runs   (   49.07 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    4009.78 ms /   127 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1627.84 ms /    41 tokens (   39.70 ms per token,    25.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1569.49 ms /    32 runs   (   49.05 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    3202.27 ms /    73 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1706.68 ms /    48 tokens (   35.56 ms per token,    28.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1116.14 ms /    23 runs   (   48.53 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    2826.27 ms /    71 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1632.05 ms /    43 tokens (   37.95 ms per token,    26.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2153.59 ms /    44 runs   (   48.95 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    3792.05 ms /    87 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1798.06 ms /    62 tokens (   29.00 ms per token,    34.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1951.51 ms /    40 runs   (   48.79 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    3755.25 ms /   102 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 109 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2040.39 ms /   109 tokens (   18.72 ms per token,    53.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5442.17 ms /   110 runs   (   49.47 ms per token,    20.21 tokens per second)\n",
      "llama_perf_context_print:       total time =    7500.81 ms /   219 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 269 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    3092.43 ms /   269 tokens (   11.50 ms per token,    86.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4063.17 ms /    81 runs   (   50.16 ms per token,    19.94 tokens per second)\n",
      "llama_perf_context_print:       total time =    7168.56 ms /   350 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 191 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2558.07 ms /   191 tokens (   13.39 ms per token,    74.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3433.69 ms /    69 runs   (   49.76 ms per token,    20.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    6003.13 ms /   260 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1664.64 ms /    34 tokens (   48.96 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1073.93 ms /    22 runs   (   48.82 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    2741.83 ms /    56 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1635.50 ms /    57 tokens (   28.69 ms per token,    34.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2216.89 ms /    45 runs   (   49.26 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    3859.46 ms /   102 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 151 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2259.63 ms /   151 tokens (   14.96 ms per token,    66.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2619.33 ms /    53 runs   (   49.42 ms per token,    20.23 tokens per second)\n",
      "llama_perf_context_print:       total time =    4887.38 ms /   204 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1671.68 ms /    39 tokens (   42.86 ms per token,    23.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1520.68 ms /    31 runs   (   49.05 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    3197.29 ms /    70 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1728.61 ms /    51 tokens (   33.89 ms per token,    29.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1570.12 ms /    32 runs   (   49.07 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    3303.56 ms /    83 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 96 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1833.92 ms /    96 tokens (   19.10 ms per token,    52.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4313.99 ms /    87 runs   (   49.59 ms per token,    20.17 tokens per second)\n",
      "llama_perf_context_print:       total time =    6161.46 ms /   183 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1676.04 ms /    59 tokens (   28.41 ms per token,    35.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3312.76 ms /    67 runs   (   49.44 ms per token,    20.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    4998.90 ms /   126 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1627.06 ms /    45 tokens (   36.16 ms per token,    27.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2852.78 ms /    58 runs   (   49.19 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    4488.34 ms /   103 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 27 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 38 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1872.67 ms /    70 tokens (   26.75 ms per token,    37.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3741.92 ms /    77 runs   (   48.60 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    5627.27 ms /   147 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1641.15 ms /    50 tokens (   32.82 ms per token,    30.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1738.22 ms /    36 runs   (   48.28 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    3384.78 ms /    86 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 282 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    3210.37 ms /   282 tokens (   11.38 ms per token,    87.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1277.85 ms /    26 runs   (   49.15 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    4492.07 ms /   308 tokens\n",
      "Llama.generate: 31 prefix-match hit, remaining 232 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2944.95 ms /   232 tokens (   12.69 ms per token,    78.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9716.85 ms /   192 runs   (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_perf_context_print:       total time =   12699.74 ms /   424 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1633.92 ms /    43 tokens (   38.00 ms per token,    26.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1335.55 ms /    27 runs   (   49.46 ms per token,    20.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    2973.47 ms /    70 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     578.06 ms /    18 tokens (   32.11 ms per token,    31.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =     887.52 ms /    18 runs   (   49.31 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    1468.22 ms /    36 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1646.73 ms /    32 tokens (   51.46 ms per token,    19.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =     897.76 ms /    18 runs   (   49.88 ms per token,    20.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    2547.20 ms /    50 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1624.52 ms /    42 tokens (   38.68 ms per token,    25.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1636.46 ms /    33 runs   (   49.59 ms per token,    20.17 tokens per second)\n",
      "llama_perf_context_print:       total time =    3265.93 ms /    75 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1637.09 ms /    55 tokens (   29.77 ms per token,    33.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3281.85 ms /    65 runs   (   50.49 ms per token,    19.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    4929.13 ms /   120 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 315 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    3451.93 ms /   315 tokens (   10.96 ms per token,    91.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8965.42 ms /   172 runs   (   52.12 ms per token,    19.18 tokens per second)\n",
      "llama_perf_context_print:       total time =   12451.36 ms /   487 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1622.48 ms /    46 tokens (   35.27 ms per token,    28.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =     908.70 ms /    18 runs   (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    2534.29 ms /    64 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 168 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2486.76 ms /   168 tokens (   14.80 ms per token,    67.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6436.86 ms /   126 runs   (   51.09 ms per token,    19.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    8946.08 ms /   294 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 101 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error translating query: 'AND([AlcoholSpiritsProdMinRev] <= '0.05',[AnimalWelfareFurOnlyProdSignInv] NONE 'Less than 5%|At least 5%',[AnimalWelfareFurOnlyDistSignInv] NONE 'At least 5%',[CivFAProdServMinRev] <= '0.05',[CivFADistMinRev] <= '0.05',[FossilFuelRevShareMin] <= '0.01',[FossilFuelCoalExtractRevShareMin] < '0.1',[FossilFuelOilExtractRevShareMin] <= '0.01',[OilSandsProdMinRev] < '0.1',[GamblingProdMinRev] <= '0.1',[GMOAgricultureProdMinRev] <= '0.1',[HazardousSubstThirdPartyLists] NONE 'ChemSec SIN List',[MilitaryEqmtProdServMinRev] <= '0.05',[MilitaryEqmtDistMinRev] <= '0.05',[NuclearPowerRevShareMin] <= '0.1',[NuclearPowerUraniumRevShareMin] <= '0.05',[TobaccoProdMinRev] <= '0.1',[ViolentVideoGamesRevShareMin] <= '0.1',[HydraulicFracturingHighVolHF] False,[HydraulicFracturingShareMin] <= '0.1',NOT ([APMinesOverallFlag] IN 'RED'),NOT ([BiologicalWeaponsOverallFlag] IN 'RED'),NOT ([ChemicalWeaponsOverallFlag] IN 'RED'),NOT ([ClusterMunitionsOverallFlag] IN 'RED'),NOT ([DepletedUraniumOverallFlag] IN 'RED'),NOT ([IncendiaryWeaponsOverallFlag] IN 'RED'),NOT ([NuclearWeaponsOverallFlag] IN 'RED'),NOT ([NuclearWeaponsNonNPTOverallFlag] IN 'RED'),NOT ([WhitePhosphorusOverallFlag] IN 'RED'))'\n",
      "Error: Requested tokens (546) exceed context window of 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1983.08 ms /   101 tokens (   19.63 ms per token,    50.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3520.83 ms /    69 runs   (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    5515.12 ms /   170 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 347 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    3946.10 ms /   347 tokens (   11.37 ms per token,    87.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5749.13 ms /   112 runs   (   51.33 ms per token,    19.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    9714.58 ms /   459 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1658.95 ms /    43 tokens (   38.58 ms per token,    25.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1783.87 ms /    36 runs   (   49.55 ms per token,    20.18 tokens per second)\n",
      "llama_perf_context_print:       total time =    3448.57 ms /    79 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1614.53 ms /    38 tokens (   42.49 ms per token,    23.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1384.52 ms /    28 runs   (   49.45 ms per token,    20.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    3003.56 ms /    66 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 181 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2530.10 ms /   181 tokens (   13.98 ms per token,    71.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9458.32 ms /   188 runs   (   50.31 ms per token,    19.88 tokens per second)\n",
      "llama_perf_context_print:       total time =   12025.36 ms /   369 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1629.69 ms /    57 tokens (   28.59 ms per token,    34.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2117.18 ms /    43 runs   (   49.24 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    3753.48 ms /   100 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1689.84 ms /    54 tokens (   31.29 ms per token,    31.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1959.21 ms /    40 runs   (   48.98 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    3655.12 ms /    94 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1624.39 ms /    50 tokens (   32.49 ms per token,    30.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1981.06 ms /    40 runs   (   49.53 ms per token,    20.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    3611.72 ms /    90 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 103 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2034.87 ms /   103 tokens (   19.76 ms per token,    50.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2161.62 ms /    44 runs   (   49.13 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    4203.43 ms /   147 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1838.81 ms /    68 tokens (   27.04 ms per token,    36.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2149.71 ms /    44 runs   (   48.86 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    3995.57 ms /   112 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1671.40 ms /    43 tokens (   38.87 ms per token,    25.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1168.69 ms /    24 runs   (   48.70 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    2843.67 ms /    67 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1718.46 ms /    51 tokens (   33.70 ms per token,    29.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1067.26 ms /    22 runs   (   48.51 ms per token,    20.61 tokens per second)\n",
      "llama_perf_context_print:       total time =    2788.81 ms /    73 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1705.91 ms /    53 tokens (   32.19 ms per token,    31.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2288.63 ms /    47 runs   (   48.69 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    4001.68 ms /   100 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1625.90 ms /    41 tokens (   39.66 ms per token,    25.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1270.24 ms /    26 runs   (   48.86 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    2900.03 ms /    67 tokens\n",
      "Llama.generate: 44 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1659.82 ms /    52 tokens (   31.92 ms per token,    31.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1713.90 ms /    35 runs   (   48.97 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    3379.12 ms /    87 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1680.21 ms /    47 tokens (   35.75 ms per token,    27.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2143.83 ms /    44 runs   (   48.72 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    3830.73 ms /    91 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1626.91 ms /    45 tokens (   36.15 ms per token,    27.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =     923.44 ms /    19 runs   (   48.60 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    2553.29 ms /    64 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1708.84 ms /    46 tokens (   37.15 ms per token,    26.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1505.89 ms /    31 runs   (   48.58 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    3219.21 ms /    77 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 127 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2032.99 ms /   127 tokens (   16.01 ms per token,    62.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6508.93 ms /   131 runs   (   49.69 ms per token,    20.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    8564.54 ms /   258 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1662.63 ms /    49 tokens (   33.93 ms per token,    29.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1614.24 ms /    33 runs   (   48.92 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    3281.86 ms /    82 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 71 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error translating query: 'AND([AnimalWelfareAnimTestInvolvement] ANY 'Pharmaceutical|Non-Pharmaceutical',[AnimalWelfareFurInvolvementTie] ANY 'Production|Distribution',[APMinesOverallFlag] IN 'RED|Amber',[BiologicalWeaponsOverallFlag] IN 'RED|Amber',[ChemicalWeaponsOverallFlag] IN 'RED|Amber',[ClusterMunitionsOverallFlag] IN 'RED|Amber',[DepletedUraniumOverallFlag] IN 'RED|Amber',[IncendiaryWeaponsOverallFlag] IN 'RED|Amber',[NuclearWeaponsINPTVerInvRedAmber] True,[NuclearWeaponsONPTVerInvRedAmber] True,[WhitePhosphorusVerInvRedAmber] True,[MilitaryEqmtCombatInvolvement] ANY 'Production|Distribution|Services',[CivFARevShareMax] > '0',[NuclearPowerInvolvement] ANY 'Production|Services',[PowGenCapacityThermalRatio] > '0',[PalmOilInvolvement] ANY 'Grower (Production)|Processor (Production)|Distribution',[GMOInvolvement] ANY 'Agriculture|Pharmaceutical|Other',[HazardousPestProdSigInvolvement] ANY 'At least 5%',[AlcoholInvolvement] ANY 'Production|Distribution|Services',[TobaccoInvolvement] ANY 'Production|Distribution|Services',[AbortifacientsInvolvement] ANY 'Production|Distribution|Services',[AbortionAnyTie] True,[ContraceptivesInvolvement] ANY 'Production|Distribution|Services',[EuthanasiaInvolvement] ANY 'Pharmaceuticals|Active Euthanasia',[StemCellAnyTie] True,[InVitroFertilizationInvolvement] ANY 'Healthcare Service|Research',[PornographyInvolvement] ANY 'Production|Distribution',[GamblingInvolvement] ANY 'Production|Distribution|Services')'\n",
      "Error: Requested tokens (539) exceed context window of 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1864.11 ms /    71 tokens (   26.26 ms per token,    38.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3251.08 ms /    66 runs   (   49.26 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    5125.25 ms /   137 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1852.87 ms /    66 tokens (   28.07 ms per token,    35.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2210.96 ms /    45 runs   (   49.13 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    4070.73 ms /   111 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1636.64 ms /    53 tokens (   30.88 ms per token,    32.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1772.47 ms /    36 runs   (   49.24 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    3414.44 ms /    89 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 138 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2203.12 ms /   138 tokens (   15.96 ms per token,    62.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4286.67 ms /    86 runs   (   49.85 ms per token,    20.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    6503.93 ms /   224 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 118 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2061.18 ms /   118 tokens (   17.47 ms per token,    57.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3871.49 ms /    78 runs   (   49.63 ms per token,    20.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    5944.90 ms /   196 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 140 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2343.56 ms /   140 tokens (   16.74 ms per token,    59.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    7201.58 ms /   145 runs   (   49.67 ms per token,    20.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    9570.98 ms /   285 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1648.82 ms /    64 tokens (   25.76 ms per token,    38.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2016.29 ms /    41 runs   (   49.18 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    3671.26 ms /   105 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1624.90 ms /    45 tokens (   36.11 ms per token,    27.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1462.90 ms /    30 runs   (   48.76 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    3092.08 ms /    75 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 104 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2043.91 ms /   104 tokens (   19.65 ms per token,    50.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3440.54 ms /    70 runs   (   49.15 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    5495.50 ms /   174 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1677.81 ms /    37 tokens (   45.35 ms per token,    22.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1311.00 ms /    27 runs   (   48.56 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    2992.90 ms /    64 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     503.78 ms /    16 tokens (   31.49 ms per token,    31.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1128.67 ms /    23 runs   (   49.07 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    1635.84 ms /    39 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1840.72 ms /    68 tokens (   27.07 ms per token,    36.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1801.20 ms /    37 runs   (   48.68 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    3647.38 ms /   105 tokens\n",
      "Llama.generate: 45 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1702.13 ms /    43 tokens (   39.58 ms per token,    25.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2061.66 ms /    42 runs   (   49.09 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    3770.13 ms /    85 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1623.08 ms /    39 tokens (   41.62 ms per token,    24.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =     923.75 ms /    19 runs   (   48.62 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    2549.93 ms /    58 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 185 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2676.21 ms /   185 tokens (   14.47 ms per token,    69.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8638.64 ms /   174 runs   (   49.65 ms per token,    20.14 tokens per second)\n",
      "llama_perf_context_print:       total time =   11347.58 ms /   359 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1709.63 ms /    61 tokens (   28.03 ms per token,    35.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1812.97 ms /    37 runs   (   49.00 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    3527.92 ms /    98 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1822.87 ms /    70 tokens (   26.04 ms per token,    38.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3063.64 ms /    62 runs   (   49.41 ms per token,    20.24 tokens per second)\n",
      "llama_perf_context_print:       total time =    4896.18 ms /   132 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1788.49 ms /    68 tokens (   26.30 ms per token,    38.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2151.38 ms /    44 runs   (   48.89 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    3946.62 ms /   112 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1707.53 ms /    47 tokens (   36.33 ms per token,    27.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1614.80 ms /    33 runs   (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    3327.59 ms /    80 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1746.25 ms /    43 tokens (   40.61 ms per token,    24.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1650.16 ms /    34 runs   (   48.53 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    3401.22 ms /    77 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1616.38 ms /    48 tokens (   33.67 ms per token,    29.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1462.11 ms /    30 runs   (   48.74 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    3082.91 ms /    78 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 311 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    3358.95 ms /   311 tokens (   10.80 ms per token,    92.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8745.19 ms /   175 runs   (   49.97 ms per token,    20.01 tokens per second)\n",
      "llama_perf_context_print:       total time =   12137.19 ms /   486 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1818.24 ms /    67 tokens (   27.14 ms per token,    36.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2559.16 ms /    52 runs   (   49.21 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    4385.23 ms /   119 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 136 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2235.66 ms /   136 tokens (   16.44 ms per token,    60.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3737.12 ms /    76 runs   (   49.17 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    5985.14 ms /   212 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1674.65 ms /    51 tokens (   32.84 ms per token,    30.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1805.64 ms /    37 runs   (   48.80 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    3485.83 ms /    88 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 294 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    3381.75 ms /   294 tokens (   11.50 ms per token,    86.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5688.06 ms /   114 runs   (   49.90 ms per token,    20.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    9089.46 ms /   408 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 380 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    4166.97 ms /   380 tokens (   10.97 ms per token,    91.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5594.35 ms /   111 runs   (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_perf_context_print:       total time =    9780.36 ms /   491 tokens\n",
      "Llama.generate: 159 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     196.13 ms /     6 tokens (   32.69 ms per token,    30.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =     835.52 ms /    17 runs   (   49.15 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    1034.24 ms /    23 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1821.75 ms /    67 tokens (   27.19 ms per token,    36.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1961.51 ms /    40 runs   (   49.04 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    3789.31 ms /   107 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 179 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2581.32 ms /   179 tokens (   14.42 ms per token,    69.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    7281.70 ms /   147 runs   (   49.54 ms per token,    20.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    9889.62 ms /   326 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 205 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2669.03 ms /   205 tokens (   13.02 ms per token,    76.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =   14291.70 ms /   286 runs   (   49.97 ms per token,    20.01 tokens per second)\n",
      "llama_perf_context_print:       total time =   17025.81 ms /   491 tokens\n",
      "Llama.generate: 50 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     535.99 ms /    18 tokens (   29.78 ms per token,    33.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1220.75 ms /    25 runs   (   48.83 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    1760.30 ms /    43 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 203 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2677.65 ms /   203 tokens (   13.19 ms per token,    75.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =   11920.17 ms /   240 runs   (   49.67 ms per token,    20.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   14647.44 ms /   443 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 127 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2134.18 ms /   127 tokens (   16.80 ms per token,    59.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4204.23 ms /    86 runs   (   48.89 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    6351.70 ms /   213 tokens\n",
      "Llama.generate: 122 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1687.39 ms /    44 tokens (   38.35 ms per token,    26.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4608.59 ms /    94 runs   (   49.03 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    6311.00 ms /   138 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 115 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2105.92 ms /   115 tokens (   18.31 ms per token,    54.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3225.47 ms /    66 runs   (   48.87 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    5341.37 ms /   181 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 176 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2572.15 ms /   176 tokens (   14.61 ms per token,    68.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2111.45 ms /    43 runs   (   49.10 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    4690.51 ms /   219 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 135 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2236.23 ms /   135 tokens (   16.56 ms per token,    60.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6752.52 ms /   138 runs   (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    9012.77 ms /   273 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1669.00 ms /    39 tokens (   42.79 ms per token,    23.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1407.57 ms /    29 runs   (   48.54 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    3080.87 ms /    68 tokens\n",
      "Llama.generate: 46 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     867.98 ms /    31 tokens (   28.00 ms per token,    35.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1413.02 ms /    29 runs   (   48.72 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    2285.00 ms /    60 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1671.64 ms /    36 tokens (   46.43 ms per token,    21.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1350.75 ms /    28 runs   (   48.24 ms per token,    20.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    3026.79 ms /    64 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1645.79 ms /    35 tokens (   47.02 ms per token,    21.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1363.22 ms /    28 runs   (   48.69 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    3013.29 ms /    63 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1637.39 ms /    47 tokens (   34.84 ms per token,    28.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1449.65 ms /    30 runs   (   48.32 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    3091.69 ms /    77 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 224 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2789.80 ms /   224 tokens (   12.45 ms per token,    80.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =   12572.77 ms /   253 runs   (   49.69 ms per token,    20.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   15414.87 ms /   477 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 167 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2498.65 ms /   167 tokens (   14.96 ms per token,    66.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5707.02 ms /   116 runs   (   49.20 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    8225.04 ms /   283 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 134 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2217.74 ms /   134 tokens (   16.55 ms per token,    60.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4306.01 ms /    88 runs   (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    6537.53 ms /   222 tokens\n",
      "Llama.generate: 89 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     214.69 ms /     6 tokens (   35.78 ms per token,    27.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1510.07 ms /    31 runs   (   48.71 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    1729.25 ms /    37 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 149 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2360.28 ms /   149 tokens (   15.84 ms per token,    63.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3888.61 ms /    79 runs   (   49.22 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    6261.72 ms /   228 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 63 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1689.29 ms /    63 tokens (   26.81 ms per token,    37.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2241.70 ms /    46 runs   (   48.73 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    3937.83 ms /   109 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     576.23 ms /    20 tokens (   28.81 ms per token,    34.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1305.98 ms /    27 runs   (   48.37 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    1886.07 ms /    47 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 172 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2512.08 ms /   172 tokens (   14.61 ms per token,    68.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5943.77 ms /   121 runs   (   49.12 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    8476.37 ms /   293 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 193 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2703.32 ms /   193 tokens (   14.01 ms per token,    71.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    7594.98 ms /   154 runs   (   49.32 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =   10325.63 ms /   347 tokens\n",
      "Llama.generate: 46 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1607.82 ms /    37 tokens (   43.45 ms per token,    23.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1911.84 ms /    39 runs   (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    3525.50 ms /    76 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1646.37 ms /    55 tokens (   29.93 ms per token,    33.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2471.20 ms /    51 runs   (   48.45 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    4125.12 ms /   106 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 191 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2491.84 ms /   191 tokens (   13.05 ms per token,    76.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5511.41 ms /   112 runs   (   49.21 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    8022.10 ms /   303 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 84 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1822.48 ms /    84 tokens (   21.70 ms per token,    46.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2006.22 ms /    41 runs   (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    3834.91 ms /   125 tokens\n",
      "Llama.generate: 84 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     213.11 ms /     6 tokens (   35.52 ms per token,    28.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1699.15 ms /    35 runs   (   48.55 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    1917.18 ms /    41 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 85 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1908.31 ms /    85 tokens (   22.45 ms per token,    44.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2527.66 ms /    52 runs   (   48.61 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    4444.13 ms /   137 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 112 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2004.41 ms /   112 tokens (   17.90 ms per token,    55.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3667.84 ms /    75 runs   (   48.90 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    5683.55 ms /   187 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 87 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1860.90 ms /    87 tokens (   21.39 ms per token,    46.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2772.77 ms /    57 runs   (   48.65 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    4641.88 ms /   144 tokens\n",
      "Llama.generate: 28 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     758.52 ms /    26 tokens (   29.17 ms per token,    34.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1111.96 ms /    23 runs   (   48.35 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    1873.60 ms /    49 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 326 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    3582.36 ms /   326 tokens (   10.99 ms per token,    91.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5020.73 ms /   101 runs   (   49.71 ms per token,    20.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    8619.79 ms /   427 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 160 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2274.20 ms /   160 tokens (   14.21 ms per token,    70.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2843.53 ms /    58 runs   (   49.03 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    5126.94 ms /   218 tokens\n",
      "Llama.generate: 160 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     194.09 ms /     6 tokens (   32.35 ms per token,    30.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6263.32 ms /   127 runs   (   49.32 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    6478.60 ms /   133 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 102 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2101.64 ms /   102 tokens (   20.60 ms per token,    48.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4071.81 ms /    83 runs   (   49.06 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    6186.28 ms /   185 tokens\n",
      "Llama.generate: 61 prefix-match hit, remaining 110 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2084.87 ms /   110 tokens (   18.95 ms per token,    52.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6115.12 ms /   124 runs   (   49.32 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    8221.19 ms /   234 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 28 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 25 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1692.28 ms /    55 tokens (   30.77 ms per token,    32.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2095.68 ms /    43 runs   (   48.74 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    3795.58 ms /    98 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 159 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2261.52 ms /   159 tokens (   14.22 ms per token,    70.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    7483.69 ms /   152 runs   (   49.23 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    9771.80 ms /   311 tokens\n",
      "Llama.generate: 89 prefix-match hit, remaining 242 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2960.35 ms /   242 tokens (   12.23 ms per token,    81.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8964.66 ms /   180 runs   (   49.80 ms per token,    20.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   11958.08 ms /   422 tokens\n",
      "Llama.generate: 47 prefix-match hit, remaining 16 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     478.77 ms /    16 tokens (   29.92 ms per token,    33.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1460.67 ms /    28 runs   (   52.17 ms per token,    19.17 tokens per second)\n",
      "llama_perf_context_print:       total time =    1943.46 ms /    44 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 97 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1985.80 ms /    97 tokens (   20.47 ms per token,    48.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2303.65 ms /    47 runs   (   49.01 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    4296.66 ms /   144 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1623.31 ms /    44 tokens (   36.89 ms per token,    27.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1658.07 ms /    34 runs   (   48.77 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    3286.44 ms /    78 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1690.64 ms /    48 tokens (   35.22 ms per token,    28.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2681.52 ms /    55 runs   (   48.75 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    4380.55 ms /   103 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1702.83 ms /    43 tokens (   39.60 ms per token,    25.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1170.26 ms /    24 runs   (   48.76 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    2876.65 ms /    67 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1628.40 ms /    44 tokens (   37.01 ms per token,    27.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1676.16 ms /    34 runs   (   49.30 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    3309.75 ms /    78 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 86 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1842.09 ms /    86 tokens (   21.42 ms per token,    46.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1972.44 ms /    40 runs   (   49.31 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    3820.76 ms /   126 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 92 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1925.56 ms /    92 tokens (   20.93 ms per token,    47.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1881.41 ms /    38 runs   (   49.51 ms per token,    20.20 tokens per second)\n",
      "llama_perf_context_print:       total time =    3812.70 ms /   130 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1780.52 ms /    70 tokens (   25.44 ms per token,    39.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2454.19 ms /    49 runs   (   50.09 ms per token,    19.97 tokens per second)\n",
      "llama_perf_context_print:       total time =    4242.32 ms /   119 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1625.72 ms /    40 tokens (   40.64 ms per token,    24.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2612.49 ms /    51 runs   (   51.23 ms per token,    19.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    4246.49 ms /    91 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1927.61 ms /    56 tokens (   34.42 ms per token,    29.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1668.46 ms /    33 runs   (   50.56 ms per token,    19.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    3601.33 ms /    89 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1082.46 ms /    26 tokens (   41.63 ms per token,    24.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1264.85 ms /    25 runs   (   50.59 ms per token,    19.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    2351.09 ms /    51 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 78 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1902.18 ms /    78 tokens (   24.39 ms per token,    41.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2784.03 ms /    54 runs   (   51.56 ms per token,    19.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    4694.74 ms /   132 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1765.79 ms /    40 tokens (   44.14 ms per token,    22.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1335.56 ms /    26 runs   (   51.37 ms per token,    19.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    3105.37 ms /    66 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1673.55 ms /    38 tokens (   44.04 ms per token,    22.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1515.85 ms /    30 runs   (   50.53 ms per token,    19.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    3194.26 ms /    68 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1631.23 ms /    53 tokens (   30.78 ms per token,    32.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1625.36 ms /    32 runs   (   50.79 ms per token,    19.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    3261.58 ms /    85 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1658.42 ms /    37 tokens (   44.82 ms per token,    22.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =     702.04 ms /    14 runs   (   50.15 ms per token,    19.94 tokens per second)\n",
      "llama_perf_context_print:       total time =    2362.84 ms /    51 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1629.94 ms /    54 tokens (   30.18 ms per token,    33.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1629.34 ms /    32 runs   (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    3264.48 ms /    86 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1630.23 ms /    53 tokens (   30.76 ms per token,    32.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1977.11 ms /    39 runs   (   50.70 ms per token,    19.73 tokens per second)\n",
      "llama_perf_context_print:       total time =    3613.53 ms /    92 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1711.55 ms /    56 tokens (   30.56 ms per token,    32.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1617.62 ms /    32 runs   (   50.55 ms per token,    19.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    3334.49 ms /    88 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1636.88 ms /    36 tokens (   45.47 ms per token,    21.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1085.64 ms /    20 runs   (   54.28 ms per token,    18.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    2725.96 ms /    56 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1684.00 ms /    40 tokens (   42.10 ms per token,    23.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1150.14 ms /    23 runs   (   50.01 ms per token,    20.00 tokens per second)\n",
      "llama_perf_context_print:       total time =    2837.51 ms /    63 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1677.78 ms /    57 tokens (   29.43 ms per token,    33.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2184.49 ms /    43 runs   (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    3869.22 ms /   100 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1712.66 ms /    38 tokens (   45.07 ms per token,    22.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1413.43 ms /    28 runs   (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    3130.62 ms /    66 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1730.70 ms /    58 tokens (   29.84 ms per token,    33.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2021.61 ms /    40 runs   (   50.54 ms per token,    19.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    3758.73 ms /    98 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1589.41 ms /    32 tokens (   49.67 ms per token,    20.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1022.96 ms /    20 runs   (   51.15 ms per token,    19.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    2615.62 ms /    52 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 88 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2097.58 ms /    88 tokens (   23.84 ms per token,    41.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4493.83 ms /    88 runs   (   51.07 ms per token,    19.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    6605.96 ms /   176 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1642.39 ms /    34 tokens (   48.31 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1143.75 ms /    23 runs   (   49.73 ms per token,    20.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    2789.58 ms /    57 tokens\n",
      "Llama.generate: 27 prefix-match hit, remaining 175 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2561.70 ms /   175 tokens (   14.64 ms per token,    68.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4008.39 ms /    79 runs   (   50.74 ms per token,    19.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    6582.97 ms /   254 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 176 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2493.08 ms /   176 tokens (   14.17 ms per token,    70.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =     950.66 ms /    19 runs   (   50.03 ms per token,    19.99 tokens per second)\n",
      "llama_perf_context_print:       total time =    3447.20 ms /   195 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1739.69 ms /    41 tokens (   42.43 ms per token,    23.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1152.50 ms /    23 runs   (   50.11 ms per token,    19.96 tokens per second)\n",
      "llama_perf_context_print:       total time =    2895.48 ms /    64 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 325 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    3550.87 ms /   325 tokens (   10.93 ms per token,    91.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    7538.86 ms /   147 runs   (   51.28 ms per token,    19.50 tokens per second)\n",
      "llama_perf_context_print:       total time =   11117.12 ms /   472 tokens\n",
      "Llama.generate: 32 prefix-match hit, remaining 71 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1809.47 ms /    71 tokens (   25.49 ms per token,    39.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2677.56 ms /    53 runs   (   50.52 ms per token,    19.79 tokens per second)\n",
      "llama_perf_context_print:       total time =    4495.20 ms /   124 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 89 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1825.11 ms /    89 tokens (   20.51 ms per token,    48.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1996.90 ms /    40 runs   (   49.92 ms per token,    20.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    3828.22 ms /   129 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1733.87 ms /    48 tokens (   36.12 ms per token,    27.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1847.15 ms /    37 runs   (   49.92 ms per token,    20.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    3586.73 ms /    85 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1599.08 ms /    37 tokens (   43.22 ms per token,    23.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1597.18 ms /    32 runs   (   49.91 ms per token,    20.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    3201.26 ms /    69 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1822.31 ms /    72 tokens (   25.31 ms per token,    39.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2146.52 ms /    43 runs   (   49.92 ms per token,    20.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    3975.54 ms /   115 tokens\n",
      "Llama.generate: 67 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     876.25 ms /    30 tokens (   29.21 ms per token,    34.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2679.90 ms /    54 runs   (   49.63 ms per token,    20.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    3564.18 ms /    84 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1873.59 ms /    65 tokens (   28.82 ms per token,    34.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2516.84 ms /    51 runs   (   49.35 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    4398.30 ms /   116 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1638.94 ms /    58 tokens (   28.26 ms per token,    35.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2465.80 ms /    50 runs   (   49.32 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    4112.55 ms /   108 tokens\n",
      "Llama.generate: 46 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     517.56 ms /    17 tokens (   30.44 ms per token,    32.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1579.41 ms /    32 runs   (   49.36 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    2101.57 ms /    49 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1710.75 ms /    41 tokens (   41.73 ms per token,    23.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2009.40 ms /    41 runs   (   49.01 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    3726.43 ms /    82 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1735.28 ms /    53 tokens (   32.74 ms per token,    30.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1919.09 ms /    39 runs   (   49.21 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    3660.25 ms /    92 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 71 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1788.74 ms /    71 tokens (   25.19 ms per token,    39.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2553.06 ms /    52 runs   (   49.10 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    4350.09 ms /   123 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1671.56 ms /    64 tokens (   26.12 ms per token,    38.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2598.61 ms /    53 runs   (   49.03 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    4278.54 ms /   117 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1682.14 ms /    50 tokens (   33.64 ms per token,    29.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1170.96 ms /    24 runs   (   48.79 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    2856.90 ms /    74 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     681.36 ms /    23 tokens (   29.62 ms per token,    33.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1611.02 ms /    33 runs   (   48.82 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    2297.21 ms /    56 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1897.40 ms /    72 tokens (   26.35 ms per token,    37.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3229.23 ms /    66 runs   (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    5137.12 ms /   138 tokens\n",
      "Llama.generate: 46 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1708.30 ms /    35 tokens (   48.81 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2140.89 ms /    44 runs   (   48.66 ms per token,    20.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    3856.15 ms /    79 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1713.71 ms /    64 tokens (   26.78 ms per token,    37.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1523.11 ms /    31 runs   (   49.13 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    3241.54 ms /    95 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 71 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1800.61 ms /    71 tokens (   25.36 ms per token,    39.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1990.62 ms /    41 runs   (   48.55 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    3797.09 ms /   112 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1686.68 ms /    61 tokens (   27.65 ms per token,    36.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2786.47 ms /    57 runs   (   48.89 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    4481.59 ms /   118 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 168 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2566.06 ms /   168 tokens (   15.27 ms per token,    65.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9860.25 ms /   198 runs   (   49.80 ms per token,    20.08 tokens per second)\n",
      "llama_perf_context_print:       total time =   12464.77 ms /   366 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1843.65 ms /    68 tokens (   27.11 ms per token,    36.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2501.53 ms /    51 runs   (   49.05 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    4352.79 ms /   119 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1645.84 ms /    38 tokens (   43.31 ms per token,    23.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1713.06 ms /    35 runs   (   48.94 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    3364.39 ms /    73 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1646.05 ms /    50 tokens (   32.92 ms per token,    30.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2050.18 ms /    42 runs   (   48.81 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    3702.51 ms /    92 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1705.65 ms /    43 tokens (   39.67 ms per token,    25.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1701.12 ms /    35 runs   (   48.60 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    3412.15 ms /    78 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1666.33 ms /    41 tokens (   40.64 ms per token,    24.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1550.89 ms /    32 runs   (   48.47 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    3222.07 ms /    73 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1649.81 ms /    49 tokens (   33.67 ms per token,    29.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2718.97 ms /    56 runs   (   48.55 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    4377.46 ms /   105 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1622.38 ms /    44 tokens (   36.87 ms per token,    27.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1550.93 ms /    32 runs   (   48.47 ms per token,    20.63 tokens per second)\n",
      "llama_perf_context_print:       total time =    3178.33 ms /    76 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1619.13 ms /    38 tokens (   42.61 ms per token,    23.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1511.91 ms /    31 runs   (   48.77 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    3135.89 ms /    69 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 77 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1811.36 ms /    77 tokens (   23.52 ms per token,    42.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2743.25 ms /    56 runs   (   48.99 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    4562.83 ms /   133 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1639.59 ms /    53 tokens (   30.94 ms per token,    32.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2350.18 ms /    48 runs   (   48.96 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    3996.89 ms /   101 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1635.47 ms /    33 tokens (   49.56 ms per token,    20.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.99 ms /    54 runs   (   48.94 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    4286.80 ms /    87 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1811.05 ms /    53 tokens (   34.17 ms per token,    29.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1998.73 ms /    41 runs   (   48.75 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    3815.97 ms /    94 tokens\n",
      "Llama.generate: 31 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1656.54 ms /    37 tokens (   44.77 ms per token,    22.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2494.45 ms /    51 runs   (   48.91 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    4158.46 ms /    88 tokens\n",
      "Llama.generate: 59 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     384.98 ms /    12 tokens (   32.08 ms per token,    31.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2642.18 ms /    54 runs   (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    3034.86 ms /    66 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1604.61 ms /    35 tokens (   45.85 ms per token,    21.81 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2502.67 ms /    51 runs   (   49.07 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    4114.99 ms /    86 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1692.15 ms /    39 tokens (   43.39 ms per token,    23.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2145.61 ms /    44 runs   (   48.76 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    3844.19 ms /    83 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1696.32 ms /    51 tokens (   33.26 ms per token,    30.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1464.96 ms /    30 runs   (   48.83 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    3165.90 ms /    81 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 55 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1632.82 ms /    55 tokens (   29.69 ms per token,    33.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2403.04 ms /    49 runs   (   49.04 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    4043.25 ms /   104 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1652.72 ms /    36 tokens (   45.91 ms per token,    21.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2433.97 ms /    50 runs   (   48.68 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    4094.03 ms /    86 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1781.00 ms /    41 tokens (   43.44 ms per token,    23.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2039.64 ms /    42 runs   (   48.56 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    3826.74 ms /    83 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     863.65 ms /    30 tokens (   28.79 ms per token,    34.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1977.32 ms /    40 runs   (   49.43 ms per token,    20.23 tokens per second)\n",
      "llama_perf_context_print:       total time =    2846.75 ms /    70 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1638.50 ms /    51 tokens (   32.13 ms per token,    31.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2098.64 ms /    43 runs   (   48.81 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    3743.65 ms /    94 tokens\n",
      "Llama.generate: 41 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     626.09 ms /    21 tokens (   29.81 ms per token,    33.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1086.31 ms /    22 runs   (   49.38 ms per token,    20.25 tokens per second)\n",
      "llama_perf_context_print:       total time =    1715.62 ms /    43 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1604.88 ms /    33 tokens (   48.63 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =     821.69 ms /    17 runs   (   48.33 ms per token,    20.69 tokens per second)\n",
      "llama_perf_context_print:       total time =    2429.20 ms /    50 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1633.95 ms /    39 tokens (   41.90 ms per token,    23.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1615.98 ms /    33 runs   (   48.97 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    3255.32 ms /    72 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 268 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    3090.70 ms /   268 tokens (   11.53 ms per token,    86.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    7433.83 ms /   149 runs   (   49.89 ms per token,    20.04 tokens per second)\n",
      "llama_perf_context_print:       total time =   10552.15 ms /   417 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 265 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    3148.05 ms /   265 tokens (   11.88 ms per token,    84.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =   11102.15 ms /   221 runs   (   50.24 ms per token,    19.91 tokens per second)\n",
      "llama_perf_context_print:       total time =   14295.22 ms /   486 tokens\n",
      "Llama.generate: 239 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     306.66 ms /     6 tokens (   51.11 ms per token,    19.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9097.03 ms /   182 runs   (   49.98 ms per token,    20.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    9437.68 ms /   188 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1653.29 ms /    47 tokens (   35.18 ms per token,    28.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =     978.42 ms /    20 runs   (   48.92 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    2634.79 ms /    67 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 115 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2057.26 ms /   115 tokens (   17.89 ms per token,    55.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3938.24 ms /    80 runs   (   49.23 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    6008.16 ms /   195 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 201 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2726.80 ms /   201 tokens (   13.57 ms per token,    73.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2904.87 ms /    59 runs   (   49.24 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    5640.89 ms /   260 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1647.14 ms /    43 tokens (   38.31 ms per token,    26.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =     925.01 ms /    19 runs   (   48.68 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    2575.04 ms /    62 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 146 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2251.34 ms /   146 tokens (   15.42 ms per token,    64.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5668.69 ms /   115 runs   (   49.29 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    7939.09 ms /   261 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1475.85 ms /    32 tokens (   46.12 ms per token,    21.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1014.07 ms /    21 runs   (   48.29 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    2492.85 ms /    53 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1635.13 ms /    51 tokens (   32.06 ms per token,    31.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2124.91 ms /    44 runs   (   48.29 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    3766.58 ms /    95 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     675.26 ms /    23 tokens (   29.36 ms per token,    34.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1307.60 ms /    27 runs   (   48.43 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    1986.76 ms /    50 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1664.36 ms /    45 tokens (   36.99 ms per token,    27.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1024.11 ms /    21 runs   (   48.77 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    2691.58 ms /    66 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1617.81 ms /    43 tokens (   37.62 ms per token,    26.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1171.85 ms /    24 runs   (   48.83 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    2793.13 ms /    67 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1631.41 ms /    53 tokens (   30.78 ms per token,    32.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1361.75 ms /    28 runs   (   48.63 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    2996.98 ms /    81 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1858.53 ms /    74 tokens (   25.12 ms per token,    39.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.67 ms /    54 runs   (   48.49 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    4485.17 ms /   128 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 73 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1882.93 ms /    73 tokens (   25.79 ms per token,    38.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3901.20 ms /    80 runs   (   48.76 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    5796.80 ms /   153 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1671.26 ms /    39 tokens (   42.85 ms per token,    23.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1374.23 ms /    28 runs   (   49.08 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    3049.69 ms /    67 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2204.04 ms /    66 tokens (   33.39 ms per token,    29.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1677.07 ms /    34 runs   (   49.33 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    3886.17 ms /   100 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1630.39 ms /    54 tokens (   30.19 ms per token,    33.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1980.69 ms /    41 runs   (   48.31 ms per token,    20.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    3617.09 ms /    95 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 29 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 39 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1629.59 ms /    37 tokens (   44.04 ms per token,    22.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1851.35 ms /    38 runs   (   48.72 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    3487.97 ms /    75 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 128 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2034.92 ms /   128 tokens (   15.90 ms per token,    62.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4884.90 ms /   100 runs   (   48.85 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    6936.00 ms /   228 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 78 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1864.76 ms /    78 tokens (   23.91 ms per token,    41.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3080.85 ms /    63 runs   (   48.90 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    4955.00 ms /   141 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1627.30 ms /    45 tokens (   36.16 ms per token,    27.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1698.89 ms /    35 runs   (   48.54 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    3331.37 ms /    80 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 105 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1990.17 ms /   105 tokens (   18.95 ms per token,    52.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2656.91 ms /    54 runs   (   49.20 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    4655.63 ms /   159 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1619.33 ms /    44 tokens (   36.80 ms per token,    27.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1217.58 ms /    25 runs   (   48.70 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    2840.86 ms /    69 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1604.66 ms /    38 tokens (   42.23 ms per token,    23.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1484.88 ms /    30 runs   (   49.50 ms per token,    20.20 tokens per second)\n",
      "llama_perf_context_print:       total time =    3094.16 ms /    68 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1629.58 ms /    48 tokens (   33.95 ms per token,    29.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1628.56 ms /    33 runs   (   49.35 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    3263.30 ms /    81 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1873.16 ms /    45 tokens (   41.63 ms per token,    24.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1328.30 ms /    27 runs   (   49.20 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    3205.59 ms /    72 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 88 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1853.44 ms /    88 tokens (   21.06 ms per token,    47.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3667.74 ms /    73 runs   (   50.24 ms per token,    19.90 tokens per second)\n",
      "llama_perf_context_print:       total time =    5532.94 ms /   161 tokens\n",
      "Llama.generate: 46 prefix-match hit, remaining 159 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2331.27 ms /   159 tokens (   14.66 ms per token,    68.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    7209.08 ms /   140 runs   (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    9566.70 ms /   299 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1609.54 ms /    34 tokens (   47.34 ms per token,    21.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1647.61 ms /    32 runs   (   51.49 ms per token,    19.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    3262.18 ms /    66 tokens\n",
      "Llama.generate: 33 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1689.06 ms /    40 tokens (   42.23 ms per token,    23.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1769.79 ms /    35 runs   (   50.57 ms per token,    19.78 tokens per second)\n",
      "llama_perf_context_print:       total time =    3464.64 ms /    75 tokens\n",
      "Llama.generate: 33 prefix-match hit, remaining 86 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1891.61 ms /    86 tokens (   22.00 ms per token,    45.46 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5413.56 ms /   105 runs   (   51.56 ms per token,    19.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    7322.97 ms /   191 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     862.15 ms /    28 tokens (   30.79 ms per token,    32.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1136.62 ms /    22 runs   (   51.66 ms per token,    19.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    2002.11 ms /    50 tokens\n",
      "Llama.generate: 33 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     529.87 ms /    15 tokens (   35.32 ms per token,    28.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1517.22 ms /    30 runs   (   50.57 ms per token,    19.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    2051.56 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1672.29 ms /    46 tokens (   36.35 ms per token,    27.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1817.07 ms /    36 runs   (   50.47 ms per token,    19.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    3495.03 ms /    82 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     797.97 ms /    23 tokens (   34.69 ms per token,    28.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1509.16 ms /    30 runs   (   50.31 ms per token,    19.88 tokens per second)\n",
      "llama_perf_context_print:       total time =    2311.77 ms /    53 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1647.46 ms /    33 tokens (   49.92 ms per token,    20.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1447.98 ms /    29 runs   (   49.93 ms per token,    20.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    3099.74 ms /    62 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 109 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2016.22 ms /   109 tokens (   18.50 ms per token,    54.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4331.80 ms /    86 runs   (   50.37 ms per token,    19.85 tokens per second)\n",
      "llama_perf_context_print:       total time =    6362.10 ms /   195 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1765.52 ms /    39 tokens (   45.27 ms per token,    22.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1979.24 ms /    40 runs   (   49.48 ms per token,    20.21 tokens per second)\n",
      "llama_perf_context_print:       total time =    3750.55 ms /    79 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1621.63 ms /    45 tokens (   36.04 ms per token,    27.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1806.53 ms /    36 runs   (   50.18 ms per token,    19.93 tokens per second)\n",
      "llama_perf_context_print:       total time =    3433.88 ms /    81 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 87 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1864.62 ms /    87 tokens (   21.43 ms per token,    46.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4421.25 ms /    89 runs   (   49.68 ms per token,    20.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    6300.31 ms /   176 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 92 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1851.72 ms /    92 tokens (   20.13 ms per token,    49.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5301.02 ms /   107 runs   (   49.54 ms per token,    20.18 tokens per second)\n",
      "llama_perf_context_print:       total time =    7170.37 ms /   199 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1655.86 ms /    37 tokens (   44.75 ms per token,    22.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1559.64 ms /    32 runs   (   48.74 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    3220.04 ms /    69 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1643.56 ms /    62 tokens (   26.51 ms per token,    37.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3485.67 ms /    71 runs   (   49.09 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    5140.24 ms /   133 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1655.69 ms /    35 tokens (   47.31 ms per token,    21.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1308.43 ms /    27 runs   (   48.46 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    2968.46 ms /    62 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1896.78 ms /    66 tokens (   28.74 ms per token,    34.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2736.86 ms /    56 runs   (   48.87 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    4642.09 ms /   122 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1688.70 ms /    51 tokens (   33.11 ms per token,    30.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1625.25 ms /    33 runs   (   49.25 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    3319.05 ms /    84 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1638.10 ms /    52 tokens (   31.50 ms per token,    31.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2189.99 ms /    45 runs   (   48.67 ms per token,    20.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    3834.72 ms /    97 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1630.89 ms /    41 tokens (   39.78 ms per token,    25.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1359.96 ms /    28 runs   (   48.57 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    2994.91 ms /    69 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1832.83 ms /    47 tokens (   39.00 ms per token,    25.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2112.39 ms /    43 runs   (   49.13 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    3951.61 ms /    90 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 63 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1657.31 ms /    63 tokens (   26.31 ms per token,    38.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1556.99 ms /    32 runs   (   48.66 ms per token,    20.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    3219.40 ms /    95 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1629.91 ms /    58 tokens (   28.10 ms per token,    35.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1992.80 ms /    41 runs   (   48.60 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    3629.20 ms /    99 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1722.47 ms /    62 tokens (   27.78 ms per token,    35.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1275.75 ms /    26 runs   (   49.07 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    3002.18 ms /    88 tokens\n",
      "Llama.generate: 44 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1876.09 ms /    67 tokens (   28.00 ms per token,    35.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3897.30 ms /    79 runs   (   49.33 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    5785.26 ms /   146 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1654.71 ms /    51 tokens (   32.45 ms per token,    30.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1740.33 ms /    35 runs   (   49.72 ms per token,    20.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    3400.47 ms /    86 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1912.63 ms /    74 tokens (   25.85 ms per token,    38.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2453.05 ms /    50 runs   (   49.06 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    4372.93 ms /   124 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1662.99 ms /    47 tokens (   35.38 ms per token,    28.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1953.25 ms /    40 runs   (   48.83 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    3622.43 ms /    87 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1647.57 ms /    50 tokens (   32.95 ms per token,    30.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1425.56 ms /    29 runs   (   49.16 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    3077.32 ms /    79 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 105 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2005.29 ms /   105 tokens (   19.10 ms per token,    52.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2111.12 ms /    43 runs   (   49.10 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    4123.07 ms /   148 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1618.40 ms /    38 tokens (   42.59 ms per token,    23.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1426.61 ms /    29 runs   (   49.19 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    3049.67 ms /    67 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 97 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2011.65 ms /    97 tokens (   20.74 ms per token,    48.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4175.17 ms /    84 runs   (   49.70 ms per token,    20.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    6200.37 ms /   181 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1668.33 ms /    46 tokens (   36.27 ms per token,    27.57 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1907.23 ms /    39 runs   (   48.90 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    3581.43 ms /    85 tokens\n",
      "Llama.generate: 46 prefix-match hit, remaining 145 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2258.10 ms /   145 tokens (   15.57 ms per token,    64.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    7783.32 ms /   155 runs   (   50.21 ms per token,    19.91 tokens per second)\n",
      "llama_perf_context_print:       total time =   10069.18 ms /   300 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 108 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2044.55 ms /   108 tokens (   18.93 ms per token,    52.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3321.39 ms /    67 runs   (   49.57 ms per token,    20.17 tokens per second)\n",
      "llama_perf_context_print:       total time =    5376.46 ms /   175 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 90 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1835.54 ms /    90 tokens (   20.39 ms per token,    49.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4021.44 ms /    81 runs   (   49.65 ms per token,    20.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    5869.93 ms /   171 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1825.32 ms /    65 tokens (   28.08 ms per token,    35.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1673.38 ms /    34 runs   (   49.22 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    3503.77 ms /    99 tokens\n",
      "Llama.generate: 65 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     729.22 ms /    24 tokens (   30.38 ms per token,    32.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1723.02 ms /    35 runs   (   49.23 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    2457.38 ms /    59 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1708.74 ms /    64 tokens (   26.70 ms per token,    37.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1914.93 ms /    39 runs   (   49.10 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    3629.80 ms /   103 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1683.42 ms /    53 tokens (   31.76 ms per token,    31.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1507.22 ms /    31 runs   (   48.62 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    3195.43 ms /    84 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1646.72 ms /    41 tokens (   40.16 ms per token,    24.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1548.56 ms /    32 runs   (   48.39 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    3199.86 ms /    73 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1611.46 ms /    42 tokens (   38.37 ms per token,    26.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1168.94 ms /    24 runs   (   48.71 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    2784.04 ms /    66 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 115 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2050.58 ms /   115 tokens (   17.83 ms per token,    56.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4259.33 ms /    87 runs   (   48.96 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    6323.19 ms /   202 tokens\n",
      "Llama.generate: 116 prefix-match hit, remaining 22 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     647.56 ms /    22 tokens (   29.43 ms per token,    33.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2313.69 ms /    47 runs   (   49.23 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    2968.03 ms /    69 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1695.57 ms /    44 tokens (   38.54 ms per token,    25.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1514.26 ms /    31 runs   (   48.85 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    3214.48 ms /    75 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1725.07 ms /    64 tokens (   26.95 ms per token,    37.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2287.40 ms /    47 runs   (   48.67 ms per token,    20.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    4019.90 ms /   111 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1812.13 ms /    74 tokens (   24.49 ms per token,    40.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2097.39 ms /    43 runs   (   48.78 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    3916.11 ms /   117 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 87 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1851.28 ms /    87 tokens (   21.28 ms per token,    46.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2290.52 ms /    47 runs   (   48.73 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    4148.70 ms /   134 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1836.07 ms /    70 tokens (   26.23 ms per token,    38.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1699.41 ms /    35 runs   (   48.55 ms per token,    20.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    3540.78 ms /   105 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 63 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1658.85 ms /    63 tokens (   26.33 ms per token,    37.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2240.65 ms /    46 runs   (   48.71 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    3906.05 ms /   109 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1673.73 ms /    45 tokens (   37.19 ms per token,    26.89 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1751.08 ms /    36 runs   (   48.64 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    3429.96 ms /    81 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1845.62 ms /    68 tokens (   27.14 ms per token,    36.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1903.49 ms /    39 runs   (   48.81 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    3754.85 ms /   107 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 124 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2089.97 ms /   124 tokens (   16.85 ms per token,    59.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4981.28 ms /   101 runs   (   49.32 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    7087.85 ms /   225 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 135 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2195.39 ms /   135 tokens (   16.26 ms per token,    61.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5460.74 ms /   110 runs   (   49.64 ms per token,    20.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    7674.46 ms /   245 tokens\n",
      "Llama.generate: 69 prefix-match hit, remaining 76 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1854.01 ms /    76 tokens (   24.39 ms per token,    40.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3468.87 ms /    70 runs   (   49.56 ms per token,    20.18 tokens per second)\n",
      "llama_perf_context_print:       total time =    5334.18 ms /   146 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 78 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1811.67 ms /    78 tokens (   23.23 ms per token,    43.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1393.08 ms /    28 runs   (   49.75 ms per token,    20.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    3208.90 ms /   106 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 103 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2025.73 ms /   103 tokens (   19.67 ms per token,    50.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3409.12 ms /    69 runs   (   49.41 ms per token,    20.24 tokens per second)\n",
      "llama_perf_context_print:       total time =    5445.84 ms /   172 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 73 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1808.66 ms /    73 tokens (   24.78 ms per token,    40.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3068.86 ms /    62 runs   (   49.50 ms per token,    20.20 tokens per second)\n",
      "llama_perf_context_print:       total time =    4887.15 ms /   135 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 129 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2232.74 ms /   129 tokens (   17.31 ms per token,    57.78 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1911.72 ms /    39 runs   (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    4150.47 ms /   168 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1687.61 ms /    43 tokens (   39.25 ms per token,    25.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1406.27 ms /    29 runs   (   48.49 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    3098.46 ms /    72 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1611.59 ms /    39 tokens (   41.32 ms per token,    24.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1775.01 ms /    36 runs   (   49.31 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    3392.43 ms /    75 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1465.46 ms /    32 tokens (   45.80 ms per token,    21.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2331.87 ms /    48 runs   (   48.58 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    3804.66 ms /    80 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1687.31 ms /    46 tokens (   36.68 ms per token,    27.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1849.45 ms /    38 runs   (   48.67 ms per token,    20.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    3542.60 ms /    84 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1608.26 ms /    39 tokens (   41.24 ms per token,    24.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1184.05 ms /    24 runs   (   49.34 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    2796.04 ms /    63 tokens\n",
      "Llama.generate: 38 prefix-match hit, remaining 140 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2223.75 ms /   140 tokens (   15.88 ms per token,    62.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3362.03 ms /    68 runs   (   49.44 ms per token,    20.23 tokens per second)\n",
      "llama_perf_context_print:       total time =    5596.25 ms /   208 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 93 prompt tokens to eval\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error translating query: 'AND([CarbonRRRatingCategoryGroup] IN 'Climate Laggard|Climate Medium Performer|Climate Outperformer|Climate Leader',[ClimateGHGReductionTargets] IN 'No Target|Non-Ambitious Target|Ambitious Target|Committed SBT|Approved SBT',[oekomIndustry] IN 'Aerospace & Defence|Air Freight & Logistics|Airlines|Asset Management & Brokerage|Auto Components|Automobile|Auxiliary Financial Services & Data|Beverages|Chemicals|Coal & Consumable Fuels|Commercial Banks & Capital Markets|Commercial Support Services|Construction|Construction Materials|Development Banks|Digital Finance & Payment Processing|Education Services|Electric Utilities|Electrical Equipment|Electronic Components|Electronic Devices & Appliances|Financial Exchanges|Food Products|Furniture & Fittings|Gas and Electricity Network Operators|Health Care Equipment & Supplies|Health Care Facilities & Services|Health Care Technology & Services|Heavy Trucks & Construction & Farm Machinery|Household & Personal Products|Human Resource & Employment Services|IT Consulting & Other Services|Industrial Conglomerates|Industrial Machinery & Equipment|Industrial Support Services|Insurance|Integrated Oil & Gas|Interactive Media & Online Consumer Services|Leisure|Managed Health Care|Marine Transportation|Media|Metals Processing & Production|Mining & Integrated Production|Mortgage & Public Sector Finance|Multi-Sector Holdings|Multi-Utilities|Oil & Gas Equipment/Services|Oil & Gas Exploration & Production|Oil & Gas Refining & Marketing|Oil & Gas Storage & Pipelines|Packaging|Paper & Forest Products|Pharmaceuticals & Biotechnology|Public & Regional Banks|Rail Transportation|Real Estate|Renewable Electricity|Research & Consulting Services|Restaurants|Retail|Road Transportation|Semiconductor Equipment|Semiconductors|Software & Diversified IT Services|Specialized Finance|Telecommunications|Textiles & Apparel|Tobacco|Trading Companies & Distributors|Transportation Infrastructure|Water and Waste Utilities',[ClimateScope1EmissionsIntUSD] >= '0',[ClimateScope2EmissionsIntUSD] >= '0',[ClimateScope123EmissionsIntUSD] >= '0',[ClimateScope123Emissions] >= '0',[OverallQualityScoreDec] >= '1')'\n",
      "Error: Requested tokens (641) exceed context window of 512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1848.93 ms /    93 tokens (   19.88 ms per token,    50.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5834.58 ms /   118 runs   (   49.45 ms per token,    20.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    7703.00 ms /   211 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 249 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2943.64 ms /   249 tokens (   11.82 ms per token,    84.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =   11762.19 ms /   232 runs   (   50.70 ms per token,    19.72 tokens per second)\n",
      "llama_perf_context_print:       total time =   14754.98 ms /   481 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 277 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    3143.94 ms /   277 tokens (   11.35 ms per token,    88.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10785.04 ms /   214 runs   (   50.40 ms per token,    19.84 tokens per second)\n",
      "llama_perf_context_print:       total time =   13972.93 ms /   491 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1635.68 ms /    42 tokens (   38.94 ms per token,    25.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1666.64 ms /    34 runs   (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    3307.46 ms /    76 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1611.01 ms /    36 tokens (   44.75 ms per token,    22.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1610.79 ms /    33 runs   (   48.81 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    3226.74 ms /    69 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1834.03 ms /    72 tokens (   25.47 ms per token,    39.26 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2487.15 ms /    51 runs   (   48.77 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    4328.94 ms /   123 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 63 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1726.81 ms /    63 tokens (   27.41 ms per token,    36.48 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1597.62 ms /    33 runs   (   48.41 ms per token,    20.66 tokens per second)\n",
      "llama_perf_context_print:       total time =    3329.60 ms /    96 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1693.01 ms /    44 tokens (   38.48 ms per token,    25.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1352.20 ms /    28 runs   (   48.29 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:       total time =    3049.32 ms /    72 tokens\n",
      "Llama.generate: 57 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     804.18 ms /    25 tokens (   32.17 ms per token,    31.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1500.92 ms /    31 runs   (   48.42 ms per token,    20.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    2309.86 ms /    56 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1683.17 ms /    49 tokens (   34.35 ms per token,    29.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2031.60 ms /    42 runs   (   48.37 ms per token,    20.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    3721.08 ms /    91 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 87 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1837.34 ms /    87 tokens (   21.12 ms per token,    47.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2339.11 ms /    48 runs   (   48.73 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    4183.36 ms /   135 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 83 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1936.27 ms /    83 tokens (   23.33 ms per token,    42.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4143.75 ms /    85 runs   (   48.75 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    6093.12 ms /   168 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 94 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1869.55 ms /    94 tokens (   19.89 ms per token,    50.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2138.39 ms /    44 runs   (   48.60 ms per token,    20.58 tokens per second)\n",
      "llama_perf_context_print:       total time =    4014.57 ms /   138 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 107 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2048.34 ms /   107 tokens (   19.14 ms per token,    52.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2635.35 ms /    54 runs   (   48.80 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    4691.84 ms /   161 tokens\n",
      "Llama.generate: 111 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     185.57 ms /     6 tokens (   30.93 ms per token,    32.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2333.30 ms /    48 runs   (   48.61 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    2525.71 ms /    54 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 155 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2364.68 ms /   155 tokens (   15.26 ms per token,    65.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    7326.35 ms /   149 runs   (   49.17 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    9717.11 ms /   304 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 167 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2426.14 ms /   167 tokens (   14.53 ms per token,    68.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3544.91 ms /    72 runs   (   49.23 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    5982.67 ms /   239 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 153 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2374.48 ms /   153 tokens (   15.52 ms per token,    64.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =     975.87 ms /    20 runs   (   48.79 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    3354.06 ms /   173 tokens\n",
      "Llama.generate: 169 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     363.57 ms /    12 tokens (   30.30 ms per token,    33.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2588.55 ms /    53 runs   (   48.84 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    2959.84 ms /    65 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 163 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2496.03 ms /   163 tokens (   15.31 ms per token,    65.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1708.08 ms /    35 runs   (   48.80 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    4209.57 ms /   198 tokens\n",
      "Llama.generate: 135 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1688.93 ms /    61 tokens (   27.69 ms per token,    36.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2109.70 ms /    43 runs   (   49.06 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    3805.21 ms /   104 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 168 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2463.92 ms /   168 tokens (   14.67 ms per token,    68.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3828.50 ms /    78 runs   (   49.08 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    6304.77 ms /   246 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 169 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2516.12 ms /   169 tokens (   14.89 ms per token,    67.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1859.28 ms /    38 runs   (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    4381.54 ms /   207 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 30 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 20 prefix-match hit, remaining 168 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2478.35 ms /   168 tokens (   14.75 ms per token,    67.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4064.36 ms /    83 runs   (   48.97 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    6557.68 ms /   251 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 164 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2485.72 ms /   164 tokens (   15.16 ms per token,    65.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3466.16 ms /    71 runs   (   48.82 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    5963.30 ms /   235 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 160 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2367.63 ms /   160 tokens (   14.80 ms per token,    67.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3468.43 ms /    71 runs   (   48.85 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    5847.11 ms /   231 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 147 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2284.41 ms /   147 tokens (   15.54 ms per token,    64.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1267.50 ms /    26 runs   (   48.75 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    3556.21 ms /   173 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 365 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    4123.99 ms /   365 tokens (   11.30 ms per token,    88.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4199.61 ms /    84 runs   (   50.00 ms per token,    20.00 tokens per second)\n",
      "llama_perf_context_print:       total time =    8337.33 ms /   449 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 124 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2024.38 ms /   124 tokens (   16.33 ms per token,    61.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2423.50 ms /    49 runs   (   49.46 ms per token,    20.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    4455.87 ms /   173 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 130 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2236.76 ms /   130 tokens (   17.21 ms per token,    58.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =     839.40 ms /    17 runs   (   49.38 ms per token,    20.25 tokens per second)\n",
      "llama_perf_context_print:       total time =    3079.31 ms /   147 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 144 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2211.89 ms /   144 tokens (   15.36 ms per token,    65.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1407.84 ms /    28 runs   (   50.28 ms per token,    19.89 tokens per second)\n",
      "llama_perf_context_print:       total time =    3624.21 ms /   172 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 133 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2237.64 ms /   133 tokens (   16.82 ms per token,    59.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3292.70 ms /    65 runs   (   50.66 ms per token,    19.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    5540.71 ms /   198 tokens\n",
      "Llama.generate: 142 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     384.70 ms /    11 tokens (   34.97 ms per token,    28.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2949.01 ms /    58 runs   (   50.85 ms per token,    19.67 tokens per second)\n",
      "llama_perf_context_print:       total time =    3342.56 ms /    69 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 138 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2304.91 ms /   138 tokens (   16.70 ms per token,    59.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2697.52 ms /    53 runs   (   50.90 ms per token,    19.65 tokens per second)\n",
      "llama_perf_context_print:       total time =    5011.48 ms /   191 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 291 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    3352.41 ms /   291 tokens (   11.52 ms per token,    86.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1924.88 ms /    37 runs   (   52.02 ms per token,    19.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    5283.80 ms /   328 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 163 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2561.81 ms /   163 tokens (   15.72 ms per token,    63.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4345.35 ms /    85 runs   (   51.12 ms per token,    19.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    6921.96 ms /   248 tokens\n",
      "Llama.generate: 164 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     425.79 ms /    12 tokens (   35.48 ms per token,    28.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3875.25 ms /    75 runs   (   51.67 ms per token,    19.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    4313.13 ms /    87 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 163 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2470.49 ms /   163 tokens (   15.16 ms per token,    65.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3716.98 ms /    73 runs   (   50.92 ms per token,    19.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    6199.51 ms /   236 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 157 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2336.55 ms /   157 tokens (   14.88 ms per token,    67.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3877.43 ms /    76 runs   (   51.02 ms per token,    19.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    6226.67 ms /   233 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 156 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2263.40 ms /   156 tokens (   14.51 ms per token,    68.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1675.37 ms /    33 runs   (   50.77 ms per token,    19.70 tokens per second)\n",
      "llama_perf_context_print:       total time =    3944.25 ms /   189 tokens\n",
      "Llama.generate: 172 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     246.04 ms /     7 tokens (   35.15 ms per token,    28.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1062.53 ms /    21 runs   (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    1311.87 ms /    28 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 108 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1998.67 ms /   108 tokens (   18.51 ms per token,    54.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2701.57 ms /    53 runs   (   50.97 ms per token,    19.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    4708.49 ms /   161 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 119 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2022.43 ms /   119 tokens (   17.00 ms per token,    58.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2355.67 ms /    47 runs   (   50.12 ms per token,    19.95 tokens per second)\n",
      "llama_perf_context_print:       total time =    4385.21 ms /   166 tokens\n",
      "Llama.generate: 120 prefix-match hit, remaining 25 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     766.37 ms /    25 tokens (   30.65 ms per token,    32.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3244.39 ms /    65 runs   (   49.91 ms per token,    20.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    4020.47 ms /    90 tokens\n",
      "Llama.generate: 119 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1720.33 ms /    50 tokens (   34.41 ms per token,    29.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3247.67 ms /    65 runs   (   49.96 ms per token,    20.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    4978.05 ms /   115 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 144 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2288.12 ms /   144 tokens (   15.89 ms per token,    62.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3462.19 ms /    69 runs   (   50.18 ms per token,    19.93 tokens per second)\n",
      "llama_perf_context_print:       total time =    5761.42 ms /   213 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 339 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    3643.91 ms /   339 tokens (   10.75 ms per token,    93.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    7488.10 ms /   148 runs   (   50.60 ms per token,    19.76 tokens per second)\n",
      "llama_perf_context_print:       total time =   11159.17 ms /   487 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 159 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2268.64 ms /   159 tokens (   14.27 ms per token,    70.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1288.95 ms /    26 runs   (   49.58 ms per token,    20.17 tokens per second)\n",
      "llama_perf_context_print:       total time =    3561.81 ms /   185 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 173 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2495.58 ms /   173 tokens (   14.43 ms per token,    69.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3517.25 ms /    71 runs   (   49.54 ms per token,    20.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    6024.64 ms /   244 tokens\n",
      "Llama.generate: 116 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     901.81 ms /    29 tokens (   31.10 ms per token,    32.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1159.95 ms /    23 runs   (   50.43 ms per token,    19.83 tokens per second)\n",
      "llama_perf_context_print:       total time =    2065.20 ms /    52 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 113 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2054.49 ms /   113 tokens (   18.18 ms per token,    55.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2416.87 ms /    49 runs   (   49.32 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    4478.89 ms /   162 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 129 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2268.09 ms /   129 tokens (   17.58 ms per token,    56.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2516.57 ms /    51 runs   (   49.34 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    4792.58 ms /   180 tokens\n",
      "Llama.generate: 122 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1633.97 ms /    39 tokens (   41.90 ms per token,    23.87 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1467.96 ms /    30 runs   (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    3106.94 ms /    69 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 125 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2108.38 ms /   125 tokens (   16.87 ms per token,    59.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2099.49 ms /    43 runs   (   48.83 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    4214.64 ms /   168 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 157 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2283.16 ms /   157 tokens (   14.54 ms per token,    68.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2949.12 ms /    60 runs   (   49.15 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    5241.61 ms /   217 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 139 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2211.66 ms /   139 tokens (   15.91 ms per token,    62.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3291.03 ms /    67 runs   (   49.12 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    5513.43 ms /   206 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 169 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2525.89 ms /   169 tokens (   14.95 ms per token,    66.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3887.83 ms /    79 runs   (   49.21 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    6426.62 ms /   248 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 164 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2514.53 ms /   164 tokens (   15.33 ms per token,    65.22 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3819.83 ms /    77 runs   (   49.61 ms per token,    20.16 tokens per second)\n",
      "llama_perf_context_print:       total time =    6346.76 ms /   241 tokens\n",
      "Llama.generate: 54 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     529.88 ms /    18 tokens (   29.44 ms per token,    33.97 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1565.05 ms /    32 runs   (   48.91 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    2099.61 ms /    50 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1733.35 ms /    59 tokens (   29.38 ms per token,    34.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1661.60 ms /    34 runs   (   48.87 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    3400.25 ms /    93 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1664.57 ms /    58 tokens (   28.70 ms per token,    34.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2106.74 ms /    43 runs   (   48.99 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    3777.95 ms /   101 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1718.17 ms /    62 tokens (   27.71 ms per token,    36.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2190.21 ms /    45 runs   (   48.67 ms per token,    20.55 tokens per second)\n",
      "llama_perf_context_print:       total time =    3915.00 ms /   107 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 81 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1815.57 ms /    81 tokens (   22.41 ms per token,    44.61 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1813.87 ms /    37 runs   (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    3635.04 ms /   118 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1834.91 ms /    67 tokens (   27.39 ms per token,    36.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2413.57 ms /    49 runs   (   49.26 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    4256.13 ms /   116 tokens\n",
      "Llama.generate: 68 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     829.70 ms /    28 tokens (   29.63 ms per token,    33.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3482.24 ms /    71 runs   (   49.05 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    4322.49 ms /    99 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1912.62 ms /    68 tokens (   28.13 ms per token,    35.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2056.14 ms /    42 runs   (   48.96 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    3974.85 ms /   110 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 94 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1885.74 ms /    94 tokens (   20.06 ms per token,    49.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2845.11 ms /    58 runs   (   49.05 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    4739.65 ms /   152 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1807.39 ms /    74 tokens (   24.42 ms per token,    40.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1967.91 ms /    40 runs   (   49.20 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    3781.56 ms /   114 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 79 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1813.97 ms /    79 tokens (   22.96 ms per token,    43.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1655.39 ms /    34 runs   (   48.69 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    3474.43 ms /   113 tokens\n",
      "Llama.generate: 42 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1692.97 ms /    49 tokens (   34.55 ms per token,    28.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1701.59 ms /    35 runs   (   48.62 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    3399.88 ms /    84 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1785.51 ms /    65 tokens (   27.47 ms per token,    36.40 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1374.79 ms /    28 runs   (   49.10 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    3164.48 ms /    93 tokens\n",
      "Llama.generate: 48 prefix-match hit, remaining 18 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     557.70 ms /    18 tokens (   30.98 ms per token,    32.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1118.41 ms /    23 runs   (   48.63 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    1679.62 ms /    41 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1640.25 ms /    58 tokens (   28.28 ms per token,    35.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1853.04 ms /    38 runs   (   48.76 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    3498.84 ms /    96 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1627.09 ms /    46 tokens (   35.37 ms per token,    28.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1264.59 ms /    26 runs   (   48.64 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    2895.74 ms /    72 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1685.52 ms /    37 tokens (   45.55 ms per token,    21.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1469.85 ms /    30 runs   (   48.99 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    3160.00 ms /    67 tokens\n",
      "Llama.generate: 46 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1608.73 ms /    34 tokens (   47.32 ms per token,    21.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1801.29 ms /    37 runs   (   48.68 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    3415.55 ms /    71 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1803.70 ms /    65 tokens (   27.75 ms per token,    36.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2447.01 ms /    50 runs   (   48.94 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    4258.30 ms /   115 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1687.67 ms /    48 tokens (   35.16 ms per token,    28.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2003.48 ms /    41 runs   (   48.87 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    3697.70 ms /    89 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1625.53 ms /    42 tokens (   38.70 ms per token,    25.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1468.52 ms /    30 runs   (   48.95 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    3098.53 ms /    72 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1618.79 ms /    44 tokens (   36.79 ms per token,    27.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1512.88 ms /    31 runs   (   48.80 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    3136.24 ms /    75 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1740.28 ms /    62 tokens (   28.07 ms per token,    35.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.99 ms /    54 runs   (   49.26 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    4408.65 ms /   116 tokens\n",
      "Llama.generate: 71 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     396.55 ms /    11 tokens (   36.05 ms per token,    27.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2763.41 ms /    56 runs   (   49.35 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    3168.33 ms /    67 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1736.15 ms /    61 tokens (   28.46 ms per token,    35.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2228.18 ms /    45 runs   (   49.52 ms per token,    20.20 tokens per second)\n",
      "llama_perf_context_print:       total time =    3971.05 ms /   106 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 98 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2021.95 ms /    98 tokens (   20.63 ms per token,    48.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4667.72 ms /    94 runs   (   49.66 ms per token,    20.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    6705.35 ms /   192 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 82 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1811.16 ms /    82 tokens (   22.09 ms per token,    45.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2024.71 ms /    41 runs   (   49.38 ms per token,    20.25 tokens per second)\n",
      "llama_perf_context_print:       total time =    3842.08 ms /   123 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 79 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1890.62 ms /    79 tokens (   23.93 ms per token,    41.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2809.00 ms /    57 runs   (   49.28 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    4708.66 ms /   136 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 73 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1911.24 ms /    73 tokens (   26.18 ms per token,    38.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2058.04 ms /    42 runs   (   49.00 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    3975.74 ms /   115 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1660.16 ms /    64 tokens (   25.94 ms per token,    38.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1865.79 ms /    38 runs   (   49.10 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    3531.61 ms /   102 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 61 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1652.11 ms /    61 tokens (   27.08 ms per token,    36.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2404.79 ms /    49 runs   (   49.08 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    4064.55 ms /   110 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1737.98 ms /    51 tokens (   34.08 ms per token,    29.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2132.81 ms /    43 runs   (   49.60 ms per token,    20.16 tokens per second)\n",
      "llama_perf_context_print:       total time =    3877.14 ms /    94 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1689.15 ms /    47 tokens (   35.94 ms per token,    27.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1911.85 ms /    39 runs   (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    3607.01 ms /    86 tokens\n",
      "Llama.generate: 53 prefix-match hit, remaining 125 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2144.22 ms /   125 tokens (   17.15 ms per token,    58.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2775.64 ms /    56 runs   (   49.57 ms per token,    20.18 tokens per second)\n",
      "llama_perf_context_print:       total time =    4928.76 ms /   181 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 108 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2049.75 ms /   108 tokens (   18.98 ms per token,    52.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2820.74 ms /    57 runs   (   49.49 ms per token,    20.21 tokens per second)\n",
      "llama_perf_context_print:       total time =    4879.72 ms /   165 tokens\n",
      "Llama.generate: 56 prefix-match hit, remaining 63 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1670.41 ms /    63 tokens (   26.51 ms per token,    37.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2659.35 ms /    54 runs   (   49.25 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    4338.30 ms /   117 tokens\n",
      "Llama.generate: 56 prefix-match hit, remaining 116 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2072.02 ms /   116 tokens (   17.86 ms per token,    55.98 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3681.03 ms /    74 runs   (   49.74 ms per token,    20.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    5764.70 ms /   190 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1650.26 ms /    58 tokens (   28.45 ms per token,    35.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1530.26 ms /    31 runs   (   49.36 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    3185.15 ms /    89 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1748.31 ms /    51 tokens (   34.28 ms per token,    29.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2163.07 ms /    44 runs   (   49.16 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    3918.12 ms /    95 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1637.45 ms /    56 tokens (   29.24 ms per token,    34.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2154.72 ms /    44 runs   (   48.97 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    3798.84 ms /   100 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1725.32 ms /    43 tokens (   40.12 ms per token,    24.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2061.56 ms /    42 runs   (   49.08 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    3793.38 ms /    85 tokens\n",
      "Llama.generate: 54 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1513.90 ms /    32 tokens (   47.31 ms per token,    21.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3021.49 ms /    61 runs   (   49.53 ms per token,    20.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    4544.84 ms /    93 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 87 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1854.37 ms /    87 tokens (   21.31 ms per token,    46.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3170.95 ms /    64 runs   (   49.55 ms per token,    20.18 tokens per second)\n",
      "llama_perf_context_print:       total time =    5034.99 ms /   151 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 79 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1876.17 ms /    79 tokens (   23.75 ms per token,    42.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1939.26 ms /    39 runs   (   49.72 ms per token,    20.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    3821.67 ms /   118 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 127 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2098.64 ms /   127 tokens (   16.52 ms per token,    60.52 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4555.35 ms /    92 runs   (   49.51 ms per token,    20.20 tokens per second)\n",
      "llama_perf_context_print:       total time =    6669.01 ms /   219 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 130 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2269.52 ms /   130 tokens (   17.46 ms per token,    57.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2769.12 ms /    56 runs   (   49.45 ms per token,    20.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    5047.60 ms /   186 tokens\n",
      "Llama.generate: 127 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     884.23 ms /    27 tokens (   32.75 ms per token,    30.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3219.87 ms /    65 runs   (   49.54 ms per token,    20.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    4113.79 ms /    92 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 115 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2064.18 ms /   115 tokens (   17.95 ms per token,    55.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3071.29 ms /    62 runs   (   49.54 ms per token,    20.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    5145.31 ms /   177 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 110 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2071.28 ms /   110 tokens (   18.83 ms per token,    53.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2218.00 ms /    45 runs   (   49.29 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    4296.20 ms /   155 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 93 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1842.68 ms /    93 tokens (   19.81 ms per token,    50.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2610.38 ms /    53 runs   (   49.25 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    4461.19 ms /   146 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 94 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1852.62 ms /    94 tokens (   19.71 ms per token,    50.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2700.60 ms /    55 runs   (   49.10 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    4561.93 ms /   149 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 101 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2076.33 ms /   101 tokens (   20.56 ms per token,    48.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2561.84 ms /    52 runs   (   49.27 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    4646.52 ms /   153 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 93 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1852.64 ms /    93 tokens (   19.92 ms per token,    50.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2905.74 ms /    59 runs   (   49.25 ms per token,    20.30 tokens per second)\n",
      "llama_perf_context_print:       total time =    4767.59 ms /   152 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 110 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2294.18 ms /   110 tokens (   20.86 ms per token,    47.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2242.50 ms /    46 runs   (   48.75 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    4543.76 ms /   156 tokens\n",
      "Llama.generate: 111 prefix-match hit, remaining 6 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     218.86 ms /     6 tokens (   36.48 ms per token,    27.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2275.71 ms /    46 runs   (   49.47 ms per token,    20.21 tokens per second)\n",
      "llama_perf_context_print:       total time =    2501.31 ms /    52 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1808.04 ms /    74 tokens (   24.43 ms per token,    40.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2113.18 ms /    43 runs   (   49.14 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    3927.65 ms /   117 tokens\n",
      "Llama.generate: 79 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1637.81 ms /    50 tokens (   32.76 ms per token,    30.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3055.08 ms /    62 runs   (   49.28 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    4702.77 ms /   112 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 86 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1835.66 ms /    86 tokens (   21.34 ms per token,    46.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2730.25 ms /    56 runs   (   48.75 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    4574.70 ms /   142 tokens\n",
      "Llama.generate: 85 prefix-match hit, remaining 91 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1998.61 ms /    91 tokens (   21.96 ms per token,    45.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5035.27 ms /   102 runs   (   49.37 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    7050.62 ms /   193 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1861.66 ms /    74 tokens (   25.16 ms per token,    39.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1697.24 ms /    35 runs   (   48.49 ms per token,    20.62 tokens per second)\n",
      "llama_perf_context_print:       total time =    3564.02 ms /   109 tokens\n",
      "Llama.generate: 87 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     620.51 ms /    14 tokens (   44.32 ms per token,    22.56 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1905.70 ms /    39 runs   (   48.86 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    2531.80 ms /    53 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 153 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2314.38 ms /   153 tokens (   15.13 ms per token,    66.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4273.92 ms /    87 runs   (   49.13 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    6602.57 ms /   240 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 172 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2563.93 ms /   172 tokens (   14.91 ms per token,    67.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4786.56 ms /    97 runs   (   49.35 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    7366.61 ms /   269 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 151 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2269.65 ms /   151 tokens (   15.03 ms per token,    66.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3444.94 ms /    70 runs   (   49.21 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    5725.47 ms /   221 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 236 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2884.29 ms /   236 tokens (   12.22 ms per token,    81.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9734.71 ms /   196 runs   (   49.67 ms per token,    20.13 tokens per second)\n",
      "llama_perf_context_print:       total time =   12656.77 ms /   432 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 31 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 43 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1834.74 ms /    68 tokens (   26.98 ms per token,    37.06 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3208.74 ms /    66 runs   (   48.62 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    5054.84 ms /   134 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 103 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2073.88 ms /   103 tokens (   20.13 ms per token,    49.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2984.48 ms /    61 runs   (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    5067.70 ms /   164 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 112 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2005.00 ms /   112 tokens (   17.90 ms per token,    55.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3325.09 ms /    68 runs   (   48.90 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    5340.75 ms /   180 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 97 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1982.97 ms /    97 tokens (   20.44 ms per token,    48.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2137.39 ms /    44 runs   (   48.58 ms per token,    20.59 tokens per second)\n",
      "llama_perf_context_print:       total time =    4127.25 ms /   141 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 195 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2684.50 ms /   195 tokens (   13.77 ms per token,    72.64 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6642.95 ms /   135 runs   (   49.21 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    9350.67 ms /   330 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 158 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2315.08 ms /   158 tokens (   14.65 ms per token,    68.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2702.04 ms /    55 runs   (   49.13 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    5025.80 ms /   213 tokens\n",
      "Llama.generate: 46 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1919.43 ms /    74 tokens (   25.94 ms per token,    38.55 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3588.49 ms /    73 runs   (   49.16 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    5518.87 ms /   147 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 180 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2516.54 ms /   180 tokens (   13.98 ms per token,    71.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    7634.32 ms /   152 runs   (   50.23 ms per token,    19.91 tokens per second)\n",
      "llama_perf_context_print:       total time =   10178.84 ms /   332 tokens\n",
      "Llama.generate: 117 prefix-match hit, remaining 109 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2106.22 ms /   109 tokens (   19.32 ms per token,    51.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6451.90 ms /   127 runs   (   50.80 ms per token,    19.68 tokens per second)\n",
      "llama_perf_context_print:       total time =    8580.47 ms /   236 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1664.74 ms /    48 tokens (   34.68 ms per token,    28.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1479.85 ms /    29 runs   (   51.03 ms per token,    19.60 tokens per second)\n",
      "llama_perf_context_print:       total time =    3149.00 ms /    77 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 102 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1993.78 ms /   102 tokens (   19.55 ms per token,    51.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4256.37 ms /    84 runs   (   50.67 ms per token,    19.74 tokens per second)\n",
      "llama_perf_context_print:       total time =    6264.07 ms /   186 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1839.17 ms /    74 tokens (   24.85 ms per token,    40.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1664.97 ms /    33 runs   (   50.45 ms per token,    19.82 tokens per second)\n",
      "llama_perf_context_print:       total time =    3509.54 ms /   107 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1646.52 ms /    39 tokens (   42.22 ms per token,    23.69 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1698.97 ms /    34 runs   (   49.97 ms per token,    20.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    3350.92 ms /    73 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1732.52 ms /    39 tokens (   44.42 ms per token,    22.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1484.69 ms /    30 runs   (   49.49 ms per token,    20.21 tokens per second)\n",
      "llama_perf_context_print:       total time =    3221.50 ms /    69 tokens\n",
      "Llama.generate: 49 prefix-match hit, remaining 11 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     366.76 ms /    11 tokens (   33.34 ms per token,    29.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1441.87 ms /    29 runs   (   49.72 ms per token,    20.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    1812.95 ms /    40 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 39 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1715.17 ms /    39 tokens (   43.98 ms per token,    22.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1493.42 ms /    30 runs   (   49.78 ms per token,    20.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    3213.62 ms /    69 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 71 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1812.61 ms /    71 tokens (   25.53 ms per token,    39.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1492.58 ms /    30 runs   (   49.75 ms per token,    20.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    3309.95 ms /   101 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 71 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1877.53 ms /    71 tokens (   26.44 ms per token,    37.82 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1501.04 ms /    30 runs   (   50.03 ms per token,    19.99 tokens per second)\n",
      "llama_perf_context_print:       total time =    3383.47 ms /   101 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 77 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1874.33 ms /    77 tokens (   24.34 ms per token,    41.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1784.63 ms /    36 runs   (   49.57 ms per token,    20.17 tokens per second)\n",
      "llama_perf_context_print:       total time =    3664.73 ms /   113 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1801.14 ms /    70 tokens (   25.73 ms per token,    38.86 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1714.31 ms /    34 runs   (   50.42 ms per token,    19.83 tokens per second)\n",
      "llama_perf_context_print:       total time =    3520.58 ms /   104 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 71 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1820.02 ms /    71 tokens (   25.63 ms per token,    39.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3649.75 ms /    73 runs   (   50.00 ms per token,    20.00 tokens per second)\n",
      "llama_perf_context_print:       total time =    5481.88 ms /   144 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1777.42 ms /    66 tokens (   26.93 ms per token,    37.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1839.62 ms /    37 runs   (   49.72 ms per token,    20.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    3623.20 ms /   103 tokens\n",
      "Llama.generate: 84 prefix-match hit, remaining 7 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     312.42 ms /     7 tokens (   44.63 ms per token,    22.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1846.98 ms /    37 runs   (   49.92 ms per token,    20.03 tokens per second)\n",
      "llama_perf_context_print:       total time =    2164.80 ms /    44 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1801.65 ms /    68 tokens (   26.49 ms per token,    37.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1455.44 ms /    29 runs   (   50.19 ms per token,    19.93 tokens per second)\n",
      "llama_perf_context_print:       total time =    3261.93 ms /    97 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1827.51 ms /    67 tokens (   27.28 ms per token,    36.66 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1900.57 ms /    38 runs   (   50.02 ms per token,    19.99 tokens per second)\n",
      "llama_perf_context_print:       total time =    3734.01 ms /   105 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1841.44 ms /    66 tokens (   27.90 ms per token,    35.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1450.15 ms /    29 runs   (   50.01 ms per token,    20.00 tokens per second)\n",
      "llama_perf_context_print:       total time =    3296.22 ms /    95 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 78 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1823.63 ms /    78 tokens (   23.38 ms per token,    42.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1985.94 ms /    40 runs   (   49.65 ms per token,    20.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    3815.72 ms /   118 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 78 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1842.80 ms /    78 tokens (   23.63 ms per token,    42.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2228.17 ms /    45 runs   (   49.51 ms per token,    20.20 tokens per second)\n",
      "llama_perf_context_print:       total time =    4077.82 ms /   123 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 81 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1841.39 ms /    81 tokens (   22.73 ms per token,    43.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1449.62 ms /    29 runs   (   49.99 ms per token,    20.01 tokens per second)\n",
      "llama_perf_context_print:       total time =    3295.44 ms /   110 tokens\n",
      "Llama.generate: 78 prefix-match hit, remaining 84 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1903.27 ms /    84 tokens (   22.66 ms per token,    44.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6469.12 ms /   129 runs   (   50.15 ms per token,    19.94 tokens per second)\n",
      "llama_perf_context_print:       total time =    8394.85 ms /   213 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 144 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2259.10 ms /   144 tokens (   15.69 ms per token,    63.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4556.48 ms /    91 runs   (   50.07 ms per token,    19.97 tokens per second)\n",
      "llama_perf_context_print:       total time =    6831.00 ms /   235 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1597.54 ms /    35 tokens (   45.64 ms per token,    21.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1294.90 ms /    26 runs   (   49.80 ms per token,    20.08 tokens per second)\n",
      "llama_perf_context_print:       total time =    2896.36 ms /    61 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1655.96 ms /    36 tokens (   46.00 ms per token,    21.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1322.75 ms /    27 runs   (   48.99 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    2982.63 ms /    63 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1697.05 ms /    53 tokens (   32.02 ms per token,    31.23 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2124.14 ms /    43 runs   (   49.40 ms per token,    20.24 tokens per second)\n",
      "llama_perf_context_print:       total time =    3828.02 ms /    96 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1689.12 ms /    33 tokens (   51.19 ms per token,    19.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1173.46 ms /    24 runs   (   48.89 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    2866.39 ms /    57 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1615.20 ms /    38 tokens (   42.51 ms per token,    23.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1429.50 ms /    29 runs   (   49.29 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    3049.12 ms /    67 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1666.81 ms /    33 tokens (   50.51 ms per token,    19.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1169.72 ms /    24 runs   (   48.74 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    2840.13 ms /    57 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1682.41 ms /    41 tokens (   41.03 ms per token,    24.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1124.80 ms /    23 runs   (   48.90 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    2810.76 ms /    64 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1697.29 ms /    42 tokens (   40.41 ms per token,    24.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1224.87 ms /    25 runs   (   48.99 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    2925.81 ms /    67 tokens\n",
      "Llama.generate: 47 prefix-match hit, remaining 15 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     659.29 ms /    15 tokens (   43.95 ms per token,    22.75 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1490.86 ms /    30 runs   (   49.70 ms per token,    20.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    2154.75 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1656.59 ms /    49 tokens (   33.81 ms per token,    29.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1863.98 ms /    38 runs   (   49.05 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    3526.12 ms /    87 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 59 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1678.47 ms /    59 tokens (   28.45 ms per token,    35.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1574.31 ms /    32 runs   (   49.20 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    3257.77 ms /    91 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1635.01 ms /    41 tokens (   39.88 ms per token,    25.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1193.49 ms /    24 runs   (   49.73 ms per token,    20.11 tokens per second)\n",
      "llama_perf_context_print:       total time =    2832.30 ms /    65 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1668.28 ms /    52 tokens (   32.08 ms per token,    31.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2355.94 ms /    48 runs   (   49.08 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    4031.62 ms /   100 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 43 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1766.57 ms /    43 tokens (   41.08 ms per token,    24.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2023.88 ms /    41 runs   (   49.36 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    3796.51 ms /    84 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1623.10 ms /    37 tokens (   43.87 ms per token,    22.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1546.61 ms /    31 runs   (   49.89 ms per token,    20.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    3174.65 ms /    68 tokens\n",
      "Llama.generate: 52 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     297.36 ms /     9 tokens (   33.04 ms per token,    30.27 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1030.20 ms /    21 runs   (   49.06 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    1330.52 ms /    30 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1666.39 ms /    40 tokens (   41.66 ms per token,    24.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1531.33 ms /    31 runs   (   49.40 ms per token,    20.24 tokens per second)\n",
      "llama_perf_context_print:       total time =    3202.62 ms /    71 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1658.04 ms /    35 tokens (   47.37 ms per token,    21.11 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1125.35 ms /    23 runs   (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    2787.02 ms /    58 tokens\n",
      "Llama.generate: 49 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     733.06 ms /    24 tokens (   30.54 ms per token,    32.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1791.32 ms /    36 runs   (   49.76 ms per token,    20.10 tokens per second)\n",
      "llama_perf_context_print:       total time =    2529.75 ms /    60 tokens\n",
      "Llama.generate: 49 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     934.78 ms /    31 tokens (   30.15 ms per token,    33.16 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2333.34 ms /    47 runs   (   49.65 ms per token,    20.14 tokens per second)\n",
      "llama_perf_context_print:       total time =    3275.01 ms /    78 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 58 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1653.33 ms /    58 tokens (   28.51 ms per token,    35.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2028.56 ms /    41 runs   (   49.48 ms per token,    20.21 tokens per second)\n",
      "llama_perf_context_print:       total time =    3688.13 ms /    99 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 154 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2259.70 ms /   154 tokens (   14.67 ms per token,    68.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3590.71 ms /    72 runs   (   49.87 ms per token,    20.05 tokens per second)\n",
      "llama_perf_context_print:       total time =    5862.19 ms /   226 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1692.76 ms /    52 tokens (   32.55 ms per token,    30.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2474.92 ms /    50 runs   (   49.50 ms per token,    20.20 tokens per second)\n",
      "llama_perf_context_print:       total time =    4175.64 ms /   102 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1628.78 ms /    52 tokens (   31.32 ms per token,    31.93 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1478.54 ms /    30 runs   (   49.28 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    3112.02 ms /    82 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1664.84 ms /    48 tokens (   34.68 ms per token,    28.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1514.01 ms /    31 runs   (   48.84 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    3183.73 ms /    79 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1621.44 ms /    52 tokens (   31.18 ms per token,    32.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1269.35 ms /    26 runs   (   48.82 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    2894.85 ms /    78 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1635.13 ms /    64 tokens (   25.55 ms per token,    39.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1809.94 ms /    37 runs   (   48.92 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    3450.30 ms /   101 tokens\n",
      "Llama.generate: 65 prefix-match hit, remaining 17 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     558.35 ms /    17 tokens (   32.84 ms per token,    30.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1485.08 ms /    30 runs   (   49.50 ms per token,    20.20 tokens per second)\n",
      "llama_perf_context_print:       total time =    2047.75 ms /    47 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 175 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2454.55 ms /   175 tokens (   14.03 ms per token,    71.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4712.48 ms /    95 runs   (   49.61 ms per token,    20.16 tokens per second)\n",
      "llama_perf_context_print:       total time =    7182.73 ms /   270 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1661.61 ms /    36 tokens (   46.16 ms per token,    21.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1663.00 ms /    34 runs   (   48.91 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    3330.00 ms /    70 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 45 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1724.63 ms /    45 tokens (   38.33 ms per token,    26.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1471.09 ms /    30 runs   (   49.04 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    3200.30 ms /    75 tokens\n",
      "Llama.generate: 56 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     288.05 ms /     9 tokens (   32.01 ms per token,    31.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1479.43 ms /    30 runs   (   49.31 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:       total time =    1771.99 ms /    39 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1608.38 ms /    38 tokens (   42.33 ms per token,    23.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1315.77 ms /    27 runs   (   48.73 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    2928.33 ms /    65 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1628.18 ms /    41 tokens (   39.71 ms per token,    25.18 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1475.05 ms /    30 runs   (   49.17 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    3107.81 ms /    71 tokens\n",
      "Llama.generate: 54 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     466.06 ms /    14 tokens (   33.29 ms per token,    30.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1611.63 ms /    33 runs   (   48.84 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    2082.48 ms /    47 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1632.33 ms /    49 tokens (   33.31 ms per token,    30.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2101.74 ms /    43 runs   (   48.88 ms per token,    20.46 tokens per second)\n",
      "llama_perf_context_print:       total time =    3740.53 ms /    92 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 52 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1685.56 ms /    52 tokens (   32.41 ms per token,    30.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2585.03 ms /    53 runs   (   48.77 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    4278.92 ms /   105 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1645.75 ms /    51 tokens (   32.27 ms per token,    30.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1462.18 ms /    30 runs   (   48.74 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    3112.48 ms /    81 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1840.02 ms /    69 tokens (   26.67 ms per token,    37.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1855.06 ms /    38 runs   (   48.82 ms per token,    20.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    3700.54 ms /   107 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 77 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1804.56 ms /    77 tokens (   23.44 ms per token,    42.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1675.32 ms /    34 runs   (   49.27 ms per token,    20.29 tokens per second)\n",
      "llama_perf_context_print:       total time =    3485.26 ms /   111 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 66 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1887.73 ms /    66 tokens (   28.60 ms per token,    34.96 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1760.29 ms /    36 runs   (   48.90 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    3653.70 ms /   102 tokens\n",
      "Llama.generate: 77 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     885.74 ms /    31 tokens (   28.57 ms per token,    35.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2173.82 ms /    44 runs   (   49.40 ms per token,    20.24 tokens per second)\n",
      "llama_perf_context_print:       total time =    3065.86 ms /    75 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 76 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1809.58 ms /    76 tokens (   23.81 ms per token,    42.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3487.20 ms /    71 runs   (   49.12 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    5307.71 ms /   147 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1890.88 ms /    69 tokens (   27.40 ms per token,    36.49 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1768.11 ms /    36 runs   (   49.11 ms per token,    20.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    3664.54 ms /   105 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1834.68 ms /    65 tokens (   28.23 ms per token,    35.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2247.62 ms /    46 runs   (   48.86 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    4089.22 ms /   111 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1680.33 ms /    57 tokens (   29.48 ms per token,    33.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2593.93 ms /    53 runs   (   48.94 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    4282.37 ms /   110 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 47 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1782.27 ms /    47 tokens (   37.92 ms per token,    26.37 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1571.16 ms /    32 runs   (   49.10 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    3358.70 ms /    79 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1780.15 ms /    65 tokens (   27.39 ms per token,    36.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1522.05 ms /    31 runs   (   49.10 ms per token,    20.37 tokens per second)\n",
      "llama_perf_context_print:       total time =    3306.80 ms /    96 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 77 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1843.32 ms /    77 tokens (   23.94 ms per token,    41.77 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1956.82 ms /    40 runs   (   48.92 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    3806.36 ms /   117 tokens\n",
      "Llama.generate: 34 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1637.45 ms /    33 tokens (   49.62 ms per token,    20.15 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1779.28 ms /    36 runs   (   49.42 ms per token,    20.23 tokens per second)\n",
      "llama_perf_context_print:       total time =    3422.22 ms /    69 tokens\n",
      "Llama.generate: 30 prefix-match hit, remaining 26 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     843.15 ms /    26 tokens (   32.43 ms per token,    30.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1367.55 ms /    28 runs   (   48.84 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    2214.54 ms /    54 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 77 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1895.58 ms /    77 tokens (   24.62 ms per token,    40.62 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3087.15 ms /    63 runs   (   49.00 ms per token,    20.41 tokens per second)\n",
      "llama_perf_context_print:       total time =    4992.40 ms /   140 tokens\n",
      "Llama.generate: 46 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     915.73 ms /    30 tokens (   30.52 ms per token,    32.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1925.43 ms /    39 runs   (   49.37 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    2846.76 ms /    69 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1636.63 ms /    62 tokens (   26.40 ms per token,    37.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2566.45 ms /    52 runs   (   49.35 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    4210.66 ms /   114 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 65 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1795.97 ms /    65 tokens (   27.63 ms per token,    36.19 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2457.75 ms /    50 runs   (   49.16 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    4260.95 ms /   115 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 72 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1895.12 ms /    72 tokens (   26.32 ms per token,    37.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3384.29 ms /    69 runs   (   49.05 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    5289.99 ms /   141 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1676.85 ms /    34 tokens (   49.32 ms per token,    20.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =     972.87 ms /    20 runs   (   48.64 ms per token,    20.56 tokens per second)\n",
      "llama_perf_context_print:       total time =    2653.14 ms /    54 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 12 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     359.04 ms /    12 tokens (   29.92 ms per token,    33.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1121.91 ms /    23 runs   (   48.78 ms per token,    20.50 tokens per second)\n",
      "llama_perf_context_print:       total time =    1484.25 ms /    35 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 82 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1888.83 ms /    82 tokens (   23.03 ms per token,    43.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2249.09 ms /    46 runs   (   48.89 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    4144.97 ms /   128 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 120 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2028.05 ms /   120 tokens (   16.90 ms per token,    59.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2614.12 ms /    53 runs   (   49.32 ms per token,    20.27 tokens per second)\n",
      "llama_perf_context_print:       total time =    4650.23 ms /   173 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 112 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2027.49 ms /   112 tokens (   18.10 ms per token,    55.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1391.23 ms /    28 runs   (   49.69 ms per token,    20.13 tokens per second)\n",
      "llama_perf_context_print:       total time =    3423.36 ms /   140 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 108 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2029.90 ms /   108 tokens (   18.80 ms per token,    53.20 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2202.77 ms /    45 runs   (   48.95 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    4239.47 ms /   153 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 70 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1881.02 ms /    70 tokens (   26.87 ms per token,    37.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1316.22 ms /    27 runs   (   48.75 ms per token,    20.51 tokens per second)\n",
      "llama_perf_context_print:       total time =    3201.47 ms /    97 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     871.53 ms /    28 tokens (   31.13 ms per token,    32.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1078.54 ms /    22 runs   (   49.02 ms per token,    20.40 tokens per second)\n",
      "llama_perf_context_print:       total time =    1953.35 ms /    50 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 124 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2078.14 ms /   124 tokens (   16.76 ms per token,    59.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2756.05 ms /    56 runs   (   49.22 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    4843.00 ms /   180 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1698.72 ms /    62 tokens (   27.40 ms per token,    36.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2586.07 ms /    53 runs   (   48.79 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    4292.80 ms /   115 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 34 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1641.57 ms /    34 tokens (   48.28 ms per token,    20.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =     978.94 ms /    20 runs   (   48.95 ms per token,    20.43 tokens per second)\n",
      "llama_perf_context_print:       total time =    2623.97 ms /    54 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1790.06 ms /    67 tokens (   26.72 ms per token,    37.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2984.91 ms /    61 runs   (   48.93 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    4784.66 ms /   128 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 76 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1893.90 ms /    76 tokens (   24.92 ms per token,    40.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1624.24 ms /    33 runs   (   49.22 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    3523.55 ms /   109 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 32 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 20 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1690.97 ms /    64 tokens (   26.42 ms per token,    37.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2484.03 ms /    51 runs   (   48.71 ms per token,    20.53 tokens per second)\n",
      "llama_perf_context_print:       total time =    4183.55 ms /   115 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 75 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1822.86 ms /    75 tokens (   24.30 ms per token,    41.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2333.77 ms /    48 runs   (   48.62 ms per token,    20.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    4163.93 ms /   123 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 96 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1882.35 ms /    96 tokens (   19.61 ms per token,    51.00 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5165.86 ms /   106 runs   (   48.73 ms per token,    20.52 tokens per second)\n",
      "llama_perf_context_print:       total time =    7065.18 ms /   202 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1729.03 ms /    51 tokens (   33.90 ms per token,    29.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1752.96 ms /    36 runs   (   48.69 ms per token,    20.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    3487.96 ms /    87 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 64 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1670.09 ms /    64 tokens (   26.10 ms per token,    38.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2098.75 ms /    43 runs   (   48.81 ms per token,    20.49 tokens per second)\n",
      "llama_perf_context_print:       total time =    3775.15 ms /   107 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 74 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1863.98 ms /    74 tokens (   25.19 ms per token,    39.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1674.23 ms /    34 runs   (   49.24 ms per token,    20.31 tokens per second)\n",
      "llama_perf_context_print:       total time =    3543.65 ms /   108 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 62 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1662.27 ms /    62 tokens (   26.81 ms per token,    37.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2894.14 ms /    58 runs   (   49.90 ms per token,    20.04 tokens per second)\n",
      "llama_perf_context_print:       total time =    4565.37 ms /   120 tokens\n",
      "Llama.generate: 46 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     423.72 ms /    14 tokens (   30.27 ms per token,    33.04 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1445.51 ms /    29 runs   (   49.85 ms per token,    20.06 tokens per second)\n",
      "llama_perf_context_print:       total time =    1873.48 ms /    43 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 450 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    4871.43 ms /   450 tokens (   10.83 ms per token,    92.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1873.05 ms /    36 runs   (   52.03 ms per token,    19.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    6750.41 ms /   486 tokens\n",
      "Llama.generate: 55 prefix-match hit, remaining 304 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    3531.60 ms /   304 tokens (   11.62 ms per token,    86.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =    7992.69 ms /   152 runs   (   52.58 ms per token,    19.02 tokens per second)\n",
      "llama_perf_context_print:       total time =   11554.05 ms /   456 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 87 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1874.49 ms /    87 tokens (   21.55 ms per token,    46.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2618.20 ms /    51 runs   (   51.34 ms per token,    19.48 tokens per second)\n",
      "llama_perf_context_print:       total time =    4500.83 ms /   138 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1625.72 ms /    48 tokens (   33.87 ms per token,    29.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1951.64 ms /    38 runs   (   51.36 ms per token,    19.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    3583.54 ms /    86 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 389 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    4470.51 ms /   389 tokens (   11.49 ms per token,    87.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5105.78 ms /    98 runs   (   52.10 ms per token,    19.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    9593.60 ms /   487 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     786.88 ms /    24 tokens (   32.79 ms per token,    30.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1599.11 ms /    31 runs   (   51.58 ms per token,    19.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    2390.69 ms /    55 tokens\n",
      "Llama.generate: 39 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1671.72 ms /    56 tokens (   29.85 ms per token,    33.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1890.87 ms /    37 runs   (   51.10 ms per token,    19.57 tokens per second)\n",
      "llama_perf_context_print:       total time =    3568.49 ms /    93 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 77 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1906.48 ms /    77 tokens (   24.76 ms per token,    40.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2176.29 ms /    43 runs   (   50.61 ms per token,    19.76 tokens per second)\n",
      "llama_perf_context_print:       total time =    4089.42 ms /   120 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 57 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1671.69 ms /    57 tokens (   29.33 ms per token,    34.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2523.99 ms /    50 runs   (   50.48 ms per token,    19.81 tokens per second)\n",
      "llama_perf_context_print:       total time =    4203.66 ms /   107 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1595.48 ms /    33 tokens (   48.35 ms per token,    20.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1437.23 ms /    29 runs   (   49.56 ms per token,    20.18 tokens per second)\n",
      "llama_perf_context_print:       total time =    3036.90 ms /    62 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1692.70 ms /    38 tokens (   44.54 ms per token,    22.45 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1594.65 ms /    32 runs   (   49.83 ms per token,    20.07 tokens per second)\n",
      "llama_perf_context_print:       total time =    3292.37 ms /    70 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1645.79 ms /    40 tokens (   41.14 ms per token,    24.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1289.68 ms /    26 runs   (   49.60 ms per token,    20.16 tokens per second)\n",
      "llama_perf_context_print:       total time =    2939.69 ms /    66 tokens\n",
      "Llama.generate: 44 prefix-match hit, remaining 49 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1701.84 ms /    49 tokens (   34.73 ms per token,    28.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1731.74 ms /    35 runs   (   49.48 ms per token,    20.21 tokens per second)\n",
      "llama_perf_context_print:       total time =    3439.21 ms /    84 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 68 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1823.18 ms /    68 tokens (   26.81 ms per token,    37.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2617.43 ms /    53 runs   (   49.39 ms per token,    20.25 tokens per second)\n",
      "llama_perf_context_print:       total time =    4448.85 ms /   121 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 67 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1860.56 ms /    67 tokens (   27.77 ms per token,    36.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3566.49 ms /    72 runs   (   49.53 ms per token,    20.19 tokens per second)\n",
      "llama_perf_context_print:       total time =    5438.44 ms /   139 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 80 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1856.48 ms /    80 tokens (   23.21 ms per token,    43.09 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3086.27 ms /    62 runs   (   49.78 ms per token,    20.09 tokens per second)\n",
      "llama_perf_context_print:       total time =    4952.65 ms /   142 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1615.41 ms /    36 tokens (   44.87 ms per token,    22.29 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1574.28 ms /    32 runs   (   49.20 ms per token,    20.33 tokens per second)\n",
      "llama_perf_context_print:       total time =    3194.48 ms /    68 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1597.66 ms /    35 tokens (   45.65 ms per token,    21.91 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1811.89 ms /    37 runs   (   48.97 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    3415.31 ms /    72 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1695.75 ms /    56 tokens (   30.28 ms per token,    33.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2584.20 ms /    52 runs   (   49.70 ms per token,    20.12 tokens per second)\n",
      "llama_perf_context_print:       total time =    4288.16 ms /   108 tokens\n",
      "Llama.generate: 44 prefix-match hit, remaining 90 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1913.71 ms /    90 tokens (   21.26 ms per token,    47.03 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5459.85 ms /   110 runs   (   49.64 ms per token,    20.15 tokens per second)\n",
      "llama_perf_context_print:       total time =    7391.72 ms /   200 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 86 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1832.03 ms /    86 tokens (   21.30 ms per token,    46.94 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1829.48 ms /    37 runs   (   49.45 ms per token,    20.22 tokens per second)\n",
      "llama_perf_context_print:       total time =    3667.07 ms /   123 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1658.44 ms /    33 tokens (   50.26 ms per token,    19.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1465.74 ms /    30 runs   (   48.86 ms per token,    20.47 tokens per second)\n",
      "llama_perf_context_print:       total time =    3128.72 ms /    63 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     888.32 ms /    29 tokens (   30.63 ms per token,    32.65 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1320.31 ms /    27 runs   (   48.90 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    2212.46 ms /    56 tokens\n",
      "Llama.generate: 37 prefix-match hit, remaining 24 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     797.47 ms /    24 tokens (   33.23 ms per token,    30.10 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1913.75 ms /    39 runs   (   49.07 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    2716.97 ms /    63 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 29 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     897.43 ms /    29 tokens (   30.95 ms per token,    32.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1376.10 ms /    28 runs   (   49.15 ms per token,    20.35 tokens per second)\n",
      "llama_perf_context_print:       total time =    2277.45 ms /    57 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 84 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1861.16 ms /    84 tokens (   22.16 ms per token,    45.13 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2116.01 ms /    43 runs   (   49.21 ms per token,    20.32 tokens per second)\n",
      "llama_perf_context_print:       total time =    3984.03 ms /   127 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 126 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2104.34 ms /   126 tokens (   16.70 ms per token,    59.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2720.80 ms /    55 runs   (   49.47 ms per token,    20.21 tokens per second)\n",
      "llama_perf_context_print:       total time =    4833.90 ms /   181 tokens\n",
      "Llama.generate: 144 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =     620.41 ms /    20 tokens (   31.02 ms per token,    32.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3060.82 ms /    62 runs   (   49.37 ms per token,    20.26 tokens per second)\n",
      "llama_perf_context_print:       total time =    3690.43 ms /    82 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 95 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1845.57 ms /    95 tokens (   19.43 ms per token,    51.47 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2598.75 ms /    53 runs   (   49.03 ms per token,    20.39 tokens per second)\n",
      "llama_perf_context_print:       total time =    4452.58 ms /   148 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 160 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2450.22 ms /   160 tokens (   15.31 ms per token,    65.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2821.62 ms /    57 runs   (   49.50 ms per token,    20.20 tokens per second)\n",
      "llama_perf_context_print:       total time =    5281.00 ms /   217 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 93 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1855.47 ms /    93 tokens (   19.95 ms per token,    50.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4464.24 ms /    91 runs   (   49.06 ms per token,    20.38 tokens per second)\n",
      "llama_perf_context_print:       total time =    6334.41 ms /   184 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1736.83 ms /    44 tokens (   39.47 ms per token,    25.33 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8722.24 ms /    29 runs   (  300.77 ms per token,     3.32 tokens per second)\n",
      "llama_perf_context_print:       total time =   10467.15 ms /    73 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 120 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   17331.95 ms /   120 tokens (  144.43 ms per token,     6.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =   33529.31 ms /   130 runs   (  257.92 ms per token,     3.88 tokens per second)\n",
      "llama_perf_context_print:       total time =   50922.81 ms /   250 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 105 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2013.87 ms /   105 tokens (   19.18 ms per token,    52.14 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5966.80 ms /   122 runs   (   48.91 ms per token,    20.45 tokens per second)\n",
      "llama_perf_context_print:       total time =    8001.11 ms /   227 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 127 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2146.28 ms /   127 tokens (   16.90 ms per token,    59.17 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5729.46 ms /   117 runs   (   48.97 ms per token,    20.42 tokens per second)\n",
      "llama_perf_context_print:       total time =    7895.45 ms /   244 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 115 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2009.97 ms /   115 tokens (   17.48 ms per token,    57.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6309.75 ms /   129 runs   (   48.91 ms per token,    20.44 tokens per second)\n",
      "llama_perf_context_print:       total time =    8341.67 ms /   244 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 176 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2561.19 ms /   176 tokens (   14.55 ms per token,    68.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6835.00 ms /   139 runs   (   49.17 ms per token,    20.34 tokens per second)\n",
      "llama_perf_context_print:       total time =    9420.70 ms /   315 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1632.03 ms /    42 tokens (   38.86 ms per token,    25.73 tokens per second)\n",
      "llama_perf_context_print:        eval time =    1307.91 ms /    27 runs   (   48.44 ms per token,    20.64 tokens per second)\n",
      "llama_perf_context_print:       total time =    2943.89 ms /    69 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    1652.61 ms /    46 tokens (   35.93 ms per token,    27.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9978.28 ms /    34 runs   (  293.48 ms per token,     3.41 tokens per second)\n",
      "llama_perf_context_print:       total time =   11641.13 ms /    80 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 27 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   21687.37 ms /    27 tokens (  803.24 ms per token,     1.24 tokens per second)\n",
      "llama_perf_context_print:        eval time =   13101.74 ms /    43 runs   (  304.69 ms per token,     3.28 tokens per second)\n",
      "llama_perf_context_print:       total time =   34809.97 ms /    70 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 33 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   15552.09 ms /    33 tokens (  471.28 ms per token,     2.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10048.95 ms /    34 runs   (  295.56 ms per token,     3.38 tokens per second)\n",
      "llama_perf_context_print:       total time =   25618.17 ms /    67 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   14738.99 ms /    46 tokens (  320.41 ms per token,     3.12 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10261.33 ms /    35 runs   (  293.18 ms per token,     3.41 tokens per second)\n",
      "llama_perf_context_print:       total time =   25017.47 ms /    81 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   18005.65 ms /    31 tokens (  580.83 ms per token,     1.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9808.65 ms /    35 runs   (  280.25 ms per token,     3.57 tokens per second)\n",
      "llama_perf_context_print:       total time =   27830.76 ms /    66 tokens\n",
      "Llama.generate: 44 prefix-match hit, remaining 99 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   16525.34 ms /    99 tokens (  166.92 ms per token,     5.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =   39893.39 ms /   129 runs   (  309.25 ms per token,     3.23 tokens per second)\n",
      "llama_perf_context_print:       total time =   56494.80 ms /   228 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 113 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   16616.04 ms /   113 tokens (  147.04 ms per token,     6.80 tokens per second)\n",
      "llama_perf_context_print:        eval time =   31440.39 ms /   104 runs   (  302.31 ms per token,     3.31 tokens per second)\n",
      "llama_perf_context_print:       total time =   48115.61 ms /   217 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   14705.30 ms /    41 tokens (  358.67 ms per token,     2.79 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9909.82 ms /    32 runs   (  309.68 ms per token,     3.23 tokens per second)\n",
      "llama_perf_context_print:       total time =   24631.26 ms /    73 tokens\n",
      "Llama.generate: 28 prefix-match hit, remaining 23 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   16524.76 ms /    23 tokens (  718.47 ms per token,     1.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5512.49 ms /    22 runs   (  250.57 ms per token,     3.99 tokens per second)\n",
      "llama_perf_context_print:       total time =   22047.77 ms /    45 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   15127.11 ms /    56 tokens (  270.13 ms per token,     3.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =   14204.20 ms /    48 runs   (  295.92 ms per token,     3.38 tokens per second)\n",
      "llama_perf_context_print:       total time =   29354.88 ms /   104 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 60 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   15036.60 ms /    60 tokens (  250.61 ms per token,     3.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =   11280.38 ms /    39 runs   (  289.24 ms per token,     3.46 tokens per second)\n",
      "llama_perf_context_print:       total time =   26335.74 ms /    99 tokens\n",
      "Llama.generate: 32 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   14956.11 ms /    50 tokens (  299.12 ms per token,     3.34 tokens per second)\n",
      "llama_perf_context_print:        eval time =   16371.58 ms /    56 runs   (  292.35 ms per token,     3.42 tokens per second)\n",
      "llama_perf_context_print:       total time =   31356.04 ms /   106 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 44 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   14904.44 ms /    44 tokens (  338.74 ms per token,     2.95 tokens per second)\n",
      "llama_perf_context_print:        eval time =    7647.19 ms /    27 runs   (  283.23 ms per token,     3.53 tokens per second)\n",
      "llama_perf_context_print:       total time =   22564.35 ms /    71 tokens\n",
      "Llama.generate: 35 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   14638.16 ms /    38 tokens (  385.21 ms per token,     2.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =   11278.78 ms /    39 runs   (  289.20 ms per token,     3.46 tokens per second)\n",
      "llama_perf_context_print:       total time =   25936.11 ms /    77 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 37 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   13818.52 ms /    37 tokens (  373.47 ms per token,     2.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9214.15 ms /    32 runs   (  287.94 ms per token,     3.47 tokens per second)\n",
      "llama_perf_context_print:       total time =   23048.27 ms /    69 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 46 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   14348.30 ms /    46 tokens (  311.92 ms per token,     3.21 tokens per second)\n",
      "llama_perf_context_print:        eval time =   12609.66 ms /    43 runs   (  293.25 ms per token,     3.41 tokens per second)\n",
      "llama_perf_context_print:       total time =   26979.44 ms /    89 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 167 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   17266.98 ms /   167 tokens (  103.40 ms per token,     9.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10451.79 ms /    36 runs   (  290.33 ms per token,     3.44 tokens per second)\n",
      "llama_perf_context_print:       total time =   27736.61 ms /   203 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 153 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   17467.69 ms /   153 tokens (  114.17 ms per token,     8.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =   21785.67 ms /    71 runs   (  306.84 ms per token,     3.26 tokens per second)\n",
      "llama_perf_context_print:       total time =   39291.95 ms /   224 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 54 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   14668.02 ms /    54 tokens (  271.63 ms per token,     3.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8049.69 ms /    28 runs   (  287.49 ms per token,     3.48 tokens per second)\n",
      "llama_perf_context_print:       total time =   22731.68 ms /    82 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 104 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   15598.29 ms /   104 tokens (  149.98 ms per token,     6.67 tokens per second)\n",
      "llama_perf_context_print:        eval time =   29206.94 ms /    97 runs   (  301.10 ms per token,     3.32 tokens per second)\n",
      "llama_perf_context_print:       total time =   44858.72 ms /   201 tokens\n",
      "Llama.generate: 61 prefix-match hit, remaining 164 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   18116.68 ms /   164 tokens (  110.47 ms per token,     9.05 tokens per second)\n",
      "llama_perf_context_print:        eval time =   71559.43 ms /   232 runs   (  308.45 ms per token,     3.24 tokens per second)\n",
      "llama_perf_context_print:       total time =   89848.05 ms /   396 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 83 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   15329.54 ms /    83 tokens (  184.69 ms per token,     5.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =   24630.54 ms /    83 runs   (  296.75 ms per token,     3.37 tokens per second)\n",
      "llama_perf_context_print:       total time =   40005.24 ms /   166 tokens\n",
      "Llama.generate: 60 prefix-match hit, remaining 105 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   16387.80 ms /   105 tokens (  156.07 ms per token,     6.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =   44741.76 ms /   146 runs   (  306.45 ms per token,     3.26 tokens per second)\n",
      "llama_perf_context_print:       total time =   61218.92 ms /   251 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 53 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   15105.37 ms /    53 tokens (  285.01 ms per token,     3.51 tokens per second)\n",
      "llama_perf_context_print:        eval time =   13134.63 ms /    45 runs   (  291.88 ms per token,     3.43 tokens per second)\n",
      "llama_perf_context_print:       total time =   28263.22 ms /    98 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 48 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   14214.31 ms /    48 tokens (  296.13 ms per token,     3.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =   11034.20 ms /    38 runs   (  290.37 ms per token,     3.44 tokens per second)\n",
      "llama_perf_context_print:       total time =   25267.02 ms /    86 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   15115.46 ms /    36 tokens (  419.87 ms per token,     2.38 tokens per second)\n",
      "llama_perf_context_print:        eval time =    7936.71 ms /    27 runs   (  293.95 ms per token,     3.40 tokens per second)\n",
      "llama_perf_context_print:       total time =   23065.38 ms /    63 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 82 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   15293.38 ms /    82 tokens (  186.50 ms per token,     5.36 tokens per second)\n",
      "llama_perf_context_print:        eval time =   28636.90 ms /    94 runs   (  304.65 ms per token,     3.28 tokens per second)\n",
      "llama_perf_context_print:       total time =   43982.19 ms /   176 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 95 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   15198.83 ms /    95 tokens (  159.99 ms per token,     6.25 tokens per second)\n",
      "llama_perf_context_print:        eval time =   25879.02 ms /    87 runs   (  297.46 ms per token,     3.36 tokens per second)\n",
      "llama_perf_context_print:       total time =   41126.19 ms /   182 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 86 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   15278.95 ms /    86 tokens (  177.66 ms per token,     5.63 tokens per second)\n",
      "llama_perf_context_print:        eval time =   22550.17 ms /    72 runs   (  313.20 ms per token,     3.19 tokens per second)\n",
      "llama_perf_context_print:       total time =   37868.55 ms /   158 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 90 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   15197.72 ms /    90 tokens (  168.86 ms per token,     5.92 tokens per second)\n",
      "llama_perf_context_print:        eval time =   17950.39 ms /    59 runs   (  304.24 ms per token,     3.29 tokens per second)\n",
      "llama_perf_context_print:       total time =   33179.18 ms /   149 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 123 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   15983.76 ms /   123 tokens (  129.95 ms per token,     7.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =   35493.10 ms /   118 runs   (  300.79 ms per token,     3.32 tokens per second)\n",
      "llama_perf_context_print:       total time =   51546.09 ms /   241 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 115 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   16402.73 ms /   115 tokens (  142.63 ms per token,     7.01 tokens per second)\n",
      "llama_perf_context_print:        eval time =   33555.34 ms /   108 runs   (  310.70 ms per token,     3.22 tokens per second)\n",
      "llama_perf_context_print:       total time =   50019.03 ms /   223 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 20 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   15671.32 ms /    20 tokens (  783.57 ms per token,     1.28 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9244.62 ms /    34 runs   (  271.90 ms per token,     3.68 tokens per second)\n",
      "llama_perf_context_print:       total time =   24931.29 ms /    54 tokens\n",
      "Llama.generate: 40 prefix-match hit, remaining 21 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   15561.00 ms /    21 tokens (  741.00 ms per token,     1.35 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8282.65 ms /    31 runs   (  267.18 ms per token,     3.74 tokens per second)\n",
      "llama_perf_context_print:       total time =   23858.07 ms /    52 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   13931.13 ms /    32 tokens (  435.35 ms per token,     2.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6667.46 ms /    24 runs   (  277.81 ms per token,     3.60 tokens per second)\n",
      "llama_perf_context_print:       total time =   20609.94 ms /    56 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   14059.44 ms /    42 tokens (  334.75 ms per token,     2.99 tokens per second)\n",
      "llama_perf_context_print:        eval time =   14241.69 ms /    45 runs   (  316.48 ms per token,     3.16 tokens per second)\n",
      "llama_perf_context_print:       total time =   28322.60 ms /    87 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 28 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   17689.44 ms /    28 tokens (  631.77 ms per token,     1.58 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6751.66 ms /    26 runs   (  259.68 ms per token,     3.85 tokens per second)\n",
      "llama_perf_context_print:       total time =   24452.95 ms /    54 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 50 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   14652.68 ms /    50 tokens (  293.05 ms per token,     3.41 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8238.29 ms /    29 runs   (  284.08 ms per token,     3.52 tokens per second)\n",
      "llama_perf_context_print:       total time =   22904.84 ms /    79 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   14095.52 ms /    38 tokens (  370.93 ms per token,     2.70 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8537.19 ms /    30 runs   (  284.57 ms per token,     3.51 tokens per second)\n",
      "llama_perf_context_print:       total time =   22646.15 ms /    68 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 40 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   14148.68 ms /    40 tokens (  353.72 ms per token,     2.83 tokens per second)\n",
      "llama_perf_context_print:        eval time =    7937.50 ms /    28 runs   (  283.48 ms per token,     3.53 tokens per second)\n",
      "llama_perf_context_print:       total time =   22099.42 ms /    68 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 51 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   14885.34 ms /    51 tokens (  291.87 ms per token,     3.43 tokens per second)\n",
      "llama_perf_context_print:        eval time =    7709.49 ms /    26 runs   (  296.52 ms per token,     3.37 tokens per second)\n",
      "llama_perf_context_print:       total time =   22607.88 ms /    77 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 82 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   16147.25 ms /    82 tokens (  196.92 ms per token,     5.08 tokens per second)\n",
      "llama_perf_context_print:        eval time =   14216.21 ms /    48 runs   (  296.17 ms per token,     3.38 tokens per second)\n",
      "llama_perf_context_print:       total time =   30388.03 ms /   130 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 153 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   16877.30 ms /   153 tokens (  110.31 ms per token,     9.07 tokens per second)\n",
      "llama_perf_context_print:        eval time =   20506.59 ms /    69 runs   (  297.20 ms per token,     3.36 tokens per second)\n",
      "llama_perf_context_print:       total time =   37420.43 ms /   222 tokens\n",
      "Llama.generate: 119 prefix-match hit, remaining 30 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   17869.91 ms /    30 tokens (  595.66 ms per token,     1.68 tokens per second)\n",
      "llama_perf_context_print:        eval time =   15975.87 ms /    56 runs   (  285.28 ms per token,     3.51 tokens per second)\n",
      "llama_perf_context_print:       total time =   33874.19 ms /    86 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 98 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   15255.34 ms /    98 tokens (  155.67 ms per token,     6.42 tokens per second)\n",
      "llama_perf_context_print:        eval time =   16322.11 ms /    52 runs   (  313.89 ms per token,     3.19 tokens per second)\n",
      "llama_perf_context_print:       total time =   31604.32 ms /   150 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 41 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   14431.37 ms /    41 tokens (  351.98 ms per token,     2.84 tokens per second)\n",
      "llama_perf_context_print:        eval time =   10343.70 ms /    36 runs   (  287.33 ms per token,     3.48 tokens per second)\n",
      "llama_perf_context_print:       total time =   24793.51 ms /    77 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 36 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   14209.97 ms /    36 tokens (  394.72 ms per token,     2.53 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8462.22 ms /    30 runs   (  282.07 ms per token,     3.55 tokens per second)\n",
      "llama_perf_context_print:       total time =   22687.31 ms /    66 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 35 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   14002.05 ms /    35 tokens (  400.06 ms per token,     2.50 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6689.94 ms /    24 runs   (  278.75 ms per token,     3.59 tokens per second)\n",
      "llama_perf_context_print:       total time =   20702.76 ms /    59 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   14964.92 ms /    56 tokens (  267.23 ms per token,     3.74 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8178.80 ms /    29 runs   (  282.03 ms per token,     3.55 tokens per second)\n",
      "llama_perf_context_print:       total time =   23158.17 ms /    85 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 14 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   13685.97 ms /    14 tokens (  977.57 ms per token,     1.02 tokens per second)\n",
      "llama_perf_context_print:        eval time =    8568.35 ms /    28 runs   (  306.01 ms per token,     3.27 tokens per second)\n",
      "llama_perf_context_print:       total time =   22266.98 ms /    42 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 42 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   14580.03 ms /    42 tokens (  347.14 ms per token,     2.88 tokens per second)\n",
      "llama_perf_context_print:        eval time =    9801.93 ms /    34 runs   (  288.29 ms per token,     3.47 tokens per second)\n",
      "llama_perf_context_print:       total time =   24398.53 ms /    76 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 31 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   17603.60 ms /    31 tokens (  567.86 ms per token,     1.76 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6831.39 ms /    26 runs   (  262.75 ms per token,     3.81 tokens per second)\n",
      "llama_perf_context_print:       total time =   24447.13 ms /    57 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 32 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   13820.73 ms /    32 tokens (  431.90 ms per token,     2.32 tokens per second)\n",
      "llama_perf_context_print:        eval time =    7685.02 ms /    24 runs   (  320.21 ms per token,     3.12 tokens per second)\n",
      "llama_perf_context_print:       total time =   21517.55 ms /    56 tokens\n",
      "Llama.generate: 24 prefix-match hit, remaining 83 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   18682.66 ms /    83 tokens (  225.09 ms per token,     4.44 tokens per second)\n",
      "llama_perf_context_print:        eval time =   24574.75 ms /    79 runs   (  311.07 ms per token,     3.21 tokens per second)\n",
      "llama_perf_context_print:       total time =   43298.90 ms /   162 tokens\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved batch 33 to translated_queries.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 25 prefix-match hit, remaining 135 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =    2473.06 ms /   135 tokens (   18.32 ms per token,    54.59 tokens per second)\n",
      "llama_perf_context_print:        eval time =   35849.90 ms /   100 runs   (  358.50 ms per token,     2.79 tokens per second)\n",
      "llama_perf_context_print:       total time =   38377.59 ms /   235 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 131 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   16692.45 ms /   131 tokens (  127.42 ms per token,     7.85 tokens per second)\n",
      "llama_perf_context_print:        eval time =   25809.19 ms /    87 runs   (  296.66 ms per token,     3.37 tokens per second)\n",
      "llama_perf_context_print:       total time =   42550.73 ms /   218 tokens\n",
      "Llama.generate: 36 prefix-match hit, remaining 69 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   14623.85 ms /    69 tokens (  211.94 ms per token,     4.72 tokens per second)\n",
      "llama_perf_context_print:        eval time =   22069.77 ms /    71 runs   (  310.84 ms per token,     3.22 tokens per second)\n",
      "llama_perf_context_print:       total time =   36730.67 ms /   140 tokens\n",
      "Llama.generate: 43 prefix-match hit, remaining 9 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   12619.41 ms /     9 tokens ( 1402.16 ms per token,     0.71 tokens per second)\n",
      "llama_perf_context_print:        eval time =    6553.07 ms /    25 runs   (  262.12 ms per token,     3.82 tokens per second)\n",
      "llama_perf_context_print:       total time =   19184.73 ms /    34 tokens\n",
      "Llama.generate: 20 prefix-match hit, remaining 38 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    2109.69 ms\n",
      "llama_perf_context_print: prompt eval time =   14612.38 ms /    38 tokens (  384.54 ms per token,     2.60 tokens per second)\n",
      "llama_perf_context_print:        eval time =    7028.68 ms /    25 runs   (  281.15 ms per token,     3.56 tokens per second)\n",
      "llama_perf_context_print:       total time =   21653.62 ms /    63 tokens\n",
      "Llama.generate: 25 prefix-match hit, remaining 61 prompt tokens to eval\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from functools import partial\n",
    "import time\n",
    "\n",
    "#Reads and stores the Esgish queries\n",
    "df = pd.read_excel(\"esgish.xlsx\")\n",
    "queries = df[\"Esgish\"].tolist()\n",
    "#Ensures no overload and efficiency\n",
    "batch_size = 100 \n",
    "output_file = \"translated_queries.xlsx\"\n",
    "\n",
    "#Looks at each query in each batch, calls the translate_query function, and stores it\n",
    "for i in range(0, len(queries), batch_size):\n",
    "    batch = queries[i:i + batch_size]\n",
    "    translated_batch = []\n",
    "    \n",
    "    for query in batch:\n",
    "        translated = translate_query(query)\n",
    "        translated_batch.append(translated)\n",
    "    \n",
    "    df_batch = pd.DataFrame({\n",
    "        \"Esgish\": batch,\n",
    "        \"English\": translated_batch\n",
    "    })\n",
    "\n",
    "    #Makes a new file if needed, or adds onto the current file during each batch in case the program crashes at some point\n",
    "    if i == 0:\n",
    "        df_batch.to_excel(output_file, index=False)  \n",
    "    else:\n",
    "        with pd.ExcelWriter(output_file, mode=\"a\", engine=\"openpyxl\", if_sheet_exists=\"overlay\") as writer:\n",
    "            df_batch.to_excel(writer, index=False, header=False, startrow=i + 1)\n",
    "    \n",
    "    print(f\"Saved batch {i // batch_size + 1} to {output_file}\")\n",
    "    #Avoids overwhelming the system/API\n",
    "    time.sleep(10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4814e3a0-0ddd-467e-8074-18a33f13a0c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f42872-6939-4c34-b74f-f177f8eb3d49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
